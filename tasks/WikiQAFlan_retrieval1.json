[
  {
    "instruction": "Write an answer to the following question: How does the ordering of releasing measurement data prevent dishonest users from acquiring the secret in the QSS protocol?",
    "context": "",
    "output": "By carefully choosing the order of releasing measurement data (receiver 1 releases measurement results, receiver 2 releases measurement results, receiver 2 releases measurement basis, and receiver 1 releases measurement basis), the QSS protocol prevents dishonest users from knowing which basis to share for tricking the other participants or controlling the correlation of measurements. This ensures that acting dishonestly will introduce errors in the eavesdropper testing phase, making it impossible for a dishonest participant to acquire the secret without being noticed by the other participants.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the ordering of releasing measurement data prevent dishonest users from acquiring the secret in the QSS protocol?",
      "answer": "By carefully choosing the order of releasing measurement data (receiver 1 releases measurement results, receiver 2 releases measurement results, receiver 2 releases measurement basis, and receiver 1 releases measurement basis), the QSS protocol prevents dishonest users from knowing which basis to share for tricking the other participants or controlling the correlation of measurements. This ensures that acting dishonestly will introduce errors in the eavesdropper testing phase, making it impossible for a dishonest participant to acquire the secret without being noticed by the other participants."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the Windows service called \"Interactive Services Detection\" in Windows Vista and Windows Server 2008?",
    "context": "",
    "output": "The Windows service called \"Interactive Services Detection\" in Windows Vista and Windows Server 2008 enables access to dialogs created by interactive services when they appear, and offers the interactive user the ability to switch to Session 0 to access the dialog box.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Windows service called \"Interactive Services Detection\" in Windows Vista and Windows Server 2008?",
      "answer": "The Windows service called \"Interactive Services Detection\" in Windows Vista and Windows Server 2008 enables access to dialogs created by interactive services when they appear, and offers the interactive user the ability to switch to Session 0 to access the dialog box."
    }
  },
  {
    "instruction": "Asprox botnet\n\n==Introduction==\nThe Asprox botnet (discovered around 2008), also known by its aliases Badsrc and Aseljo, is a botnet mostly involved in phishing scams and performing SQL injections into websites in order to spread malware. It is a highly infectious malware which spreads through an email or through a clone website. It can be used to trace any kind of personal or financial information and activities online.\n\n== Operations ==\nSince its discovery in 2008 the Asprox botnet has been involved in multiple high-profile attacks on various websites in order to spread malware. The botnet itself consists of roughly 15,000 infected computers as of May, 2008,  although the size of the botnet itself is highly variable as the controllers of the botnet have been known to deliberately shrink (and later regrow) their botnet in order to prevent more aggressive countermeasures from the IT Community.The botnet propagates itself in a somewhat unusual way, as it actively searches and infects vulnerable websites running Active Server Pages. Once it finds a potential target the botnet performs a SQL injection on the website, inserting an IFrame which redirects the user visiting the site to a site hosting Malware.The botnet usually attacks in waves - the goal of each wave is to infect as many websites as possible, thus achieving the highest possible spread rate. Once a wave is completed the botnet lay dormant for an extended amount of time, likely to prevent aggressive counterreactions from the security community. The initial wave took place in July, 2008, which infected an estimated 1,000 - 2,000 pages. An additional wave took place in October 2009, infecting an unknown number of websites. Another wave took place in June 2010, increasing the estimated total number of infected domains from 2,000 to an estimated 10,000 - 13,000 within a day.\n\n== Notable high-profile infections ==\nWhile the infection targets of the Asprox botnet are randomly determined through Google searches, some high-profile websites have been infected in the past. Some of these infections have received individual coverage.\n\nSony PlayStation U.S.\nAdobe's Serious Magic website \nSeveral government, healthcare and business related websites\n\nQ: How does the Asprox botnet spread malware?",
    "context": "",
    "output": "A: The Asprox botnet spreads malware by performing SQL injections on vulnerable websites and redirecting users visiting the sites to a site hosting Malware.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Asprox botnet spread malware?",
      "answer": "The Asprox botnet spreads malware by performing SQL injections on vulnerable websites and redirecting users visiting the sites to a site hosting Malware.",
      "context": "Asprox botnet\n\n==Introduction==\nThe Asprox botnet (discovered around 2008), also known by its aliases Badsrc and Aseljo, is a botnet mostly involved in phishing scams and performing SQL injections into websites in order to spread malware. It is a highly infectious malware which spreads through an email or through a clone website. It can be used to trace any kind of personal or financial information and activities online.\n\n== Operations ==\nSince its discovery in 2008 the Asprox botnet has been involved in multiple high-profile attacks on various websites in order to spread malware. The botnet itself consists of roughly 15,000 infected computers as of May, 2008,  although the size of the botnet itself is highly variable as the controllers of the botnet have been known to deliberately shrink (and later regrow) their botnet in order to prevent more aggressive countermeasures from the IT Community.The botnet propagates itself in a somewhat unusual way, as it actively searches and infects vulnerable websites running Active Server Pages. Once it finds a potential target the botnet performs a SQL injection on the website, inserting an IFrame which redirects the user visiting the site to a site hosting Malware.The botnet usually attacks in waves - the goal of each wave is to infect as many websites as possible, thus achieving the highest possible spread rate. Once a wave is completed the botnet lay dormant for an extended amount of time, likely to prevent aggressive counterreactions from the security community. The initial wave took place in July, 2008, which infected an estimated 1,000 - 2,000 pages. An additional wave took place in October 2009, infecting an unknown number of websites. Another wave took place in June 2010, increasing the estimated total number of infected domains from 2,000 to an estimated 10,000 - 13,000 within a day.\n\n== Notable high-profile infections ==\nWhile the infection targets of the Asprox botnet are randomly determined through Google searches, some high-profile websites have been infected in the past. Some of these infections have received individual coverage.\n\nSony PlayStation U.S.\nAdobe's Serious Magic website \nSeveral government, healthcare and business related websites"
    }
  },
  {
    "instruction": "context: The XOR cipher used in the Flash proxy helps to protect user privacy by encrypting Tor traffic, making it difficult for censors to detect and analyze the traffic. This helps to maintain the anonymity of users accessing the Tor network.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the XOR cipher used in the Flash proxy help to protect user privacy?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the XOR cipher used in the Flash proxy help to protect user privacy?",
      "answer": "The XOR cipher used in the Flash proxy helps to protect user privacy by encrypting Tor traffic, making it difficult for censors to detect and analyze the traffic. This helps to maintain the anonymity of users accessing the Tor network."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the rua tag in DMARC?",
    "context": "",
    "output": "The rua tag in DMARC specifies the address where aggregate reports should be sent. These reports provide an overview of messages that pass and/or fail DMARC checks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the rua tag in DMARC?",
      "answer": "The rua tag in DMARC specifies the address where aggregate reports should be sent. These reports provide an overview of messages that pass and/or fail DMARC checks."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of using fake referrer URLs in referrer spam?",
    "context": "",
    "output": "The purpose of using fake referrer URLs in referrer spam is to create inadvertent links to the spammer's site in access logs, which are then indexed by search engines to improve the spammer's search engine ranking.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of using fake referrer URLs in referrer spam?",
      "answer": "The purpose of using fake referrer URLs in referrer spam is to create inadvertent links to the spammer's site in access logs, which are then indexed by search engines to improve the spammer's search engine ranking."
    }
  },
  {
    "instruction": "context: Virtual data rooms can automate the mathematics of pricing and integrate CRM to ensure accurate synchronization of all account data, preventing revenue leakage by providing accurate and controlled access to confidential sales information.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can virtual data rooms help prevent revenue leakage in B2B sales?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can virtual data rooms help prevent revenue leakage in B2B sales?",
      "answer": "Virtual data rooms can automate the mathematics of pricing and integrate CRM to ensure accurate synchronization of all account data, preventing revenue leakage by providing accurate and controlled access to confidential sales information."
    }
  },
  {
    "instruction": "context: With the release of Core Rule Set 3.0 (CRS3), a Lynx user agent does not trigger any rules anymore.\n\nAsk a question about this context.",
    "context": "",
    "output": "What was the change made in Core Rule Set 3.0 (CRS3) regarding the Lynx browser?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the change made in Core Rule Set 3.0 (CRS3) regarding the Lynx browser?",
      "answer": "With the release of Core Rule Set 3.0 (CRS3), a Lynx user agent does not trigger any rules anymore."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the general consensus on what the terminology of CIAM includes?",
    "context": "",
    "output": "It is generally accepted that CIAM represents an external and user-centric alternative to legacy IAM.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the general consensus on what the terminology of CIAM includes?",
      "answer": "It is generally accepted that CIAM represents an external and user-centric alternative to legacy IAM."
    }
  },
  {
    "instruction": "Context: Transparent data encryption\n\n==Introduction==\nTransparent Data Encryption (often abbreviated to TDE) is a technology employed by Microsoft, IBM and Oracle to encrypt database files. TDE offers encryption at file level. TDE solves the problem of protecting data at rest, encrypting databases both on the hard drive and consequently on backup media. It does not protect data in transit nor data in use. Enterprises typically employ TDE to solve compliance issues such as PCI DSS which require the protection of data at rest.\nMicrosoft offers TDE as part of its Microsoft SQL Server 2008, 2008 R2, 2012, 2014, 2016, 2017 and 2019. TDE was only supported on the Evaluation, Developer, Enterprise and Datacenter editions of Microsoft SQL Server, until it was also made available in the Standard edition for 2019.  SQL TDE is supported by hardware security modules from Thales e-Security, Townsend Security and SafeNet, Inc.\nIBM offers TDE as part of Db2 as of version 10.5 fixpack 5. It is also supported in cloud versions of the product by default, Db2 on Cloud and Db2 Warehouse on Cloud.\nOracle requires the Oracle Advanced Security option for Oracle 10g and 11g to enable TDE. Oracle TDE addresses encryption requirements associated with public and private privacy and security mandates such as PCI and California SB 1386. Oracle Advanced Security TDE column encryption was introduced in Oracle Database 10g Release 2. Oracle Advanced Security TDE tablespace encryption and support for hardware security modules (HSMs) were introduced with Oracle Database 11gR1. Keys for TDE can be stored in an HSM to manage keys across servers, protect keys with hardware, and introduce a separation of duties.\nThe same key is used to encrypt columns in a table, regardless of the number of columns to be encrypted. These encryption keys are encrypted using the database server master key and are stored in a dictionary table in the database.\n\n\n\n== Microsoft SQL Server TDE ==\nSQL Server utilizes an encryption hierarchy that enables databases to be shared within a cluster or migrated to other instances without re-encrypting them.  The hierarchy consists of a combination of symmetric and asymmetric ciphers:\nWindows Data Protection API (DPAPI) protects a single instance-wide Service Master Key (SMK).\nThe Service Master Key encrypts the Database Master Key (DMK).\nThe Database Master Key is used in conjunction with a certificate to encrypt the Database Encryption Key.\nThe Database Encryption Key is used to encrypt the underlying database files with either the AES or 3DES cipher.\nThe master database that contains various system level information, user accounts and management services is not encrypted.During database backups, compression occurs after encryption. Due to the fact that strongly encrypted data cannot be significantly compressed, backups of TDE encrypted databases require additional resources.\nTo enable automatic booting, SQL Server stores the lowest level encryption keys in persistent storage (using the DPAPI store).  This presents a potential security issue because the stored keys can be directly recovered from a live system or from backups and used to decrypt the databases.\nAnswer this question: What is the potential security issue with storing the lowest level encryption keys in persistent storage in Microsoft SQL Server TDE?",
    "context": "",
    "output": "The stored keys can be directly recovered from a live system or from backups and used to decrypt the databases, which presents a potential security issue in Microsoft SQL Server TDE.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the potential security issue with storing the lowest level encryption keys in persistent storage in Microsoft SQL Server TDE?",
      "answer": "The stored keys can be directly recovered from a live system or from backups and used to decrypt the databases, which presents a potential security issue in Microsoft SQL Server TDE.",
      "context": "Transparent data encryption\n\n==Introduction==\nTransparent Data Encryption (often abbreviated to TDE) is a technology employed by Microsoft, IBM and Oracle to encrypt database files. TDE offers encryption at file level. TDE solves the problem of protecting data at rest, encrypting databases both on the hard drive and consequently on backup media. It does not protect data in transit nor data in use. Enterprises typically employ TDE to solve compliance issues such as PCI DSS which require the protection of data at rest.\nMicrosoft offers TDE as part of its Microsoft SQL Server 2008, 2008 R2, 2012, 2014, 2016, 2017 and 2019. TDE was only supported on the Evaluation, Developer, Enterprise and Datacenter editions of Microsoft SQL Server, until it was also made available in the Standard edition for 2019.  SQL TDE is supported by hardware security modules from Thales e-Security, Townsend Security and SafeNet, Inc.\nIBM offers TDE as part of Db2 as of version 10.5 fixpack 5. It is also supported in cloud versions of the product by default, Db2 on Cloud and Db2 Warehouse on Cloud.\nOracle requires the Oracle Advanced Security option for Oracle 10g and 11g to enable TDE. Oracle TDE addresses encryption requirements associated with public and private privacy and security mandates such as PCI and California SB 1386. Oracle Advanced Security TDE column encryption was introduced in Oracle Database 10g Release 2. Oracle Advanced Security TDE tablespace encryption and support for hardware security modules (HSMs) were introduced with Oracle Database 11gR1. Keys for TDE can be stored in an HSM to manage keys across servers, protect keys with hardware, and introduce a separation of duties.\nThe same key is used to encrypt columns in a table, regardless of the number of columns to be encrypted. These encryption keys are encrypted using the database server master key and are stored in a dictionary table in the database.\n\n\n\n== Microsoft SQL Server TDE ==\nSQL Server utilizes an encryption hierarchy that enables databases to be shared within a cluster or migrated to other instances without re-encrypting them.  The hierarchy consists of a combination of symmetric and asymmetric ciphers:\nWindows Data Protection API (DPAPI) protects a single instance-wide Service Master Key (SMK).\nThe Service Master Key encrypts the Database Master Key (DMK).\nThe Database Master Key is used in conjunction with a certificate to encrypt the Database Encryption Key.\nThe Database Encryption Key is used to encrypt the underlying database files with either the AES or 3DES cipher.\nThe master database that contains various system level information, user accounts and management services is not encrypted.During database backups, compression occurs after encryption. Due to the fact that strongly encrypted data cannot be significantly compressed, backups of TDE encrypted databases require additional resources.\nTo enable automatic booting, SQL Server stores the lowest level encryption keys in persistent storage (using the DPAPI store).  This presents a potential security issue because the stored keys can be directly recovered from a live system or from backups and used to decrypt the databases."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the Integrity (I) metric in CVSS v2 and v3?",
    "context": "",
    "output": "The Integrity (I) metric in CVSS v2 and v3 describes the impact on the integrity of the exploited system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the Integrity (I) metric in CVSS v2 and v3?",
      "answer": "The Integrity (I) metric in CVSS v2 and v3 describes the impact on the integrity of the exploited system."
    }
  },
  {
    "instruction": "Answer based on context:\n\nPrivate information retrieval\n\n==Introduction==\nIn cryptography, a private information retrieval (PIR) protocol is a protocol that allows a user to retrieve an item from a server in possession of a database without revealing which item is retrieved. PIR is a weaker version of 1-out-of-n oblivious transfer, where it is also required that the user should not get information about other database items.\nOne trivial, but very inefficient way to achieve PIR is for the server to send an entire copy of the database to the user. In fact, this is the only possible protocol (in the classical or the quantum setting) that gives the user information theoretic privacy for their query in a single-server setting. There are two ways to address this problem: make the server computationally bounded or assume that there are multiple non-cooperating servers, each having a copy of the database.\nThe problem was introduced in 1995 by Chor, Goldreich, Kushilevitz and Sudan in the information-theoretic setting and in 1997 by Kushilevitz and Ostrovsky in the computational setting. Since then, very efficient solutions have been discovered. Single database (computationally private) PIR can be achieved with constant (amortized) communication and k-database (information theoretic) PIR can be done with \n  \n    \n      \n        \n          n\n          \n            O\n            \n              (\n              \n                \n                  \n                    log\n                    \u2061\n                    log\n                    \u2061\n                    k\n                  \n                  \n                    k\n                    log\n                    \u2061\n                    k\n                  \n                \n              \n              )\n            \n          \n        \n      \n    \n    {\\displaystyle n^{O\\left({\\frac {\\log \\log k}{k\\log k}}\\right)}}\n   communication.\n\n\n\n== Advances in computational PIR ==\nThe first single-database computational PIR scheme to achieve communication complexity less than \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   was created in 1997 by Kushilevitz and Ostrovsky  and achieved communication complexity of \n  \n    \n      \n        \n          n\n          \n            \u03f5\n          \n        \n      \n    \n    {\\displaystyle n^{\\epsilon }}\n   for any \n  \n    \n      \n        \u03f5\n      \n    \n    {\\displaystyle \\epsilon }\n  , where \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is the number of bits in the database. The security of their scheme was based on the well-studied Quadratic residuosity problem. In 1999, Christian Cachin, Silvio Micali and Markus Stadler achieved poly-logarithmic communication complexity. The security of their system is based on the Phi-hiding assumption. In 2004, Helger Lipmaa achieved log-squared communication complexity \n  \n    \n      \n        O\n        (\n        \u2113\n        log\n        \u2061\n        n\n        +\n        k\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(\\ell \\log n+k\\log ^{2}n)}\n  , where \n  \n    \n      \n        \u2113\n      \n    \n    {\\displaystyle \\ell }\n   is the length of the strings and \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   is the security parameter. The security of his system reduces to the semantic security of a length-flexible additively homomorphic cryptosystem like the Damg\u00e5rd\u2013Jurik cryptosystem. In 2005 Craig Gentry and Zulfikar Ramzan achieved log-squared communication complexity which retrieves log-square (consecutive) bits of the database. The security of their scheme is also based on a variant of the Phi-hiding assumption. The communication rate was finally brought down to \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n   by Aggelos Kiayias, Nikos Leonardos, Helger Lipmaa, Kateryna Pavlyk, Qiang Tang, in 2015.All previous sublinear-communication computational PIR protocol required linear computational complexity of \n  \n    \n      \n        \u03a9\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\Omega (n)}\n   public-key operations. In 2009, Helger Lipmaa designed a computational PIR protocol with communication complexity \n  \n    \n      \n        O\n        (\n        \u2113\n        log\n        \u2061\n        n\n        +\n        k\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(\\ell \\log n+k\\log ^{2}n)}\n   and worst-case computation of \n  \n    \n      \n        O\n        (\n        n\n        \n          /\n        \n        log\n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(n/\\log n)}\n   public-key operations. Amortization techniques that retrieve non-consecutive bits have been considered by Yuval Ishai, Eyal Kushilevitz, Rafail Ostrovsky and Amit Sahai.As shown by Ostrovsky and Skeith, the schemes by Kushilevitz and Ostrovsky  and Lipmaa  use similar ideas based on homomorphic encryption. The Kushilevitz and Ostrovsky protocol is based on the Goldwasser\u2013Micali cryptosystem while the protocol by Lipmaa is based on the Damg\u00e5rd\u2013Jurik cryptosystem.\n\n== Advances in information theoretic PIR ==\nAchieving information theoretic security requires the assumption that there are multiple non-cooperating servers, each having a copy of the database. Without this assumption, any information-theoretically secure PIR protocol requires an amount of communication that is at least the size of the database n.  Multi-server PIR protocols tolerant of non-responsive or malicious/colluding servers are called robust or Byzantine robust respectively.  These issues were first considered by Beimel and Stahl (2002).  An \u2113-server system that can operate where only k of the servers respond, \u03bd of the servers respond incorrectly, and which can withstand up to t colluding servers without revealing the client's query is called \"t-private \u03bd-Byzantine robust k-out-of-\u2113 PIR\" [DGH 2012].  In 2012, C. Devet, I. Goldberg, and N. Heninger (DGH 2012) proposed an optimally robust scheme that is Byzantine-robust to \n  \n    \n      \n        \u03bd\n        <\n        k\n        \u2212\n        t\n        \u2212\n        1\n      \n    \n    {\\displaystyle \\nu <k-t-1}\n   which is the theoretical maximum value.  It is based on an earlier protocol of Goldberg that uses Shamir's Secret Sharing to hide the query.  Goldberg has released a C++ implementation on SourceForge.\n\n== Relation to other cryptographic primitives ==\nOne-way functions are necessary, but not known to be sufficient, for nontrivial (i.e., with sublinear communication) single database computationally private information retrieval. In fact, such a protocol was proved by Giovanni Di Crescenzo, Tal Malkin and Rafail Ostrovsky to imply oblivious transfer (see below).Oblivious transfer, also called symmetric PIR, is PIR with the additional restriction that the user may not learn any item other than the one she requested. It is termed symmetric because both the user and the database have a privacy requirement.\nCollision-resistant cryptographic hash functions are implied by any one-round computational PIR scheme, as shown by Ishai, Kushilevitz and Ostrovsky.\n\n== PIR variations ==\nThe basic motivation for Private Information Retrieval is a family of two-party protocols in which one of the parties (the sender) owns a database, and the other part (the receiver) wants to query it with certain privacy restrictions and warranties. So, as a result of the protocol, if the receiver wants the i-th value in the database he  must learn the i-th entry, but the sender must learn nothing about i. In a general PIR protocol, a computationally unbounded sender can learn nothing about i so privacy is theoretically preserved. Since the PIR problem was posed, different approaches to its solution have been pursued and some variations were proposed.\nA CPIR (Computationally Private Information Retrieval) protocol is similar to a PIR protocol: the receiver retrieves an element chosen by him from the sender's database, so that the sender obtains no knowledge about which element was transferred. The only difference is that privacy is safeguarded against a polynomially bounded sender.A CSPIR (Computationally Symmetric Private Information Retrieval) protocol is used in a similar scenario in which a CPIR protocol is used. If the sender owns a database, and the receiver wants to get the i-th value in this database, at the end of the execution of a SPIR protocol, the receiver should have learned nothing about values in the database other than the i-th one.\n\n== PIR implementations ==\nNumerous Computational PIR and Information theoretic PIR schemes in the literature have been implemented. Here is an incomplete list:\n\nMuchPIR is a CPIR implementation as a Postgres C/C++ Extension [GitHub, 2021].\nSealPIR is a fast CPIR implementation [ACLS 2018].\nPopcorn is a PIR implementation tailored for media [GCMSAW 2016].\nPercy++ includes implementations of [AG 2007, DGH 2012, CGKS 1998, Goldberg 2007, HOG 2011, LG 2015].\nRAID-PIR is an implementation of the ITPIR scheme of [DHS 2014].\nXPIR is a fast CPIR implementation [ABFK 2014].\nupPIR is an ITPIR implementation [Cappos 2013].\n\n\n*** Notes ***\n\nWhat is the communication rate of the computational PIR protocol that finally brought down the communication rate to 1 in 2015 by Aggelos Kiayias, Nikos Leonardos, Helger Lipmaa, Kateryna Pavlyk, and Qiang Tang?",
    "context": "",
    "output": "The communication rate of the computational PIR protocol that finally brought down the communication rate to 1 in 2015 by Aggelos Kiayias, Nikos Leonardos, Helger Lipmaa, Kateryna Pavlyk, and Qiang Tang is 1.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the communication rate of the computational PIR protocol that finally brought down the communication rate to 1 in 2015 by Aggelos Kiayias, Nikos Leonardos, Helger Lipmaa, Kateryna Pavlyk, and Qiang Tang?",
      "answer": "The communication rate of the computational PIR protocol that finally brought down the communication rate to 1 in 2015 by Aggelos Kiayias, Nikos Leonardos, Helger Lipmaa, Kateryna Pavlyk, and Qiang Tang is 1.",
      "context": "Private information retrieval\n\n==Introduction==\nIn cryptography, a private information retrieval (PIR) protocol is a protocol that allows a user to retrieve an item from a server in possession of a database without revealing which item is retrieved. PIR is a weaker version of 1-out-of-n oblivious transfer, where it is also required that the user should not get information about other database items.\nOne trivial, but very inefficient way to achieve PIR is for the server to send an entire copy of the database to the user. In fact, this is the only possible protocol (in the classical or the quantum setting) that gives the user information theoretic privacy for their query in a single-server setting. There are two ways to address this problem: make the server computationally bounded or assume that there are multiple non-cooperating servers, each having a copy of the database.\nThe problem was introduced in 1995 by Chor, Goldreich, Kushilevitz and Sudan in the information-theoretic setting and in 1997 by Kushilevitz and Ostrovsky in the computational setting. Since then, very efficient solutions have been discovered. Single database (computationally private) PIR can be achieved with constant (amortized) communication and k-database (information theoretic) PIR can be done with \n  \n    \n      \n        \n          n\n          \n            O\n            \n              (\n              \n                \n                  \n                    log\n                    \u2061\n                    log\n                    \u2061\n                    k\n                  \n                  \n                    k\n                    log\n                    \u2061\n                    k\n                  \n                \n              \n              )\n            \n          \n        \n      \n    \n    {\\displaystyle n^{O\\left({\\frac {\\log \\log k}{k\\log k}}\\right)}}\n   communication.\n\n\n\n== Advances in computational PIR ==\nThe first single-database computational PIR scheme to achieve communication complexity less than \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   was created in 1997 by Kushilevitz and Ostrovsky  and achieved communication complexity of \n  \n    \n      \n        \n          n\n          \n            \u03f5\n          \n        \n      \n    \n    {\\displaystyle n^{\\epsilon }}\n   for any \n  \n    \n      \n        \u03f5\n      \n    \n    {\\displaystyle \\epsilon }\n  , where \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   is the number of bits in the database. The security of their scheme was based on the well-studied Quadratic residuosity problem. In 1999, Christian Cachin, Silvio Micali and Markus Stadler achieved poly-logarithmic communication complexity. The security of their system is based on the Phi-hiding assumption. In 2004, Helger Lipmaa achieved log-squared communication complexity \n  \n    \n      \n        O\n        (\n        \u2113\n        log\n        \u2061\n        n\n        +\n        k\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(\\ell \\log n+k\\log ^{2}n)}\n  , where \n  \n    \n      \n        \u2113\n      \n    \n    {\\displaystyle \\ell }\n   is the length of the strings and \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   is the security parameter. The security of his system reduces to the semantic security of a length-flexible additively homomorphic cryptosystem like the Damg\u00e5rd\u2013Jurik cryptosystem. In 2005 Craig Gentry and Zulfikar Ramzan achieved log-squared communication complexity which retrieves log-square (consecutive) bits of the database. The security of their scheme is also based on a variant of the Phi-hiding assumption. The communication rate was finally brought down to \n  \n    \n      \n        1\n      \n    \n    {\\displaystyle 1}\n   by Aggelos Kiayias, Nikos Leonardos, Helger Lipmaa, Kateryna Pavlyk, Qiang Tang, in 2015.All previous sublinear-communication computational PIR protocol required linear computational complexity of \n  \n    \n      \n        \u03a9\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\Omega (n)}\n   public-key operations. In 2009, Helger Lipmaa designed a computational PIR protocol with communication complexity \n  \n    \n      \n        O\n        (\n        \u2113\n        log\n        \u2061\n        n\n        +\n        k\n        \n          log\n          \n            2\n          \n        \n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(\\ell \\log n+k\\log ^{2}n)}\n   and worst-case computation of \n  \n    \n      \n        O\n        (\n        n\n        \n          /\n        \n        log\n        \u2061\n        n\n        )\n      \n    \n    {\\displaystyle O(n/\\log n)}\n   public-key operations. Amortization techniques that retrieve non-consecutive bits have been considered by Yuval Ishai, Eyal Kushilevitz, Rafail Ostrovsky and Amit Sahai.As shown by Ostrovsky and Skeith, the schemes by Kushilevitz and Ostrovsky  and Lipmaa  use similar ideas based on homomorphic encryption. The Kushilevitz and Ostrovsky protocol is based on the Goldwasser\u2013Micali cryptosystem while the protocol by Lipmaa is based on the Damg\u00e5rd\u2013Jurik cryptosystem.\n\n== Advances in information theoretic PIR ==\nAchieving information theoretic security requires the assumption that there are multiple non-cooperating servers, each having a copy of the database. Without this assumption, any information-theoretically secure PIR protocol requires an amount of communication that is at least the size of the database n.  Multi-server PIR protocols tolerant of non-responsive or malicious/colluding servers are called robust or Byzantine robust respectively.  These issues were first considered by Beimel and Stahl (2002).  An \u2113-server system that can operate where only k of the servers respond, \u03bd of the servers respond incorrectly, and which can withstand up to t colluding servers without revealing the client's query is called \"t-private \u03bd-Byzantine robust k-out-of-\u2113 PIR\" [DGH 2012].  In 2012, C. Devet, I. Goldberg, and N. Heninger (DGH 2012) proposed an optimally robust scheme that is Byzantine-robust to \n  \n    \n      \n        \u03bd\n        <\n        k\n        \u2212\n        t\n        \u2212\n        1\n      \n    \n    {\\displaystyle \\nu <k-t-1}\n   which is the theoretical maximum value.  It is based on an earlier protocol of Goldberg that uses Shamir's Secret Sharing to hide the query.  Goldberg has released a C++ implementation on SourceForge.\n\n== Relation to other cryptographic primitives ==\nOne-way functions are necessary, but not known to be sufficient, for nontrivial (i.e., with sublinear communication) single database computationally private information retrieval. In fact, such a protocol was proved by Giovanni Di Crescenzo, Tal Malkin and Rafail Ostrovsky to imply oblivious transfer (see below).Oblivious transfer, also called symmetric PIR, is PIR with the additional restriction that the user may not learn any item other than the one she requested. It is termed symmetric because both the user and the database have a privacy requirement.\nCollision-resistant cryptographic hash functions are implied by any one-round computational PIR scheme, as shown by Ishai, Kushilevitz and Ostrovsky.\n\n== PIR variations ==\nThe basic motivation for Private Information Retrieval is a family of two-party protocols in which one of the parties (the sender) owns a database, and the other part (the receiver) wants to query it with certain privacy restrictions and warranties. So, as a result of the protocol, if the receiver wants the i-th value in the database he  must learn the i-th entry, but the sender must learn nothing about i. In a general PIR protocol, a computationally unbounded sender can learn nothing about i so privacy is theoretically preserved. Since the PIR problem was posed, different approaches to its solution have been pursued and some variations were proposed.\nA CPIR (Computationally Private Information Retrieval) protocol is similar to a PIR protocol: the receiver retrieves an element chosen by him from the sender's database, so that the sender obtains no knowledge about which element was transferred. The only difference is that privacy is safeguarded against a polynomially bounded sender.A CSPIR (Computationally Symmetric Private Information Retrieval) protocol is used in a similar scenario in which a CPIR protocol is used. If the sender owns a database, and the receiver wants to get the i-th value in this database, at the end of the execution of a SPIR protocol, the receiver should have learned nothing about values in the database other than the i-th one.\n\n== PIR implementations ==\nNumerous Computational PIR and Information theoretic PIR schemes in the literature have been implemented. Here is an incomplete list:\n\nMuchPIR is a CPIR implementation as a Postgres C/C++ Extension [GitHub, 2021].\nSealPIR is a fast CPIR implementation [ACLS 2018].\nPopcorn is a PIR implementation tailored for media [GCMSAW 2016].\nPercy++ includes implementations of [AG 2007, DGH 2012, CGKS 1998, Goldberg 2007, HOG 2011, LG 2015].\nRAID-PIR is an implementation of the ITPIR scheme of [DHS 2014].\nXPIR is a fast CPIR implementation [ABFK 2014].\nupPIR is an ITPIR implementation [Cappos 2013].\n\n\n*** Notes ***"
    }
  },
  {
    "instruction": "OMEMO\n\n==Introduction==\nOMEMO is an extension to the Extensible Messaging and Presence Protocol (XMPP) for multi-client end-to-end encryption developed by Andreas Straub. According to Straub, OMEMO uses the Double Ratchet Algorithm \"to provide multi-end to multi-end encryption, allowing messages to be synchronized securely across multiple clients, even if some of them are offline\". The name \"OMEMO\" is a recursive acronym for \"OMEMO Multi-End Message and Object Encryption\".\nIt is an open standard based on the Double Ratchet Algorithm and the Personal Eventing Protocol (PEP, XEP-0163).\nOMEMO offers future and forward secrecy and deniability with message synchronization and offline delivery.\n\n\n\n== Features ==\nIn comparison with OTR, the OMEMO protocol offers many-to-many encrypted chat, offline messages queuing, forward secrecy, file transfer, verifiability and deniability at the cost of slightly larger message size overhead.\n\n== Client support ==\nSelected clients supporting OMEMO (full list of clients also exists):\n\nc0nnect PRO (Android - Conversations Fork)\nBeagleIM (macOS)\nChatSecure (iOS)\nConversations (Android)\nConverse.js (Browser-based)\nDino (Linux, macOS)\nGajim via official plugin (Linux, Windows, BSD)\nMonal (iOS)\nMovim (Browser-based)\nPsi via official plugin (Linux, Windows, macOS)\nPsi+ via official plugin (Linux, Windows, macOS, Haiku, FreeBSD)\nlibpurple clients such as Pidgin or Finch via experimental plugin \nAdium via an Xtra based on the libpurple plugin\nProfanity via experimental plugin (BSD, Linux, macOS, Windows)\nSiskinIM (iOS)\n\n== Library support ==\nSmack supports OMEMO using the two modules smack-omemo and smack-omemo-signal\nXMPPFramework (macOS, iOS, tvOS)  supports OMEMO via the OMEMOModule extension  when used in conjunction with the SignalProtocol-ObjC library.\n\nBased on the above text, answer a question. How does OMEMO provide message synchronization?",
    "context": "",
    "output": "OMEMO provides message synchronization using the Personal Eventing Protocol (PEP, XEP-0163), which allows for event notifications and message synchronization across multiple clients.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does OMEMO provide message synchronization?",
      "answer": "OMEMO provides message synchronization using the Personal Eventing Protocol (PEP, XEP-0163), which allows for event notifications and message synchronization across multiple clients.",
      "context": "OMEMO\n\n==Introduction==\nOMEMO is an extension to the Extensible Messaging and Presence Protocol (XMPP) for multi-client end-to-end encryption developed by Andreas Straub. According to Straub, OMEMO uses the Double Ratchet Algorithm \"to provide multi-end to multi-end encryption, allowing messages to be synchronized securely across multiple clients, even if some of them are offline\". The name \"OMEMO\" is a recursive acronym for \"OMEMO Multi-End Message and Object Encryption\".\nIt is an open standard based on the Double Ratchet Algorithm and the Personal Eventing Protocol (PEP, XEP-0163).\nOMEMO offers future and forward secrecy and deniability with message synchronization and offline delivery.\n\n\n\n== Features ==\nIn comparison with OTR, the OMEMO protocol offers many-to-many encrypted chat, offline messages queuing, forward secrecy, file transfer, verifiability and deniability at the cost of slightly larger message size overhead.\n\n== Client support ==\nSelected clients supporting OMEMO (full list of clients also exists):\n\nc0nnect PRO (Android - Conversations Fork)\nBeagleIM (macOS)\nChatSecure (iOS)\nConversations (Android)\nConverse.js (Browser-based)\nDino (Linux, macOS)\nGajim via official plugin (Linux, Windows, BSD)\nMonal (iOS)\nMovim (Browser-based)\nPsi via official plugin (Linux, Windows, macOS)\nPsi+ via official plugin (Linux, Windows, macOS, Haiku, FreeBSD)\nlibpurple clients such as Pidgin or Finch via experimental plugin \nAdium via an Xtra based on the libpurple plugin\nProfanity via experimental plugin (BSD, Linux, macOS, Windows)\nSiskinIM (iOS)\n\n== Library support ==\nSmack supports OMEMO using the two modules smack-omemo and smack-omemo-signal\nXMPPFramework (macOS, iOS, tvOS)  supports OMEMO via the OMEMOModule extension  when used in conjunction with the SignalProtocol-ObjC library."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the nym server return a confirmation to the user when a nym is created?",
    "context": "",
    "output": "The nym server returns a confirmation through the reply block when a nym is created.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the nym server return a confirmation to the user when a nym is created?",
      "answer": "The nym server returns a confirmation through the reply block when a nym is created."
    }
  },
  {
    "instruction": "context: Some examples of serious false positives include Symantec removing essential operating system files, Norton AntiVirus deleting Pegasus Mail executables, McAfee VirusScan detecting svchost.exe as a virus, AVG damaging Windows 7, Microsoft Security Essentials removing Google Chrome, Sophos identifying its own update-mechanisms as malware, and Google Play Protect identifying Motorola's Moto G4 Bluetooth application as malware.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are some examples of serious false positives caused by antivirus software?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some examples of serious false positives caused by antivirus software?",
      "answer": "Some examples of serious false positives include Symantec removing essential operating system files, Norton AntiVirus deleting Pegasus Mail executables, McAfee VirusScan detecting svchost.exe as a virus, AVG damaging Windows 7, Microsoft Security Essentials removing Google Chrome, Sophos identifying its own update-mechanisms as malware, and Google Play Protect identifying Motorola's Moto G4 Bluetooth application as malware."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Festi ensure the continuity of control over the botnet?",
    "context": "",
    "output": "Festi uses a system of bindings and reserve command centers, allowing it to restore control over the botnet even after a change in command center.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Festi ensure the continuity of control over the botnet?",
      "answer": "Festi uses a system of bindings and reserve command centers, allowing it to restore control over the botnet even after a change in command center."
    }
  },
  {
    "instruction": "context: The Zealot Campaign uses two HTTP requests to scan and target vulnerable systems on the network. It is unique in that it is prepared for both Windows and Linux-based systems, using the version of the Apache Struts exploit along with using DNN.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the Zealot Campaign scan and target vulnerable systems on the network?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Zealot Campaign scan and target vulnerable systems on the network?",
      "answer": "The Zealot Campaign uses two HTTP requests to scan and target vulnerable systems on the network. It is unique in that it is prepared for both Windows and Linux-based systems, using the version of the Apache Struts exploit along with using DNN."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some of the most common EAP-methods used in the EAP authentication protocol, and what are their characteristics?",
    "context": "",
    "output": "Some of the most common EAP-methods used in the EAP authentication protocol are EAP-MD5, EAP-TLS, EAP-TTLS, EAP-FAST, and EAP-PEAP. EAP-MD5 is a simple and fast authentication method that uses MD5 hash function for authentication, while EAP-TLS is a more secure authentication method that uses digital certificates and SSL/TLS for authentication. EAP-TTLS and EAP-FAST are similar to EAP-TLS, but they allow for the use of unencrypted passwords, while EAP-PEAP is similar to EAP-TTLS but uses a more secure TLS tunnel for authentication.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the most common EAP-methods used in the EAP authentication protocol, and what are their characteristics?",
      "answer": "Some of the most common EAP-methods used in the EAP authentication protocol are EAP-MD5, EAP-TLS, EAP-TTLS, EAP-FAST, and EAP-PEAP. EAP-MD5 is a simple and fast authentication method that uses MD5 hash function for authentication, while EAP-TLS is a more secure authentication method that uses digital certificates and SSL/TLS for authentication. EAP-TTLS and EAP-FAST are similar to EAP-TLS, but they allow for the use of unencrypted passwords, while EAP-PEAP is similar to EAP-TTLS but uses a more secure TLS tunnel for authentication."
    }
  },
  {
    "instruction": "context: Yehuda Lindell and Benny Pinkas, Ishai, Manoj Prabhakaran, and Amit Sahai, as well as Jesper Buus Nielsen and Claudio Orlandi, have proposed alternative protocols that provide security against active adversaries.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are some alternative secure two-party computation protocols that are secure against active adversaries?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some alternative secure two-party computation protocols that are secure against active adversaries?",
      "answer": "Yehuda Lindell and Benny Pinkas, Ishai, Manoj Prabhakaran, and Amit Sahai, as well as Jesper Buus Nielsen and Claudio Orlandi, have proposed alternative protocols that provide security against active adversaries."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the Introduction section in the given text?",
    "context": "",
    "output": "The Introduction section in the given text provides an overview of the concept of SIGADs, their purpose, and their usage by signals intelligence agencies of the Five Eyes community.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the Introduction section in the given text?",
      "answer": "The Introduction section in the given text provides an overview of the concept of SIGADs, their purpose, and their usage by signals intelligence agencies of the Five Eyes community."
    }
  },
  {
    "instruction": "Context: Partial password\n\n==Introduction==\nA partial password is a mode of password authentication intended to make keystroke logging and shoulder surfing less effective.By asking the user to enter only a few specific characters from their password, rather than the whole password, partial passwords help to protect the user from password theft. As only part of the password is revealed at once it becomes more difficult to obtain the password using techniques such as keystroke logging or shoulder surfing.\nA paper by David Aspinall and Mike Just describes partial password implementations and attacks in a detailed study.Tested with 110,000 simulations using passwords longer than 8 characters long, Junade Ali has noted:\n58% of passwords are revealed in entirety after 7 logins, 90% after 12 and 99% after 19 logins.\nUsing a dataset of 488,129 breached passwords, 58% of tested 3-character password segments were only valid for that password in the database. Additionally, 28% could be associated with only one other password and 8% with two other passwords.\n\n== Verifying partial passwords ==\nIt is considered good practice to not store passwords in plaintext. Instead, when checking a whole password, it is common to store the result of passing the password to a cryptographic hash function. As the user does not supply the whole password, it cannot be verified against a stored digest of the whole password. Some have suggested storing the digest of each combination of letters that could be requested, but they note that this results in generating and storing a large amount of digests. A better solution in terms of storage space and security is using a secret sharing scheme.\n\nQuestion: How does storing the digest of each combination of letters that could be requested address the challenge of verifying partial passwords?\n\nAnswer:",
    "context": "",
    "output": "Storing the digest of each combination of letters that could be requested would allow for verification of partial passwords, but it would result in generating and storing a large amount of digests, which can be inefficient and may introduce security risks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does storing the digest of each combination of letters that could be requested address the challenge of verifying partial passwords?",
      "answer": "Storing the digest of each combination of letters that could be requested would allow for verification of partial passwords, but it would result in generating and storing a large amount of digests, which can be inefficient and may introduce security risks.",
      "context": "Partial password\n\n==Introduction==\nA partial password is a mode of password authentication intended to make keystroke logging and shoulder surfing less effective.By asking the user to enter only a few specific characters from their password, rather than the whole password, partial passwords help to protect the user from password theft. As only part of the password is revealed at once it becomes more difficult to obtain the password using techniques such as keystroke logging or shoulder surfing.\nA paper by David Aspinall and Mike Just describes partial password implementations and attacks in a detailed study.Tested with 110,000 simulations using passwords longer than 8 characters long, Junade Ali has noted:\n58% of passwords are revealed in entirety after 7 logins, 90% after 12 and 99% after 19 logins.\nUsing a dataset of 488,129 breached passwords, 58% of tested 3-character password segments were only valid for that password in the database. Additionally, 28% could be associated with only one other password and 8% with two other passwords.\n\n== Verifying partial passwords ==\nIt is considered good practice to not store passwords in plaintext. Instead, when checking a whole password, it is common to store the result of passing the password to a cryptographic hash function. As the user does not supply the whole password, it cannot be verified against a stored digest of the whole password. Some have suggested storing the digest of each combination of letters that could be requested, but they note that this results in generating and storing a large amount of digests. A better solution in terms of storage space and security is using a secret sharing scheme."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the type level in GBAC's organizational graph?",
    "context": "",
    "output": "The type level in GBAC's organizational graph describes organizational structures in a more general manner and can be used to create new instances or reuse organizational knowledge in case of exceptions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the type level in GBAC's organizational graph?",
      "answer": "The type level in GBAC's organizational graph describes organizational structures in a more general manner and can be used to create new instances or reuse organizational knowledge in case of exceptions."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between application security and segregation of duties in the context of information security?",
    "context": "",
    "output": "Application security and segregation of duties are both related to protecting the integrity of a company's data and preventing fraud, but they approach this goal in different ways. Application security focuses on preventing unauthorized access to hardware and software through physical and electronic security measures, while segregation of duties is primarily a physical review of individuals\u2019 access to the systems and processing and ensuring that there are no overlaps that could lead to fraud.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between application security and segregation of duties in the context of information security?",
      "answer": "Application security and segregation of duties are both related to protecting the integrity of a company's data and preventing fraud, but they approach this goal in different ways. Application security focuses on preventing unauthorized access to hardware and software through physical and electronic security measures, while segregation of duties is primarily a physical review of individuals\u2019 access to the systems and processing and ensuring that there are no overlaps that could lead to fraud."
    }
  },
  {
    "instruction": "context: Spybot - Search & Destroy was formerly released as freeware for personal users, but is now donationware. Corporate and technician users have to buy a commercial version. The paid versions contain an anti-virus component that uses the BitDefender engine. Versions 1.5 and 1.6 were released in 2009 and 2014 respectively, with better compatibility and faster scanning capabilities.\n\nAsk a question about this context.",
    "context": "",
    "output": "How is Spybot - Search & Destroy licensed and what are its available versions for purchase?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is Spybot - Search & Destroy licensed and what are its available versions for purchase?",
      "answer": "Spybot - Search & Destroy was formerly released as freeware for personal users, but is now donationware. Corporate and technician users have to buy a commercial version. The paid versions contain an anti-virus component that uses the BitDefender engine. Versions 1.5 and 1.6 were released in 2009 and 2014 respectively, with better compatibility and faster scanning capabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does a theorem prover contribute to the packet filter example in proof-carrying code?",
    "context": "",
    "output": "A theorem prover is used to demonstrate that the machine code of the packet filter satisfies the specified security policy. The steps of this proof are then recorded and attached to the machine code, which is given to the kernel program loader.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a theorem prover contribute to the packet filter example in proof-carrying code?",
      "answer": "A theorem prover is used to demonstrate that the machine code of the packet filter satisfies the specified security policy. The steps of this proof are then recorded and attached to the machine code, which is given to the kernel program loader."
    }
  },
  {
    "instruction": "context: MOSS uses symmetric (secret key) cryptography in support of the encryption service.\n\nAsk a question about this context.",
    "context": "",
    "output": "What type of cryptography is used in MOSS to support the encryption service?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What type of cryptography is used in MOSS to support the encryption service?",
      "answer": "MOSS uses symmetric (secret key) cryptography in support of the encryption service."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the relationship between data-centric security and business strategy?",
    "context": "",
    "output": "Data-centric security allows organizations to directly relate security services to the data they protect, which can help to align security objectives with business strategy. This is in contrast to traditional security approaches, which may present security as an end in itself.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the relationship between data-centric security and business strategy?",
      "answer": "Data-centric security allows organizations to directly relate security services to the data they protect, which can help to align security objectives with business strategy. This is in contrast to traditional security approaches, which may present security as an end in itself."
    }
  },
  {
    "instruction": "Context: Cryptographic accelerator\n\n==Introduction==\nIn computing, a cryptographic accelerator is a co-processor designed specifically to perform computationally intensive cryptographic operations, doing so far more efficiently than the general-purpose CPU. Because many servers' system loads consist mostly of cryptographic operations, this can greatly increase performance.\nIntel's AES-NI is by far the most common cryptographic accelerator in commodity hardware. VIA PadLock is another recent example.\n\n\n\n== Operating system support ==\nSeveral operating systems provide some support for cryptographic hardware. The BSD family of systems has the OpenBSD Cryptographic Framework (OCF), Linux systems have the Crypto API, Solaris OS has the Solaris Cryptographic Framework (SCF) and Microsoft Windows has the Microsoft CryptoAPI.\nSome cryptographic accelerators offer new machine instructions and can therefore be used directly by programs. Libraries such as OpenSSL and LibreSSL support some such cryptographic accelerators.\nAlmost all Unix-like operating systems use OpenSSL or the fork LibreSSL as their cryptography library. These libraries use cryptographic accelerators such as AES-NI if available.\nAnswer this question: Are there any notable differences between OpenSSL and LibreSSL in terms of cryptographic accelerator support?",
    "context": "",
    "output": "Both libraries support cryptographic accelerators, but there may be subtle differences in their implementation or compatibility with various accelerators.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Are there any notable differences between OpenSSL and LibreSSL in terms of cryptographic accelerator support?",
      "answer": "Both libraries support cryptographic accelerators, but there may be subtle differences in their implementation or compatibility with various accelerators.",
      "context": "Cryptographic accelerator\n\n==Introduction==\nIn computing, a cryptographic accelerator is a co-processor designed specifically to perform computationally intensive cryptographic operations, doing so far more efficiently than the general-purpose CPU. Because many servers' system loads consist mostly of cryptographic operations, this can greatly increase performance.\nIntel's AES-NI is by far the most common cryptographic accelerator in commodity hardware. VIA PadLock is another recent example.\n\n\n\n== Operating system support ==\nSeveral operating systems provide some support for cryptographic hardware. The BSD family of systems has the OpenBSD Cryptographic Framework (OCF), Linux systems have the Crypto API, Solaris OS has the Solaris Cryptographic Framework (SCF) and Microsoft Windows has the Microsoft CryptoAPI.\nSome cryptographic accelerators offer new machine instructions and can therefore be used directly by programs. Libraries such as OpenSSL and LibreSSL support some such cryptographic accelerators.\nAlmost all Unix-like operating systems use OpenSSL or the fork LibreSSL as their cryptography library. These libraries use cryptographic accelerators such as AES-NI if available."
    }
  },
  {
    "instruction": "context: The average person can protect themselves from cybercrime by using strong and unique passwords, enabling two-factor authentication, keeping their software and systems up to date, being cautious of suspicious emails and links, and using a reputable antivirus software.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can the average person protect themselves from cybercrime?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can the average person protect themselves from cybercrime?",
      "answer": "The average person can protect themselves from cybercrime by using strong and unique passwords, enabling two-factor authentication, keeping their software and systems up to date, being cautious of suspicious emails and links, and using a reputable antivirus software."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do black hat hackers utilize entryway pages in their methods?",
    "context": "",
    "output": "Black hat hackers use entryway pages to conceal the substance of a website from both clients and web indexes, making it difficult for search engines to index or rank the website for relevant keywords or phrases.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do black hat hackers utilize entryway pages in their methods?",
      "answer": "Black hat hackers use entryway pages to conceal the substance of a website from both clients and web indexes, making it difficult for search engines to index or rank the website for relevant keywords or phrases."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the two types of user authentication methods that Bitvise software supports?",
    "context": "",
    "output": "Bitvise software supports GSSAPI-enabled Kerberos 5 exchange and NTLM Kerberos 5 user authentication.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the two types of user authentication methods that Bitvise software supports?",
      "answer": "Bitvise software supports GSSAPI-enabled Kerberos 5 exchange and NTLM Kerberos 5 user authentication."
    }
  },
  {
    "instruction": "context: Companies can protect themselves from Typosquatting by aggressively chasing down typosquatted names, as Verizon, Lufthansa, and Lego have done. They can also register common misspellings or plural forms of their domain names to prevent Typosquatters from capitalizing on users' mistakes.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can companies protect themselves from Typosquatting?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can companies protect themselves from Typosquatting?",
      "answer": "Companies can protect themselves from Typosquatting by aggressively chasing down typosquatted names, as Verizon, Lufthansa, and Lego have done. They can also register common misspellings or plural forms of their domain names to prevent Typosquatters from capitalizing on users' mistakes."
    }
  },
  {
    "instruction": "context: DarkSide's ransomware checks the system's location and language to avoid machines in former Soviet countries. The list of languages that are excluded includes Russian, Ukrainian, Belarusian, Tajik, Armenian, Azerbaijani, Georgian, Kazakh, Kyrgyz, Turkmen, Uzbek, Tatar, Moldovan Romanian, and Syrian Arabic.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does DarkSide's ransomware ensure that it is not encrypting files in former Soviet countries?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does DarkSide's ransomware ensure that it is not encrypting files in former Soviet countries?",
      "answer": "DarkSide's ransomware checks the system's location and language to avoid machines in former Soviet countries. The list of languages that are excluded includes Russian, Ukrainian, Belarusian, Tajik, Armenian, Azerbaijani, Georgian, Kazakh, Kyrgyz, Turkmen, Uzbek, Tatar, Moldovan Romanian, and Syrian Arabic."
    }
  },
  {
    "instruction": "Context: Technical support scam\n\n==Introduction==\nA technical support scam, or tech support scam, is a type of fraud in which a scammer claims to offer a legitimate technical support service. Victims contact scammers in a variety of ways, often through fake pop-ups resembling error messages or via fake \"help lines\" advertised on websites owned by the scammers. Technical support scammers use social engineering and a variety of confidence tricks to persuade their victim of the presence of problems on their computer or mobile device, such as a malware infection, when there are no issues with the victim's device. The scammer will then persuade the victim to pay to fix the fictitious \"problems\" that they claim to have found. Payment is made to the scammer through ways which are hard to trace and have fewer consumer protections in place which could allow the victim to claim their money back, usually through gift cards.\nTechnical support scams have occurred as early as 2008. A 2017 study of technical support scams found that of the IPs that could be geolocated, 85% could be traced to locations in India, 7% to locations in the United States and 3% to locations in Costa Rica.  Research into tech support scams suggests that millennials and those in generation Z have the highest exposure to such scams; however, senior citizens are more likely to fall for these scams and lose money to them. Technical support scams were named by Norton as the top phishing threat to consumers in October 2021; Microsoft found that 60% of consumers who took part in a survey had been exposed to a technical support scam within the previous twelve months. Responses to technical support scams include lawsuits brought against companies responsible for running fraudulent call centres and scam baiting.\n\n== Origin and distribution ==\nThe first tech support scams were recorded in 2008. Technical support scams have been seen in a variety of countries, including the United States, Canada, United Kingdom, Ireland, Australia, New Zealand, India and South Africa.A 2017 study of technical support scams published at the NDSS Symposium found that, of the tech support scams in which the IPs involved could be geolocated, 85% could be traced to locations in India, 7% to locations in the United States and 3% to locations in Costa Rica. India has millions of English speakers who are competing for relatively few jobs. One municipality had 114 jobs and received 19,000 applicants. This high level of unemployment serves as an incentive for tech scamming jobs, which are often well-paid. Additionally, scammers exploit the levels of unemployment by offering jobs to people desperate to be employed. Many scammers do not realise they are applying and being trained for tech support scam jobs, but many decide to stay after finding out the nature of their job as they feel it is too late to back out of the job and change careers.  Scammers are forced to choose between keeping their job or becoming jobless. Some scammers convince themselves that they are targeting wealthy people that have money to spare, which justifies their theft, whilst others see their job as generating \"easy money\".\n\n== Operation ==\nTechnical support scams rely on social engineering to persuade victims that their device is infected with malware. Scammers use a variety of confidence tricks to persuade the victim to install remote desktop software, with which the scammer can then take control of the victim's computer. With this access, the scammer may then launch various Windows components and utilities (such as the Event Viewer), install third-party utilities (such as rogue security software) and perform other tasks in an effort to convince the victim that the computer has critical problems that must be remediated, such as infection with a virus. Scammers target a variety of people, though research by Microsoft suggests that millennials (defined by Microsoft as age 24-37) and people part of generation Z (age 18-23) have the highest exposure to tech support scams and the Federal Trade Commission has found that seniors (age 60 and over) are more likely to lose money to tech support scams. The scammer will urge the victim to pay so the \"issues\" can be fixed.\n\n\n*** Initiation ***\n\nTechnical support scams can begin in a variety of ways. Some variants of the scam are initiated using pop-up advertising on infected websites or via cybersquatting of major websites. The victim is shown pop-ups which resemble legitimate error messages such as a Blue Screen of Death and freeze the victim's web browser. The pop-up instructs the victim to call the scammers via a phone number to fix the \"error\". Technical support scams can also be initiated via cold calls. These are usually robocalls which claim to be associated with a legitimate third party such as Microsoft or Apple. Technical support scams can also attract victims by purchasing keyword advertising on major search engines for phrases such as \"Microsoft support\". Victims who click on these adverts are taken to web pages containing the scammer's phone numbers.\n\n\n*** Confidence tricks ***\nOnce a victim has contacted a scammer, the scammer will usually instruct them to download and install a remote access program such as TeamViewer, AnyDesk, LogMeIn or GoToAssist. The scammer convinces the victim to provide them with the credentials required to initiate a remote-control session, giving the scammer complete control of the victim's desktop.After gaining access, the scammer attempts to convince the victim that the computer is suffering from problems that must be repaired, most often as the putative result of malicious hacking activity. Scammers use several methods to misrepresent the content and significance of common Windows tools and system directories as evidence of malicious activity, such as viruses and other malware. These tricks are meant to target victims who may be unfamiliar with the actual uses of these tools, such as inexperienced users and senior citizens. The scammer then coaxes the victim into paying for the scammer's services or software, which they claim is designed to \"repair\" or \"clean\" the computer but is actually malware that infects it or software that causes other damage, or does nothing at all.\nThe scammer may direct users to Windows' Event Viewer, which displays a logfile of various events for use by system administrators to troubleshoot problems. Although many of the log entries are relatively harmless notifications, the scammer may claim that log entries labeled as warnings and errors are evidence of malware activity or that the computer is becoming corrupted, and must be \"fixed\".\nThe scammer may show system folders that contain unusually named files to the victim, such as Windows' Prefetch and Temp folders, and claim that the files are evidence of malware on the victim's computer. The scammer may open some of these files in Notepad, where the file contents are rendered as mojibake. The scammer claims that malware has corrupted these files, causing the unintelligible output. In reality, the files in Prefetch are typically harmless, intact binary files used to speed up certain operations.\nThe scammer may claim that normally disabled services should not be disabled, when not all services need to be enabled.\nThe scammer may misuse Command Prompt tools to generate suspicious-looking output, for instance using the tree or dir /s command which displays an extensive listing of files and directories. The scammer may claim that the utility is a malware scanner, and while the tool is running the scammer will enter text purporting to be an error message (such as \"security breach ... trojans found\") that will appear when the job finishes, or into a blank Notepad document.\nThe scammer may misrepresent values and keys stored in the Windows Registry as being malicious, such as innocuous keys whose values are listed as not being set.\nThe \"Send To\" Windows function is associated with a globally unique identifier. The output of the command assoc, which lists all file associations on the system, displays this association with the line ZFSendToTarget\n\n== Response ==\nLegal action has been taken against some companies carrying out technical support scams. In December 2014, Microsoft filed a lawsuit against a California-based company operating such scams for \"misusing Microsoft's name and trademarks\" and \"creating security issues for victims by gaining access to their computers and installing malicious software, including a password grabber that could provide access to personal and financial information\". In December 2015, the state of Washington sued the firm iYogi for scamming consumers and making false claims in order to scare the users into buying iYogi's diagnostic software. iYogi was also accused of falsely claiming that they were affiliated with Microsoft, Hewlett-Packard and Apple.In September 2011, Microsoft dropped gold partner Comantra from its Microsoft Partner Network following accusations of involvement in cold-call technical-support scams. However, the ease of which companies that carry out technical support scams can be launched makes it difficult to prevent tech support scams from taking place.Major search engines such as Bing and Google have taken steps to restrict the promotion of fake technical support websites through keyword advertising. Microsoft-owned advertising network Bing Ads (which services ad sales on Bing and Yahoo! Search engines) amended its terms of service in May 2016 to prohibit the advertising of third-party technical support services or ads claiming to \"provide a service that can only be provided by the actual owner of the products or service advertised\". Google announced a verification program in 2018 in an attempt to restrict advertising for third-party tech support to legitimate companies.\n\n\n*** Scam baiting ***\n\nTech support scammers are regularly targeted by scam baiting, with individuals seeking to raise awareness of these scams by uploading recordings on platforms like YouTube, cause scammers inconvenience by wasting their time and protect potential victims.Advanced scam baiters may infiltrate the scammer's computer, and potentially disable it by deploying RATs, distributed denial of service attacks and destructive malware. Scam baiters may also attempt to lure scammers into exposing their unethical practices by leaving dummy files or malware disguised as confidential information such as credit/debit card information and passwords on a virtual machine, which the scammer may attempt to steal, only to become infected. Sensitive information important to carrying out further investigations by a law enforcement agency may be retrieved, and additional information on the rogue firm may then be posted or compiled online to warn potential victims.In March 2020, an anonymous YouTuber under the alias Jim Browning successfully infiltrated and gathered drone and CCTV footage of a fraudulent call centre scam operation through the help of fellow YouTube personality Karl Rock. Through the aid of the British documentary programme Panorama, a police raid was carried out when the documentary was brought to the attention of assistant police commissioner Karan Goel, leading to the arrest of call centre operator Amit Chauhan who also operated a fraudulent travel agency under the name \"Faremart Travels\".\n\nQuestion: How have legal actions been taken against companies carrying out technical support scams?\n\nAnswer:",
    "context": "",
    "output": "Legal actions against companies carrying out technical support scams include lawsuits brought against companies for misusing trademarks and creating security issues for victims. Companies have also been accused of falsely claiming affiliation with legitimate third parties and making false claims to scare users into buying their software.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How have legal actions been taken against companies carrying out technical support scams?",
      "answer": "Legal actions against companies carrying out technical support scams include lawsuits brought against companies for misusing trademarks and creating security issues for victims. Companies have also been accused of falsely claiming affiliation with legitimate third parties and making false claims to scare users into buying their software.",
      "context": "Technical support scam\n\n==Introduction==\nA technical support scam, or tech support scam, is a type of fraud in which a scammer claims to offer a legitimate technical support service. Victims contact scammers in a variety of ways, often through fake pop-ups resembling error messages or via fake \"help lines\" advertised on websites owned by the scammers. Technical support scammers use social engineering and a variety of confidence tricks to persuade their victim of the presence of problems on their computer or mobile device, such as a malware infection, when there are no issues with the victim's device. The scammer will then persuade the victim to pay to fix the fictitious \"problems\" that they claim to have found. Payment is made to the scammer through ways which are hard to trace and have fewer consumer protections in place which could allow the victim to claim their money back, usually through gift cards.\nTechnical support scams have occurred as early as 2008. A 2017 study of technical support scams found that of the IPs that could be geolocated, 85% could be traced to locations in India, 7% to locations in the United States and 3% to locations in Costa Rica.  Research into tech support scams suggests that millennials and those in generation Z have the highest exposure to such scams; however, senior citizens are more likely to fall for these scams and lose money to them. Technical support scams were named by Norton as the top phishing threat to consumers in October 2021; Microsoft found that 60% of consumers who took part in a survey had been exposed to a technical support scam within the previous twelve months. Responses to technical support scams include lawsuits brought against companies responsible for running fraudulent call centres and scam baiting.\n\n== Origin and distribution ==\nThe first tech support scams were recorded in 2008. Technical support scams have been seen in a variety of countries, including the United States, Canada, United Kingdom, Ireland, Australia, New Zealand, India and South Africa.A 2017 study of technical support scams published at the NDSS Symposium found that, of the tech support scams in which the IPs involved could be geolocated, 85% could be traced to locations in India, 7% to locations in the United States and 3% to locations in Costa Rica. India has millions of English speakers who are competing for relatively few jobs. One municipality had 114 jobs and received 19,000 applicants. This high level of unemployment serves as an incentive for tech scamming jobs, which are often well-paid. Additionally, scammers exploit the levels of unemployment by offering jobs to people desperate to be employed. Many scammers do not realise they are applying and being trained for tech support scam jobs, but many decide to stay after finding out the nature of their job as they feel it is too late to back out of the job and change careers.  Scammers are forced to choose between keeping their job or becoming jobless. Some scammers convince themselves that they are targeting wealthy people that have money to spare, which justifies their theft, whilst others see their job as generating \"easy money\".\n\n== Operation ==\nTechnical support scams rely on social engineering to persuade victims that their device is infected with malware. Scammers use a variety of confidence tricks to persuade the victim to install remote desktop software, with which the scammer can then take control of the victim's computer. With this access, the scammer may then launch various Windows components and utilities (such as the Event Viewer), install third-party utilities (such as rogue security software) and perform other tasks in an effort to convince the victim that the computer has critical problems that must be remediated, such as infection with a virus. Scammers target a variety of people, though research by Microsoft suggests that millennials (defined by Microsoft as age 24-37) and people part of generation Z (age 18-23) have the highest exposure to tech support scams and the Federal Trade Commission has found that seniors (age 60 and over) are more likely to lose money to tech support scams. The scammer will urge the victim to pay so the \"issues\" can be fixed.\n\n\n*** Initiation ***\n\nTechnical support scams can begin in a variety of ways. Some variants of the scam are initiated using pop-up advertising on infected websites or via cybersquatting of major websites. The victim is shown pop-ups which resemble legitimate error messages such as a Blue Screen of Death and freeze the victim's web browser. The pop-up instructs the victim to call the scammers via a phone number to fix the \"error\". Technical support scams can also be initiated via cold calls. These are usually robocalls which claim to be associated with a legitimate third party such as Microsoft or Apple. Technical support scams can also attract victims by purchasing keyword advertising on major search engines for phrases such as \"Microsoft support\". Victims who click on these adverts are taken to web pages containing the scammer's phone numbers.\n\n\n*** Confidence tricks ***\nOnce a victim has contacted a scammer, the scammer will usually instruct them to download and install a remote access program such as TeamViewer, AnyDesk, LogMeIn or GoToAssist. The scammer convinces the victim to provide them with the credentials required to initiate a remote-control session, giving the scammer complete control of the victim's desktop.After gaining access, the scammer attempts to convince the victim that the computer is suffering from problems that must be repaired, most often as the putative result of malicious hacking activity. Scammers use several methods to misrepresent the content and significance of common Windows tools and system directories as evidence of malicious activity, such as viruses and other malware. These tricks are meant to target victims who may be unfamiliar with the actual uses of these tools, such as inexperienced users and senior citizens. The scammer then coaxes the victim into paying for the scammer's services or software, which they claim is designed to \"repair\" or \"clean\" the computer but is actually malware that infects it or software that causes other damage, or does nothing at all.\nThe scammer may direct users to Windows' Event Viewer, which displays a logfile of various events for use by system administrators to troubleshoot problems. Although many of the log entries are relatively harmless notifications, the scammer may claim that log entries labeled as warnings and errors are evidence of malware activity or that the computer is becoming corrupted, and must be \"fixed\".\nThe scammer may show system folders that contain unusually named files to the victim, such as Windows' Prefetch and Temp folders, and claim that the files are evidence of malware on the victim's computer. The scammer may open some of these files in Notepad, where the file contents are rendered as mojibake. The scammer claims that malware has corrupted these files, causing the unintelligible output. In reality, the files in Prefetch are typically harmless, intact binary files used to speed up certain operations.\nThe scammer may claim that normally disabled services should not be disabled, when not all services need to be enabled.\nThe scammer may misuse Command Prompt tools to generate suspicious-looking output, for instance using the tree or dir /s command which displays an extensive listing of files and directories. The scammer may claim that the utility is a malware scanner, and while the tool is running the scammer will enter text purporting to be an error message (such as \"security breach ... trojans found\") that will appear when the job finishes, or into a blank Notepad document.\nThe scammer may misrepresent values and keys stored in the Windows Registry as being malicious, such as innocuous keys whose values are listed as not being set.\nThe \"Send To\" Windows function is associated with a globally unique identifier. The output of the command assoc, which lists all file associations on the system, displays this association with the line ZFSendToTarget\n\n== Response ==\nLegal action has been taken against some companies carrying out technical support scams. In December 2014, Microsoft filed a lawsuit against a California-based company operating such scams for \"misusing Microsoft's name and trademarks\" and \"creating security issues for victims by gaining access to their computers and installing malicious software, including a password grabber that could provide access to personal and financial information\". In December 2015, the state of Washington sued the firm iYogi for scamming consumers and making false claims in order to scare the users into buying iYogi's diagnostic software. iYogi was also accused of falsely claiming that they were affiliated with Microsoft, Hewlett-Packard and Apple.In September 2011, Microsoft dropped gold partner Comantra from its Microsoft Partner Network following accusations of involvement in cold-call technical-support scams. However, the ease of which companies that carry out technical support scams can be launched makes it difficult to prevent tech support scams from taking place.Major search engines such as Bing and Google have taken steps to restrict the promotion of fake technical support websites through keyword advertising. Microsoft-owned advertising network Bing Ads (which services ad sales on Bing and Yahoo! Search engines) amended its terms of service in May 2016 to prohibit the advertising of third-party technical support services or ads claiming to \"provide a service that can only be provided by the actual owner of the products or service advertised\". Google announced a verification program in 2018 in an attempt to restrict advertising for third-party tech support to legitimate companies.\n\n\n*** Scam baiting ***\n\nTech support scammers are regularly targeted by scam baiting, with individuals seeking to raise awareness of these scams by uploading recordings on platforms like YouTube, cause scammers inconvenience by wasting their time and protect potential victims.Advanced scam baiters may infiltrate the scammer's computer, and potentially disable it by deploying RATs, distributed denial of service attacks and destructive malware. Scam baiters may also attempt to lure scammers into exposing their unethical practices by leaving dummy files or malware disguised as confidential information such as credit/debit card information and passwords on a virtual machine, which the scammer may attempt to steal, only to become infected. Sensitive information important to carrying out further investigations by a law enforcement agency may be retrieved, and additional information on the rogue firm may then be posted or compiled online to warn potential victims.In March 2020, an anonymous YouTuber under the alias Jim Browning successfully infiltrated and gathered drone and CCTV footage of a fraudulent call centre scam operation through the help of fellow YouTube personality Karl Rock. Through the aid of the British documentary programme Panorama, a police raid was carried out when the documentary was brought to the attention of assistant police commissioner Karan Goel, leading to the arrest of call centre operator Amit Chauhan who also operated a fraudulent travel agency under the name \"Faremart Travels\"."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can Snare's customizable architecture benefit different types of organizations?",
    "context": "",
    "output": "Snare's customizable architecture can benefit different types of organizations by allowing them to tailor the solution to their specific needs. Organizations can choose between commercial and open-source versions, select the most suitable agents for their systems, and configure the central server to provide the required analysis, reporting, and archival capabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can Snare's customizable architecture benefit different types of organizations?",
      "answer": "Snare's customizable architecture can benefit different types of organizations by allowing them to tailor the solution to their specific needs. Organizations can choose between commercial and open-source versions, select the most suitable agents for their systems, and configure the central server to provide the required analysis, reporting, and archival capabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the AIX operating system materialize the trusted computing base?",
    "context": "",
    "output": "The AIX operating system materializes the trusted computing base as an optional component in its install-time package management system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the AIX operating system materialize the trusted computing base?",
      "answer": "The AIX operating system materializes the trusted computing base as an optional component in its install-time package management system."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the portability of XOFTspy Anti-Spyware benefit users in terms of removing malware?",
    "context": "",
    "output": "The portability of XOFTspy Anti-Spyware allows it to run from a USB drive and protect users from malicious threats even if the computer is heavily infected, bogged down, or sluggish. This is useful because the software can clean the computer directly from the U3 device, which can remove malware items that the computer may not be able to download or run other anti-spyware programs.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the portability of XOFTspy Anti-Spyware benefit users in terms of removing malware?",
      "answer": "The portability of XOFTspy Anti-Spyware allows it to run from a USB drive and protect users from malicious threats even if the computer is heavily infected, bogged down, or sluggish. This is useful because the software can clean the computer directly from the U3 device, which can remove malware items that the computer may not be able to download or run other anti-spyware programs."
    }
  },
  {
    "instruction": "Context: ExpressVPN\n\n==Introduction==\nExpressVPN is a VPN service offered by the British Virgin Islands-registered company Express Technologies Ltd. The software is marketed as a privacy and security tool that encrypts users' web traffic and masks their IP addresses.As of September 2021, ExpressVPN is owned by Kape Technologies and reportedly has 4 million users.\n\n== Features ==\nExpressVPN has released apps for Windows, macOS, iOS, Android, Linux, and routers. The apps use a 4096-bit CA, AES-256-CBC encryption, and TLSv1.2 to secure user traffic. Available VPN protocols include Lightway, OpenVPN (with TCP/UDP), SSTP, L2TP/IPSec, and PPTP.The software also features a Smart DNS feature called MediaStreamer, to add VPN capabilities to devices that do not support them, and a router app, allowing the VPN to be set up on a router, bypassing unsupported devices such as gaming consoles.ExpressVPN is incorporated in the British Virgin Islands, a privacy-friendly country that has no data retention laws, and is a separate legal jurisdiction to the United Kingdom.ExpressVPN's parent company also develops leak testing tools, which enable users to determine if their VPN provider is leaking network traffic, DNS, or true IP addresses while connected to the VPN, such as when switching from a wireless to a wired internet connection.In December 2021, ExpressVPN modified its product to protect against Log4Shell, updating its VPN to automatically block all outgoing traffic on ports used by LDAP.In January 2022, ExpressVPN launched Parallel Connections, a backend feature which simultaneously runs multiple methods of connecting a user to a given server, automatically picking the one that connects a user first.ExpressVPN launched Aircove, a Wi-Fi 6 router that includes a built-in VPN, in September 2022. Aircove permits speeds up to 1,200 Mbps (600 Mbps for 2.4GHz and 1,200 Mbps for 5GHz), covers areas up to 1,600 sq feet, and offers a quad-core 64-bit processor.\n\n\n*** TrustedServer ***\nIn April 2019, ExpressVPN announced that all their VPN servers ran solely on random-access memory (RAM), without the need of hard disk drives. In theory, as soon as a computer is shut down, all information on the server vanishes and cannot be recovered; the next time the server reboots, a fresh version of the VPN infrastructure is spawned. This was the first example in the VPN industry for such a server security setup, and was referred to as TrustedServer.In February 2022, ExpressVPN announced a $100,000 bug bounty for anyone who was able to hack its in-house technology, TrustedServer.As of August 2022, ExpressVPN's server network covered 94 countries.\n\n\n*** Lightway protocol ***\nLightway is ExpressVPN's open source VPN protocol. Launched in 2020, it is similar to the WireGuard protocol, but uses wolfSSL encryption to improve speed on embedded devices such as routers and smartphones. It does not run in the operating system's kernel, but is lightweight to support auditing. It is reportedly 2.5x as fast as OpenVPN and other older protocols, improves reliability by 40%, and supports TCP and UDP.In August 2021, ExpressVPN announced the full public release of Lightway as well as full open-sourcing of Lightway\u2019s code.\n\n== Research ==\nIn 2020, ExpressVPN announced its new digital security research initiative Digital Security Lab, which investigates digital rights and security issues while educating consumers.In 2021, Digital Security Lab released a new report that examined data collection practices in apps for opioid addiction and recovery. Research found that the large majority of all these apps provided third parties, including Facebook, Stripe, Inc., and Google, access to user data. In a similar 2021 study, Digital Security Lab analyzed 450 apps and found that all studied apps contained questionable location trackers. Digital Security Lab also conducted a study on Generation Z\u2019s mental health, finding that 86% of Gen Z participants perceived that social media had a direct impact on their happiness.A 2022 survey on remote workers found that 78% of employers digitally monitor their employees without staff knowledge.\n\nQuestion: How does ExpressVPN's Aircove router support auditing?\n\nAnswer:",
    "context": "",
    "output": "ExpressVPN's Aircove router supports auditing by using Lightway, an open-source VPN protocol that does not run in the operating system's kernel. This allows for easier auditing and validation of the VPN protocol and the router's firmware, ensuring that there are no backdoors or vulnerabilities that could be exploited by attackers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does ExpressVPN's Aircove router support auditing?",
      "answer": "ExpressVPN's Aircove router supports auditing by using Lightway, an open-source VPN protocol that does not run in the operating system's kernel. This allows for easier auditing and validation of the VPN protocol and the router's firmware, ensuring that there are no backdoors or vulnerabilities that could be exploited by attackers.",
      "context": "ExpressVPN\n\n==Introduction==\nExpressVPN is a VPN service offered by the British Virgin Islands-registered company Express Technologies Ltd. The software is marketed as a privacy and security tool that encrypts users' web traffic and masks their IP addresses.As of September 2021, ExpressVPN is owned by Kape Technologies and reportedly has 4 million users.\n\n== Features ==\nExpressVPN has released apps for Windows, macOS, iOS, Android, Linux, and routers. The apps use a 4096-bit CA, AES-256-CBC encryption, and TLSv1.2 to secure user traffic. Available VPN protocols include Lightway, OpenVPN (with TCP/UDP), SSTP, L2TP/IPSec, and PPTP.The software also features a Smart DNS feature called MediaStreamer, to add VPN capabilities to devices that do not support them, and a router app, allowing the VPN to be set up on a router, bypassing unsupported devices such as gaming consoles.ExpressVPN is incorporated in the British Virgin Islands, a privacy-friendly country that has no data retention laws, and is a separate legal jurisdiction to the United Kingdom.ExpressVPN's parent company also develops leak testing tools, which enable users to determine if their VPN provider is leaking network traffic, DNS, or true IP addresses while connected to the VPN, such as when switching from a wireless to a wired internet connection.In December 2021, ExpressVPN modified its product to protect against Log4Shell, updating its VPN to automatically block all outgoing traffic on ports used by LDAP.In January 2022, ExpressVPN launched Parallel Connections, a backend feature which simultaneously runs multiple methods of connecting a user to a given server, automatically picking the one that connects a user first.ExpressVPN launched Aircove, a Wi-Fi 6 router that includes a built-in VPN, in September 2022. Aircove permits speeds up to 1,200 Mbps (600 Mbps for 2.4GHz and 1,200 Mbps for 5GHz), covers areas up to 1,600 sq feet, and offers a quad-core 64-bit processor.\n\n\n*** TrustedServer ***\nIn April 2019, ExpressVPN announced that all their VPN servers ran solely on random-access memory (RAM), without the need of hard disk drives. In theory, as soon as a computer is shut down, all information on the server vanishes and cannot be recovered; the next time the server reboots, a fresh version of the VPN infrastructure is spawned. This was the first example in the VPN industry for such a server security setup, and was referred to as TrustedServer.In February 2022, ExpressVPN announced a $100,000 bug bounty for anyone who was able to hack its in-house technology, TrustedServer.As of August 2022, ExpressVPN's server network covered 94 countries.\n\n\n*** Lightway protocol ***\nLightway is ExpressVPN's open source VPN protocol. Launched in 2020, it is similar to the WireGuard protocol, but uses wolfSSL encryption to improve speed on embedded devices such as routers and smartphones. It does not run in the operating system's kernel, but is lightweight to support auditing. It is reportedly 2.5x as fast as OpenVPN and other older protocols, improves reliability by 40%, and supports TCP and UDP.In August 2021, ExpressVPN announced the full public release of Lightway as well as full open-sourcing of Lightway\u2019s code.\n\n== Research ==\nIn 2020, ExpressVPN announced its new digital security research initiative Digital Security Lab, which investigates digital rights and security issues while educating consumers.In 2021, Digital Security Lab released a new report that examined data collection practices in apps for opioid addiction and recovery. Research found that the large majority of all these apps provided third parties, including Facebook, Stripe, Inc., and Google, access to user data. In a similar 2021 study, Digital Security Lab analyzed 450 apps and found that all studied apps contained questionable location trackers. Digital Security Lab also conducted a study on Generation Z\u2019s mental health, finding that 86% of Gen Z participants perceived that social media had a direct impact on their happiness.A 2022 survey on remote workers found that 78% of employers digitally monitor their employees without staff knowledge."
    }
  },
  {
    "instruction": "context: The function h in Cohen's cryptosystem is used to decrypt the ciphertext and obtain the plaintext bit m.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the role of the function h in Cohen's cryptosystem?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the function h in Cohen's cryptosystem?",
      "answer": "The function h in Cohen's cryptosystem is used to decrypt the ciphertext and obtain the plaintext bit m."
    }
  },
  {
    "instruction": "Context: Searchable symmetric encryption\n\n==Introduction==\nSearchable symmetric encryption (SSE) is a form of encryption that allows one to efficiently search over a collection of encrypted documents or files without the ability to decrypt them. SSE can be used to outsource files to an untrusted cloud storage server without ever revealing the files in the clear but while preserving the server's ability to search over them.\n\n== Description ==\nA searchable symmetric encryption scheme is a symmetric-key encryption scheme that encrypts a collection of documents  \n  \n    \n      \n        \n          D\n\n== History of Searchable Symmetric Encryption ==\nThe problem of searching on encrypted data was considered by Song, Wagner and Perrig though previous work on Oblivious RAM by Goldreich and Ostrovsky could be used in theory to address the problem. This work proposed an SSE scheme with a search algorithm that runs in time \n  \n    \n      \n        O\n        (\n        s\n        )\n      \n    \n    {\\displaystyle O(s)}\n  , where \n  \n    \n      \n        s\n\n== Security ==\nSSE schemes are designed to guarantee that the untrusted server cannot learn any partial information about the documents or the search queries beyond some well-defined and reasonable leakage. The leakage of a scheme is formally described using a leakage profile which itself can consists of several leakage patterns. SSE constructions attempt to minimize leakage while achieving the best possible search efficiency. \nSSE security can be analyzed in several adversarial models but the most common are: \n\nthe persistent model, where an adversary is given the encrypted data collection and a transcript of all the operations executed on the collection;\nthe snapshot model, where an adversary is only given the encrypted data collection (but possibly after each operation).\n\n\n*** Security in the Persistent Model ***\nIn the persistent model, there are SSE schemes that achieve a wide variety of leakage profiles. The most common leakage profile for static schemes that achieve single keyword search in optimal time is \n  \n    \n      \n        \n          \u039b\n          \n            \n              o\n              p\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle \\Lambda _{\\mathrm {opt} }}\n   which reveals the number of documents in the collection, the size of each document in the  collection, if and when a query was repeated and which encrypted documents match the search query. It is known, however, how to construct schemes that leak considerably less at an additional cost in search time and storage.When considering dynamic SSE schemes, the state-of-the-art constructions with optimal time search have leakage profiles that guarantee forward privacy which means that inserts cannot be correlated with past search queries. \n\n\n*** Security in the Snapshot Model ***\nIn the snapshot model, efficient dynamic SSE schemes with no leakage beyond the number of documents and the size of the collection can be constructed. When using an SSE construction that is secure in the snapshot model one has to carefully consider how the scheme will be deployed because some systems might cache previous search queries.\n\n\n*** Cryptanalysis ***\nA leakage profile only describes the leakage of an SSE scheme but it says nothing about whether that leakage can be exploited or not. Cryptanalysis is therefore used to better understand the real-world security of a leakage profile. There is a wide variety of attacks working in different adversarial models, based on a variety of assumptions and attacking different leakage profiles.\n\nQuestion: Can SSE schemes leak information beyond the documents and their sizes in the encrypted data collection?\n\nAnswer:",
    "context": "",
    "output": "Yes, SSE schemes can leak information beyond the documents and their sizes in the encrypted data collection, depending on the leakage profile of the SSE scheme.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can SSE schemes leak information beyond the documents and their sizes in the encrypted data collection?",
      "answer": "Yes, SSE schemes can leak information beyond the documents and their sizes in the encrypted data collection, depending on the leakage profile of the SSE scheme.",
      "context": "Searchable symmetric encryption\n\n==Introduction==\nSearchable symmetric encryption (SSE) is a form of encryption that allows one to efficiently search over a collection of encrypted documents or files without the ability to decrypt them. SSE can be used to outsource files to an untrusted cloud storage server without ever revealing the files in the clear but while preserving the server's ability to search over them.\n\n== Description ==\nA searchable symmetric encryption scheme is a symmetric-key encryption scheme that encrypts a collection of documents  \n  \n    \n      \n        \n          D\n\n== History of Searchable Symmetric Encryption ==\nThe problem of searching on encrypted data was considered by Song, Wagner and Perrig though previous work on Oblivious RAM by Goldreich and Ostrovsky could be used in theory to address the problem. This work proposed an SSE scheme with a search algorithm that runs in time \n  \n    \n      \n        O\n        (\n        s\n        )\n      \n    \n    {\\displaystyle O(s)}\n  , where \n  \n    \n      \n        s\n\n== Security ==\nSSE schemes are designed to guarantee that the untrusted server cannot learn any partial information about the documents or the search queries beyond some well-defined and reasonable leakage. The leakage of a scheme is formally described using a leakage profile which itself can consists of several leakage patterns. SSE constructions attempt to minimize leakage while achieving the best possible search efficiency. \nSSE security can be analyzed in several adversarial models but the most common are: \n\nthe persistent model, where an adversary is given the encrypted data collection and a transcript of all the operations executed on the collection;\nthe snapshot model, where an adversary is only given the encrypted data collection (but possibly after each operation).\n\n\n*** Security in the Persistent Model ***\nIn the persistent model, there are SSE schemes that achieve a wide variety of leakage profiles. The most common leakage profile for static schemes that achieve single keyword search in optimal time is \n  \n    \n      \n        \n          \u039b\n          \n            \n              o\n              p\n              t\n            \n          \n        \n      \n    \n    {\\displaystyle \\Lambda _{\\mathrm {opt} }}\n   which reveals the number of documents in the collection, the size of each document in the  collection, if and when a query was repeated and which encrypted documents match the search query. It is known, however, how to construct schemes that leak considerably less at an additional cost in search time and storage.When considering dynamic SSE schemes, the state-of-the-art constructions with optimal time search have leakage profiles that guarantee forward privacy which means that inserts cannot be correlated with past search queries. \n\n\n*** Security in the Snapshot Model ***\nIn the snapshot model, efficient dynamic SSE schemes with no leakage beyond the number of documents and the size of the collection can be constructed. When using an SSE construction that is secure in the snapshot model one has to carefully consider how the scheme will be deployed because some systems might cache previous search queries.\n\n\n*** Cryptanalysis ***\nA leakage profile only describes the leakage of an SSE scheme but it says nothing about whether that leakage can be exploited or not. Cryptanalysis is therefore used to better understand the real-world security of a leakage profile. There is a wide variety of attacks working in different adversarial models, based on a variety of assumptions and attacking different leakage profiles."
    }
  },
  {
    "instruction": "Context: YapBrowser\n\n==Introduction==\nYapBrowser, also known as YapSearch or YapCash, is a rogue Web browser that was removed from the Internet after security researchers found it was serving up child porn advertising. It eventually reappeared [1], with a peculiar twist; it now came with the odd claim that users could expect protection from harmful exploits and viruses.\nThe site hosting the browser download originates from Russia and includes an \"adult version\" that lets users search for and browse pornography-themed content for free.\nThe site even offers a \"100% guarantee\" that no malicious system infection will occur when using the software, but security researchers tracking the seedier side of the Internet have flagged YapBrowser as a serious threat to computer users.\nThe first sign of YapBrowser trouble came in April 2006 when malware researchers discovered that the browser was serving up spyware and underage porn advertising.\nMcAfee flags YapBrowser as a \"potentially unwanted program\" that directs the user to use the yapsearch.com search portal.\nIt appears that YapBrowser is primarily a front-end for an Internet Explorer HTML rendering engine that uses commercial links to push users to other shopping search portals.\nIn June 2006 YapBrowser was acquired by Search engine MyAllSearch.com. \n\n\n\n\n\nQuestion: What is YapBrowser and what are its origins, despite its misleading claims of providing protection from harmful exploits and viruses?\n\nAnswer:",
    "context": "",
    "output": "YapBrowser, also known as YapSearch or YapCash, is a rogue Web browser that originates from Russia. Initially, it was found serving up child porn advertising and later reappeared with a claim of offering protection from harmful exploits and viruses. Security researchers, however, have flagged it as a serious threat to computer users.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is YapBrowser and what are its origins, despite its misleading claims of providing protection from harmful exploits and viruses?",
      "answer": "YapBrowser, also known as YapSearch or YapCash, is a rogue Web browser that originates from Russia. Initially, it was found serving up child porn advertising and later reappeared with a claim of offering protection from harmful exploits and viruses. Security researchers, however, have flagged it as a serious threat to computer users.",
      "context": "YapBrowser\n\n==Introduction==\nYapBrowser, also known as YapSearch or YapCash, is a rogue Web browser that was removed from the Internet after security researchers found it was serving up child porn advertising. It eventually reappeared [1], with a peculiar twist; it now came with the odd claim that users could expect protection from harmful exploits and viruses.\nThe site hosting the browser download originates from Russia and includes an \"adult version\" that lets users search for and browse pornography-themed content for free.\nThe site even offers a \"100% guarantee\" that no malicious system infection will occur when using the software, but security researchers tracking the seedier side of the Internet have flagged YapBrowser as a serious threat to computer users.\nThe first sign of YapBrowser trouble came in April 2006 when malware researchers discovered that the browser was serving up spyware and underage porn advertising.\nMcAfee flags YapBrowser as a \"potentially unwanted program\" that directs the user to use the yapsearch.com search portal.\nIt appears that YapBrowser is primarily a front-end for an Internet Explorer HTML rendering engine that uses commercial links to push users to other shopping search portals.\nIn June 2006 YapBrowser was acquired by Search engine MyAllSearch.com. \n\n\n\n"
    }
  },
  {
    "instruction": "context: The breach of Kaspersky Lab in 2014 was significant in the context of international negotiations with Iran as the malware, Duqu 2.0, was found on computers in hotels in Austria and Switzerland hosting the negotiations. This breach potentially allowed for the retrieval of sensitive data related to the negotiations. The New York Times alleges that this incident enabled Israel to inform the US of Russian hackers using Kaspersky software to collect confidential information, which could have influenced the negotiations.\n\nAsk a question about this context.",
    "context": "",
    "output": "How was the breach of Kaspersky Lab in 2014 significant in the context of international negotiations with Iran over its nuclear program and economic sanctions?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How was the breach of Kaspersky Lab in 2014 significant in the context of international negotiations with Iran over its nuclear program and economic sanctions?",
      "answer": "The breach of Kaspersky Lab in 2014 was significant in the context of international negotiations with Iran as the malware, Duqu 2.0, was found on computers in hotels in Austria and Switzerland hosting the negotiations. This breach potentially allowed for the retrieval of sensitive data related to the negotiations. The New York Times alleges that this incident enabled Israel to inform the US of Russian hackers using Kaspersky software to collect confidential information, which could have influenced the negotiations."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can netcat be used as a proxy, and what are the benefits of using it in this way?",
    "context": "",
    "output": "Netcat can act as a proxy by redirecting ports and hosts. This can be useful for various purposes, such as testing network configurations, bypassing firewalls, or monitoring network traffic. Using netcat as a proxy also allows for flexibility and customization, as users can define their own rules and settings for handling connections and data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can netcat be used as a proxy, and what are the benefits of using it in this way?",
      "answer": "Netcat can act as a proxy by redirecting ports and hosts. This can be useful for various purposes, such as testing network configurations, bypassing firewalls, or monitoring network traffic. Using netcat as a proxy also allows for flexibility and customization, as users can define their own rules and settings for handling connections and data."
    }
  },
  {
    "instruction": "context: IPFire is developed as a stateful packet inspection (SPI) firewall and separates the network into different segments based on their security risk. Normal clients connected to the LAN are represented as green, the Internet is represented as red, an optional DMZ is represented as orange and an optional Wireless network is represented as blue. No traffic can flow between segments unless specifically permitted through a firewall rule.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does IPFire handle network security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does IPFire handle network security?",
      "answer": "IPFire is developed as a stateful packet inspection (SPI) firewall and separates the network into different segments based on their security risk. Normal clients connected to the LAN are represented as green, the Internet is represented as red, an optional DMZ is represented as orange and an optional Wireless network is represented as blue. No traffic can flow between segments unless specifically permitted through a firewall rule."
    }
  },
  {
    "instruction": "ANOM\n\n==Introduction==\nThe ANOM (also stylized as AN0M or \u039bN\u00d8M) sting operation (known as Operation Trojan Shield (stylized TR\u00d8JAN SHIELD) or  Operation Ironside) is a collaboration by law enforcement agencies from several countries, running between 2018 and 2021, that intercepted millions of messages sent through the supposedly secure smartphone-based messaging app ANOM. The ANOM service was widely used by criminals, but instead of providing secure communication, it was actually a trojan horse covertly distributed by the United States Federal Bureau of Investigation (FBI) and the Australian Federal Police (AFP), enabling them to monitor all communications. Through collaboration with other law enforcement agencies worldwide, the operation resulted in the arrest of over 800 suspects allegedly involved in criminal activity, in 16 countries. Among the arrested people were alleged members of Australian-based Italian mafia, Albanian organised crime, outlaw motorcycle clubs, drug syndicates and other organised crime groups.\n\n== Background ==\nThe shutdown of the Canadian secure messaging company Phantom Secure in March 2018 left international criminals in need of an alternative system for secure communication. Around the same time, the San Diego FBI branch had been working with a person who had been developing a \"next-generation\" encrypted device for use by criminal networks. The person was facing charges and cooperated with the FBI in exchange for a reduced sentence. The person offered to develop ANOM and then distribute it to criminals through their existing networks. The first communication devices with ANOM were offered by this informant to three former distributors of Phantom Secure in October 2018.The FBI also negotiated with an unnamed third country to set up a communication interception, but based on a court order that allowed passing the information back to the FBI. Since October 2019, ANOM communications have been passed on to the FBI from this third country.The FBI named the operation \"Trojan Shield\", and the AFP named it \"Ironside\". Europol set up the Operational Task Force Greenlight.\n\n== Distribution and usage ==\n\nThe ANOM devices consisted of a messaging app running on Android smartphones that had been specially modified to disable normal functions such as voice telephony, email, or location services, and with the addition of PIN entry screen scrambling to randomise the layout of the numbers, the deletion of all information on the phone if a specific PIN is entered, and the option for the automatic deletion of all information if unused for a specific period of time.The app was opened by entering a specific calculation within the calculator app, described by the developer of GrapheneOS as \"quite amusing security theater\", where the messaging app then communicated with other devices via supposedly secure proxy servers, which also \u2013 unknown to the app's users \u2013 copied all sent messages to servers controlled by the FBI. The FBI could then decrypt the messages with a private key associated with the message, without ever needing remote access to the devices. The devices also had a fixed identification number assigned to each user, allowing messages from the same user to be connected to each other.About 50 devices were distributed in Australia for beta testing from October 2018. The intercepted communications showed that every device was used for criminal activities, primarily being used by organised criminal gangs. About 125 devices were shipped to different drop-off points to the United States in 2020.Use of the app spread through word of mouth, and was also encouraged by undercover agents; drug trafficker Hakan Ayik was identified \"as someone who was trusted and was going to be able to successfully distribute this platform\", and without his knowledge was encouraged by undercover agents to use and sell the devices on the black market, further expanding its use. After users of the devices requested smaller and newer phones, new devices were designed and sold; customer service and technical assistance was also provided by the company. The most commonly used languages on the app were Dutch, German and Swedish.After a slow start, the rate of distribution of ANOM increased from mid-2019. By October 2019, there were several hundred users. By May 2021, there had been 11,800 devices with ANOM installed, of which about 9,000 were in use. New Zealand had 57 users of the ANOM communication system. The Swedish Police had access to conversations from 1,600 users, of which they focused their surveillance on 600 users. Europol stated 27 million messages were collected from ANOM devices across over 100 countries.Some skepticism of the app did exist; one March 2021 WordPress blog post called the app a scam.\n\n== Arrests and reactions ==\n\nThe sting operation culminated in search warrants that were executed simultaneously around the globe on 8 June 2021. It is not entirely clear why this date was chosen, but news organisations have speculated it might be related to a warrant for server access expiring on 7 June. The background to the sting operation and its transnational nature was revealed following the execution of the search warrants. Over 800 people were arrested in 16 countries. Among the arrested people were alleged members of Australian-based Italian mafia, Albanian organised crime, outlaw motorcycle gangs, drug syndicates and other crime groups. In the European Union, arrests were coordinated through Europol. Arrests were also made in the United Kingdom, although the National Crime Agency was unwilling to provide details about the number arrested.The seized evidence included almost 40 tons of drugs (over eight tons of cocaine, 22 tons of cannabis and cannabis resin, six tons of synthetic drug precursors, two tons of synthetic drugs), 250 guns, 55 luxury cars, and more than $48 million in various currencies and cryptocurrencies. In Australia, 224 people were arrested on 526 total charges. In New Zealand, 35 people were arrested and faced a total of 900 charges. Police seized $3.7 million in assets, including 14 vehicles, drugs, firearms and more than $1 million in cash.Over the course of the three years, more than 9,000 police officers across 18 countries were involved in the sting operation. Australian Prime Minister Scott Morrison said that the sting operation had \"struck a heavy blow against organised crime\". Europol described it as the \"biggest ever law enforcement operation against encrypted communication\".In 2022, Motherboard journalist Joseph Cox published documents stating that the FBI obtained message data through the cooperation of an unnamed country within the European Union.\n\n\n*** Australia ***\nAbout 50 of the devices had been sold in Australia. Police arrested 224 suspects and seized 104 firearms and confiscated cash and possessions valued at more than 45 million AUD.\n\n\n*** Germany ***\nIn Germany, the majority of the police activity was in the state of Hesse where 60 of the 70 nationwide suspects were arrested. Police searched 150 locations and in many cases under suspicion of drug trafficking.\n\n\n*** Netherlands ***\nIn the Netherlands, 49 people were arrested by Dutch police while they investigated 25 drug production facilities and narcotics caches. Police also seized eight firearms, large supplies of narcotics and more than 2.3 million euros.\n\n\n*** Sweden ***\n\nIn Sweden, 155 people were arrested as part of the operation. According to police in Sweden which received intelligence from the FBI, during an early phase of the operation it was discovered that many of the suspects were in Sweden. Linda Staaf, head of the Swedish police's intelligence activities, said that the suspects in Sweden had a higher rate of violent crime than the other countries.\n\n\n*** United States ***\n\nNo arrests were made in the United States because of privacy laws that prevented law enforcement from collecting messages from domestic subjects. However, the United States Department of Justice indicted seventeen persons (all foreign nationals) under the Racketeer Influenced and Corrupt Organizations Act for their participation in \"the ANOM enterprise\" which spread the devices.\n\n== Legal challenges ==\nAs of April 2023, multiple court cases have been brought in Australia to challenge the legitimacy of the ANOM sting operation. A judgment in one of the cases before the Supreme Court of South Australia has ruled in favor of the police.\n\nHow many court cases have been brought in Australia to challenge the legitimacy of the ANOM sting operation as of April 2023?",
    "context": "",
    "output": "Multiple court cases have been brought in Australia to challenge the legitimacy of the ANOM sting operation as of April 2023.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many court cases have been brought in Australia to challenge the legitimacy of the ANOM sting operation as of April 2023?",
      "answer": "Multiple court cases have been brought in Australia to challenge the legitimacy of the ANOM sting operation as of April 2023.",
      "context": "ANOM\n\n==Introduction==\nThe ANOM (also stylized as AN0M or \u039bN\u00d8M) sting operation (known as Operation Trojan Shield (stylized TR\u00d8JAN SHIELD) or  Operation Ironside) is a collaboration by law enforcement agencies from several countries, running between 2018 and 2021, that intercepted millions of messages sent through the supposedly secure smartphone-based messaging app ANOM. The ANOM service was widely used by criminals, but instead of providing secure communication, it was actually a trojan horse covertly distributed by the United States Federal Bureau of Investigation (FBI) and the Australian Federal Police (AFP), enabling them to monitor all communications. Through collaboration with other law enforcement agencies worldwide, the operation resulted in the arrest of over 800 suspects allegedly involved in criminal activity, in 16 countries. Among the arrested people were alleged members of Australian-based Italian mafia, Albanian organised crime, outlaw motorcycle clubs, drug syndicates and other organised crime groups.\n\n== Background ==\nThe shutdown of the Canadian secure messaging company Phantom Secure in March 2018 left international criminals in need of an alternative system for secure communication. Around the same time, the San Diego FBI branch had been working with a person who had been developing a \"next-generation\" encrypted device for use by criminal networks. The person was facing charges and cooperated with the FBI in exchange for a reduced sentence. The person offered to develop ANOM and then distribute it to criminals through their existing networks. The first communication devices with ANOM were offered by this informant to three former distributors of Phantom Secure in October 2018.The FBI also negotiated with an unnamed third country to set up a communication interception, but based on a court order that allowed passing the information back to the FBI. Since October 2019, ANOM communications have been passed on to the FBI from this third country.The FBI named the operation \"Trojan Shield\", and the AFP named it \"Ironside\". Europol set up the Operational Task Force Greenlight.\n\n== Distribution and usage ==\n\nThe ANOM devices consisted of a messaging app running on Android smartphones that had been specially modified to disable normal functions such as voice telephony, email, or location services, and with the addition of PIN entry screen scrambling to randomise the layout of the numbers, the deletion of all information on the phone if a specific PIN is entered, and the option for the automatic deletion of all information if unused for a specific period of time.The app was opened by entering a specific calculation within the calculator app, described by the developer of GrapheneOS as \"quite amusing security theater\", where the messaging app then communicated with other devices via supposedly secure proxy servers, which also \u2013 unknown to the app's users \u2013 copied all sent messages to servers controlled by the FBI. The FBI could then decrypt the messages with a private key associated with the message, without ever needing remote access to the devices. The devices also had a fixed identification number assigned to each user, allowing messages from the same user to be connected to each other.About 50 devices were distributed in Australia for beta testing from October 2018. The intercepted communications showed that every device was used for criminal activities, primarily being used by organised criminal gangs. About 125 devices were shipped to different drop-off points to the United States in 2020.Use of the app spread through word of mouth, and was also encouraged by undercover agents; drug trafficker Hakan Ayik was identified \"as someone who was trusted and was going to be able to successfully distribute this platform\", and without his knowledge was encouraged by undercover agents to use and sell the devices on the black market, further expanding its use. After users of the devices requested smaller and newer phones, new devices were designed and sold; customer service and technical assistance was also provided by the company. The most commonly used languages on the app were Dutch, German and Swedish.After a slow start, the rate of distribution of ANOM increased from mid-2019. By October 2019, there were several hundred users. By May 2021, there had been 11,800 devices with ANOM installed, of which about 9,000 were in use. New Zealand had 57 users of the ANOM communication system. The Swedish Police had access to conversations from 1,600 users, of which they focused their surveillance on 600 users. Europol stated 27 million messages were collected from ANOM devices across over 100 countries.Some skepticism of the app did exist; one March 2021 WordPress blog post called the app a scam.\n\n== Arrests and reactions ==\n\nThe sting operation culminated in search warrants that were executed simultaneously around the globe on 8 June 2021. It is not entirely clear why this date was chosen, but news organisations have speculated it might be related to a warrant for server access expiring on 7 June. The background to the sting operation and its transnational nature was revealed following the execution of the search warrants. Over 800 people were arrested in 16 countries. Among the arrested people were alleged members of Australian-based Italian mafia, Albanian organised crime, outlaw motorcycle gangs, drug syndicates and other crime groups. In the European Union, arrests were coordinated through Europol. Arrests were also made in the United Kingdom, although the National Crime Agency was unwilling to provide details about the number arrested.The seized evidence included almost 40 tons of drugs (over eight tons of cocaine, 22 tons of cannabis and cannabis resin, six tons of synthetic drug precursors, two tons of synthetic drugs), 250 guns, 55 luxury cars, and more than $48 million in various currencies and cryptocurrencies. In Australia, 224 people were arrested on 526 total charges. In New Zealand, 35 people were arrested and faced a total of 900 charges. Police seized $3.7 million in assets, including 14 vehicles, drugs, firearms and more than $1 million in cash.Over the course of the three years, more than 9,000 police officers across 18 countries were involved in the sting operation. Australian Prime Minister Scott Morrison said that the sting operation had \"struck a heavy blow against organised crime\". Europol described it as the \"biggest ever law enforcement operation against encrypted communication\".In 2022, Motherboard journalist Joseph Cox published documents stating that the FBI obtained message data through the cooperation of an unnamed country within the European Union.\n\n\n*** Australia ***\nAbout 50 of the devices had been sold in Australia. Police arrested 224 suspects and seized 104 firearms and confiscated cash and possessions valued at more than 45 million AUD.\n\n\n*** Germany ***\nIn Germany, the majority of the police activity was in the state of Hesse where 60 of the 70 nationwide suspects were arrested. Police searched 150 locations and in many cases under suspicion of drug trafficking.\n\n\n*** Netherlands ***\nIn the Netherlands, 49 people were arrested by Dutch police while they investigated 25 drug production facilities and narcotics caches. Police also seized eight firearms, large supplies of narcotics and more than 2.3 million euros.\n\n\n*** Sweden ***\n\nIn Sweden, 155 people were arrested as part of the operation. According to police in Sweden which received intelligence from the FBI, during an early phase of the operation it was discovered that many of the suspects were in Sweden. Linda Staaf, head of the Swedish police's intelligence activities, said that the suspects in Sweden had a higher rate of violent crime than the other countries.\n\n\n*** United States ***\n\nNo arrests were made in the United States because of privacy laws that prevented law enforcement from collecting messages from domestic subjects. However, the United States Department of Justice indicted seventeen persons (all foreign nationals) under the Racketeer Influenced and Corrupt Organizations Act for their participation in \"the ANOM enterprise\" which spread the devices.\n\n== Legal challenges ==\nAs of April 2023, multiple court cases have been brought in Australia to challenge the legitimacy of the ANOM sting operation. A judgment in one of the cases before the Supreme Court of South Australia has ruled in favor of the police."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the initial demand made by the hackers before they resorted to threatening terrorist actions against the film The Interview?",
    "context": "",
    "output": "The initial demand made by the hackers was for Sony to withdraw the film The Interview and pay them monetary compensation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the initial demand made by the hackers before they resorted to threatening terrorist actions against the film The Interview?",
      "answer": "The initial demand made by the hackers was for Sony to withdraw the film The Interview and pay them monetary compensation."
    }
  },
  {
    "instruction": "Trapdoor function\n\n==Introduction==\nIn theoretical computer science and cryptography, a trapdoor function is a function that is easy to compute in one direction, yet difficult to compute in the opposite direction (finding its inverse) without special information, called the \"trapdoor\". Trapdoor functions are a special case of one-way functions and are widely used in public-key cryptography.In mathematical terms, if f is a trapdoor function, then there exists some secret information t, such that given f(x) and t, it is easy to compute x. Consider a padlock and its key. It is trivial to change the padlock from open to closed without using the key, by pushing the shackle into the lock mechanism. Opening the padlock easily, however, requires the key to be used. Here the key t is the trapdoor and the padlock is the trapdoor function.\nAn example of a simple mathematical trapdoor is \"6895601 is the product of two prime numbers.  What are those numbers?\" A typical \"brute-force\" solution would be to try dividing 6895601 by many prime numbers until finding the answer. However, if one is told that 1931 is one of the numbers, one can find the answer by entering \"6895601 \u00f7 1931\" into any calculator. This example is not a sturdy trapdoor function \u2013 modern computers can guess all of the possible answers within a second \u2013 but this sample problem could be improved by using the product of two much larger primes.\nTrapdoor functions came to prominence in cryptography in the mid-1970s with the publication of asymmetric (or public-key) encryption techniques by Diffie, Hellman, and Merkle. Indeed, Diffie & Hellman (1976) coined the term. Several function classes had been proposed, and it soon became obvious that trapdoor functions are harder to find than was initially thought. For example, an early suggestion was to use schemes based on the subset sum problem. This turned out rather quickly to be unsuitable.\nAs of 2004, the best known trapdoor function (family) candidates are the RSA and Rabin families of functions.  Both are written as exponentiation modulo a composite number, and both are related to the problem of prime factorization.\nFunctions related to the hardness of the discrete logarithm problem (either modulo a prime or in a group defined over an elliptic curve) are not known to be trapdoor functions, because there is no known \"trapdoor\" information about the group that enables the efficient computation of discrete logarithms.\nA trapdoor in cryptography has the very specific aforementioned meaning and is not to be confused with a backdoor (these are frequently used interchangeably, which is incorrect). A backdoor is a deliberate mechanism that is added to a cryptographic algorithm (e.g., a key pair generation algorithm, digital signing algorithm, etc.) or operating system, for example, that permits one or more unauthorized parties to bypass or subvert the security of the system in some fashion.\n\n\n\n== Definition ==\nA trapdoor function is a collection of one-way functions { fk : Dk \u2192 Rk } (k \u2208 K), in which all of K, Dk, Rk are subsets of binary strings {0, 1}*, satisfying the following conditions:\n\nThere exists a probabilistic polynomial time (PPT) sampling algorithm Gen s.t. Gen(1n)\n\n== Examples ==\nIn the following two examples, we always assume it is difficult to factorize a large composite number (see Integer factorization).\n\n\n*** RSA Assumption ***\nIn this example, the inverse \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n   of \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n   modulo \n  \n    \n      \n        \u03d5\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\phi (n)}\n   (Euler's totient function of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  ) is the trapdoor:\n\n  \n    \n      \n        f\n        (\n        x\n        )\nRead the text above and answer this question: Can you explain the concept of 'brute-force' solution in the context of trapdoor functions?",
    "context": "",
    "output": "A brute-force solution is a method of solving a problem by trying all possible solutions until the correct one is found. For example, to find the prime factors of a large composite number, one could try dividing it by all prime numbers until the correct factors are found. This method can be computationally expensive, and it is not an efficient way to invert trapdoor functions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can you explain the concept of 'brute-force' solution in the context of trapdoor functions?",
      "answer": "A brute-force solution is a method of solving a problem by trying all possible solutions until the correct one is found. For example, to find the prime factors of a large composite number, one could try dividing it by all prime numbers until the correct factors are found. This method can be computationally expensive, and it is not an efficient way to invert trapdoor functions.",
      "context": "Trapdoor function\n\n==Introduction==\nIn theoretical computer science and cryptography, a trapdoor function is a function that is easy to compute in one direction, yet difficult to compute in the opposite direction (finding its inverse) without special information, called the \"trapdoor\". Trapdoor functions are a special case of one-way functions and are widely used in public-key cryptography.In mathematical terms, if f is a trapdoor function, then there exists some secret information t, such that given f(x) and t, it is easy to compute x. Consider a padlock and its key. It is trivial to change the padlock from open to closed without using the key, by pushing the shackle into the lock mechanism. Opening the padlock easily, however, requires the key to be used. Here the key t is the trapdoor and the padlock is the trapdoor function.\nAn example of a simple mathematical trapdoor is \"6895601 is the product of two prime numbers.  What are those numbers?\" A typical \"brute-force\" solution would be to try dividing 6895601 by many prime numbers until finding the answer. However, if one is told that 1931 is one of the numbers, one can find the answer by entering \"6895601 \u00f7 1931\" into any calculator. This example is not a sturdy trapdoor function \u2013 modern computers can guess all of the possible answers within a second \u2013 but this sample problem could be improved by using the product of two much larger primes.\nTrapdoor functions came to prominence in cryptography in the mid-1970s with the publication of asymmetric (or public-key) encryption techniques by Diffie, Hellman, and Merkle. Indeed, Diffie & Hellman (1976) coined the term. Several function classes had been proposed, and it soon became obvious that trapdoor functions are harder to find than was initially thought. For example, an early suggestion was to use schemes based on the subset sum problem. This turned out rather quickly to be unsuitable.\nAs of 2004, the best known trapdoor function (family) candidates are the RSA and Rabin families of functions.  Both are written as exponentiation modulo a composite number, and both are related to the problem of prime factorization.\nFunctions related to the hardness of the discrete logarithm problem (either modulo a prime or in a group defined over an elliptic curve) are not known to be trapdoor functions, because there is no known \"trapdoor\" information about the group that enables the efficient computation of discrete logarithms.\nA trapdoor in cryptography has the very specific aforementioned meaning and is not to be confused with a backdoor (these are frequently used interchangeably, which is incorrect). A backdoor is a deliberate mechanism that is added to a cryptographic algorithm (e.g., a key pair generation algorithm, digital signing algorithm, etc.) or operating system, for example, that permits one or more unauthorized parties to bypass or subvert the security of the system in some fashion.\n\n\n\n== Definition ==\nA trapdoor function is a collection of one-way functions { fk : Dk \u2192 Rk } (k \u2208 K), in which all of K, Dk, Rk are subsets of binary strings {0, 1}*, satisfying the following conditions:\n\nThere exists a probabilistic polynomial time (PPT) sampling algorithm Gen s.t. Gen(1n)\n\n== Examples ==\nIn the following two examples, we always assume it is difficult to factorize a large composite number (see Integer factorization).\n\n\n*** RSA Assumption ***\nIn this example, the inverse \n  \n    \n      \n        d\n      \n    \n    {\\displaystyle d}\n   of \n  \n    \n      \n        e\n      \n    \n    {\\displaystyle e}\n   modulo \n  \n    \n      \n        \u03d5\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\phi (n)}\n   (Euler's totient function of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n  ) is the trapdoor:\n\n  \n    \n      \n        f\n        (\n        x\n        )"
    }
  },
  {
    "instruction": "LogLogic\n\n==Introduction==\nLogLogic is a technology company that specializes in Security Management, Compliance Reporting, and IT Operations products.  LogLogic developed the first appliance-based log management platform.  LogLogic's Log Management platform collects and correlates user activity and event data.  LogLogic's products are used by many of the world's largest enterprises to rapidly identify and alert on compliance violations, policy breaches, cyber attacks, and insider threats.\n\n\n\n== Products ==\nLogLogic makes a computer appliance that IT system administrators, compliance managers, CIOs and CiSOs can use to collect logs and events from network devices, servers, databases, operating systems and applications. The appliances also translate various log formats, search through logs, generate alerts and create graphs with logging trends.LogLogic products help in several industry compliance mandates and standards, such as the Payment Card Industry Data Security Standard (PCI DSS), Health Insurance Portability and Accountability Act (HIPAA) and Sarbanes\u2013Oxley (SOX).\n\n== Investors ==\nFocus Ventures, Sequoia Capital, Telesoft Partners, Worldview Technology Partners, INVESCO Private Capital, SAP Ventures, CM-CIC Private Equity, Cr\u00e9dit Agricole Private Equity and ELAIA Partners\n\nQ: Who are the investors that have backed LogLogic, a technology company specializing in Security Management, Compliance Reporting, and IT Operations products?",
    "context": "",
    "output": "A: The investors that have backed LogLogic include Focus Ventures, Sequoia Capital, Telesoft Partners, Worldview Technology Partners, INVESCO Private Capital, SAP Ventures, CM-CIC Private Equity, Cr\u00e9dit Agricole Private Equity, and ELAIA Partners.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who are the investors that have backed LogLogic, a technology company specializing in Security Management, Compliance Reporting, and IT Operations products?",
      "answer": "The investors that have backed LogLogic include Focus Ventures, Sequoia Capital, Telesoft Partners, Worldview Technology Partners, INVESCO Private Capital, SAP Ventures, CM-CIC Private Equity, Cr\u00e9dit Agricole Private Equity, and ELAIA Partners.",
      "context": "LogLogic\n\n==Introduction==\nLogLogic is a technology company that specializes in Security Management, Compliance Reporting, and IT Operations products.  LogLogic developed the first appliance-based log management platform.  LogLogic's Log Management platform collects and correlates user activity and event data.  LogLogic's products are used by many of the world's largest enterprises to rapidly identify and alert on compliance violations, policy breaches, cyber attacks, and insider threats.\n\n\n\n== Products ==\nLogLogic makes a computer appliance that IT system administrators, compliance managers, CIOs and CiSOs can use to collect logs and events from network devices, servers, databases, operating systems and applications. The appliances also translate various log formats, search through logs, generate alerts and create graphs with logging trends.LogLogic products help in several industry compliance mandates and standards, such as the Payment Card Industry Data Security Standard (PCI DSS), Health Insurance Portability and Accountability Act (HIPAA) and Sarbanes\u2013Oxley (SOX).\n\n== Investors ==\nFocus Ventures, Sequoia Capital, Telesoft Partners, Worldview Technology Partners, INVESCO Private Capital, SAP Ventures, CM-CIC Private Equity, Cr\u00e9dit Agricole Private Equity and ELAIA Partners"
    }
  },
  {
    "instruction": "Write an answer to the following question: How does a \"billion laughs\" attack cause a denial-of-service (DoS) in XML parsers?",
    "context": "",
    "output": "A \"billion laughs\" attack overloads the XML parser with an exponential number of entities, causing it to consume a large amount of memory or processing time. This results in the parser becoming unresponsive or crashing, leading to a denial-of-service.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a \"billion laughs\" attack cause a denial-of-service (DoS) in XML parsers?",
      "answer": "A \"billion laughs\" attack overloads the XML parser with an exponential number of entities, causing it to consume a large amount of memory or processing time. This results in the parser becoming unresponsive or crashing, leading to a denial-of-service."
    }
  },
  {
    "instruction": "context: At DEF CON, white-hat hackers have demonstrated the vulnerabilities of voting equipment by compromising every piece of equipment made available to them, including remotely hacking one voting machine to play Rick Astley's song \"Never Gonna Give You Up.\" These demonstrations have highlighted the need for improved election security measures.\n\nAsk a question about this context.",
    "context": "",
    "output": "How have white-hat hackers demonstrated the vulnerabilities of voting equipment at DEF CON?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How have white-hat hackers demonstrated the vulnerabilities of voting equipment at DEF CON?",
      "answer": "At DEF CON, white-hat hackers have demonstrated the vulnerabilities of voting equipment by compromising every piece of equipment made available to them, including remotely hacking one voting machine to play Rick Astley's song \"Never Gonna Give You Up.\" These demonstrations have highlighted the need for improved election security measures."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of Detekt being released under the GPLv3 free license?",
    "context": "",
    "output": "By releasing Detekt under the GPLv3 free license, the developers ensured that the tool would remain free and open source, allowing anyone to access, use, modify, and distribute the software. This also enables other developers to contribute to the project, potentially improving its capabilities and increasing its impact.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of Detekt being released under the GPLv3 free license?",
      "answer": "By releasing Detekt under the GPLv3 free license, the developers ensured that the tool would remain free and open source, allowing anyone to access, use, modify, and distribute the software. This also enables other developers to contribute to the project, potentially improving its capabilities and increasing its impact."
    }
  },
  {
    "instruction": "Sigreturn-oriented programming\n\n==Introduction==\nSigreturn-oriented programming (SROP) is a computer security exploit technique that allows an attacker to execute code in presence of security measures such as non-executable memory and code signing. It was presented for the first time at the 35th IEEE Symposium on Security and Privacy in 2014 where it won the best student paper award. This technique employs the same basic assumptions behind the return-oriented programming (ROP) technique: an attacker controlling the call stack, for example through a stack buffer overflow, is able to influence the control flow of the program through simple instruction sequences called gadgets. The attack works by pushing a forged sigcontext structure on the call stack, overwriting the original return address with the location of a gadget that allows the attacker to call the sigreturn system call. Often just a single gadget is needed to successfully put this attack into effect. This gadget may reside at a fixed location, making this attack simple and effective, with a setup generally simpler and more portable than the one needed by the plain return-oriented programming technique.Sigreturn-oriented programming can be considered a weird machine since it allows code execution outside the original specification of the program.\n\n\n\n== Background ==\nSigreturn-oriented programming (SROP) is a technique similar to return-oriented programming (ROP), since it employs code reuse to execute code outside the scope of the original control flow.\nIn this sense, the adversary needs to be able to carry out a stack smashing attack, usually through a stack buffer overflow, to overwrite the return address contained inside the call stack.\n\n\n*** Stack hopping exploits ***\nIf mechanisms such as data execution prevention are employed, it won't be possible for the attacker to just place a shellcode on the stack and cause the machine to execute it by overwriting the return address.\nWith such protections in place, the machine won't execute any code present in memory areas marked as writable and non-executable.\nTherefore, the attacker will need to reuse code already present in memory.\nMost programs do not contain functions that will allow the attacker to directly carry out the desired action (e.g., obtain access to a shell), but the necessary instructions are often scattered around memory.Return-oriented programming requires these sequences of instructions, called gadgets, to end with a RET instruction. In this way, the attacker can write a sequence of addresses for these gadgets to the stack, and as soon as a RET instruction in one gadget is executed, the control flow will proceed to the next gadget in the list.\n\n\n*** Signal handler mechanism ***\n\nThis attack is made possible by how signals are handled in most POSIX-like systems.\nWhenever a signal is delivered, the kernel needs to context switch to the installed signal handler.  To do so, the kernel saves the current execution context in a frame on the stack.\nThe structure pushed onto the stack is an architecture-specific variant of the sigcontext structure, which holds various data comprising the contents of the registers at the moment of the context switch.\nWhen the execution of the signal handler is completed, the sigreturn() system call is called.\nCalling the sigreturn syscall means being able to easily set the contents of registers using a single gadget that can be easily found on most systems.\n\n\n*** Differences from ROP ***\nThere are several factors that characterize an SROP exploit and distinguish it from a classical return-oriented programming exploit.First, ROP is dependent on available gadgets, which can be very different in distinct binaries, thus making chains of gadget non-portable.\nAddress space layout randomization (ASLR) makes it hard to use gadgets without an information leakage to get their exact positions in memory.\nAlthough Turing-complete ROP compilers exist, it is usually non-trivial to create a ROP chain.SROP exploits are usually portable across different binaries with minimal or no effort and allow easily setting the contents of the registers, which could be non-trivial or unfeasible for ROP exploits if the needed gadgets are not present.\nMoreover, SROP requires a minimal number of gadgets and allows constructing effective shellcodes by chaining system calls. These gadgets are always present in memory, and in some cases are always at fixed locations:\n\n== Attacks ==\n\n\n*** Linux ***\nAn example of the kind of gadget needed for SROP exploits can always be found in the VDSO memory area on x86-Linux systems:\n\nOn some Linux kernel versions, ASLR can be disabled by setting the limit for the stack size to unlimited, effectively bypassing ASLR and allowing easy access to the gadget present in VDSO.\nFor Linux kernels prior to version 3.3, it is also possible to find a suitable gadget inside the vsyscall page, which is a mechanism to accelerate the access to certain system calls often used by legacy programs and resides always at a fixed location.\n\n\n*** Turing-completeness ***\nIt is possible to use gadgets to write into the contents of the stack frames, thereby constructing a self-modifying program. Using this technique, it is possible to devise a simple virtual machine, which can be used as the compilation target for a Turing-complete language.\nAn example of such an approach can be found in Bosman's paper, which demonstrates the construction of an interpreter for a language similar to the Brainfuck programming language.\nThe language provides a program counter PC, a memory pointer P, and a temporary register used for 8-bit addition A. This means that also complex backdoors or obfuscated attacks can be devised.\n\n== Defenses and mitigations ==\nA number of techniques exists to mitigate SROP attacks, relying on address space layout randomization, canaries and cookies, or shadow stacks.\n\n\n*** Address space layout randomization ***\nAddress space layout randomization makes it harder to use suitable gadgets by making their locations unpredictable.\n\n\n*** Signal cookies ***\nA mitigation for SROP called signal cookies has been proposed. It consists of a way of verifying that the sigcontext structure has not been tampered with by the means of a random cookie XORed with the address of the stack location where it is to be stored.\nIn this way, the sigreturn syscall just needs to verify the cookie's existence at the expected location, effectively mitigating SROP with a minimal impact on performances.\n\n\n*** Vsyscall emulation ***\nIn Linux kernel versions greater than 3.3, the vsyscall interface is emulated, and any attempt to directly execute gadgets in the page will result in an exception.\n\n\n*** RAP ***\nGrsecurity is a set of patches for the Linux kernel to harden and improve system security. It includes the so-called Return-Address Protection (RAP) to help protect from code reuse attacks.\n\n\n*** CET ***\nStarting in 2016, Intel is developing a Control-flow Enforcement Technology (CET) to help mitigate and prevent stack-hopping exploits. CET works by implementing a shadow stack in RAM which will only contain return addresses, protected by the CPU's memory management unit.\nRead the text above and answer this question: How do signal handlers play a role in SROP attacks?",
    "context": "",
    "output": "SROP attacks leverage the signal handler mechanism in most POSIX-like systems. Whenever a signal is delivered, the kernel saves the current execution context in a frame on the stack using an architecture-specific variant of the sigcontext structure. When the execution of the signal handler is completed, the sigreturn() system call is called, allowing the attacker to easily set the contents of registers using a single gadget.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do signal handlers play a role in SROP attacks?",
      "answer": "SROP attacks leverage the signal handler mechanism in most POSIX-like systems. Whenever a signal is delivered, the kernel saves the current execution context in a frame on the stack using an architecture-specific variant of the sigcontext structure. When the execution of the signal handler is completed, the sigreturn() system call is called, allowing the attacker to easily set the contents of registers using a single gadget.",
      "context": "Sigreturn-oriented programming\n\n==Introduction==\nSigreturn-oriented programming (SROP) is a computer security exploit technique that allows an attacker to execute code in presence of security measures such as non-executable memory and code signing. It was presented for the first time at the 35th IEEE Symposium on Security and Privacy in 2014 where it won the best student paper award. This technique employs the same basic assumptions behind the return-oriented programming (ROP) technique: an attacker controlling the call stack, for example through a stack buffer overflow, is able to influence the control flow of the program through simple instruction sequences called gadgets. The attack works by pushing a forged sigcontext structure on the call stack, overwriting the original return address with the location of a gadget that allows the attacker to call the sigreturn system call. Often just a single gadget is needed to successfully put this attack into effect. This gadget may reside at a fixed location, making this attack simple and effective, with a setup generally simpler and more portable than the one needed by the plain return-oriented programming technique.Sigreturn-oriented programming can be considered a weird machine since it allows code execution outside the original specification of the program.\n\n\n\n== Background ==\nSigreturn-oriented programming (SROP) is a technique similar to return-oriented programming (ROP), since it employs code reuse to execute code outside the scope of the original control flow.\nIn this sense, the adversary needs to be able to carry out a stack smashing attack, usually through a stack buffer overflow, to overwrite the return address contained inside the call stack.\n\n\n*** Stack hopping exploits ***\nIf mechanisms such as data execution prevention are employed, it won't be possible for the attacker to just place a shellcode on the stack and cause the machine to execute it by overwriting the return address.\nWith such protections in place, the machine won't execute any code present in memory areas marked as writable and non-executable.\nTherefore, the attacker will need to reuse code already present in memory.\nMost programs do not contain functions that will allow the attacker to directly carry out the desired action (e.g., obtain access to a shell), but the necessary instructions are often scattered around memory.Return-oriented programming requires these sequences of instructions, called gadgets, to end with a RET instruction. In this way, the attacker can write a sequence of addresses for these gadgets to the stack, and as soon as a RET instruction in one gadget is executed, the control flow will proceed to the next gadget in the list.\n\n\n*** Signal handler mechanism ***\n\nThis attack is made possible by how signals are handled in most POSIX-like systems.\nWhenever a signal is delivered, the kernel needs to context switch to the installed signal handler.  To do so, the kernel saves the current execution context in a frame on the stack.\nThe structure pushed onto the stack is an architecture-specific variant of the sigcontext structure, which holds various data comprising the contents of the registers at the moment of the context switch.\nWhen the execution of the signal handler is completed, the sigreturn() system call is called.\nCalling the sigreturn syscall means being able to easily set the contents of registers using a single gadget that can be easily found on most systems.\n\n\n*** Differences from ROP ***\nThere are several factors that characterize an SROP exploit and distinguish it from a classical return-oriented programming exploit.First, ROP is dependent on available gadgets, which can be very different in distinct binaries, thus making chains of gadget non-portable.\nAddress space layout randomization (ASLR) makes it hard to use gadgets without an information leakage to get their exact positions in memory.\nAlthough Turing-complete ROP compilers exist, it is usually non-trivial to create a ROP chain.SROP exploits are usually portable across different binaries with minimal or no effort and allow easily setting the contents of the registers, which could be non-trivial or unfeasible for ROP exploits if the needed gadgets are not present.\nMoreover, SROP requires a minimal number of gadgets and allows constructing effective shellcodes by chaining system calls. These gadgets are always present in memory, and in some cases are always at fixed locations:\n\n== Attacks ==\n\n\n*** Linux ***\nAn example of the kind of gadget needed for SROP exploits can always be found in the VDSO memory area on x86-Linux systems:\n\nOn some Linux kernel versions, ASLR can be disabled by setting the limit for the stack size to unlimited, effectively bypassing ASLR and allowing easy access to the gadget present in VDSO.\nFor Linux kernels prior to version 3.3, it is also possible to find a suitable gadget inside the vsyscall page, which is a mechanism to accelerate the access to certain system calls often used by legacy programs and resides always at a fixed location.\n\n\n*** Turing-completeness ***\nIt is possible to use gadgets to write into the contents of the stack frames, thereby constructing a self-modifying program. Using this technique, it is possible to devise a simple virtual machine, which can be used as the compilation target for a Turing-complete language.\nAn example of such an approach can be found in Bosman's paper, which demonstrates the construction of an interpreter for a language similar to the Brainfuck programming language.\nThe language provides a program counter PC, a memory pointer P, and a temporary register used for 8-bit addition A. This means that also complex backdoors or obfuscated attacks can be devised.\n\n== Defenses and mitigations ==\nA number of techniques exists to mitigate SROP attacks, relying on address space layout randomization, canaries and cookies, or shadow stacks.\n\n\n*** Address space layout randomization ***\nAddress space layout randomization makes it harder to use suitable gadgets by making their locations unpredictable.\n\n\n*** Signal cookies ***\nA mitigation for SROP called signal cookies has been proposed. It consists of a way of verifying that the sigcontext structure has not been tampered with by the means of a random cookie XORed with the address of the stack location where it is to be stored.\nIn this way, the sigreturn syscall just needs to verify the cookie's existence at the expected location, effectively mitigating SROP with a minimal impact on performances.\n\n\n*** Vsyscall emulation ***\nIn Linux kernel versions greater than 3.3, the vsyscall interface is emulated, and any attempt to directly execute gadgets in the page will result in an exception.\n\n\n*** RAP ***\nGrsecurity is a set of patches for the Linux kernel to harden and improve system security. It includes the so-called Return-Address Protection (RAP) to help protect from code reuse attacks.\n\n\n*** CET ***\nStarting in 2016, Intel is developing a Control-flow Enforcement Technology (CET) to help mitigate and prevent stack-hopping exploits. CET works by implementing a shadow stack in RAM which will only contain return addresses, protected by the CPU's memory management unit."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is one example of a large open-entry CTF competition for students learning cybersecurity?",
    "context": "",
    "output": "Computer Science Annual Workshop (CSAW) CTF is one example of a large open-entry CTF competition for students learning cybersecurity from around the world.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is one example of a large open-entry CTF competition for students learning cybersecurity?",
      "answer": "Computer Science Annual Workshop (CSAW) CTF is one example of a large open-entry CTF competition for students learning cybersecurity from around the world."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the name of the fork of FreeOTP available for Android?",
    "context": "",
    "output": "The name of the fork of FreeOTP available for Android is FreeOTP Plus.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the name of the fork of FreeOTP available for Android?",
      "answer": "The name of the fork of FreeOTP available for Android is FreeOTP Plus."
    }
  },
  {
    "instruction": "context: The organizations that collaborated to take down the 3ve botnet included White Ops, Google, Department of Homeland Security, FBI Internet Crime Complaint Center, Adobe, Trade Desk, Amazon Advertising, Oath, Malwarebytes, ESET, Proofpoint, Symantec, F-Secure, McAfee, and Trend Micro.\n\nAsk a question about this context.",
    "context": "",
    "output": "Which organizations collaborated to take down the 3ve botnet?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which organizations collaborated to take down the 3ve botnet?",
      "answer": "The organizations that collaborated to take down the 3ve botnet included White Ops, Google, Department of Homeland Security, FBI Internet Crime Complaint Center, Adobe, Trade Desk, Amazon Advertising, Oath, Malwarebytes, ESET, Proofpoint, Symantec, F-Secure, McAfee, and Trend Micro."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can vulnerabilities in low-level code be addressed in language-based security?",
    "context": "",
    "output": "Language-based security approaches to address vulnerabilities in low-level code include using safe high-level languages, adding defensive execution of unsafe languages using run-time checks, and implementing isolated execution of modules to separate sensitive code from application data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can vulnerabilities in low-level code be addressed in language-based security?",
      "answer": "Language-based security approaches to address vulnerabilities in low-level code include using safe high-level languages, adding defensive execution of unsafe languages using run-time checks, and implementing isolated execution of modules to separate sensitive code from application data."
    }
  },
  {
    "instruction": "Storm botnet\n\n==Introduction==\nThe Storm botnet or Storm worm botnet (also known as Dorf botnet and Ecard malware) was a remotely controlled network of \"zombie\" computers (or \"botnet\") that had been linked by the Storm Worm, a Trojan horse spread through e-mail spam. At its height in September 2007, the Storm botnet was running on anywhere from 1 million to 50 million computer systems, and accounted for 8% of all malware on Microsoft Windows computers. It was first identified around January 2007, having been distributed by email with subjects such as \"230 dead as storm batters Europe,\" giving it its well-known name. The botnet began to decline in late 2007, and by mid-2008 had been reduced to infecting about 85,000 computers, far less than it had infected a year earlier.As of December 2012, the original creators of Storm have not been found. The Storm botnet has displayed defensive behaviors that indicated that its controllers were actively protecting the botnet against attempts at tracking and disabling it, by specifically attacking the online operations of some security vendors and researchers who had attempted to investigate it. Security expert Joe Stewart revealed that in late 2007, the operators of the botnet began to further decentralize their operations, in possible plans to sell portions of the Storm botnet to other operators. It was reportedly powerful enough to force entire countries off the Internet, and was estimated to be capable of executing more instructions per second than some of the world's top supercomputers. The United States Federal Bureau of Investigation considered the botnet a major risk to increased bank fraud, identity theft, and other cybercrimes.\n\n== Origins ==\nFirst detected on the Internet in January 2007, the Storm botnet and worm are so-called because of the storm-related subject lines its infectious e-mail employed initially, such as \"230 dead as storm batters Europe.\" Later provocative subjects included \"Chinese missile shot down USA aircraft,\" and \"U.S. Secretary of State Condoleezza Rice has kicked German Chancellor Angela Merkel.\" It is suspected by some information security professionals that well-known fugitive spammers, including Leo Kuvayev, may have been involved in the operation and control of the Storm botnet. According to technology journalist Daniel Tynan, writing under his \"Robert X. Cringely\" pseudonym, a great portion of the fault for the existence of the Storm botnet lay with Microsoft and Adobe Systems. Other sources state that Storm Worm's primary method of victim acquisition was through enticing users via frequently changing social engineering (confidence trickery) schemes. According to Patrick Runald, the Storm botnet had a strong American focus, and likely had agents working to support it within the United States. Some experts, however, believe the Storm botnet controllers were Russian, some pointing specifically at the Russian Business Network, citing that the Storm software mentions a hatred of the Moscow-based security firm Kaspersky Lab, and includes the Russian word \"buldozhka,\" which means \"bulldog.\"\n\n== Composition ==\nThe botnet, or zombie network, comprises computers running Microsoft Windows as their operating system. Once infected, a computer becomes known as a bot. This bot then performs automated tasks\u2014anything from gathering data on the user, to attacking web sites, to forwarding infected e-mail\u2014without its owner's knowledge or permission. Estimates indicate that 5,000 to 6,000 computers are dedicated to propagating the spread of the worm through the use of e-mails with infected attachments; 1.2 billion virus messages have been sent by the botnet through September 2007, including a record 57 million on August 22, 2007 alone. Lawrence Baldwin, a computer forensics specialist, was quoted as saying, \"Cumulatively, Storm is sending billions of messages a day. It could be double digits in the billions, easily.\" One of the methods used to entice victims to infection-hosting web sites are offers of free music, from artists such as Beyonc\u00e9 Knowles, Kelly Clarkson, Rihanna, The Eagles, Foo Fighters, R. Kelly, and Velvet Revolver.  Signature-based detection, the main defense of most computer systems against virus and malware infections, is hampered by the large number of Storm variants.Back-end servers that control the spread of the botnet and Storm worm automatically re-encode their distributed infection software twice an hour, for new transmissions, making it difficult for anti-virus vendors to stop the virus and infection spread. Additionally, the location of the remote servers which control the botnet are hidden behind a constantly changing DNS technique called 'fast flux', making it difficult to find and stop virus hosting sites and mail servers. In short, the name and location of such machines are frequently changed and rotated, often on a minute by minute basis. The Storm botnet's operators control the system via peer-to-peer techniques, making external monitoring and disabling of the system more difficult. There is no central \"command-and-control point\" in the Storm botnet that can be shut down. The botnet also makes use of encrypted traffic. Efforts to infect computers usually revolve around convincing people to download e-mail attachments which contain the virus through subtle manipulation. In one instance, the botnet's controllers took advantage of the National Football League's opening weekend, sending out mail offering \"football tracking programs\" which did nothing more than infect a user's computer. According to Matt Sergeant, chief anti-spam technologist at MessageLabs, \"In terms of power, [the botnet] utterly blows the supercomputers away. If you add up all 500 of the top supercomputers, it blows them all away with just 2 million of its machines. It's very frightening that criminals have access to that much computing power, but there's not much we can do about it.\" It is estimated that only 10\u200a\u201320% of the total capacity and power of the Storm botnet is currently being used.Computer security expert Joe Stewart detailed the process by which compromised machines join the botnet: attempts to join the botnet are made by launching a series of EXE files on the compromised machine, in stages. Usually, they are named in a sequence from game0.exe through game5.exe, or similar. It will then continue launching executables in turn. They typically perform the following:\ngame0.exe \u2013 Backdoor/downloader\ngame1.exe \u2013 SMTP relay\ngame2.exe \u2013 E-mail address stealer\ngame3.exe \u2013 E-mail virus spreader\ngame4.exe \u2013 Distributed Denial of Service (DDoS) attack tool\ngame5.exe \u2013 Updated copy of Storm Worm dropperAt each stage the compromised system will connect into the botnet; fast flux DNS makes tracking this process exceptionally difficult.\nThis code is run from %windir%\\system32\\wincom32.sys on a Windows system, via a kernel rootkit, and all connections back to the botnet are sent through a modified version of the eDonkey/Overnet communications protocol.\n\n== Method ==\nThe Storm botnet and its variants employ a variety of attack vectors, and a variety of defensive steps exist as well. The Storm botnet was observed to be defending itself, and attacking computer systems that scanned for Storm virus-infected computer systems online. The botnet will defend itself with DDoS counter-attacks, to maintain its own internal integrity. At certain points in time, the Storm worm used to spread the botnet has attempted to release hundreds or thousands of versions of itself onto the Internet, in a concentrated attempt to overwhelm the defenses of anti-virus and malware security firms. According to Joshua Corman, an IBM security researcher, \"This is the first time that I can remember ever seeing researchers who were actually afraid of investigating an exploit.\" Researchers are still unsure if the botnet's defenses and counterattacks are a form of automation, or manually executed by the system's operators. \"If you try to attach a debugger, or query sites it's reporting into, it knows and punishes you instantaneously. [Over at] SecureWorks, a chunk of it DDoS-ed [distributed-denial-of-service attacked] a researcher off the network. Every time I hear of an investigator trying to investigate, they're automatically punished. It knows it's being investigated, and it punishes them. It fights back\", Corman said.Spameater.com as well as other sites such as 419eater.com and Artists Against 419, both of which deal with 419 spam e-mail fraud, have experienced DDoS attacks, temporarily rendering them completely inoperable. The DDoS attacks consist of making massed parallel network calls to those and other target IP addresses, overloading the servers' capacities and preventing them from responding to requests. Other anti-spam and anti-fraud groups, such as the Spamhaus Project, were also attacked. The webmaster of Artists Against 419 said that the website's server succumbed after the attack increased to over 100Mbit.  Similar attacks were perpetrated against over a dozen anti-fraud site hosts. Jeff Chan, a spam researcher, stated, \"In terms of mitigating Storm, it's challenging at best and impossible at worst since the bad guys control many hundreds of megabits of traffic. There's some evidence that they may control hundreds of Gigabits of traffic, which is enough to force some countries off the Internet.\"The Storm botnet's systems also take steps to defend itself locally, on victims' computer systems. The botnet, on some compromised systems, creates a computer process on the Windows machine that notifies the Storm systems whenever a new program or other processes begin. Previously, the Storm worms locally would tell the other programs\u2014such as anti-virus, or anti-malware software, to simply not run. However, according to IBM security research, versions of Storm also now simply \"fool\" the local computer system into thinking it has run the hostile program successfully, but in fact, they are not doing anything. \"Programs, including not just AV exes, dlls and sys files, but also software such as the P2P applications BearShare and eDonkey, will appear to run successfully, even though they didn't actually do anything, which is far less suspicious than a process that gets terminated suddenly from the outside\", said Richard Cohen of Sophos. Compromised users, and related security systems, will assume that security software is running successfully when it in fact is not.On September 17, 2007, a Republican Party website in the United States was compromised, and used to propagate the Storm worm and botnet. In October 2007, the botnet took advantage of flaws in YouTube's captcha application on its mail systems, to send targeted spam e-mails to Xbox owners with a scam involving winning a special version of the video game Halo 3. Other attack methods include using appealing animated images of laughing cats to get people to click on a trojan software download, and tricking users of Yahoo!'s GeoCities service to download software that was claimed to be needed to use GeoCities itself. The GeoCities attack in particular was called a \"full-fledged attack vector\" by Paul Ferguson of Trend Micro, and implicated members of the Russian Business Network, a well-known spam and malware service. On Christmas Eve in 2007, the Storm botnet began sending out holiday-themed messages revolving around male interest in women, with such titles as \"Find Some Christmas Tail\", \"The Twelve Girls of Christmas\", and \"Mrs. Claus Is Out Tonight!\" and photos of attractive women. It was described as an attempt to draw more unprotected systems into the botnet and boost its size over the holidays, when security updates from protection vendors may take longer to be distributed. A day after the e-mails with Christmas strippers were distributed, the Storm botnet operators immediately began sending new infected e-mails that claimed to wish their recipients a \"Happy New Year 2008!\"In January 2008, the botnet was detected for the first time to be involved in phishing attacks against major financial institutions, targeting both Barclays and Halifax.\n\n== Encryption and sales ==\nAround October 15, 2007, it was uncovered that portions of the Storm botnet and its variants could be for sale. This is being done by using unique security keys in the encryption of the botnet's Internet traffic and information. The unique keys will allow each segment, or sub-section of the Storm botnet, to communicate with a section that has a matching security key. However, this may also allow people to detect, track, and block Storm botnet traffic in the future, if the security keys have unique lengths and signatures. Computer security vendor Sophos has agreed with the assessment that the partitioning of the Storm botnet indicated likely resale of its services. Graham Cluley of Sophos said, \"Storm's use of encrypted traffic is an interesting feature which has raised eyebrows in our lab. Its most likely use is for the cybercriminals to lease out portions of the network for misuse. It wouldn't be a surprise if the network was used for spamming, distributed denial-of-service attacks, and other malicious activities.\" Security experts reported that if Storm is broken up for the malware market, in the form of a \"ready-to-use botnet-making spam kit\", the world could see a sharp rise in the number of Storm related infections and compromised computer systems. The encryption only seems to affect systems compromised by Storm from the second week of October 2007 onwards, meaning that any of the computer systems compromised after that time frame will remain difficult to track and block.Within days of the discovery of this segmenting of the Storm botnet, spam e-mail from the new subsection was uncovered by major security vendors. On the evening of October 17, security vendors began seeing new spam with embedded MP3 sound files, which attempted to trick victims into investing in a penny stock, as part of an illegal pump-and-dump stock scam. It was believed that this was the first-ever spam e-mail scam that made use of audio to fool victims. Unlike nearly all other Storm-related e-mails, however, these new audio stock scam messages did not include any sort of virus or Storm malware payload; they were simply part of the stock scam.In January 2008, the botnet was detected for the first time to be involved in phishing attacks against the customers of major financial institutions, targeting banking establishments in Europe including Barclays, Halifax and the Royal Bank of Scotland. The unique security keys used indicated to F-Secure that segments of the botnet were being leased.\n\n== Claimed decline of the botnet ==\nOn September 25, 2007, it was estimated that a Microsoft update to the Windows Malicious Software Removal Tool (MSRT) may have helped reduce the size of the botnet by up to 20%. The new patch, as claimed by Microsoft, removed Storm from approximately 274,372 infected systems out of 2.6 million scanned Windows systems. However, according to senior security staff at Microsoft, \"the 180,000+ additional machines that have been cleaned by MSRT since the first day are likely to be home user machines that were not notably incorporated into the daily operation of the 'Storm' botnet,\" indicating that the MSRT cleaning may have been symbolic at best.As of late October 2007, some reports indicated that the Storm botnet was losing the size of its Internet footprint, and was significantly reduced in size. Brandon Enright, a University of California at San Diego security analyst, estimated that the botnet had by late October fallen to a size of approximately 160,000 compromised systems, from Enright's previous estimated high in July 2007 of 1,500,000 systems. Enright noted, however, that the botnet's composition was constantly changing, and that it was still actively defending itself against attacks and observation. \"If you're a researcher and you hit the pages hosting the malware too much\u2026 there is an automated process that automatically launches a denial of service [attack] against you\", he said, and added that his research caused a Storm botnet attack that knocked part of the UC San Diego network offline.The computer security company McAfee is reported as saying that the Storm Worm would be the basis of future attacks. Craig Schmugar, a noted security expert who discovered the Mydoom worm, called the Storm botnet a trend-setter, which has led to more usage of similar tactics by criminals. One such derivative botnet has been dubbed the \"Celebrity Spam Gang\", due to their use of similar technical tools as the Storm botnet controllers. Unlike the sophisticated social engineering that the Storm operators use to entice victims, however, the Celebrity spammers make use of offers of nude images of celebrities such as Angelina Jolie and Britney Spears. Cisco Systems security experts stated in a report that they believe the Storm botnet would remain a critical threat in 2008, and said they estimated that its size remained in the \"millions\".As of early 2008, the Storm botnet also found business competition in its black hat economy, in the form of Nugache, another similar botnet which was first identified in 2006. Reports have indicated a price war may be underway between the operators of both botnets, for the sale of their spam E-mail delivery. Following the Christmas and New Year's holidays bridging 2007\u20132008, the researchers of the German Honeynet Project reported that the Storm botnet may have increased in size by up to 20% over the holidays. The MessageLabs Intelligence report dated March 2008 estimates that over 20% of all spam on the Internet originates from Storm.\n\n== Present state of the botnet ==\nThe Storm botnet was sending out spam for more than two years until its decline in late 2008. One factor in this\u2014on account of making it less interesting for the creators to maintain the botnet\u2014may have been the Stormfucker tool, which made it possible to take control over parts of the botnet.\n\n== Stormbot 2 ==\nOn April 28, 2010, McAfee made an announcement that the so-called \"rumors\" of a Stormbot 2 were verified. Mark Schloesser, Tillmann Werner, and Felix Leder, the German researchers who did a lot of work in analyzing the original Storm, found that around two-thirds of the \"new\" functions are a copy and paste from the last Storm code base. The only thing missing is the P2P infrastructure, perhaps because of the tool which used P2P to bring down the original Storm. Honeynet blog dubbed this Stormbot 2.\nQ: How does the Storm botnet evade signature-based detection?",
    "context": "",
    "output": "The Storm botnet evades signature-based detection by automatically re-encoding its distributed infection software twice an hour for new transmissions and hiding the location of the remote servers which control the botnet behind a constantly changing DNS technique called 'fast flux'.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Storm botnet evade signature-based detection?",
      "answer": "The Storm botnet evades signature-based detection by automatically re-encoding its distributed infection software twice an hour for new transmissions and hiding the location of the remote servers which control the botnet behind a constantly changing DNS technique called 'fast flux'.",
      "context": "Storm botnet\n\n==Introduction==\nThe Storm botnet or Storm worm botnet (also known as Dorf botnet and Ecard malware) was a remotely controlled network of \"zombie\" computers (or \"botnet\") that had been linked by the Storm Worm, a Trojan horse spread through e-mail spam. At its height in September 2007, the Storm botnet was running on anywhere from 1 million to 50 million computer systems, and accounted for 8% of all malware on Microsoft Windows computers. It was first identified around January 2007, having been distributed by email with subjects such as \"230 dead as storm batters Europe,\" giving it its well-known name. The botnet began to decline in late 2007, and by mid-2008 had been reduced to infecting about 85,000 computers, far less than it had infected a year earlier.As of December 2012, the original creators of Storm have not been found. The Storm botnet has displayed defensive behaviors that indicated that its controllers were actively protecting the botnet against attempts at tracking and disabling it, by specifically attacking the online operations of some security vendors and researchers who had attempted to investigate it. Security expert Joe Stewart revealed that in late 2007, the operators of the botnet began to further decentralize their operations, in possible plans to sell portions of the Storm botnet to other operators. It was reportedly powerful enough to force entire countries off the Internet, and was estimated to be capable of executing more instructions per second than some of the world's top supercomputers. The United States Federal Bureau of Investigation considered the botnet a major risk to increased bank fraud, identity theft, and other cybercrimes.\n\n== Origins ==\nFirst detected on the Internet in January 2007, the Storm botnet and worm are so-called because of the storm-related subject lines its infectious e-mail employed initially, such as \"230 dead as storm batters Europe.\" Later provocative subjects included \"Chinese missile shot down USA aircraft,\" and \"U.S. Secretary of State Condoleezza Rice has kicked German Chancellor Angela Merkel.\" It is suspected by some information security professionals that well-known fugitive spammers, including Leo Kuvayev, may have been involved in the operation and control of the Storm botnet. According to technology journalist Daniel Tynan, writing under his \"Robert X. Cringely\" pseudonym, a great portion of the fault for the existence of the Storm botnet lay with Microsoft and Adobe Systems. Other sources state that Storm Worm's primary method of victim acquisition was through enticing users via frequently changing social engineering (confidence trickery) schemes. According to Patrick Runald, the Storm botnet had a strong American focus, and likely had agents working to support it within the United States. Some experts, however, believe the Storm botnet controllers were Russian, some pointing specifically at the Russian Business Network, citing that the Storm software mentions a hatred of the Moscow-based security firm Kaspersky Lab, and includes the Russian word \"buldozhka,\" which means \"bulldog.\"\n\n== Composition ==\nThe botnet, or zombie network, comprises computers running Microsoft Windows as their operating system. Once infected, a computer becomes known as a bot. This bot then performs automated tasks\u2014anything from gathering data on the user, to attacking web sites, to forwarding infected e-mail\u2014without its owner's knowledge or permission. Estimates indicate that 5,000 to 6,000 computers are dedicated to propagating the spread of the worm through the use of e-mails with infected attachments; 1.2 billion virus messages have been sent by the botnet through September 2007, including a record 57 million on August 22, 2007 alone. Lawrence Baldwin, a computer forensics specialist, was quoted as saying, \"Cumulatively, Storm is sending billions of messages a day. It could be double digits in the billions, easily.\" One of the methods used to entice victims to infection-hosting web sites are offers of free music, from artists such as Beyonc\u00e9 Knowles, Kelly Clarkson, Rihanna, The Eagles, Foo Fighters, R. Kelly, and Velvet Revolver.  Signature-based detection, the main defense of most computer systems against virus and malware infections, is hampered by the large number of Storm variants.Back-end servers that control the spread of the botnet and Storm worm automatically re-encode their distributed infection software twice an hour, for new transmissions, making it difficult for anti-virus vendors to stop the virus and infection spread. Additionally, the location of the remote servers which control the botnet are hidden behind a constantly changing DNS technique called 'fast flux', making it difficult to find and stop virus hosting sites and mail servers. In short, the name and location of such machines are frequently changed and rotated, often on a minute by minute basis. The Storm botnet's operators control the system via peer-to-peer techniques, making external monitoring and disabling of the system more difficult. There is no central \"command-and-control point\" in the Storm botnet that can be shut down. The botnet also makes use of encrypted traffic. Efforts to infect computers usually revolve around convincing people to download e-mail attachments which contain the virus through subtle manipulation. In one instance, the botnet's controllers took advantage of the National Football League's opening weekend, sending out mail offering \"football tracking programs\" which did nothing more than infect a user's computer. According to Matt Sergeant, chief anti-spam technologist at MessageLabs, \"In terms of power, [the botnet] utterly blows the supercomputers away. If you add up all 500 of the top supercomputers, it blows them all away with just 2 million of its machines. It's very frightening that criminals have access to that much computing power, but there's not much we can do about it.\" It is estimated that only 10\u200a\u201320% of the total capacity and power of the Storm botnet is currently being used.Computer security expert Joe Stewart detailed the process by which compromised machines join the botnet: attempts to join the botnet are made by launching a series of EXE files on the compromised machine, in stages. Usually, they are named in a sequence from game0.exe through game5.exe, or similar. It will then continue launching executables in turn. They typically perform the following:\ngame0.exe \u2013 Backdoor/downloader\ngame1.exe \u2013 SMTP relay\ngame2.exe \u2013 E-mail address stealer\ngame3.exe \u2013 E-mail virus spreader\ngame4.exe \u2013 Distributed Denial of Service (DDoS) attack tool\ngame5.exe \u2013 Updated copy of Storm Worm dropperAt each stage the compromised system will connect into the botnet; fast flux DNS makes tracking this process exceptionally difficult.\nThis code is run from %windir%\\system32\\wincom32.sys on a Windows system, via a kernel rootkit, and all connections back to the botnet are sent through a modified version of the eDonkey/Overnet communications protocol.\n\n== Method ==\nThe Storm botnet and its variants employ a variety of attack vectors, and a variety of defensive steps exist as well. The Storm botnet was observed to be defending itself, and attacking computer systems that scanned for Storm virus-infected computer systems online. The botnet will defend itself with DDoS counter-attacks, to maintain its own internal integrity. At certain points in time, the Storm worm used to spread the botnet has attempted to release hundreds or thousands of versions of itself onto the Internet, in a concentrated attempt to overwhelm the defenses of anti-virus and malware security firms. According to Joshua Corman, an IBM security researcher, \"This is the first time that I can remember ever seeing researchers who were actually afraid of investigating an exploit.\" Researchers are still unsure if the botnet's defenses and counterattacks are a form of automation, or manually executed by the system's operators. \"If you try to attach a debugger, or query sites it's reporting into, it knows and punishes you instantaneously. [Over at] SecureWorks, a chunk of it DDoS-ed [distributed-denial-of-service attacked] a researcher off the network. Every time I hear of an investigator trying to investigate, they're automatically punished. It knows it's being investigated, and it punishes them. It fights back\", Corman said.Spameater.com as well as other sites such as 419eater.com and Artists Against 419, both of which deal with 419 spam e-mail fraud, have experienced DDoS attacks, temporarily rendering them completely inoperable. The DDoS attacks consist of making massed parallel network calls to those and other target IP addresses, overloading the servers' capacities and preventing them from responding to requests. Other anti-spam and anti-fraud groups, such as the Spamhaus Project, were also attacked. The webmaster of Artists Against 419 said that the website's server succumbed after the attack increased to over 100Mbit.  Similar attacks were perpetrated against over a dozen anti-fraud site hosts. Jeff Chan, a spam researcher, stated, \"In terms of mitigating Storm, it's challenging at best and impossible at worst since the bad guys control many hundreds of megabits of traffic. There's some evidence that they may control hundreds of Gigabits of traffic, which is enough to force some countries off the Internet.\"The Storm botnet's systems also take steps to defend itself locally, on victims' computer systems. The botnet, on some compromised systems, creates a computer process on the Windows machine that notifies the Storm systems whenever a new program or other processes begin. Previously, the Storm worms locally would tell the other programs\u2014such as anti-virus, or anti-malware software, to simply not run. However, according to IBM security research, versions of Storm also now simply \"fool\" the local computer system into thinking it has run the hostile program successfully, but in fact, they are not doing anything. \"Programs, including not just AV exes, dlls and sys files, but also software such as the P2P applications BearShare and eDonkey, will appear to run successfully, even though they didn't actually do anything, which is far less suspicious than a process that gets terminated suddenly from the outside\", said Richard Cohen of Sophos. Compromised users, and related security systems, will assume that security software is running successfully when it in fact is not.On September 17, 2007, a Republican Party website in the United States was compromised, and used to propagate the Storm worm and botnet. In October 2007, the botnet took advantage of flaws in YouTube's captcha application on its mail systems, to send targeted spam e-mails to Xbox owners with a scam involving winning a special version of the video game Halo 3. Other attack methods include using appealing animated images of laughing cats to get people to click on a trojan software download, and tricking users of Yahoo!'s GeoCities service to download software that was claimed to be needed to use GeoCities itself. The GeoCities attack in particular was called a \"full-fledged attack vector\" by Paul Ferguson of Trend Micro, and implicated members of the Russian Business Network, a well-known spam and malware service. On Christmas Eve in 2007, the Storm botnet began sending out holiday-themed messages revolving around male interest in women, with such titles as \"Find Some Christmas Tail\", \"The Twelve Girls of Christmas\", and \"Mrs. Claus Is Out Tonight!\" and photos of attractive women. It was described as an attempt to draw more unprotected systems into the botnet and boost its size over the holidays, when security updates from protection vendors may take longer to be distributed. A day after the e-mails with Christmas strippers were distributed, the Storm botnet operators immediately began sending new infected e-mails that claimed to wish their recipients a \"Happy New Year 2008!\"In January 2008, the botnet was detected for the first time to be involved in phishing attacks against major financial institutions, targeting both Barclays and Halifax.\n\n== Encryption and sales ==\nAround October 15, 2007, it was uncovered that portions of the Storm botnet and its variants could be for sale. This is being done by using unique security keys in the encryption of the botnet's Internet traffic and information. The unique keys will allow each segment, or sub-section of the Storm botnet, to communicate with a section that has a matching security key. However, this may also allow people to detect, track, and block Storm botnet traffic in the future, if the security keys have unique lengths and signatures. Computer security vendor Sophos has agreed with the assessment that the partitioning of the Storm botnet indicated likely resale of its services. Graham Cluley of Sophos said, \"Storm's use of encrypted traffic is an interesting feature which has raised eyebrows in our lab. Its most likely use is for the cybercriminals to lease out portions of the network for misuse. It wouldn't be a surprise if the network was used for spamming, distributed denial-of-service attacks, and other malicious activities.\" Security experts reported that if Storm is broken up for the malware market, in the form of a \"ready-to-use botnet-making spam kit\", the world could see a sharp rise in the number of Storm related infections and compromised computer systems. The encryption only seems to affect systems compromised by Storm from the second week of October 2007 onwards, meaning that any of the computer systems compromised after that time frame will remain difficult to track and block.Within days of the discovery of this segmenting of the Storm botnet, spam e-mail from the new subsection was uncovered by major security vendors. On the evening of October 17, security vendors began seeing new spam with embedded MP3 sound files, which attempted to trick victims into investing in a penny stock, as part of an illegal pump-and-dump stock scam. It was believed that this was the first-ever spam e-mail scam that made use of audio to fool victims. Unlike nearly all other Storm-related e-mails, however, these new audio stock scam messages did not include any sort of virus or Storm malware payload; they were simply part of the stock scam.In January 2008, the botnet was detected for the first time to be involved in phishing attacks against the customers of major financial institutions, targeting banking establishments in Europe including Barclays, Halifax and the Royal Bank of Scotland. The unique security keys used indicated to F-Secure that segments of the botnet were being leased.\n\n== Claimed decline of the botnet ==\nOn September 25, 2007, it was estimated that a Microsoft update to the Windows Malicious Software Removal Tool (MSRT) may have helped reduce the size of the botnet by up to 20%. The new patch, as claimed by Microsoft, removed Storm from approximately 274,372 infected systems out of 2.6 million scanned Windows systems. However, according to senior security staff at Microsoft, \"the 180,000+ additional machines that have been cleaned by MSRT since the first day are likely to be home user machines that were not notably incorporated into the daily operation of the 'Storm' botnet,\" indicating that the MSRT cleaning may have been symbolic at best.As of late October 2007, some reports indicated that the Storm botnet was losing the size of its Internet footprint, and was significantly reduced in size. Brandon Enright, a University of California at San Diego security analyst, estimated that the botnet had by late October fallen to a size of approximately 160,000 compromised systems, from Enright's previous estimated high in July 2007 of 1,500,000 systems. Enright noted, however, that the botnet's composition was constantly changing, and that it was still actively defending itself against attacks and observation. \"If you're a researcher and you hit the pages hosting the malware too much\u2026 there is an automated process that automatically launches a denial of service [attack] against you\", he said, and added that his research caused a Storm botnet attack that knocked part of the UC San Diego network offline.The computer security company McAfee is reported as saying that the Storm Worm would be the basis of future attacks. Craig Schmugar, a noted security expert who discovered the Mydoom worm, called the Storm botnet a trend-setter, which has led to more usage of similar tactics by criminals. One such derivative botnet has been dubbed the \"Celebrity Spam Gang\", due to their use of similar technical tools as the Storm botnet controllers. Unlike the sophisticated social engineering that the Storm operators use to entice victims, however, the Celebrity spammers make use of offers of nude images of celebrities such as Angelina Jolie and Britney Spears. Cisco Systems security experts stated in a report that they believe the Storm botnet would remain a critical threat in 2008, and said they estimated that its size remained in the \"millions\".As of early 2008, the Storm botnet also found business competition in its black hat economy, in the form of Nugache, another similar botnet which was first identified in 2006. Reports have indicated a price war may be underway between the operators of both botnets, for the sale of their spam E-mail delivery. Following the Christmas and New Year's holidays bridging 2007\u20132008, the researchers of the German Honeynet Project reported that the Storm botnet may have increased in size by up to 20% over the holidays. The MessageLabs Intelligence report dated March 2008 estimates that over 20% of all spam on the Internet originates from Storm.\n\n== Present state of the botnet ==\nThe Storm botnet was sending out spam for more than two years until its decline in late 2008. One factor in this\u2014on account of making it less interesting for the creators to maintain the botnet\u2014may have been the Stormfucker tool, which made it possible to take control over parts of the botnet.\n\n== Stormbot 2 ==\nOn April 28, 2010, McAfee made an announcement that the so-called \"rumors\" of a Stormbot 2 were verified. Mark Schloesser, Tillmann Werner, and Felix Leder, the German researchers who did a lot of work in analyzing the original Storm, found that around two-thirds of the \"new\" functions are a copy and paste from the last Storm code base. The only thing missing is the P2P infrastructure, perhaps because of the tool which used P2P to bring down the original Storm. Honeynet blog dubbed this Stormbot 2."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does \"blind\" hijacking differ from other types of session hijacking attacks?",
    "context": "",
    "output": "\"Blind\" hijacking differs from other types of session hijacking attacks because the attacker cannot see the response to their commands. This is because they are not inline between the two parties and cannot use source-routed IP packets. Instead, they must guess the responses of the two machines in order to carry out the attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does \"blind\" hijacking differ from other types of session hijacking attacks?",
      "answer": "\"Blind\" hijacking differs from other types of session hijacking attacks because the attacker cannot see the response to their commands. This is because they are not inline between the two parties and cannot use source-routed IP packets. Instead, they must guess the responses of the two machines in order to carry out the attack."
    }
  },
  {
    "instruction": "International Carnahan Conference on Security Technology\n\n==Introduction==\nThe IEEE International Carnahan Conference on Security Technology (ICCST) is an annual IEEE conference related to security technology, with a particular focus on physical security, biometrics, information security, threat detection, and cyber security.The 56th Annual International Carnahan Conference on Security Technology (ICCST 2023) will be held at the Defence Institute of Advanced Technology (DIAT), Girinagar, Pune, India, and is scheduled for 11-15 October 2023.\nThe conference is named after the Carnahan House, a conference center at the University of Kentucky located in Lexington, Kentucky, USA. The initial conferences were held at this location, hosted by the Lexington Chapter of the IEEE.\n\n\n\n== Previous conference locations ==\nQuestion: What is the name of the conference center where the initial ICCST conferences were held?",
    "context": "",
    "output": "Answer: The Carnahan House, a conference center at the University of Kentucky located in Lexington, Kentucky, USA.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the name of the conference center where the initial ICCST conferences were held?",
      "answer": "The Carnahan House, a conference center at the University of Kentucky located in Lexington, Kentucky, USA.",
      "context": "International Carnahan Conference on Security Technology\n\n==Introduction==\nThe IEEE International Carnahan Conference on Security Technology (ICCST) is an annual IEEE conference related to security technology, with a particular focus on physical security, biometrics, information security, threat detection, and cyber security.The 56th Annual International Carnahan Conference on Security Technology (ICCST 2023) will be held at the Defence Institute of Advanced Technology (DIAT), Girinagar, Pune, India, and is scheduled for 11-15 October 2023.\nThe conference is named after the Carnahan House, a conference center at the University of Kentucky located in Lexington, Kentucky, USA. The initial conferences were held at this location, hosted by the Lexington Chapter of the IEEE.\n\n\n\n== Previous conference locations =="
    }
  },
  {
    "instruction": "Torrent poisoning\n\n==Introduction==\nTorrent poisoning is intentionally sharing corrupt data or data with misleading file names using the BitTorrent protocol. This practice of uploading fake torrents is sometimes carried out by anti-infringement organisations as an attempt to prevent the peer-to-peer (P2P) sharing of copyrighted content, and to gather the IP addresses of downloaders.\n\n== Methods of attack ==\n\n\n*** Decoy insertion ***\nDecoy insertion (or content pollution) is a method by which corrupted versions of a particular file are inserted into the network. This deters users from finding an uncorrupted version and also increases distribution of the corrupted file.  A malicious user pollutes the file by converting it into another format that is indistinguishable from uncorrupted files (e.g. it may have similar or same metadata). In order to entice users to download the decoys, malicious users may make the corrupted file available via high bandwidth connections.  This method consumes a large amount of computing resources since the malicious server must respond to a large quantity of requests.  As a result, queries return principally corrupted copies such as a blank file or executable files infected with a virus. There were known cases when a company had created a special version of a game and published it on file sharing services advertising it as cracked, having undocumented hidden functionality, making it impossible to win this variant of the game.\n\n\n*** Index poisoning ***\nThis method targets the index found in P2P file sharing systems. The index allows users to locate the IP addresses of desired content.  Thus, this method of attack makes searching difficult for network users. The attacker inserts a large amount of invalid information into the index to prevent users from finding the correct resource.  Invalid information could include random content identifiers or fake IP addresses and port numbers.  When a user attempts to download the corrupted content, the server will fail to establish a connection due to the large volume of invalid information. Users will then waste time trying to establish a connection with bogus users thus increasing the average time it takes to download the file.  The index poisoning attack requires less bandwidth and server resources than decoy insertion. Furthermore, the attacker does not have to transfer files nor respond to requests.  For this reason, index poisoning requires less effort than other methods of attack.\n\n\n*** Spoofing ***\nSome companies that disrupt P2P file sharing on behalf of content providers create their own software in order to launch attacks. MediaDefender has written their own program which directs users to non-existent locations via bogus search results. As users typically select one of the top five search results only, this method requires users to persevere beyond their initial failed attempts to locate the desired file.  The idea is that many users will simply give up their search through frustration.\n\n\n*** Interdiction ***\nThis method of attack prevents distributors from serving users and thus slows P2P file sharing. The attacker's servers constantly connect to the desired file, which floods the provider's upstream bandwidth and prevents other users from downloading the file.\n\n\n*** Selective content poisoning ***\nSelective content poisoning (also known as proactive or discriminatory content poisoning) attempts to detect copyright violators while allowing legitimate users to continue to enjoy the service provided by an open P2P network. The protocol identifies a peer with its endpoint address while the file index format is changed to incorporate a digital signature. A peer authentication protocol can then establish the legitimacy of a peer when she downloads and uploads files. Using identity based signatures, the system enables each peer to identify infringing users without the need for communication with a central authority. The protocol then sends poisoned chunks to these detected users requesting a copyright protected file only. If all legitimate users simply deny download requests from known infringers, the latter can usually accumulate clean chunks from colluders (paid peers who share content with others without authorization). However, this method of content poisoning forces illegitimate users to discard even clean chunks, prolonging their download time.Voluntary Collective Licensing and the Open Music Model are theoretical systems where users pay a subscription fee for access to a file-sharing network, and are able to legally download and distribute copyright content.  Selective content poisoning could potentially be used here to limit access to legitimate and subscribed users, by providing poisoned content to non-subscribed users who attempt to illegitimately use the network.\n\n\n*** Eclipse attack ***\nThe eclipse attack (also known as routing-table poisoning), instead of poisoning the network, targets requesting peers directly. In this attack, the attacker takes over the peer's routing table so that they are unable to communicate with any other peer except the attacker. As the attacker replicates the whole network for the targeted peer, they can manipulate them in a number of ways.  For example, the attacker can specify which search results are returned.  The attacker can also modify file comments. The peer's requests can also be directed back into the network by the attacker and can also be modified. It also checks data randomly for any errors found in that.\n\n\n*** Uncooperative-peer attack ***\nIn this attack, the attacker joins the targeted swarm and establishes connections with many peers. However, the attacker never provides any chunks (authentic or otherwise) to the peers. A common version of this attack is the \"chatty peer\" attack. The attacker establishes connection with targeted peers via the required handshake message, followed by a message advertising that they have a number of available chunks. Not only does the attacker never provide any chunks, they also repeatedly resend the handshake and message. These attacks prevent downloads as, essentially, the peer wastes time dealing with the attacker, instead of downloading chunks from others.\n\n== Barriers to torrent poisoning ==\nThere are several reasons why content providers and copyright holders may not choose torrent poisoning as a method for guarding their content. First, before injecting decoys, content providers have to normally monitor the BitTorrent network for signs that their content is being illegally shared (this includes watching for variations of files and files in compressed formats).\nThis process can be expensive and time-consuming.  As a result, most poisoning is only continued for the first few months following a leak or release.  Second, it is also unlikely that torrent poisoning can be successful in disrupting every illegal download.\nInstead, the aim of content providers is to make illegal downloads statistically less likely to be clean and complete, in the hope that users will be discouraged from illegally downloading copyright material. Content providers and copyright holders may decide that the financial outlay is not worth the end result of their efforts.\n\n\n*** Countermeasures ***\nThe methods of attack described above are not particularly effective on their own, as for each measure effective countermeasures have evolved. These measures must be combined in order to have a significant impact on illegal peer-to-peer filesharing using BitTorrent protocols and Torrent files.\n\nBitTorrent is highly resistant to content poisoning (as opposed to index poisoning), as it is able to verify individual file chunks.  Overall, BitTorrent is one of the most resistant P2P filesharing methods to poisoning.\nOn private tracker websites, where all posted torrents can be traced to a particular member, poisoned torrents can be quickly labeled and deleted and the poster can be banned, preventing further introduction of poisoned torrents by that user.\nPublic torrent tracker sites have enabled the ability to report if a torrent has been poisoned (or is fake or malicious in any way). Thus torrent files shared by public trackers can have similar levels of quality assurance as Private Tracker websites.\nTracker technology (as well as BitTorrent client programs) has improved over time, and many kinds of spoofing that were possible in the past are no longer possible.\nBitTorrent was once an exclusively TCP-IP protocol, but this is no longer true. Use of UDP, with the uTP protocol has made TCP Man in the Middle attacks more difficult to nearly impossible.\nPublic or Private tracker websites have selectively switched over to using HTTPS for the distribution of their web text and image content. By using HTTPS for the website content (versus tracker communications) many poisoning techniques are rendered impossible.\n\n\n*** Legal issues ***\nIn September 2004, Altnet sued the Recording Industry Association of America, Overpeer, Loudeye, MediaSentry and others, claiming that their spoofing services violated Altnet's patent for a file identification method called TrueNames.In 2005 the Finnish anti-infringement organisation Viralg claimed that their software, which uses a similar approach to spoofing, could be used to bring an end to illegal P2P file sharing. The firm offered \"total blocking of peer 2 peer sharing for your intellectual property\" and claimed that its \"patented virtual algorithm blocks out all illegal swapping of your data\". as well as claiming that their approach was 99% effective.  Despite these claims, the algorithm has not yet been tested with BitTorrent. A group of Finnish musicians requested an investigation into the company, arguing that their software was effectively a virus and was in violation of Finnish law.  The investigation was declined by Finnish police, and later by the Finnish parliamentary ombudsman.In some jurisdictions, there were concerns that content providers and copyright holders engaging in poisoning activities may be held liable for damages to users' computers.  In the US in 2002, Representative Howard Berman proposed the Peer To Peer Piracy Prevention Act, which would have granted immunity to copyright holders for taking steps to prevent the illegal distribution of their content (i.e. poisoning activities) on P2P networks, as long as they did not go as far as to harm the files stored on a P2P user's computer.  However, the bill died later in 2002 when the Congressional Term ended and has not been reintroduced.\n\n== High-profile cases ==\nIn 2005, it was reported that HBO was poisoning torrents of its show Rome by providing chunks of garbage data to users. HBO were also reported to have sent cease-and-desist letters to the Internet service providers (ISPs) of downloaders they believe have illegally downloaded episodes of The Sopranos.\nAlthough not targeted specifically at BitTorrent, Madonna's 2003 album American Life was an early example of content poisoning.  Before the release of the album, tracks that appeared to be of similar length and file size to the real album tracks were leaked by the singer's record label.  The tracks featured only a clip of Madonna saying \"What the fuck do you think you're doing?\" followed by minutes of silence.Similarly, the band Barenaked Ladies released a number of tracks online in 2000 that appeared to be legitimate copies of tracks from the band's latest album.  Each file contained a short sample of the song, followed by a clip of a band member saying, \"Although you thought you were downloading our new single, what you were actually downloading is an advertisement for our new album.\u201dAfter an unauthorized copy of Michael Moore's movie Sicko was uploaded online, it became a hit on P2P websites such as Pirate Bay. MediaDefender was hired to poison torrents using decoy insertion.In an example of Internet vigilantism, anti-infringement vigilantes have been known to create viruses that are distributed exclusively via P2P networks, and are designed to attack mp3s and other music files stored on a user's PC.  The Nopir-B worm, which originated in France, poses as a DVD copying program and deletes all the mp3 files on a user's computer, regardless of whether or not they were legally obtained.On 19 October 2007 Associated Press (AP) released information accusing the broadband service provider Comcast of \"hindering\" P2P file sharing traffic.  Tests conducted by AP have shown that Comcast hindered the uploading of complete files to BitTorrent. The Federal Communications Commission conducted public hearings in response to the allegations. Comcast argued that it was regulating network traffic to enable reasonable downloading times for the majority of users. On 21 August 2008 the FCC issued an order which stated that Comcast's network management was unreasonable and that Comcast must terminate the use of its discriminatory network management by the end of the year. Comcast complied with the order and appealed. On 6 June 2010, the District Court of Appeals for the Columbia vacated the FCC order in Comcast Corp. v. FCC.\n\nQ: How does the eclipse attack target requesting peers in BitTorrent protocol?",
    "context": "",
    "output": "A: The eclipse attack targets requesting peers by taking over the peer's routing table so that they are unable to communicate with any other peer except the attacker. The attacker then manipulates the targeted peer in various ways, such as specifying which search results are returned, modifying file comments, and directing the peer's requests back into the network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the eclipse attack target requesting peers in BitTorrent protocol?",
      "answer": "The eclipse attack targets requesting peers by taking over the peer's routing table so that they are unable to communicate with any other peer except the attacker. The attacker then manipulates the targeted peer in various ways, such as specifying which search results are returned, modifying file comments, and directing the peer's requests back into the network.",
      "context": "Torrent poisoning\n\n==Introduction==\nTorrent poisoning is intentionally sharing corrupt data or data with misleading file names using the BitTorrent protocol. This practice of uploading fake torrents is sometimes carried out by anti-infringement organisations as an attempt to prevent the peer-to-peer (P2P) sharing of copyrighted content, and to gather the IP addresses of downloaders.\n\n== Methods of attack ==\n\n\n*** Decoy insertion ***\nDecoy insertion (or content pollution) is a method by which corrupted versions of a particular file are inserted into the network. This deters users from finding an uncorrupted version and also increases distribution of the corrupted file.  A malicious user pollutes the file by converting it into another format that is indistinguishable from uncorrupted files (e.g. it may have similar or same metadata). In order to entice users to download the decoys, malicious users may make the corrupted file available via high bandwidth connections.  This method consumes a large amount of computing resources since the malicious server must respond to a large quantity of requests.  As a result, queries return principally corrupted copies such as a blank file or executable files infected with a virus. There were known cases when a company had created a special version of a game and published it on file sharing services advertising it as cracked, having undocumented hidden functionality, making it impossible to win this variant of the game.\n\n\n*** Index poisoning ***\nThis method targets the index found in P2P file sharing systems. The index allows users to locate the IP addresses of desired content.  Thus, this method of attack makes searching difficult for network users. The attacker inserts a large amount of invalid information into the index to prevent users from finding the correct resource.  Invalid information could include random content identifiers or fake IP addresses and port numbers.  When a user attempts to download the corrupted content, the server will fail to establish a connection due to the large volume of invalid information. Users will then waste time trying to establish a connection with bogus users thus increasing the average time it takes to download the file.  The index poisoning attack requires less bandwidth and server resources than decoy insertion. Furthermore, the attacker does not have to transfer files nor respond to requests.  For this reason, index poisoning requires less effort than other methods of attack.\n\n\n*** Spoofing ***\nSome companies that disrupt P2P file sharing on behalf of content providers create their own software in order to launch attacks. MediaDefender has written their own program which directs users to non-existent locations via bogus search results. As users typically select one of the top five search results only, this method requires users to persevere beyond their initial failed attempts to locate the desired file.  The idea is that many users will simply give up their search through frustration.\n\n\n*** Interdiction ***\nThis method of attack prevents distributors from serving users and thus slows P2P file sharing. The attacker's servers constantly connect to the desired file, which floods the provider's upstream bandwidth and prevents other users from downloading the file.\n\n\n*** Selective content poisoning ***\nSelective content poisoning (also known as proactive or discriminatory content poisoning) attempts to detect copyright violators while allowing legitimate users to continue to enjoy the service provided by an open P2P network. The protocol identifies a peer with its endpoint address while the file index format is changed to incorporate a digital signature. A peer authentication protocol can then establish the legitimacy of a peer when she downloads and uploads files. Using identity based signatures, the system enables each peer to identify infringing users without the need for communication with a central authority. The protocol then sends poisoned chunks to these detected users requesting a copyright protected file only. If all legitimate users simply deny download requests from known infringers, the latter can usually accumulate clean chunks from colluders (paid peers who share content with others without authorization). However, this method of content poisoning forces illegitimate users to discard even clean chunks, prolonging their download time.Voluntary Collective Licensing and the Open Music Model are theoretical systems where users pay a subscription fee for access to a file-sharing network, and are able to legally download and distribute copyright content.  Selective content poisoning could potentially be used here to limit access to legitimate and subscribed users, by providing poisoned content to non-subscribed users who attempt to illegitimately use the network.\n\n\n*** Eclipse attack ***\nThe eclipse attack (also known as routing-table poisoning), instead of poisoning the network, targets requesting peers directly. In this attack, the attacker takes over the peer's routing table so that they are unable to communicate with any other peer except the attacker. As the attacker replicates the whole network for the targeted peer, they can manipulate them in a number of ways.  For example, the attacker can specify which search results are returned.  The attacker can also modify file comments. The peer's requests can also be directed back into the network by the attacker and can also be modified. It also checks data randomly for any errors found in that.\n\n\n*** Uncooperative-peer attack ***\nIn this attack, the attacker joins the targeted swarm and establishes connections with many peers. However, the attacker never provides any chunks (authentic or otherwise) to the peers. A common version of this attack is the \"chatty peer\" attack. The attacker establishes connection with targeted peers via the required handshake message, followed by a message advertising that they have a number of available chunks. Not only does the attacker never provide any chunks, they also repeatedly resend the handshake and message. These attacks prevent downloads as, essentially, the peer wastes time dealing with the attacker, instead of downloading chunks from others.\n\n== Barriers to torrent poisoning ==\nThere are several reasons why content providers and copyright holders may not choose torrent poisoning as a method for guarding their content. First, before injecting decoys, content providers have to normally monitor the BitTorrent network for signs that their content is being illegally shared (this includes watching for variations of files and files in compressed formats).\nThis process can be expensive and time-consuming.  As a result, most poisoning is only continued for the first few months following a leak or release.  Second, it is also unlikely that torrent poisoning can be successful in disrupting every illegal download.\nInstead, the aim of content providers is to make illegal downloads statistically less likely to be clean and complete, in the hope that users will be discouraged from illegally downloading copyright material. Content providers and copyright holders may decide that the financial outlay is not worth the end result of their efforts.\n\n\n*** Countermeasures ***\nThe methods of attack described above are not particularly effective on their own, as for each measure effective countermeasures have evolved. These measures must be combined in order to have a significant impact on illegal peer-to-peer filesharing using BitTorrent protocols and Torrent files.\n\nBitTorrent is highly resistant to content poisoning (as opposed to index poisoning), as it is able to verify individual file chunks.  Overall, BitTorrent is one of the most resistant P2P filesharing methods to poisoning.\nOn private tracker websites, where all posted torrents can be traced to a particular member, poisoned torrents can be quickly labeled and deleted and the poster can be banned, preventing further introduction of poisoned torrents by that user.\nPublic torrent tracker sites have enabled the ability to report if a torrent has been poisoned (or is fake or malicious in any way). Thus torrent files shared by public trackers can have similar levels of quality assurance as Private Tracker websites.\nTracker technology (as well as BitTorrent client programs) has improved over time, and many kinds of spoofing that were possible in the past are no longer possible.\nBitTorrent was once an exclusively TCP-IP protocol, but this is no longer true. Use of UDP, with the uTP protocol has made TCP Man in the Middle attacks more difficult to nearly impossible.\nPublic or Private tracker websites have selectively switched over to using HTTPS for the distribution of their web text and image content. By using HTTPS for the website content (versus tracker communications) many poisoning techniques are rendered impossible.\n\n\n*** Legal issues ***\nIn September 2004, Altnet sued the Recording Industry Association of America, Overpeer, Loudeye, MediaSentry and others, claiming that their spoofing services violated Altnet's patent for a file identification method called TrueNames.In 2005 the Finnish anti-infringement organisation Viralg claimed that their software, which uses a similar approach to spoofing, could be used to bring an end to illegal P2P file sharing. The firm offered \"total blocking of peer 2 peer sharing for your intellectual property\" and claimed that its \"patented virtual algorithm blocks out all illegal swapping of your data\". as well as claiming that their approach was 99% effective.  Despite these claims, the algorithm has not yet been tested with BitTorrent. A group of Finnish musicians requested an investigation into the company, arguing that their software was effectively a virus and was in violation of Finnish law.  The investigation was declined by Finnish police, and later by the Finnish parliamentary ombudsman.In some jurisdictions, there were concerns that content providers and copyright holders engaging in poisoning activities may be held liable for damages to users' computers.  In the US in 2002, Representative Howard Berman proposed the Peer To Peer Piracy Prevention Act, which would have granted immunity to copyright holders for taking steps to prevent the illegal distribution of their content (i.e. poisoning activities) on P2P networks, as long as they did not go as far as to harm the files stored on a P2P user's computer.  However, the bill died later in 2002 when the Congressional Term ended and has not been reintroduced.\n\n== High-profile cases ==\nIn 2005, it was reported that HBO was poisoning torrents of its show Rome by providing chunks of garbage data to users. HBO were also reported to have sent cease-and-desist letters to the Internet service providers (ISPs) of downloaders they believe have illegally downloaded episodes of The Sopranos.\nAlthough not targeted specifically at BitTorrent, Madonna's 2003 album American Life was an early example of content poisoning.  Before the release of the album, tracks that appeared to be of similar length and file size to the real album tracks were leaked by the singer's record label.  The tracks featured only a clip of Madonna saying \"What the fuck do you think you're doing?\" followed by minutes of silence.Similarly, the band Barenaked Ladies released a number of tracks online in 2000 that appeared to be legitimate copies of tracks from the band's latest album.  Each file contained a short sample of the song, followed by a clip of a band member saying, \"Although you thought you were downloading our new single, what you were actually downloading is an advertisement for our new album.\u201dAfter an unauthorized copy of Michael Moore's movie Sicko was uploaded online, it became a hit on P2P websites such as Pirate Bay. MediaDefender was hired to poison torrents using decoy insertion.In an example of Internet vigilantism, anti-infringement vigilantes have been known to create viruses that are distributed exclusively via P2P networks, and are designed to attack mp3s and other music files stored on a user's PC.  The Nopir-B worm, which originated in France, poses as a DVD copying program and deletes all the mp3 files on a user's computer, regardless of whether or not they were legally obtained.On 19 October 2007 Associated Press (AP) released information accusing the broadband service provider Comcast of \"hindering\" P2P file sharing traffic.  Tests conducted by AP have shown that Comcast hindered the uploading of complete files to BitTorrent. The Federal Communications Commission conducted public hearings in response to the allegations. Comcast argued that it was regulating network traffic to enable reasonable downloading times for the majority of users. On 21 August 2008 the FCC issued an order which stated that Comcast's network management was unreasonable and that Comcast must terminate the use of its discriminatory network management by the end of the year. Comcast complied with the order and appealed. On 6 June 2010, the District Court of Appeals for the Columbia vacated the FCC order in Comcast Corp. v. FCC."
    }
  },
  {
    "instruction": "context: The self-shrinking generator ensures the randomness of the output sequence by using alternating output bits of the LFSR to control the final output and discarding pairs of bits that do not match either 10 or 11.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the self-shrinking generator ensure the randomness of the output sequence?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the self-shrinking generator ensure the randomness of the output sequence?",
      "answer": "The self-shrinking generator ensures the randomness of the output sequence by using alternating output bits of the LFSR to control the final output and discarding pairs of bits that do not match either 10 or 11."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the Payment Card Industry (PCI) Data Security Standard and how does it relate to multi-factor authentication?",
    "context": "",
    "output": "The Payment Card Industry (PCI) Data Security Standard is a set of security standards for organizations that handle branded credit cards from the major card schemes. The standard requires the use of multi-factor authentication for remote network access and administrative access to the Card Data Environment.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Payment Card Industry (PCI) Data Security Standard and how does it relate to multi-factor authentication?",
      "answer": "The Payment Card Industry (PCI) Data Security Standard is a set of security standards for organizations that handle branded credit cards from the major card schemes. The standard requires the use of multi-factor authentication for remote network access and administrative access to the Card Data Environment."
    }
  },
  {
    "instruction": "Secure Communications Interoperability Protocol\n\n==Introduction==\nThe Secure Communications Interoperability Protocol (SCIP) is a US standard for secure voice and data communication, for circuit-switched one-to-one connections, not packet-switched networks.  SCIP derived from the US Government  Future Narrowband Digital Terminal (FNBDT) project.\nSCIP supports a number of different modes, including national and multinational modes which employ different cryptography. Many nations and industries develop SCIP devices to support the multinational and national modes of SCIP.\nSCIP has to operate over the wide variety of communications systems, including commercial land line telephone, military radios, communication satellites, Voice over IP and the several different  cellular telephone standards. Therefore, it was designed to make no assumptions about the underlying channel other than a minimum bandwidth of 2400 Hz. It is similar to a dial-up modem in that once a connection is made, two SCIP phones first negotiate the parameters they need and then communicate in the best way possible.\nUS SCIP or FNBDT systems were used since 2001, beginning with the CONDOR secure cell phone. The standard is designed to cover wideband as well as narrowband voice and data security.\nSCIP was designed by the Department of Defense Digital Voice Processor Consortium (DDVPC) in cooperation with the U.S. National Security Agency and is intended to solve problems with earlier NSA encryption systems for voice, including STU-III and Secure Terminal Equipment (STE) which made assumptions about the underlying communication systems that prevented interoperability with more modern wireless systems. STE sets can be upgraded to work with SCIP, but STU-III cannot. This has led to some resistance since various government agencies already own over 350,000 STU-III telephones at a cost of several thousand dollars each.\nThere are several components to the SCIP standard: key management, voice compression, encryption and a signalling plan for voice, data and multimedia applications.\n\n== Key Management (120) ==\nTo set up a secure call, a new Traffic Encryption Key (TEK) must be negotiated. For Type 1 security (classified calls), the SCIP signalling plan uses an enhanced FIREFLY messaging system for key exchange. FIREFLY is an NSA key management system based on public key cryptography. At least one commercial grade implementation uses Diffie-Hellman key exchange.\nSTEs use security tokens to limit use of the secure voice capability to authorized users while other SCIP devices only require a PIN code, 7 digits for Type 1 security, 4 digits for unclassified.\n\n== Voice compression using Voice Coders (vocoders) ==\nSCIP can work with a variety of vocoders. The standard requires, as a minimum, support for the mixed-excitation linear prediction (MELP) coder, an enhanced MELP algorithm known as MELPe, with additional preprocessing, analyzer and synthesizer capabilities for improved intelligibility and noise robustness.  The old MELP and the new MELPe are interoperable and both operate at 2400 bit/s, sending a 54 bit data frame every 22.5 milliseconds but the MELPe has optional additional rates of 1200 bit/s and 600 bit/s.\n2400 bit/s MELPe is the only mandatory voice coder required for SCIP. Other voice coders can be supported in terminals. These can be used if all terminals involved in the call support the same coder (agreed during the negotiation stage of call setup) and the network can support the required throughput. G.729D is the most widely supported non-mandatory voice coder in SCIP terminals as it offers a good compromise between higher voice quality without dramatically increasing the required throughput.\n\n== Encryption (SCIP 23x) ==\nThe security used by the multinational and national modes of SCIP is defined by the SCIP 23x family of documents.\nSCIP 231 defines AES based cryptography which can be used multinationally.\nSCIP 232 defines an alternate multinational cryptographic solution.\nSeveral nations have defined, or are defining, their own national security modes for SCIP.\n\n== US National Mode (SCIP 230) ==\nSCIP 230 defines the cryptography of the US national mode of SCIP. The rest of this section refers to SCIP 230.\nFor security, SCIP uses a block cipher operating in counter mode. A new Traffic Encryption Key (TEK) is negotiated for each call. The block cipher is fed a 64-bit state vector (SV) as input. If the cipher's block size is longer than 64 bits, a fixed filler is added. The output from the block cipher is xored with the MELP data frames to create the cipher text that is then transmitted.\nThe low-order two bits of the state vector are reserved for applications where the data frame is longer than the block cipher output. The next 42 bits are the counter. Four bits are used to represent the transmission mode. This allows more than one mode, e.g. voice and data, to operate at the same time with the same TEK. The high-order 16 bits are a sender ID. This allows multiple senders on a single channel to all use the same TEK. Note that  since overall SCIP encryption is effectively a stream cipher, it is essential that the same state vector value never be used twice for a given TEK. At MELP data rates, a 42-bit counter allows a call over three thousand years long before the encryption repeats.\nFor Type 1 security,  SCIP uses BATON, a 128-bit block design. With this or other 128-bit ciphers, such as AES, SCIP specifies that two data frames are encrypted with each cipher output bloc, the first beginning at bit 1, the second at bit 57 (i.e. the next byte boundary). At least one commercial grade implementation uses the Triple DES cipher.\n\n== Signalling plan (210) ==\nThe SCIP signalling plan is common to all national and multinational modes of SCIP. SCIP has two mandatory types of transmission. The mandatory data service uses an ARQ protocol with forward error correction (FEC) to ensure reliable transmission. The receiving station acknowledges accurate receipt of data blocks and can ask for a block to be re-transmitted, if necessary. For voice, SCIP simply sends a stream of voice data frames (typically MELPe frames, but possibly G.729D or another codec if that has been negotiated between the terminals). To save power on voice calls, SCIP stops sending if there is no speech input. A synchronization block is sent roughly twice a second in place of a data frame. The low order 14 bits of the encryption counter are sent with every sync block. The 14 bits are enough to cover a fade out of more than six minutes. Part of the rest of the state vector are sent as well so that with receipt of three sync blocks, the entire state vector is recovered. This handles longer fades and allows a station with the proper TEK to join a multi station net and be synchronized within 1.5 seconds.\n\n== Availability ==\nAs of March 2011 a range of SCIP documents, including the SCIP-210 signalling standard, are publicly available from the IAD website.Prior to this, SCIP specifications were not widely diffused or easily accessible. This made the protocol for government use rather \"opaque\" outside governments or defense industries.\nNo public implementation of the Type 1 security and transport protocols are available, precluding its security from being publicly verified.\n\nBased on the above text, answer a question. How does the SCIP 230 family of documents define the security used by the multinational and national modes of SCIP?",
    "context": "",
    "output": "The SCIP 23x family of documents defines the security used by the multinational and national modes of SCIP. SCIP 231 defines AES based cryptography which can be used multinationally, and SCIP 232 defines an alternate multinational cryptographic solution.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the SCIP 230 family of documents define the security used by the multinational and national modes of SCIP?",
      "answer": "The SCIP 23x family of documents defines the security used by the multinational and national modes of SCIP. SCIP 231 defines AES based cryptography which can be used multinationally, and SCIP 232 defines an alternate multinational cryptographic solution.",
      "context": "Secure Communications Interoperability Protocol\n\n==Introduction==\nThe Secure Communications Interoperability Protocol (SCIP) is a US standard for secure voice and data communication, for circuit-switched one-to-one connections, not packet-switched networks.  SCIP derived from the US Government  Future Narrowband Digital Terminal (FNBDT) project.\nSCIP supports a number of different modes, including national and multinational modes which employ different cryptography. Many nations and industries develop SCIP devices to support the multinational and national modes of SCIP.\nSCIP has to operate over the wide variety of communications systems, including commercial land line telephone, military radios, communication satellites, Voice over IP and the several different  cellular telephone standards. Therefore, it was designed to make no assumptions about the underlying channel other than a minimum bandwidth of 2400 Hz. It is similar to a dial-up modem in that once a connection is made, two SCIP phones first negotiate the parameters they need and then communicate in the best way possible.\nUS SCIP or FNBDT systems were used since 2001, beginning with the CONDOR secure cell phone. The standard is designed to cover wideband as well as narrowband voice and data security.\nSCIP was designed by the Department of Defense Digital Voice Processor Consortium (DDVPC) in cooperation with the U.S. National Security Agency and is intended to solve problems with earlier NSA encryption systems for voice, including STU-III and Secure Terminal Equipment (STE) which made assumptions about the underlying communication systems that prevented interoperability with more modern wireless systems. STE sets can be upgraded to work with SCIP, but STU-III cannot. This has led to some resistance since various government agencies already own over 350,000 STU-III telephones at a cost of several thousand dollars each.\nThere are several components to the SCIP standard: key management, voice compression, encryption and a signalling plan for voice, data and multimedia applications.\n\n== Key Management (120) ==\nTo set up a secure call, a new Traffic Encryption Key (TEK) must be negotiated. For Type 1 security (classified calls), the SCIP signalling plan uses an enhanced FIREFLY messaging system for key exchange. FIREFLY is an NSA key management system based on public key cryptography. At least one commercial grade implementation uses Diffie-Hellman key exchange.\nSTEs use security tokens to limit use of the secure voice capability to authorized users while other SCIP devices only require a PIN code, 7 digits for Type 1 security, 4 digits for unclassified.\n\n== Voice compression using Voice Coders (vocoders) ==\nSCIP can work with a variety of vocoders. The standard requires, as a minimum, support for the mixed-excitation linear prediction (MELP) coder, an enhanced MELP algorithm known as MELPe, with additional preprocessing, analyzer and synthesizer capabilities for improved intelligibility and noise robustness.  The old MELP and the new MELPe are interoperable and both operate at 2400 bit/s, sending a 54 bit data frame every 22.5 milliseconds but the MELPe has optional additional rates of 1200 bit/s and 600 bit/s.\n2400 bit/s MELPe is the only mandatory voice coder required for SCIP. Other voice coders can be supported in terminals. These can be used if all terminals involved in the call support the same coder (agreed during the negotiation stage of call setup) and the network can support the required throughput. G.729D is the most widely supported non-mandatory voice coder in SCIP terminals as it offers a good compromise between higher voice quality without dramatically increasing the required throughput.\n\n== Encryption (SCIP 23x) ==\nThe security used by the multinational and national modes of SCIP is defined by the SCIP 23x family of documents.\nSCIP 231 defines AES based cryptography which can be used multinationally.\nSCIP 232 defines an alternate multinational cryptographic solution.\nSeveral nations have defined, or are defining, their own national security modes for SCIP.\n\n== US National Mode (SCIP 230) ==\nSCIP 230 defines the cryptography of the US national mode of SCIP. The rest of this section refers to SCIP 230.\nFor security, SCIP uses a block cipher operating in counter mode. A new Traffic Encryption Key (TEK) is negotiated for each call. The block cipher is fed a 64-bit state vector (SV) as input. If the cipher's block size is longer than 64 bits, a fixed filler is added. The output from the block cipher is xored with the MELP data frames to create the cipher text that is then transmitted.\nThe low-order two bits of the state vector are reserved for applications where the data frame is longer than the block cipher output. The next 42 bits are the counter. Four bits are used to represent the transmission mode. This allows more than one mode, e.g. voice and data, to operate at the same time with the same TEK. The high-order 16 bits are a sender ID. This allows multiple senders on a single channel to all use the same TEK. Note that  since overall SCIP encryption is effectively a stream cipher, it is essential that the same state vector value never be used twice for a given TEK. At MELP data rates, a 42-bit counter allows a call over three thousand years long before the encryption repeats.\nFor Type 1 security,  SCIP uses BATON, a 128-bit block design. With this or other 128-bit ciphers, such as AES, SCIP specifies that two data frames are encrypted with each cipher output bloc, the first beginning at bit 1, the second at bit 57 (i.e. the next byte boundary). At least one commercial grade implementation uses the Triple DES cipher.\n\n== Signalling plan (210) ==\nThe SCIP signalling plan is common to all national and multinational modes of SCIP. SCIP has two mandatory types of transmission. The mandatory data service uses an ARQ protocol with forward error correction (FEC) to ensure reliable transmission. The receiving station acknowledges accurate receipt of data blocks and can ask for a block to be re-transmitted, if necessary. For voice, SCIP simply sends a stream of voice data frames (typically MELPe frames, but possibly G.729D or another codec if that has been negotiated between the terminals). To save power on voice calls, SCIP stops sending if there is no speech input. A synchronization block is sent roughly twice a second in place of a data frame. The low order 14 bits of the encryption counter are sent with every sync block. The 14 bits are enough to cover a fade out of more than six minutes. Part of the rest of the state vector are sent as well so that with receipt of three sync blocks, the entire state vector is recovered. This handles longer fades and allows a station with the proper TEK to join a multi station net and be synchronized within 1.5 seconds.\n\n== Availability ==\nAs of March 2011 a range of SCIP documents, including the SCIP-210 signalling standard, are publicly available from the IAD website.Prior to this, SCIP specifications were not widely diffused or easily accessible. This made the protocol for government use rather \"opaque\" outside governments or defense industries.\nNo public implementation of the Type 1 security and transport protocols are available, precluding its security from being publicly verified."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is an example of a physical security system that uses multi-factor authentication?",
    "context": "",
    "output": "An example of a physical security system that uses multi-factor authentication is access control, which typically requires a physical possession such as a fob or keycard as well as a validation of one's identity such as facial biometrics or a retinal scan.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is an example of a physical security system that uses multi-factor authentication?",
      "answer": "An example of a physical security system that uses multi-factor authentication is access control, which typically requires a physical possession such as a fob or keycard as well as a validation of one's identity such as facial biometrics or a retinal scan."
    }
  },
  {
    "instruction": "context: SHA-1 is used in several widely used security applications and protocols, including TLS and SSL, PGP, SSH, S/MIME, and IPsec. It is also required by law for use in certain U.S. government applications for the protection of sensitive unclassified information.\n\nAsk a question about this context.",
    "context": "",
    "output": "What applications use SHA-1 for cryptographic purposes?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What applications use SHA-1 for cryptographic purposes?",
      "answer": "SHA-1 is used in several widely used security applications and protocols, including TLS and SSL, PGP, SSH, S/MIME, and IPsec. It is also required by law for use in certain U.S. government applications for the protection of sensitive unclassified information."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some commercial products that have been verified to comply with the noninterference property?",
    "context": "",
    "output": "There may be only one or two commercially available products that have been verified to comply with the noninterference property, and these would essentially be as simple as switches and one-way information filters.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some commercial products that have been verified to comply with the noninterference property?",
      "answer": "There may be only one or two commercially available products that have been verified to comply with the noninterference property, and these would essentially be as simple as switches and one-way information filters."
    }
  },
  {
    "instruction": "context: In electronic authentication, a verifier is the party that verifies that the claimant has possession and control of the token that verifies his or her identity. A claimant authenticates his or her identity to a verifier by the use of a token and an authentication protocol, such as Proof of Possession (PoP). Many PoP protocols are designed so that a verifier, with no knowledge of the token before the authentication protocol run, learns nothing about the token from the run.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the role of a verifier in electronic authentication and what are some types of authentication protocols used in this process?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of a verifier in electronic authentication and what are some types of authentication protocols used in this process?",
      "answer": "In electronic authentication, a verifier is the party that verifies that the claimant has possession and control of the token that verifies his or her identity. A claimant authenticates his or her identity to a verifier by the use of a token and an authentication protocol, such as Proof of Possession (PoP). Many PoP protocols are designed so that a verifier, with no knowledge of the token before the authentication protocol run, learns nothing about the token from the run."
    }
  },
  {
    "instruction": "Write an answer to the following question: Can you name some of the areas where COSIC's research and expertise in digital security have applications?",
    "context": "",
    "output": "COSIC's research and expertise in digital security have applications in areas such as cloud, automotive, privacy, data protection, trusted systems, e-payments, and e-documents.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can you name some of the areas where COSIC's research and expertise in digital security have applications?",
      "answer": "COSIC's research and expertise in digital security have applications in areas such as cloud, automotive, privacy, data protection, trusted systems, e-payments, and e-documents."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Polybius square lead to the reordered square?",
    "context": "",
    "output": "The Polybius square leads to the reordered square when a key is used in the square, with the letters of the key being placed at the beginning and the remaining letters following it in alphabetical order.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Polybius square lead to the reordered square?",
      "answer": "The Polybius square leads to the reordered square when a key is used in the square, with the letters of the key being placed at the beginning and the remaining letters following it in alphabetical order."
    }
  },
  {
    "instruction": "context: To meet the A1 class in the TCSEC, a system must provide Verified Design, which is functionally identical to B3 and includes formal design and verification techniques including a formal top-level specification, formal management and distribution procedures, System Architecture demonstrates that the requirements of self-protection and completeness for reference monitors have been implemented in the Trusted Computing Base (TCB), Security Testing automatically generates test-case from the formal top-level specification or formal lower-level specifications, Formal Specification and Verification is where the TCB is verified down to the source code level, using formal verification methods where feasible, and Trusted Design Environment is where the TCB is designed in a trusted facility with only trusted (cleared) personnel.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are the requirements for a system to meet the A1 class in the TCSEC?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the requirements for a system to meet the A1 class in the TCSEC?",
      "answer": "To meet the A1 class in the TCSEC, a system must provide Verified Design, which is functionally identical to B3 and includes formal design and verification techniques including a formal top-level specification, formal management and distribution procedures, System Architecture demonstrates that the requirements of self-protection and completeness for reference monitors have been implemented in the Trusted Computing Base (TCB), Security Testing automatically generates test-case from the formal top-level specification or formal lower-level specifications, Formal Specification and Verification is where the TCB is verified down to the source code level, using formal verification methods where feasible, and Trusted Design Environment is where the TCB is designed in a trusted facility with only trusted (cleared) personnel."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why did Virgil Griffith state that there is no guarantee that an edit was made by an authorized user rather than an intruder?",
    "context": "",
    "output": "Virgil Griffith stated that there is no guarantee that an edit was made by an authorized user rather than an intruder because it depends on an organization's network security, and organizations with public access terminals or networks are more susceptible to intrusions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why did Virgil Griffith state that there is no guarantee that an edit was made by an authorized user rather than an intruder?",
      "answer": "Virgil Griffith stated that there is no guarantee that an edit was made by an authorized user rather than an intruder because it depends on an organization's network security, and organizations with public access terminals or networks are more susceptible to intrusions."
    }
  },
  {
    "instruction": "context: Fancy Bear targets government, military, and security organizations, especially those in Transcaucasian and NATO-aligned states. They have also been known to target citizens of the Russian Federation who are political enemies of the Kremlin.\n\nAsk a question about this context.",
    "context": "",
    "output": "What kind of targets does Fancy Bear typically go after?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What kind of targets does Fancy Bear typically go after?",
      "answer": "Fancy Bear targets government, military, and security organizations, especially those in Transcaucasian and NATO-aligned states. They have also been known to target citizens of the Russian Federation who are political enemies of the Kremlin."
    }
  },
  {
    "instruction": "SIGCUM\n\n==Introduction==\nSIGCUM, also known as Converter M-228, was a rotor cipher machine used to encrypt teleprinter traffic by the United States Army. Hastily designed by William Friedman and Frank Rowlett, the system was put into service in January 1943 before any rigorous analysis of its security had taken place. SIGCUM was subsequently discovered to be insecure by Rowlett, and was immediately withdrawn from service. The machine was redesigned to improve its security, reintroduced into service by April 1943, and remained in use until the 1960s.\n\n\n\n== Development ==\nIn 1939, Friedman and Rowlett worked on the problem of creating a secure teleprinter encryption system. They decided against using a tape-based system, such as those proposed by Gilbert Vernam, and instead conceived of the idea of generating a stream of five-bit pulses by use of wired rotors. Because of lack of funds and interest, however, the proposal was not pursued any further at that time. This changed with the United States' entry into World War II in December 1941. Rowlett was assigned to develop a teleprinter encryption system for use between Army command centers in United Kingdom and Australia (and later in North Africa).\nFriedman described to Rowlett a concrete design for a teleprinter cipher machine that he had invented. However, Rowlett discovered some flaws in Friedman's proposed circuitry that showed the design to be flawed. Under pressure to report to a superior about the progress of the machine, Friedman responded angrily, accusing Rowlett of trying to destroy his reputation as a cryptanalyst. After Friedman calmed down, Rowlett proposed some designs for a replacement machine based on rotors. They settled on one, and agreed to write up a complete design and have it reviewed by another cryptanalyst by the following day.\nThe design agreed upon was a special attachment for a standard teleprinter. The attachment used a stack of five 26-contact rotors, the same as those used in the SIGABA, the highly secure US off-line cipher machine. Each time a key character was needed, thirteen inputs to the rotor stack were energized at the input endplate. Passing through the rotor stack, these thirteen inputs were to be scrambled at the output endplate. However, only five live contacts would be used. These five outputs would form five binary impulses, which would form the keystream for the cipher, to be combined with the message itself, encoded in the 5-bit Baudot code.\nThe rotors advanced odometrically; that is, after each encipherment, the \"fast\" rotor would advance one step. Once every revolution of the fast rotor, the \"medium\" rotor would step once. Similarly, ever revolution of the medium rotor, the \"slow\" rotor would step, and so on for the other two rotors. However, which rotor was assigned as the \"fast\", \"medium\", \"slow\" etc. rotors was controlled by a set of five multi-switches. This gave a total of \n  \n    \n      \n        5\n        !\n\n== Introduction of the machine ==\nThe design for this machine, which was designated the Converter M-228, or SIGCUM, was given to the Teletype Corporation, who were also producing SIGABA. Rowlett recommended that the adoption of the machine be postponed until after a study of its cryptographic security, but SIGCUM was urgently needed by the Army, and the machine was put into production. Rowlett then proposed that the machine used in the Pentagon code room be monitored by connecting a page-printing \"spy machine\". The output could be then studied to establish whether the machine was resistant to attack. Rowlett's suggestion was implemented at the same time the first M-228 machines were installed at the Pentagon in January 1943, used for the Washington-Algiers link.\nThe machines worked as planned, and, initially, Rowlett's study of its security, joined by cryptanalyst Robert Ferner, uncovered no signs of cryptographic weakness. However, after a few days, a SIGCUM operator made a serious operating error, retransmitting the same message twice using the same machine settings, producing a depth.\nFrom this, Rowlett was able to deduce the underlying plaintext and keystream used by the machine. By 2 a.m., an analysis of the keystream allowed him to deduce the wiring of the fast and medium rotors, and of the output wiring. SIGCUM was immediately withdrawn from service, and work on a replacement system, SIGTOT \u2014 a one-time tape machine designed by Leo Rosen \u2014 was given top priority.\n\n== Redesign ==\nMeanwhile, M-228 was redesigned to improve its security. Only five inputs, rather than thirteen, were energized. The five output contacts, instead of being used as the five output bits directly, were instead connected by three leads, each connected to different output point. That meant that an output bit could be energized by any of three different outputs from the rotor maze, making analysis of the machine more complex. The reduced number of inputs ensured that the generated key would not be biased.\nThe rotor stepping was also made more complex. The slowest two rotors, which originally were unlikely to step during the course of an encipherment, were redesigned so that they stepped depending on the output of the previous key output. One rotor, designated the \"fast bump\" rotor, would step if the fourth and fifth bits of the previous output were both true; and similarly the \"slow bump\" rotor would do the same for the first, second and third bits.\nCertain of the rotor stepping arrangements were discovered to be weaker than others, and so these were ruled out for key lists.\nThis redesigned version of the M-228 was put into service by April 1943. However, the machine was judged to be only secure enough to handle traffic up to SECRET by landline, and  CONFIDENTIAL by radio. The machine was also shared with the United Kingdom for joint communications.\nA further-modified version of the M-228 that could be used for the highest level traffic, was designated M-228-M, or SIGHUAD.\nFrom that point on, the Army monitored the communications of its high-level systems to ensure that good operational procedure was being followed, even for highly secure devices such as the SIGABA and SIGTOT devices. As a result, poor operator practices, such as transmitting messages in depth, were largely eliminated.\nQuestion: What was the purpose of the SIGABA machine in the development of SIGCUM's rotor cipher machine?",
    "context": "",
    "output": "Answer: The SIGABA machine was significant in the development of SIGCUM's rotor cipher machine because it used a stack of five 26-contact rotors, the same as those used in SIGCUM's rotor stack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the purpose of the SIGABA machine in the development of SIGCUM's rotor cipher machine?",
      "answer": "The SIGABA machine was significant in the development of SIGCUM's rotor cipher machine because it used a stack of five 26-contact rotors, the same as those used in SIGCUM's rotor stack.",
      "context": "SIGCUM\n\n==Introduction==\nSIGCUM, also known as Converter M-228, was a rotor cipher machine used to encrypt teleprinter traffic by the United States Army. Hastily designed by William Friedman and Frank Rowlett, the system was put into service in January 1943 before any rigorous analysis of its security had taken place. SIGCUM was subsequently discovered to be insecure by Rowlett, and was immediately withdrawn from service. The machine was redesigned to improve its security, reintroduced into service by April 1943, and remained in use until the 1960s.\n\n\n\n== Development ==\nIn 1939, Friedman and Rowlett worked on the problem of creating a secure teleprinter encryption system. They decided against using a tape-based system, such as those proposed by Gilbert Vernam, and instead conceived of the idea of generating a stream of five-bit pulses by use of wired rotors. Because of lack of funds and interest, however, the proposal was not pursued any further at that time. This changed with the United States' entry into World War II in December 1941. Rowlett was assigned to develop a teleprinter encryption system for use between Army command centers in United Kingdom and Australia (and later in North Africa).\nFriedman described to Rowlett a concrete design for a teleprinter cipher machine that he had invented. However, Rowlett discovered some flaws in Friedman's proposed circuitry that showed the design to be flawed. Under pressure to report to a superior about the progress of the machine, Friedman responded angrily, accusing Rowlett of trying to destroy his reputation as a cryptanalyst. After Friedman calmed down, Rowlett proposed some designs for a replacement machine based on rotors. They settled on one, and agreed to write up a complete design and have it reviewed by another cryptanalyst by the following day.\nThe design agreed upon was a special attachment for a standard teleprinter. The attachment used a stack of five 26-contact rotors, the same as those used in the SIGABA, the highly secure US off-line cipher machine. Each time a key character was needed, thirteen inputs to the rotor stack were energized at the input endplate. Passing through the rotor stack, these thirteen inputs were to be scrambled at the output endplate. However, only five live contacts would be used. These five outputs would form five binary impulses, which would form the keystream for the cipher, to be combined with the message itself, encoded in the 5-bit Baudot code.\nThe rotors advanced odometrically; that is, after each encipherment, the \"fast\" rotor would advance one step. Once every revolution of the fast rotor, the \"medium\" rotor would step once. Similarly, ever revolution of the medium rotor, the \"slow\" rotor would step, and so on for the other two rotors. However, which rotor was assigned as the \"fast\", \"medium\", \"slow\" etc. rotors was controlled by a set of five multi-switches. This gave a total of \n  \n    \n      \n        5\n        !\n\n== Introduction of the machine ==\nThe design for this machine, which was designated the Converter M-228, or SIGCUM, was given to the Teletype Corporation, who were also producing SIGABA. Rowlett recommended that the adoption of the machine be postponed until after a study of its cryptographic security, but SIGCUM was urgently needed by the Army, and the machine was put into production. Rowlett then proposed that the machine used in the Pentagon code room be monitored by connecting a page-printing \"spy machine\". The output could be then studied to establish whether the machine was resistant to attack. Rowlett's suggestion was implemented at the same time the first M-228 machines were installed at the Pentagon in January 1943, used for the Washington-Algiers link.\nThe machines worked as planned, and, initially, Rowlett's study of its security, joined by cryptanalyst Robert Ferner, uncovered no signs of cryptographic weakness. However, after a few days, a SIGCUM operator made a serious operating error, retransmitting the same message twice using the same machine settings, producing a depth.\nFrom this, Rowlett was able to deduce the underlying plaintext and keystream used by the machine. By 2 a.m., an analysis of the keystream allowed him to deduce the wiring of the fast and medium rotors, and of the output wiring. SIGCUM was immediately withdrawn from service, and work on a replacement system, SIGTOT \u2014 a one-time tape machine designed by Leo Rosen \u2014 was given top priority.\n\n== Redesign ==\nMeanwhile, M-228 was redesigned to improve its security. Only five inputs, rather than thirteen, were energized. The five output contacts, instead of being used as the five output bits directly, were instead connected by three leads, each connected to different output point. That meant that an output bit could be energized by any of three different outputs from the rotor maze, making analysis of the machine more complex. The reduced number of inputs ensured that the generated key would not be biased.\nThe rotor stepping was also made more complex. The slowest two rotors, which originally were unlikely to step during the course of an encipherment, were redesigned so that they stepped depending on the output of the previous key output. One rotor, designated the \"fast bump\" rotor, would step if the fourth and fifth bits of the previous output were both true; and similarly the \"slow bump\" rotor would do the same for the first, second and third bits.\nCertain of the rotor stepping arrangements were discovered to be weaker than others, and so these were ruled out for key lists.\nThis redesigned version of the M-228 was put into service by April 1943. However, the machine was judged to be only secure enough to handle traffic up to SECRET by landline, and  CONFIDENTIAL by radio. The machine was also shared with the United Kingdom for joint communications.\nA further-modified version of the M-228 that could be used for the highest level traffic, was designated M-228-M, or SIGHUAD.\nFrom that point on, the Army monitored the communications of its high-level systems to ensure that good operational procedure was being followed, even for highly secure devices such as the SIGABA and SIGTOT devices. As a result, poor operator practices, such as transmitting messages in depth, were largely eliminated."
    }
  },
  {
    "instruction": "context: Mimic functions alter the input file's statistical properties by adjusting the probabilities of outputting certain symbols. By approximating the probability distribution of the target file for substrings of a specific length, the recoded file's statistical properties will closely resemble those of the target file, effectively hiding information within the recoded file.\n\nAsk a question about this context.",
    "context": "",
    "output": "How do mimic functions ensure that the recoded file's statistical properties closely resemble those of the target file?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do mimic functions ensure that the recoded file's statistical properties closely resemble those of the target file?",
      "answer": "Mimic functions alter the input file's statistical properties by adjusting the probabilities of outputting certain symbols. By approximating the probability distribution of the target file for substrings of a specific length, the recoded file's statistical properties will closely resemble those of the target file, effectively hiding information within the recoded file."
    }
  },
  {
    "instruction": "context: The Ministry of Health abandoned negotiations with information technology industrial vendors in 2019 for a more advanced cybersecurity system due to a lack of budget. This suggests that the Ministry was unable to allocate sufficient resources to purchase and implement the proposed system, leaving district health boards vulnerable to cyber attacks.\n\nAsk a question about this context.",
    "context": "",
    "output": "Why did the Ministry of Health abandon negotiations with information technology industrial vendors in 2019 for a more advanced cybersecurity system for district health boards?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why did the Ministry of Health abandon negotiations with information technology industrial vendors in 2019 for a more advanced cybersecurity system for district health boards?",
      "answer": "The Ministry of Health abandoned negotiations with information technology industrial vendors in 2019 for a more advanced cybersecurity system due to a lack of budget. This suggests that the Ministry was unable to allocate sufficient resources to purchase and implement the proposed system, leaving district health boards vulnerable to cyber attacks."
    }
  },
  {
    "instruction": "Write an answer to the following question: How are adjacent 4-bit blocks mixed in JH?",
    "context": "",
    "output": "Adjacent 4-bit blocks are mixed using a maximum distance separable code over GF(2^4) in JH.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are adjacent 4-bit blocks mixed in JH?",
      "answer": "Adjacent 4-bit blocks are mixed using a maximum distance separable code over GF(2^4) in JH."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the creation date and the origin of certain hacker groups relate to their motivations and tactics?",
    "context": "",
    "output": "The creation date and origin of a hacker group can often provide insight into its motivations and tactics. For instance, Anonymous, originating in 2003, was created as a group for people who fought for the right to privacy. Similarly, Croatian Revolution Hackers, founded in 2012, were credited with one of the largest attacks in the Balkans. In contrast, older groups like Legion of Doom, active in the early 80s and mid-90s, were known for their rivalry with other hacker groups. Additionally, hacker groups believed to be associated with intelligence agencies or governments, like Cozy Bear and Fancy Bear, often employ sophisticated cyberespionage techniques for political or strategic purposes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the creation date and the origin of certain hacker groups relate to their motivations and tactics?",
      "answer": "The creation date and origin of a hacker group can often provide insight into its motivations and tactics. For instance, Anonymous, originating in 2003, was created as a group for people who fought for the right to privacy. Similarly, Croatian Revolution Hackers, founded in 2012, were credited with one of the largest attacks in the Balkans. In contrast, older groups like Legion of Doom, active in the early 80s and mid-90s, were known for their rivalry with other hacker groups. Additionally, hacker groups believed to be associated with intelligence agencies or governments, like Cozy Bear and Fancy Bear, often employ sophisticated cyberespionage techniques for political or strategic purposes."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the initial motivation behind the creation of the Penet remailer?",
    "context": "",
    "output": "The Penet remailer was initially created as a response to an argument in a Finnish newsgroup regarding whether people should tie their real names to their online communications. Its creator, Johan \"Julf\" Helsingius, believed that people should not be required to do so.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the initial motivation behind the creation of the Penet remailer?",
      "answer": "The Penet remailer was initially created as a response to an argument in a Finnish newsgroup regarding whether people should tie their real names to their online communications. Its creator, Johan \"Julf\" Helsingius, believed that people should not be required to do so."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the vulnerability in ARP that allows for ARP spoofing?",
    "context": "",
    "output": "The vulnerability in ARP that allows for ARP spoofing is that it is a stateless protocol, meaning there is no method for a host to authenticate the peer from which an ARP reply originated. Network hosts will automatically cache any ARP replies they receive, regardless of whether they were requested or not, and even ARP entries that have not yet expired will be overwritten when a new ARP reply packet is received.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the vulnerability in ARP that allows for ARP spoofing?",
      "answer": "The vulnerability in ARP that allows for ARP spoofing is that it is a stateless protocol, meaning there is no method for a host to authenticate the peer from which an ARP reply originated. Network hosts will automatically cache any ARP replies they receive, regardless of whether they were requested or not, and even ARP entries that have not yet expired will be overwritten when a new ARP reply packet is received."
    }
  },
  {
    "instruction": "context: Acid Cryptofiler's design is tailored to address the challenges of data encryption in multi-recipient scenarios by utilizing asymmetric encryption. In this approach, each user has a unique pair of keys (public and private). The sender encrypts the data using the recipients' public keys, and the recipients decrypt the data using their private keys. This method ensures data confidentiality and integrity and simplifies key management and distribution in multi-recipient scenarios.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the design of Acid Cryptofiler address the challenges of data encryption in multi-recipient scenarios, and what are the advantages of using asymmetric encryption in this context?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the design of Acid Cryptofiler address the challenges of data encryption in multi-recipient scenarios, and what are the advantages of using asymmetric encryption in this context?",
      "answer": "Acid Cryptofiler's design is tailored to address the challenges of data encryption in multi-recipient scenarios by utilizing asymmetric encryption. In this approach, each user has a unique pair of keys (public and private). The sender encrypts the data using the recipients' public keys, and the recipients decrypt the data using their private keys. This method ensures data confidentiality and integrity and simplifies key management and distribution in multi-recipient scenarios."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who is the leader of NullCrew and what is their pseudonym?",
    "context": "",
    "output": "The leader of NullCrew is a person who goes by the pseudonym Null.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is the leader of NullCrew and what is their pseudonym?",
      "answer": "The leader of NullCrew is a person who goes by the pseudonym Null."
    }
  },
  {
    "instruction": "Central Equipment Identity Register\n\n==Introduction==\nA Central Equipment Identity Register (CEIR) is a database of mobile equipment identifiers (IMEI \u2013 for networks of GSM standard, MEID \u2013 for networks of CDMA standard). Such an identifier is assigned to each SIM slot of the mobile device.\nLists of IMEIs may be the:\n\nWhite \u2013 for devices that are allowed to register in the cellular network,\nBlack \u2013 for devices that are prohibited to register in the cellular network,\nGrey \u2013 for devices in intermediate status (when it is not yet defined in which of the lists - black or white - the device should be placed).Depending on the rules of mobile equipment registration in a country the CEIR database may contain other lists or fields beside IMEI. For example, the subscriber number (MSISDN), which is bound to the IMEI, the ID of the individual (passport data, National ID, etc.) who registered IMEI in the database, details of the importer who brought the device into the country, etc.\nOriginally abbreviation CEIR stood for IMEI Database, created and provided by GSM Association. It was proposed to blacklist the IMEIs of stolen or lost phones. It was assumed that any MNO would be able to receive this list to block the registration of such devices on their network. Thus, it turns out that a stolen phone, once blacklisted by the GSMA CEIR, cannot be used on a large number of cellular networks, which means that the theft of mobile devices will become meaningless. However, it soon became clear that the MNOs on their initiative were not going to do this because if many phones stopped working in their networks, but works in another, it puts them at a disadvantage and can lead to an outflow of subscribers. It became clear that the blocking of stolen devices should be introduced simultaneously in all mobile networks of the country by legislative measures at the initiative of the communications regulator. In this case, as a rule, a national IMEI database is created, which contains general lists of blocked IMEIs. Since the registration in the cellular operator's network is directly blocked by a network node called EIR (Equipment Identity Register), the system that contains the national IMEI base became known as Central EIR (CEIR). To avoid confusion the database of GSM Association was renamed to IMEI Database - IMEI DB (it was in 2003-2008, see \u201cDocument History\u201d at IMEI Database File Format Specification). Also sometimes a common IMEI database for several EIRs is called SEIR (Shared EIR).\nIn each country, the CEIR can interact with IMEI DB differently. National CEIR may not communicate with IMEI DB at all. Firstly, it is separately decided whether CEIR will send information about its blacklist to IMEI DB (which IMEIs are placed in it or removed from there). Secondly, upon receipt of the blacklist from IMEI DB, the regulator decides from which countries it will receive it (IMEI DB stores the information exactly who blacklisted the IMEI). For example, you can get a list from neighboring countries, from countries in your region, from around the world.\nIn addition to the blacklist, the GSMA is developing a list of IMEIs allocated to manufacturers for use in their devices. The manufacturer for each new device model gets at least one TAC (Type Allocation Code) allocated by GSMA, consisting of 8 digits, to which he can add a 6-digit serial number to obtain the IMEI. Thus, with one TAC, a manufacturer can release up to 1 million devices with a unique IMEI. Usually, CEIR receives a list of allocated TACs from the GSMA, since if the first 8 digits of the IMEI of a device are not in this list, this is a sign that it is counterfeit.\nIf the central database of identifiers does not work with GSM networks, but with CDMA, then for the same purposes it is necessary to interact with another worldwide database that contains MEIDs \u2013 MEID Database.A system that directly blocks the registration of a mobile device on a cellular network \u2013 EIR. Each MNO must have at least one EIR, to which IMEI check requests (CheckIMEI) are sent when registering a device on the network. A typical EIR and CERI interaction scheme: \n\nThe CEIR accumulates black, white, and grey lists using various data sources and verification methods.\nThese lists are periodically transmitted to all EIRs.\nEIR uses them when processing every CheckIMEI request to determine whether to allow the device on the network or not.EIR can transmit some data to the CEIR database too. Usually, changes in a grey list \u2013 new IMEIs on the network that are not in any list \u2013 are transmitted from EIR to CEIR.\nIn addition to synchronizing lists across multiple networks, the main function of CEIR is to implement the scenarios of changes at these lists. This usually requires interaction with various IT systems (databases) of other organizations and/or with subscribers. \u0415xamples of such scenarios:\n\nWhitelisting the IMEI of devices imported by the legal entity\nWhitelisting the IMEI of devices manufactured domestically\nWhitelisting the IMEI of devices imported by individual\nBlacklisting the IMEI of stolen/lost devices\nBinding IMEI to the subscriber's number and, vice versa, unbinding IMEI from the subscriber\n\n== System implementation results ==\nThe goals and results of CEIR implementation in a country are usually:\n\nReducing mobile phone theft\nReducing the import of devices stolen in other countries\nReducing the presence of counterfeit devices on the market (null IMEI, incorrect IMEI, changed IMEI)\nReducing illegal imports of mobile devices (increase in the collection of customs duties)Additionally, CEIR most often contributes to the solution of such problems:\n\nCombating various mobile fraud schemes\nObtaining more accurate statistics on the state of the mobile communications market for the regulator\nFight against terrorism (the ability to block the device at once in all mobile networks of the country).Known results achieved in some countries:\n\nGreat Britain \u2013 reducing mobile phone theft.\nTurkey \u2013 reducing mobile phone theft, decreasing the current account deficit of Turkey and maximizing tax revenues.\nUzbekistan \u2013 preventing black import of mobile devices by 98%, increase in revenues from the import of mobile devices by 700%.\nKenya \u2013 disposing the market of counterfeit mobile equipment.\nAzerbaijan \u2013 disposing the market of counterfeit mobile equipment.\nUkraine \u2013 increasing of legally imported mobile devices by 95%, increase in revenues from the import of mobile devices.\n\n== CEIR and EIR manufacturers ==\nSome countries have used local developers to implement CEIR for their country (Great Britain, Turkey, India, and Azerbaijan). There are also a number of companies that offer their solution already installed in at least one country: Invigo, Mediafon Datapro, PortingXS, Qualcomm, Svyazcom, Oratech Bilisim.\nEIR is a system that is standardized in a 2G-5G networks. Such system may be established at mobile network even it doesn\u2019t use black list and there are no CEIR in a country. The most common EIR manufacturers are companies Invigo, BroadForward, Mahindra Comviva, Primal Technologies, Mavenir, Nokia, Svyazcom. Some developers of MNO\u2019s signal core include EIR in a complex solution. However, its standard capabilities are usually lacking for specific requirements when implementing CEIR.\n\nHow does the IMEI database help in fighting terrorism?",
    "context": "",
    "output": "The IMEI database can help in fighting terrorism by providing the ability to block a device at once in all mobile networks of the country. This can be useful in situations where a device is being used for illegal activities or where there is a threat to national security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the IMEI database help in fighting terrorism?",
      "answer": "The IMEI database can help in fighting terrorism by providing the ability to block a device at once in all mobile networks of the country. This can be useful in situations where a device is being used for illegal activities or where there is a threat to national security.",
      "context": "Central Equipment Identity Register\n\n==Introduction==\nA Central Equipment Identity Register (CEIR) is a database of mobile equipment identifiers (IMEI \u2013 for networks of GSM standard, MEID \u2013 for networks of CDMA standard). Such an identifier is assigned to each SIM slot of the mobile device.\nLists of IMEIs may be the:\n\nWhite \u2013 for devices that are allowed to register in the cellular network,\nBlack \u2013 for devices that are prohibited to register in the cellular network,\nGrey \u2013 for devices in intermediate status (when it is not yet defined in which of the lists - black or white - the device should be placed).Depending on the rules of mobile equipment registration in a country the CEIR database may contain other lists or fields beside IMEI. For example, the subscriber number (MSISDN), which is bound to the IMEI, the ID of the individual (passport data, National ID, etc.) who registered IMEI in the database, details of the importer who brought the device into the country, etc.\nOriginally abbreviation CEIR stood for IMEI Database, created and provided by GSM Association. It was proposed to blacklist the IMEIs of stolen or lost phones. It was assumed that any MNO would be able to receive this list to block the registration of such devices on their network. Thus, it turns out that a stolen phone, once blacklisted by the GSMA CEIR, cannot be used on a large number of cellular networks, which means that the theft of mobile devices will become meaningless. However, it soon became clear that the MNOs on their initiative were not going to do this because if many phones stopped working in their networks, but works in another, it puts them at a disadvantage and can lead to an outflow of subscribers. It became clear that the blocking of stolen devices should be introduced simultaneously in all mobile networks of the country by legislative measures at the initiative of the communications regulator. In this case, as a rule, a national IMEI database is created, which contains general lists of blocked IMEIs. Since the registration in the cellular operator's network is directly blocked by a network node called EIR (Equipment Identity Register), the system that contains the national IMEI base became known as Central EIR (CEIR). To avoid confusion the database of GSM Association was renamed to IMEI Database - IMEI DB (it was in 2003-2008, see \u201cDocument History\u201d at IMEI Database File Format Specification). Also sometimes a common IMEI database for several EIRs is called SEIR (Shared EIR).\nIn each country, the CEIR can interact with IMEI DB differently. National CEIR may not communicate with IMEI DB at all. Firstly, it is separately decided whether CEIR will send information about its blacklist to IMEI DB (which IMEIs are placed in it or removed from there). Secondly, upon receipt of the blacklist from IMEI DB, the regulator decides from which countries it will receive it (IMEI DB stores the information exactly who blacklisted the IMEI). For example, you can get a list from neighboring countries, from countries in your region, from around the world.\nIn addition to the blacklist, the GSMA is developing a list of IMEIs allocated to manufacturers for use in their devices. The manufacturer for each new device model gets at least one TAC (Type Allocation Code) allocated by GSMA, consisting of 8 digits, to which he can add a 6-digit serial number to obtain the IMEI. Thus, with one TAC, a manufacturer can release up to 1 million devices with a unique IMEI. Usually, CEIR receives a list of allocated TACs from the GSMA, since if the first 8 digits of the IMEI of a device are not in this list, this is a sign that it is counterfeit.\nIf the central database of identifiers does not work with GSM networks, but with CDMA, then for the same purposes it is necessary to interact with another worldwide database that contains MEIDs \u2013 MEID Database.A system that directly blocks the registration of a mobile device on a cellular network \u2013 EIR. Each MNO must have at least one EIR, to which IMEI check requests (CheckIMEI) are sent when registering a device on the network. A typical EIR and CERI interaction scheme: \n\nThe CEIR accumulates black, white, and grey lists using various data sources and verification methods.\nThese lists are periodically transmitted to all EIRs.\nEIR uses them when processing every CheckIMEI request to determine whether to allow the device on the network or not.EIR can transmit some data to the CEIR database too. Usually, changes in a grey list \u2013 new IMEIs on the network that are not in any list \u2013 are transmitted from EIR to CEIR.\nIn addition to synchronizing lists across multiple networks, the main function of CEIR is to implement the scenarios of changes at these lists. This usually requires interaction with various IT systems (databases) of other organizations and/or with subscribers. \u0415xamples of such scenarios:\n\nWhitelisting the IMEI of devices imported by the legal entity\nWhitelisting the IMEI of devices manufactured domestically\nWhitelisting the IMEI of devices imported by individual\nBlacklisting the IMEI of stolen/lost devices\nBinding IMEI to the subscriber's number and, vice versa, unbinding IMEI from the subscriber\n\n== System implementation results ==\nThe goals and results of CEIR implementation in a country are usually:\n\nReducing mobile phone theft\nReducing the import of devices stolen in other countries\nReducing the presence of counterfeit devices on the market (null IMEI, incorrect IMEI, changed IMEI)\nReducing illegal imports of mobile devices (increase in the collection of customs duties)Additionally, CEIR most often contributes to the solution of such problems:\n\nCombating various mobile fraud schemes\nObtaining more accurate statistics on the state of the mobile communications market for the regulator\nFight against terrorism (the ability to block the device at once in all mobile networks of the country).Known results achieved in some countries:\n\nGreat Britain \u2013 reducing mobile phone theft.\nTurkey \u2013 reducing mobile phone theft, decreasing the current account deficit of Turkey and maximizing tax revenues.\nUzbekistan \u2013 preventing black import of mobile devices by 98%, increase in revenues from the import of mobile devices by 700%.\nKenya \u2013 disposing the market of counterfeit mobile equipment.\nAzerbaijan \u2013 disposing the market of counterfeit mobile equipment.\nUkraine \u2013 increasing of legally imported mobile devices by 95%, increase in revenues from the import of mobile devices.\n\n== CEIR and EIR manufacturers ==\nSome countries have used local developers to implement CEIR for their country (Great Britain, Turkey, India, and Azerbaijan). There are also a number of companies that offer their solution already installed in at least one country: Invigo, Mediafon Datapro, PortingXS, Qualcomm, Svyazcom, Oratech Bilisim.\nEIR is a system that is standardized in a 2G-5G networks. Such system may be established at mobile network even it doesn\u2019t use black list and there are no CEIR in a country. The most common EIR manufacturers are companies Invigo, BroadForward, Mahindra Comviva, Primal Technologies, Mavenir, Nokia, Svyazcom. Some developers of MNO\u2019s signal core include EIR in a complex solution. However, its standard capabilities are usually lacking for specific requirements when implementing CEIR."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who introduced the concept of proof-carrying code in 1996?",
    "context": "",
    "output": "George Necula and Peter Lee introduced the concept of proof-carrying code in 1996.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who introduced the concept of proof-carrying code in 1996?",
      "answer": "George Necula and Peter Lee introduced the concept of proof-carrying code in 1996."
    }
  },
  {
    "instruction": "SIGINT Activity Designator\n\n==Introduction==\nA SIGINT Activity Designator (or SIGAD) identifies a signals intelligence (SIGINT) line of collection activity associated with a signals collection station, such as a base or a ship. For example, the SIGAD for Menwith Hill in the UK is USD1000. SIGADs are used by the signals intelligence agencies of the United States, the United Kingdom, Canada, Australia and New Zealand (the Five Eyes).\n\nThere are several thousand SIGADs including the substation SIGADs denoted with a trailing alpha character. Several dozen of these are significant. The leaked Boundless Informant reporting screenshot showed that it summarized 504 active SIGADs during a 30-day period in March 2013.\n\n\n\n== General format ==\nA SIGAD consists of five to eight case insensitive alphanumeric characters. It takes the general form of an alphanumeric designator normally composed of a two- or three-letter prefix followed by one to three numbers. Often a dash is used to separate the alphabetic and numeric characters in the primary part of the designator, but less frequently a space is used as a separator or the alphabetic and numeric characters are concatenated together. An additional alphabetic character can be added to denote a sub-designator for a subset of the primary unit, such as a detachment. Lastly, a numeric character can be added after the aforementioned alphabetic to provide for a sub-sub-designator.\nIn the examples below an X represents an alphabetic character and an N represents a numeric character that are part of the primary designator. Likewise, an x represents an alphabetic character and an n represents a numeric character that are part of a sub-designator. Here are valid generalized examples of SIGADs:\n\nThe first two characters show which country operates the particular SIGINT facility, which can be US for the United States, UK for the United Kingdom, CA for Canada, AU for Australia and NZ for New Zealand. A third letter shows what sort of staff runs the station. SIGADs beginning with US without a third letter are used for intercept facilities run by the NSA.\n\n== PRISM SIGAD ==\nOne prominent SIGAD as of April 2013 is US-984XN, with an unclassified codename of PRISM. It is \"the number one source of raw intelligence used for NSA analytic reports\" according to National Security Agency sources in a document leaked by Edward Snowden. The President's Daily Brief, an all-source intelligence product, cited SIGAD US-984XN as a source in 1,477 items in 2012. The U.S. government operates the PRISM electronic surveillance collection program through NSA's Special Source Operations, an alliance with trusted telecommunications providers.\n\n== SIGADs for spy ships ==\nThe declassifed SIGAD for the USS Liberty (AGTR-5) was USN-855. The USS Liberty incident occurred on 8 June 1967, during the Six-Day War, when Israeli Air Force jet fighter aircraft and Israeli Navy motor torpedo boats attacked the USS Liberty in international waters.\nThe USS Pueblo (AGER-2) was a technical research ship, which was boarded and captured by North Korean forces on 23 January 1968, in what is known as the Pueblo incident. The declassified SIGAD for the NSA Direct Support Unit (DSU) from the Naval Security Group (NSG) on the USS Pueblo patrol involved in the incident was USN-467Y. The USS Pueblo, which officially remains a commissioned vessel of the United States Navy, is the only ship of the U.S. Navy currently being held captive.\n\n== Vietnam War SIGADs ==\nThe following are the Vietnam War-era declassified SIGADs from inside South Vietnam during the period of 1969 to 1975:\nSome locations have multiple SIGADs due to different types of collection activities and/or collection at different times during the period. The SIGADs beginning with USA were operated by the United States Air Force's United States Air Force Security Service (USAFSS). The SIGADs beginning with USM were operated by the United States Army's Army Security Agency (ASA). Lastly, the SIGADs beginning with USN were operated by the United States Navy's Naval Security Group (NAVSECGRU). All three of these units have been merged into other units or inactivated.The above list consists of the higher-echelon SIGADs. It does not include the numerous miscellaneous and temporary detachments, or direction finding stations belonging to major units or sites unless that detachment or site was the only one stationed in South Vietnam. Many of the \"dets\" were short-lived, often formed to support ongoing MACV operations or forward deployments of combat operational or maneuver units. These detachments usually were designated by a letter suffix attached to the higher-echelon SIGAD such as \"USM-633J,\" which was a detachment of the 372d Radio Research Company, USM-633, supporting the United States Army's 25th Infantry Division.\n\n\n*** Supporting Southeast Asia SIGADs ***\nThe following declassified SIGADs were highly relevant to the Vietnam Campaign, but were located in areas outside of South Vietnam in Southeast Asia.\nAgain, detachments are not listed separately. In the case of the USS Maddox, naval Direct Support Units (DSUs) used the SIGAD USN-467 as a generic designator for their missions. Each specific patrol received a letter suffix for its duration. The subsequent mission would receive the next letter in an alphabetic sequence. Thus, SIGAD USN-467N specifically designates the USS Maddox patrol involved with the Gulf of Tonkin incident.\n\n== Joint Base SIGADs ==\nIn November 2005, the US Congress performed a fifth round of Base Realignment and Closure. This 2005 law also created twelve joint bases by merging adjacent installations belonging to different services in an effort to reduce costs and improve efficiencies.Joint bases with a primarily SIGINT mission have SIGADs that begin with USJ. A joint base would have a primary SIGAD in the general form of USJ-NNN, where NNN are numeric characters. An actual example is not given, since these units are currently active.\n\nBased on the above text, answer a question. What is the purpose of the General format section in the given text?",
    "context": "",
    "output": "The General format section in the given text provides a generalized description of the format and structure of a SIGAD, including its composition, the meaning of its alphanumeric characters, and the use of separators.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the General format section in the given text?",
      "answer": "The General format section in the given text provides a generalized description of the format and structure of a SIGAD, including its composition, the meaning of its alphanumeric characters, and the use of separators.",
      "context": "SIGINT Activity Designator\n\n==Introduction==\nA SIGINT Activity Designator (or SIGAD) identifies a signals intelligence (SIGINT) line of collection activity associated with a signals collection station, such as a base or a ship. For example, the SIGAD for Menwith Hill in the UK is USD1000. SIGADs are used by the signals intelligence agencies of the United States, the United Kingdom, Canada, Australia and New Zealand (the Five Eyes).\n\nThere are several thousand SIGADs including the substation SIGADs denoted with a trailing alpha character. Several dozen of these are significant. The leaked Boundless Informant reporting screenshot showed that it summarized 504 active SIGADs during a 30-day period in March 2013.\n\n\n\n== General format ==\nA SIGAD consists of five to eight case insensitive alphanumeric characters. It takes the general form of an alphanumeric designator normally composed of a two- or three-letter prefix followed by one to three numbers. Often a dash is used to separate the alphabetic and numeric characters in the primary part of the designator, but less frequently a space is used as a separator or the alphabetic and numeric characters are concatenated together. An additional alphabetic character can be added to denote a sub-designator for a subset of the primary unit, such as a detachment. Lastly, a numeric character can be added after the aforementioned alphabetic to provide for a sub-sub-designator.\nIn the examples below an X represents an alphabetic character and an N represents a numeric character that are part of the primary designator. Likewise, an x represents an alphabetic character and an n represents a numeric character that are part of a sub-designator. Here are valid generalized examples of SIGADs:\n\nThe first two characters show which country operates the particular SIGINT facility, which can be US for the United States, UK for the United Kingdom, CA for Canada, AU for Australia and NZ for New Zealand. A third letter shows what sort of staff runs the station. SIGADs beginning with US without a third letter are used for intercept facilities run by the NSA.\n\n== PRISM SIGAD ==\nOne prominent SIGAD as of April 2013 is US-984XN, with an unclassified codename of PRISM. It is \"the number one source of raw intelligence used for NSA analytic reports\" according to National Security Agency sources in a document leaked by Edward Snowden. The President's Daily Brief, an all-source intelligence product, cited SIGAD US-984XN as a source in 1,477 items in 2012. The U.S. government operates the PRISM electronic surveillance collection program through NSA's Special Source Operations, an alliance with trusted telecommunications providers.\n\n== SIGADs for spy ships ==\nThe declassifed SIGAD for the USS Liberty (AGTR-5) was USN-855. The USS Liberty incident occurred on 8 June 1967, during the Six-Day War, when Israeli Air Force jet fighter aircraft and Israeli Navy motor torpedo boats attacked the USS Liberty in international waters.\nThe USS Pueblo (AGER-2) was a technical research ship, which was boarded and captured by North Korean forces on 23 January 1968, in what is known as the Pueblo incident. The declassified SIGAD for the NSA Direct Support Unit (DSU) from the Naval Security Group (NSG) on the USS Pueblo patrol involved in the incident was USN-467Y. The USS Pueblo, which officially remains a commissioned vessel of the United States Navy, is the only ship of the U.S. Navy currently being held captive.\n\n== Vietnam War SIGADs ==\nThe following are the Vietnam War-era declassified SIGADs from inside South Vietnam during the period of 1969 to 1975:\nSome locations have multiple SIGADs due to different types of collection activities and/or collection at different times during the period. The SIGADs beginning with USA were operated by the United States Air Force's United States Air Force Security Service (USAFSS). The SIGADs beginning with USM were operated by the United States Army's Army Security Agency (ASA). Lastly, the SIGADs beginning with USN were operated by the United States Navy's Naval Security Group (NAVSECGRU). All three of these units have been merged into other units or inactivated.The above list consists of the higher-echelon SIGADs. It does not include the numerous miscellaneous and temporary detachments, or direction finding stations belonging to major units or sites unless that detachment or site was the only one stationed in South Vietnam. Many of the \"dets\" were short-lived, often formed to support ongoing MACV operations or forward deployments of combat operational or maneuver units. These detachments usually were designated by a letter suffix attached to the higher-echelon SIGAD such as \"USM-633J,\" which was a detachment of the 372d Radio Research Company, USM-633, supporting the United States Army's 25th Infantry Division.\n\n\n*** Supporting Southeast Asia SIGADs ***\nThe following declassified SIGADs were highly relevant to the Vietnam Campaign, but were located in areas outside of South Vietnam in Southeast Asia.\nAgain, detachments are not listed separately. In the case of the USS Maddox, naval Direct Support Units (DSUs) used the SIGAD USN-467 as a generic designator for their missions. Each specific patrol received a letter suffix for its duration. The subsequent mission would receive the next letter in an alphabetic sequence. Thus, SIGAD USN-467N specifically designates the USS Maddox patrol involved with the Gulf of Tonkin incident.\n\n== Joint Base SIGADs ==\nIn November 2005, the US Congress performed a fifth round of Base Realignment and Closure. This 2005 law also created twelve joint bases by merging adjacent installations belonging to different services in an effort to reduce costs and improve efficiencies.Joint bases with a primarily SIGINT mission have SIGADs that begin with USJ. A joint base would have a primary SIGAD in the general form of USJ-NNN, where NNN are numeric characters. An actual example is not given, since these units are currently active."
    }
  },
  {
    "instruction": "Context: Software-defined protection\n\n==Introduction==\nSoftware-defined protection (SDP) is a computer network security architecture and methodology that combines network security devices and defensive protections which leverage both internal and external intelligence sources. An SDP infrastructure is designed to be modular, scalable, and secure. The SDP architecture partitions the security infrastructure into three interconnected layers. The Enforcement Layer inspects traffic and enforces protection within well-defined network segments. The Control Layer generates security policies and deploys those protections to enforcement points. The Management Layer orchestrates the infrastructure and integrates security with business processes. The SDP architecture supports traditional network security and access control policy requirements, as well as the threat prevention required for enterprises implementing technologies such as mobile computing and software-defined Networking (SDN).\n\n\n\n== Enforcement Layer ==\nThe Enforcement Layer of SDP enables organizations to design segmented networks, implement physical and virtual security enforcement points based upon that segmentation, and execute the protection logic for the prescribed network segments.\nSDP incorporates the principal of segmentation into the Enforcement Layer. Segmentation divides a network into compartments that have different security characteristics. Based upon segment requirements, security controls are established for threat containment and recovery. Enforcement points, or platforms for executing protections, must then be implemented at the boundaries of the segments to enforce the defined protection logic. Enforcement points may be implemented as network security gateways, host-based software, mobile device applications, or virtual machines in the cloud.\n\n== Control Layer ==\nThe Control Layer is the core of the SDP architecture. Its role is to generate protections and deploy them for execution at the appropriate enforcement points within the Enforcement Layer. To develop the appropriate protections, the Control Layer relies upon repositories of data that include knowledge of the organization and its information systems (Access Control), knowledge of data assets and their classifications (data protection) and knowledge of threats (threat prevention). Security Solutions commonly implemented within the Control layer include firewall, anti-virus, application control, threat emulation, anti-bot, anti-spam and email security, data loss prevention (DLP), and intrusion prevention systems (IPS). Through systematic mapping of these protective controls to the associated risk for each segment and its assets within the Enforcement Layer, organizations can deliver multi-layer protection against attacks.\n\n== Management Layer ==\nThe Management Layer serves as the interface between network administrators and the other two layers of the SDP infrastructure. This layer supports the enterprise segmentation and enables the definition of access and data control policies and the activation of threat prevention separately. The Management Layer also provides the ability to delegate management to specific administrators who can work with them simultaneously. The Management Layer provides visibility into what is happening in the network, supports proactive incident response, and provides the intelligence required to tailor security controls for the organization.\nAnswer this question: How does SDP architecture support scalability and security?",
    "context": "",
    "output": "SDP architecture is designed to be modular, scalable, and secure. It partitions the security infrastructure into three interconnected layers and enables organizations to design segmented networks and implement physical and virtual security enforcement points based upon that segmentation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SDP architecture support scalability and security?",
      "answer": "SDP architecture is designed to be modular, scalable, and secure. It partitions the security infrastructure into three interconnected layers and enables organizations to design segmented networks and implement physical and virtual security enforcement points based upon that segmentation.",
      "context": "Software-defined protection\n\n==Introduction==\nSoftware-defined protection (SDP) is a computer network security architecture and methodology that combines network security devices and defensive protections which leverage both internal and external intelligence sources. An SDP infrastructure is designed to be modular, scalable, and secure. The SDP architecture partitions the security infrastructure into three interconnected layers. The Enforcement Layer inspects traffic and enforces protection within well-defined network segments. The Control Layer generates security policies and deploys those protections to enforcement points. The Management Layer orchestrates the infrastructure and integrates security with business processes. The SDP architecture supports traditional network security and access control policy requirements, as well as the threat prevention required for enterprises implementing technologies such as mobile computing and software-defined Networking (SDN).\n\n\n\n== Enforcement Layer ==\nThe Enforcement Layer of SDP enables organizations to design segmented networks, implement physical and virtual security enforcement points based upon that segmentation, and execute the protection logic for the prescribed network segments.\nSDP incorporates the principal of segmentation into the Enforcement Layer. Segmentation divides a network into compartments that have different security characteristics. Based upon segment requirements, security controls are established for threat containment and recovery. Enforcement points, or platforms for executing protections, must then be implemented at the boundaries of the segments to enforce the defined protection logic. Enforcement points may be implemented as network security gateways, host-based software, mobile device applications, or virtual machines in the cloud.\n\n== Control Layer ==\nThe Control Layer is the core of the SDP architecture. Its role is to generate protections and deploy them for execution at the appropriate enforcement points within the Enforcement Layer. To develop the appropriate protections, the Control Layer relies upon repositories of data that include knowledge of the organization and its information systems (Access Control), knowledge of data assets and their classifications (data protection) and knowledge of threats (threat prevention). Security Solutions commonly implemented within the Control layer include firewall, anti-virus, application control, threat emulation, anti-bot, anti-spam and email security, data loss prevention (DLP), and intrusion prevention systems (IPS). Through systematic mapping of these protective controls to the associated risk for each segment and its assets within the Enforcement Layer, organizations can deliver multi-layer protection against attacks.\n\n== Management Layer ==\nThe Management Layer serves as the interface between network administrators and the other two layers of the SDP infrastructure. This layer supports the enterprise segmentation and enables the definition of access and data control policies and the activation of threat prevention separately. The Management Layer also provides the ability to delegate management to specific administrators who can work with them simultaneously. The Management Layer provides visibility into what is happening in the network, supports proactive incident response, and provides the intelligence required to tailor security controls for the organization."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does IASME Governance compare to the Cyber Assessment Framework (CAF)?",
    "context": "",
    "output": "The IASME Governance Standard maps closely to the CAF, which has been developed by the UK Government to allow organizations to demonstrate their compliance to the NIS Directive.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does IASME Governance compare to the Cyber Assessment Framework (CAF)?",
      "answer": "The IASME Governance Standard maps closely to the CAF, which has been developed by the UK Government to allow organizations to demonstrate their compliance to the NIS Directive."
    }
  },
  {
    "instruction": "context: The general consensus among security experts to protect oneself from ransomware, including Locky, is to keep installed programs updated and to only open attachments from known senders.\n\nAsk a question about this context.",
    "context": "",
    "output": "How are ransomware infections, including Locky, prevented?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are ransomware infections, including Locky, prevented?",
      "answer": "The general consensus among security experts to protect oneself from ransomware, including Locky, is to keep installed programs updated and to only open attachments from known senders."
    }
  },
  {
    "instruction": "context: Over 50 countries have adopted biometric voting registration as of 2016.\n\nAsk a question about this context.",
    "context": "",
    "output": "How many countries have adopted biometric voting registration as of 2016?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many countries have adopted biometric voting registration as of 2016?",
      "answer": "Over 50 countries have adopted biometric voting registration as of 2016."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the Merkle tree in the Merkle signature scheme?",
    "context": "",
    "output": "The Merkle tree in the Merkle signature scheme plays a crucial role in proving that the key pair used to sign a message was one of the original key pairs, by allowing the verifier to verify the intermediate nodes of the Merkle tree.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Merkle tree in the Merkle signature scheme?",
      "answer": "The Merkle tree in the Merkle signature scheme plays a crucial role in proving that the key pair used to sign a message was one of the original key pairs, by allowing the verifier to verify the intermediate nodes of the Merkle tree."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the difference between BestCrypt Volume Encryption and BestCrypt Container Encryption?",
    "context": "",
    "output": "BestCrypt Volume Encryption is used to encrypt entire disk volumes, while BestCrypt Container Encryption is used to encrypt virtual disks stored as computer files.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between BestCrypt Volume Encryption and BestCrypt Container Encryption?",
      "answer": "BestCrypt Volume Encryption is used to encrypt entire disk volumes, while BestCrypt Container Encryption is used to encrypt virtual disks stored as computer files."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is one of the four grand research challenges in information security and assurance identified by the Computing Research Association in 2003?",
    "context": "",
    "output": "One of the four grand research challenges in information security and assurance identified by the Computing Research Association in 2003 is: \"Give end-users security controls they can understand and privacy they can control for the dynamic, pervasive computing environments of the future.\"",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is one of the four grand research challenges in information security and assurance identified by the Computing Research Association in 2003?",
      "answer": "One of the four grand research challenges in information security and assurance identified by the Computing Research Association in 2003 is: \"Give end-users security controls they can understand and privacy they can control for the dynamic, pervasive computing environments of the future.\""
    }
  },
  {
    "instruction": "Write an answer to the following question: Can a user continue to use the program installed with Cydoor after uninstalling Cydoor?",
    "context": "",
    "output": "In some cases, uninstalling Cydoor may cause the program it is integrated with to stop working.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can a user continue to use the program installed with Cydoor after uninstalling Cydoor?",
      "answer": "In some cases, uninstalling Cydoor may cause the program it is integrated with to stop working."
    }
  },
  {
    "instruction": "DCLeaks\n\n==Introduction==\nDCLeaks (also known as DC Leaks) was a website that was established in June 2016. It was responsible for publishing leaks of emails belonging to multiple prominent figures in the United States government and military. Cybersecurity research firms determined the site is a front for the Russian cyber-espionage group Fancy Bear. On July 13, 2018, an indictment was made against 12 Russian GRU military officers; it alleged that DCLeaks is part of a Russian military operation to interfere in the 2016 U.S. presidential election.\n\n== Identity ==\nThe site is thought by private cybersecurity analysts and the US intelligence community to be a part of Russian interference in the 2016 US elections.\nCybersecurity research firm ThreatConnect concluded that the DCLeaks project showed the hallmarks of Russian intelligence, matching the attack pattern of the GRU hacker group Fancy Bear. ThreatConnect determined that the site is likely linked to Russian persona Guccifer 2.0 and the GRU-linked hacker group Fancy Bear.According to the DCLeaks site's \"About\" page, their aim is \"to find out and tell you the truth about U.S. decision-making process  [sic] as well as about the key elements of American political life.\" Of themselves, they say that they were launched by \"the American hacktivists who respect and appreciate freedom of speech, human rights and government of the people.\"On July 13, 2018 a federal grand jury for the District of Columbia indicted 12 members of Unit 26165 of the Russian Main Intelligence Directorate (GRU) for creating the false identity DCLeaks website, hacking the Democratic National Committee and releasing stolen data on the website.\n\n== Response ==\nIn August 2017, Dana Rohrabacher meets with Julian Assange in the Ecuadorian Embassy in London to offer Assange a pardon from President Trump if Assange could offer material supporting Seth Rich as the source of email leaks from the Democratic National Committee during 2016 and not Russians. In February 2020, Rohrabacher told Yahoo News his goal during this meeting with Assange was to find evidence for a widely debunked conspiracy theory that WikiLeaks' real source was not Russian intelligence agents for the DNC emails but former DNC staffer Seth Rich. Stephanie Grisham, White House spokesperson for President Trump, stated that Trump barely knows Rohrabacher except that he's an ex-congressman and has not spoken with Rohrabacher on almost any subject. On February 19, 2020, Edward Fitzgerald, Julian Assange's barrister, asserted at Westminster Magistrates\u2019 Court in London that Rohrabacher had been sent on behalf of President Trump in August 2017 to offer Assange a pardon from Trump if Assange could release material to show that Russian hackers were not involved in the 2016 United States election interference. However, on July 14, 2016, which is four days after the death of Seth Rich, WikiLeaks had received from Russian hackers the stolen documents file of emails.During November 2017, the Associated Press revealed that the FBI had failed to notify almost all of the persons in the cross hairs of the Kremlin-backed Fancy Bear's attack of 312 prominent government and defense officials who had their emails posted on DCLeaks. The FBI was in violation of its own policy of robustly informing victims of hacking.\n\n\n*** Indictments ***\nOn July 13, 2018, Deputy Attorney General Rod Rosenstein announced that twelve Russian hackers, who were operating in multiple units including Units 26165 and 74455 with the Main Intelligence Directorate of the General Staff (GRU), were named on an 11-count indictment for obtaining access and distributing information from data about 500,000 voters from a state election board website as well as the email accounts of John Podesta, Hillary Clinton, and volunteers and employees of the United States Presidential Campaign of Hillary Clinton (Clinton Campaign), the Democratic Congressional Campaign Committee (DCCC) and the Democratic National Committee (DNC). Following Donald Trump's request on July 27, 2016, during a rally in Florida that Vladimir Putin should have Russia hack into Trump's opponents networks, servers, and emails to make Hillary Clinton's 30,000 missing emails made public, Russian hackers tried for the first time to hack into Hillary Clinton's personal offices.The GRU mined Bitcoins to later purchase the DCLeaks domain and operate both the DCLeaks server and Guccifer 2.0 server to distribute information obtained from these hackers in order to discredit and disrupt the Clinton Campaign, the DCCC, and the DNC so that the Bernie Sanders Presidential Campaign, Republican candidates and the Donald Trump Presidential Campaign would benefit during the 2016 election cycle. They obtained the data about 500,000 voters by breaking into voter verification software and targeting local and state election officials. Although Roger Stone did not know the names of the Russian's sources, he had publicly stated that these Russians were in contact with the Trump Campaign and that he had communicated with them.Russians had also passed embarrassing information from these hacks to Wikileaks. This led to the resignation of the DNC Chairwoman Debbie Wasserman-Schultz in July, 2016. Using peer-to-peer exchanges and pre-paid cards, the Russians mined and used Bitcoins with public Blockchain recorded transactions using hundreds of emails with fictitious names to prevent monitoring by United States authorities on traditional financial transaction networks. The Internet Research Agency in Saint Petersburg spearheaded parts of the operation.\n\nWhat request did Donald Trump make during a rally in Florida in July 2016, and how did Russian hackers respond?",
    "context": "",
    "output": "Donald Trump requested that Vladimir Putin have Russia hack into his opponents' networks, servers, and emails to make Hillary Clinton's 30,000 missing emails public. Four days later, Russian hackers received stolen documents from WikiLeaks, and they attempted to hack into Hillary Clinton's personal offices for the first time.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What request did Donald Trump make during a rally in Florida in July 2016, and how did Russian hackers respond?",
      "answer": "Donald Trump requested that Vladimir Putin have Russia hack into his opponents' networks, servers, and emails to make Hillary Clinton's 30,000 missing emails public. Four days later, Russian hackers received stolen documents from WikiLeaks, and they attempted to hack into Hillary Clinton's personal offices for the first time.",
      "context": "DCLeaks\n\n==Introduction==\nDCLeaks (also known as DC Leaks) was a website that was established in June 2016. It was responsible for publishing leaks of emails belonging to multiple prominent figures in the United States government and military. Cybersecurity research firms determined the site is a front for the Russian cyber-espionage group Fancy Bear. On July 13, 2018, an indictment was made against 12 Russian GRU military officers; it alleged that DCLeaks is part of a Russian military operation to interfere in the 2016 U.S. presidential election.\n\n== Identity ==\nThe site is thought by private cybersecurity analysts and the US intelligence community to be a part of Russian interference in the 2016 US elections.\nCybersecurity research firm ThreatConnect concluded that the DCLeaks project showed the hallmarks of Russian intelligence, matching the attack pattern of the GRU hacker group Fancy Bear. ThreatConnect determined that the site is likely linked to Russian persona Guccifer 2.0 and the GRU-linked hacker group Fancy Bear.According to the DCLeaks site's \"About\" page, their aim is \"to find out and tell you the truth about U.S. decision-making process  [sic] as well as about the key elements of American political life.\" Of themselves, they say that they were launched by \"the American hacktivists who respect and appreciate freedom of speech, human rights and government of the people.\"On July 13, 2018 a federal grand jury for the District of Columbia indicted 12 members of Unit 26165 of the Russian Main Intelligence Directorate (GRU) for creating the false identity DCLeaks website, hacking the Democratic National Committee and releasing stolen data on the website.\n\n== Response ==\nIn August 2017, Dana Rohrabacher meets with Julian Assange in the Ecuadorian Embassy in London to offer Assange a pardon from President Trump if Assange could offer material supporting Seth Rich as the source of email leaks from the Democratic National Committee during 2016 and not Russians. In February 2020, Rohrabacher told Yahoo News his goal during this meeting with Assange was to find evidence for a widely debunked conspiracy theory that WikiLeaks' real source was not Russian intelligence agents for the DNC emails but former DNC staffer Seth Rich. Stephanie Grisham, White House spokesperson for President Trump, stated that Trump barely knows Rohrabacher except that he's an ex-congressman and has not spoken with Rohrabacher on almost any subject. On February 19, 2020, Edward Fitzgerald, Julian Assange's barrister, asserted at Westminster Magistrates\u2019 Court in London that Rohrabacher had been sent on behalf of President Trump in August 2017 to offer Assange a pardon from Trump if Assange could release material to show that Russian hackers were not involved in the 2016 United States election interference. However, on July 14, 2016, which is four days after the death of Seth Rich, WikiLeaks had received from Russian hackers the stolen documents file of emails.During November 2017, the Associated Press revealed that the FBI had failed to notify almost all of the persons in the cross hairs of the Kremlin-backed Fancy Bear's attack of 312 prominent government and defense officials who had their emails posted on DCLeaks. The FBI was in violation of its own policy of robustly informing victims of hacking.\n\n\n*** Indictments ***\nOn July 13, 2018, Deputy Attorney General Rod Rosenstein announced that twelve Russian hackers, who were operating in multiple units including Units 26165 and 74455 with the Main Intelligence Directorate of the General Staff (GRU), were named on an 11-count indictment for obtaining access and distributing information from data about 500,000 voters from a state election board website as well as the email accounts of John Podesta, Hillary Clinton, and volunteers and employees of the United States Presidential Campaign of Hillary Clinton (Clinton Campaign), the Democratic Congressional Campaign Committee (DCCC) and the Democratic National Committee (DNC). Following Donald Trump's request on July 27, 2016, during a rally in Florida that Vladimir Putin should have Russia hack into Trump's opponents networks, servers, and emails to make Hillary Clinton's 30,000 missing emails made public, Russian hackers tried for the first time to hack into Hillary Clinton's personal offices.The GRU mined Bitcoins to later purchase the DCLeaks domain and operate both the DCLeaks server and Guccifer 2.0 server to distribute information obtained from these hackers in order to discredit and disrupt the Clinton Campaign, the DCCC, and the DNC so that the Bernie Sanders Presidential Campaign, Republican candidates and the Donald Trump Presidential Campaign would benefit during the 2016 election cycle. They obtained the data about 500,000 voters by breaking into voter verification software and targeting local and state election officials. Although Roger Stone did not know the names of the Russian's sources, he had publicly stated that these Russians were in contact with the Trump Campaign and that he had communicated with them.Russians had also passed embarrassing information from these hacks to Wikileaks. This led to the resignation of the DNC Chairwoman Debbie Wasserman-Schultz in July, 2016. Using peer-to-peer exchanges and pre-paid cards, the Russians mined and used Bitcoins with public Blockchain recorded transactions using hundreds of emails with fictitious names to prevent monitoring by United States authorities on traditional financial transaction networks. The Internet Research Agency in Saint Petersburg spearheaded parts of the operation."
    }
  },
  {
    "instruction": "Write an answer to the following question: What were some of the engines removed in the initial release of LibreSSL due to irrelevance of hardware or dependency on non-free libraries?",
    "context": "",
    "output": "The IBM 4758, Broadcom ubsec, Sureware, Nuron, GOST, GMP, CSwift, CHIL, CAPI, Atalla and AEP engines were removed from the initial release of LibreSSL due to irrelevance of hardware or dependency on non-free libraries.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What were some of the engines removed in the initial release of LibreSSL due to irrelevance of hardware or dependency on non-free libraries?",
      "answer": "The IBM 4758, Broadcom ubsec, Sureware, Nuron, GOST, GMP, CSwift, CHIL, CAPI, Atalla and AEP engines were removed from the initial release of LibreSSL due to irrelevance of hardware or dependency on non-free libraries."
    }
  },
  {
    "instruction": "context: Twitter, Facebook, and Apple advised users to disable Java due to ongoing security concerns and attacks exploiting Java vulnerabilities.\n\nAsk a question about this context.",
    "context": "",
    "output": "Why did Twitter, Facebook, and Apple advise users to disable Java in 2013?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why did Twitter, Facebook, and Apple advise users to disable Java in 2013?",
      "answer": "Twitter, Facebook, and Apple advised users to disable Java due to ongoing security concerns and attacks exploiting Java vulnerabilities."
    }
  },
  {
    "instruction": "context: Defense in depth is a strategy for defending against session fixation attacks that involves combining several countermeasures. The idea is that if one obstacle is easy to overcome, several obstacles could be difficult to overcome. A defense in depth strategy could involve enabling HTTPS, correct configuration, such as not accepting external SIDs and setting time-outs, and performing session regeneration and supporting log-out.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the concept of \"defense in depth\" in the context of session fixation attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the concept of \"defense in depth\" in the context of session fixation attacks?",
      "answer": "Defense in depth is a strategy for defending against session fixation attacks that involves combining several countermeasures. The idea is that if one obstacle is easy to overcome, several obstacles could be difficult to overcome. A defense in depth strategy could involve enabling HTTPS, correct configuration, such as not accepting external SIDs and setting time-outs, and performing session regeneration and supporting log-out."
    }
  },
  {
    "instruction": "Write an answer to the following question: Can a proof of knowledge be used to prove membership in a language?",
    "context": "",
    "output": "Yes, a proof of knowledge can be used to prove membership in a language, but it also requires the definition of the witnesses.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can a proof of knowledge be used to prove membership in a language?",
      "answer": "Yes, a proof of knowledge can be used to prove membership in a language, but it also requires the definition of the witnesses."
    }
  },
  {
    "instruction": "context: Authbind is currently distributed with the Debian and Ubuntu Linux distributions.\n\nAsk a question about this context.",
    "context": "",
    "output": "On which Linux distributions is authbind currently distributed?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "On which Linux distributions is authbind currently distributed?",
      "answer": "Authbind is currently distributed with the Debian and Ubuntu Linux distributions."
    }
  },
  {
    "instruction": "Rustock botnet\n\n==Introduction==\nThe Rustock botnet was a botnet that operated from around 2006 until March 2011.\nIt consisted of computers running Microsoft Windows, and was capable of sending up to 25,000 spam messages per hour from an infected PC. At the height of its activities, it sent an average of 192 spam messages per compromised machine per minute. Reported estimates on its size vary greatly across different sources, with claims that the botnet may have comprised anywhere between 150,000 and 2,400,000 machines.  The size of the botnet was increased and maintained mostly through self-propagation, where the botnet sent many malicious e-mails intended to infect machines opening them with a trojan which would incorporate the machine into the botnet.The botnet took a hit after the 2008 takedown of McColo, an ISP which was responsible for hosting most of the botnet's command and control servers. McColo regained Internet connectivity for several hours, and in those hours up to 15 Mbit a second of traffic was observed, likely indicating a transfer of command and control to Russia. While these actions temporarily reduced global spam levels by around 75%, the effect did not last long: spam levels increased by 60% between January and June 2009, 40% of which was attributed to the Rustock botnet.On March 16, 2011, the botnet was taken down through what was initially reported as a coordinated effort by Internet service providers and software vendors. It was revealed the next day that the take-down, called Operation b107, was the action of Microsoft, U.S. federal law enforcement agents, FireEye, and the University of Washington.To capture the individuals involved with the Rustock botnet, on July 18, 2011, Microsoft is offering \"a monetary reward in the amount of US$250,000 for new information that results in the identification, arrest and criminal conviction of such individual(s).\"\n\n\n\n== Operations ==\nBotnets are composed of infected computers used by unwitting Internet users. In order to hide its presence from the user and anti-virus software, the Rustock botnet employed rootkit technology. Once a computer was infected, it would seek contact with command-and-control servers at a number of IP addresses and any of 2,500 domains and backup domains that may direct the zombies in the botnet to perform various tasks such as sending spam or executing  distributed denial of service (DDoS) attacks. Ninety-six servers were in operation at the time of the takedown. When sending spam the botnet uses TLS encryption in around 35 percent of the cases as an extra layer of protection to hide its presence. Whether detected or not, this creates additional overhead for the mail servers handling the spam. Some experts pointed out that this extra load could negatively impact the mail infrastructure of the Internet, as most of the e-mails sent these days are spam.\nQuestion: What reward is being offered for information leading to the identification, arrest, and criminal conviction of the individuals involved with the Rustock botnet?",
    "context": "",
    "output": "Answer: Microsoft is offering a reward of US$250,000 for new information that results in the identification, arrest, and criminal conviction of the individuals involved with the Rustock botnet.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What reward is being offered for information leading to the identification, arrest, and criminal conviction of the individuals involved with the Rustock botnet?",
      "answer": "Microsoft is offering a reward of US$250,000 for new information that results in the identification, arrest, and criminal conviction of the individuals involved with the Rustock botnet.",
      "context": "Rustock botnet\n\n==Introduction==\nThe Rustock botnet was a botnet that operated from around 2006 until March 2011.\nIt consisted of computers running Microsoft Windows, and was capable of sending up to 25,000 spam messages per hour from an infected PC. At the height of its activities, it sent an average of 192 spam messages per compromised machine per minute. Reported estimates on its size vary greatly across different sources, with claims that the botnet may have comprised anywhere between 150,000 and 2,400,000 machines.  The size of the botnet was increased and maintained mostly through self-propagation, where the botnet sent many malicious e-mails intended to infect machines opening them with a trojan which would incorporate the machine into the botnet.The botnet took a hit after the 2008 takedown of McColo, an ISP which was responsible for hosting most of the botnet's command and control servers. McColo regained Internet connectivity for several hours, and in those hours up to 15 Mbit a second of traffic was observed, likely indicating a transfer of command and control to Russia. While these actions temporarily reduced global spam levels by around 75%, the effect did not last long: spam levels increased by 60% between January and June 2009, 40% of which was attributed to the Rustock botnet.On March 16, 2011, the botnet was taken down through what was initially reported as a coordinated effort by Internet service providers and software vendors. It was revealed the next day that the take-down, called Operation b107, was the action of Microsoft, U.S. federal law enforcement agents, FireEye, and the University of Washington.To capture the individuals involved with the Rustock botnet, on July 18, 2011, Microsoft is offering \"a monetary reward in the amount of US$250,000 for new information that results in the identification, arrest and criminal conviction of such individual(s).\"\n\n\n\n== Operations ==\nBotnets are composed of infected computers used by unwitting Internet users. In order to hide its presence from the user and anti-virus software, the Rustock botnet employed rootkit technology. Once a computer was infected, it would seek contact with command-and-control servers at a number of IP addresses and any of 2,500 domains and backup domains that may direct the zombies in the botnet to perform various tasks such as sending spam or executing  distributed denial of service (DDoS) attacks. Ninety-six servers were in operation at the time of the takedown. When sending spam the botnet uses TLS encryption in around 35 percent of the cases as an extra layer of protection to hide its presence. Whether detected or not, this creates additional overhead for the mail servers handling the spam. Some experts pointed out that this extra load could negatively impact the mail infrastructure of the Internet, as most of the e-mails sent these days are spam."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the role of cryptocurrency in Dream Market?",
    "context": "",
    "output": "Cryptocurrency was used for all transactions in Dream Market.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the role of cryptocurrency in Dream Market?",
      "answer": "Cryptocurrency was used for all transactions in Dream Market."
    }
  },
  {
    "instruction": "Subliminal channel\n\n==Introduction==\nIn cryptography, subliminal channels are covert channels that can be used to communicate secretly in normal looking communication over an insecure channel. Subliminal channels in digital signature crypto systems were found in 1984 by Gustavus Simmons.\nSimmons describes how the \"Prisoners' Problem\" can be solved through parameter substitution in digital signature algorithms.  (Note that Simmons' Prisoners' Problem is not the same as the Prisoner's Dilemma.)\nSignature algorithms like ElGamal and DSA have parameters which must be set with random information. He shows how one can make use of these parameters to send a message subliminally. Because the algorithm's signature creation procedure is unchanged, the signature remains verifiable and indistinguishable from a normal signature. Therefore, it is hard to detect if the subliminal channel is used.\n\nSubliminal channels can be classified into broadband and narrowband channel types.\nBroadband and narrowband channels can exist in the same datastream.\nThe broadband channel uses almost all available bits that are available to use. This is commonly understood to mean {\u226550% but \u226490%} channel utilization.\nEvery channel which uses fewer bits is called a narrow-band channel.\nThe additional used bits are needed for further protection, e.g., impersonation.The broadband and the narrow-band channels can use different algorithm parameters. A narrow-band channel cannot transport maximal information, but it can be used to send the authentication key or datastream.\nResearch is ongoing : further developments can enhance the subliminal channel, e.g., allow for establishing a broadband channel without the need to agree on an authentication key in advance. Other developments try to avoid the entire subliminal channel.\n\n== Examples ==\nAn easy example of a narrowband subliminal channel for normal human-language text would be to define that an even word count in a sentence is associated with the bit \"0\" and an odd word count with the bit \"1\". The question \"Hello, how do you do?\" would therefore send the subliminal message \"1\".\nThe Digital Signature Algorithm has one subliminal broadband and three subliminal narrow-band channels At signing the parameter \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   has to be set random. For the broadband channel this parameter is instead set with a subliminal message \n  \n    \n      \n        \n          m\n          \u2032\n        \n      \n    \n    {\\displaystyle m'}\n  .\n\nKey generation\nchoose prime \n  \n    \n      \n        p\n\n== Example - RSA Case study ==\nHere is a (real, working) PGP public key (using the RSA algorithm), which was generated to include two subliminal channels - the first is the \"key ID\", which should normally be random hex, but below is \"covertly\" modified to read \"C0DED00D\".  The second is the base64 representation of the public key - again, supposed to be all random gibberish, but the English-readable message \"//This+is+Christopher+Drakes+PGP+public+key//Who/What+is+watcHIng+you//\" has been inserted.  Adding both these subliminal messages was accomplished by tampering with the random number generation during the RSA key generation phase.\n\n PGP Key. RSA 2020/C0DED00D   Fprint: 250A 7E38 9A1F 8A86  0811 C704 AF21 222C\n \n -----BEGIN PGP PUBLIC KEY BLOCK-----\n Version: Private\n \n mQESAgAAAAAAAAEH5Ar//This+is+Christopher+Drakes+PGP+public+key//\n Who/What+is+watcHIng+you//Di0nAraP+Ebz+iq83gCa06rGL4+hc9Gdsq667x\n 8FrpohTQzOlMF1Mj6aHeH2iy7+OcN7lL0tCJuvVGZ5lQxVAjhX8Lc98XjLm3vr1w\n ZBa9slDAvv98rJ8+8YGQQPJsQKq3L3rN9kabusMs0ZMuJQdOX3eBRdmurtGlQ6AQ\n AfjzUm8z5/2w0sYLc2g+aIlRkedDJWAFeJwAVENaY0LfkD3qpPFIhALN5MEWzdHt\n Apc0WrnjJDby5oPz1DXxg6jaHD/WD8De0A0ARRAAAAAAAAAAAbQvQ2hyaXN0b3Bo\n ZXIgRHJha2UgPENocmlzdG9waGVyLkRyYWtlQFBvQm94LmNvbT60SE5ldFNhZmUg\n c2VjdXJpdHkgc29mdHdhcmUgZGlyZWN0b3IgQ2hyaXN0b3BoZXIgRHJha2UgPE5l\n dFNhZmVAUG9Cb3guY29tPokBEgMFEDPXgvkcP9YPwN7QDQEB25oH4wWEhg9cBshB\n i6l17fJRqIJpXKAz4Zt0CfAfXphRGXC7wC9bCYzpHZSerOi1pd3TpHWyGX3HjGEP\n 6hyPfMldN/sm5MzOqgFc2pO5Ke5ukfgxI05NI0+OKrfc5NQnDOBHcm47EkK9TsnM\n c3Gz7HlWcHL6llRFwk75TWwSTVbfURbXKx4sC+nNExW7oJRKqpuN0JZxQxZaELdg\n 9wtdArqW/SY7jXQn//YJV/kftKvFrA24UYLxvGOXfZXpP7Gl2CGkDI6fzism75ya\n xSAgn9B7BqQ4BLY5Vn+viS++6Rdavykyd8j9sDAK+oPz/qRtYJrMvTqBErN4C5uA\n IV88P1U\n\n== Improvements ==\nA modification to the Brickell and DeLaurentis signature scheme provides a broadband channel without the necessity to share the authentication key.\nThe Newton channel is not a subliminal channel, but it can be viewed as an enhancement.\n\n== Countermeasures ==\nWith the help of the zero-knowledge proof and the commitment scheme it is possible to prevent the usage of the subliminal channel.It should be mentioned that this countermeasure has a 1-bit subliminal channel. The reason for that is the problem that a proof can succeed or purposely fail.Another countermeasure can detect, but not prevent, the subliminal usage of the randomness.\n\nBased on the above text, answer a question. What is the problem with using a countermeasure to prevent subliminal channels?",
    "context": "",
    "output": "The problem with using a countermeasure to prevent subliminal channels is that it has a 1-bit subliminal channel, as a proof can succeed or purposely fail.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the problem with using a countermeasure to prevent subliminal channels?",
      "answer": "The problem with using a countermeasure to prevent subliminal channels is that it has a 1-bit subliminal channel, as a proof can succeed or purposely fail.",
      "context": "Subliminal channel\n\n==Introduction==\nIn cryptography, subliminal channels are covert channels that can be used to communicate secretly in normal looking communication over an insecure channel. Subliminal channels in digital signature crypto systems were found in 1984 by Gustavus Simmons.\nSimmons describes how the \"Prisoners' Problem\" can be solved through parameter substitution in digital signature algorithms.  (Note that Simmons' Prisoners' Problem is not the same as the Prisoner's Dilemma.)\nSignature algorithms like ElGamal and DSA have parameters which must be set with random information. He shows how one can make use of these parameters to send a message subliminally. Because the algorithm's signature creation procedure is unchanged, the signature remains verifiable and indistinguishable from a normal signature. Therefore, it is hard to detect if the subliminal channel is used.\n\nSubliminal channels can be classified into broadband and narrowband channel types.\nBroadband and narrowband channels can exist in the same datastream.\nThe broadband channel uses almost all available bits that are available to use. This is commonly understood to mean {\u226550% but \u226490%} channel utilization.\nEvery channel which uses fewer bits is called a narrow-band channel.\nThe additional used bits are needed for further protection, e.g., impersonation.The broadband and the narrow-band channels can use different algorithm parameters. A narrow-band channel cannot transport maximal information, but it can be used to send the authentication key or datastream.\nResearch is ongoing : further developments can enhance the subliminal channel, e.g., allow for establishing a broadband channel without the need to agree on an authentication key in advance. Other developments try to avoid the entire subliminal channel.\n\n== Examples ==\nAn easy example of a narrowband subliminal channel for normal human-language text would be to define that an even word count in a sentence is associated with the bit \"0\" and an odd word count with the bit \"1\". The question \"Hello, how do you do?\" would therefore send the subliminal message \"1\".\nThe Digital Signature Algorithm has one subliminal broadband and three subliminal narrow-band channels At signing the parameter \n  \n    \n      \n        k\n      \n    \n    {\\displaystyle k}\n   has to be set random. For the broadband channel this parameter is instead set with a subliminal message \n  \n    \n      \n        \n          m\n          \u2032\n        \n      \n    \n    {\\displaystyle m'}\n  .\n\nKey generation\nchoose prime \n  \n    \n      \n        p\n\n== Example - RSA Case study ==\nHere is a (real, working) PGP public key (using the RSA algorithm), which was generated to include two subliminal channels - the first is the \"key ID\", which should normally be random hex, but below is \"covertly\" modified to read \"C0DED00D\".  The second is the base64 representation of the public key - again, supposed to be all random gibberish, but the English-readable message \"//This+is+Christopher+Drakes+PGP+public+key//Who/What+is+watcHIng+you//\" has been inserted.  Adding both these subliminal messages was accomplished by tampering with the random number generation during the RSA key generation phase.\n\n PGP Key. RSA 2020/C0DED00D   Fprint: 250A 7E38 9A1F 8A86  0811 C704 AF21 222C\n \n -----BEGIN PGP PUBLIC KEY BLOCK-----\n Version: Private\n \n mQESAgAAAAAAAAEH5Ar//This+is+Christopher+Drakes+PGP+public+key//\n Who/What+is+watcHIng+you//Di0nAraP+Ebz+iq83gCa06rGL4+hc9Gdsq667x\n 8FrpohTQzOlMF1Mj6aHeH2iy7+OcN7lL0tCJuvVGZ5lQxVAjhX8Lc98XjLm3vr1w\n ZBa9slDAvv98rJ8+8YGQQPJsQKq3L3rN9kabusMs0ZMuJQdOX3eBRdmurtGlQ6AQ\n AfjzUm8z5/2w0sYLc2g+aIlRkedDJWAFeJwAVENaY0LfkD3qpPFIhALN5MEWzdHt\n Apc0WrnjJDby5oPz1DXxg6jaHD/WD8De0A0ARRAAAAAAAAAAAbQvQ2hyaXN0b3Bo\n ZXIgRHJha2UgPENocmlzdG9waGVyLkRyYWtlQFBvQm94LmNvbT60SE5ldFNhZmUg\n c2VjdXJpdHkgc29mdHdhcmUgZGlyZWN0b3IgQ2hyaXN0b3BoZXIgRHJha2UgPE5l\n dFNhZmVAUG9Cb3guY29tPokBEgMFEDPXgvkcP9YPwN7QDQEB25oH4wWEhg9cBshB\n i6l17fJRqIJpXKAz4Zt0CfAfXphRGXC7wC9bCYzpHZSerOi1pd3TpHWyGX3HjGEP\n 6hyPfMldN/sm5MzOqgFc2pO5Ke5ukfgxI05NI0+OKrfc5NQnDOBHcm47EkK9TsnM\n c3Gz7HlWcHL6llRFwk75TWwSTVbfURbXKx4sC+nNExW7oJRKqpuN0JZxQxZaELdg\n 9wtdArqW/SY7jXQn//YJV/kftKvFrA24UYLxvGOXfZXpP7Gl2CGkDI6fzism75ya\n xSAgn9B7BqQ4BLY5Vn+viS++6Rdavykyd8j9sDAK+oPz/qRtYJrMvTqBErN4C5uA\n IV88P1U\n\n== Improvements ==\nA modification to the Brickell and DeLaurentis signature scheme provides a broadband channel without the necessity to share the authentication key.\nThe Newton channel is not a subliminal channel, but it can be viewed as an enhancement.\n\n== Countermeasures ==\nWith the help of the zero-knowledge proof and the commitment scheme it is possible to prevent the usage of the subliminal channel.It should be mentioned that this countermeasure has a 1-bit subliminal channel. The reason for that is the problem that a proof can succeed or purposely fail.Another countermeasure can detect, but not prevent, the subliminal usage of the randomness."
    }
  },
  {
    "instruction": "context: The Private profile in Windows Firewall allows more inbound connections than public, assuming that the network is isolated from the Internet.\n\nAsk a question about this context.",
    "context": "",
    "output": "What does the Private profile in Windows Firewall allow inbound connections for?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What does the Private profile in Windows Firewall allow inbound connections for?",
      "answer": "The Private profile in Windows Firewall allows more inbound connections than public, assuming that the network is isolated from the Internet."
    }
  },
  {
    "instruction": "Context: Rotational cryptanalysis\n\n==Introduction==\nIn cryptography, rotational cryptanalysis is a generic cryptanalytic attack against algorithms that rely on three operations: modular addition, rotation and XOR \u2014 ARX for short. Algorithms relying on these operations are popular because they are relatively cheap in both hardware and software and run in constant time, making them safe from timing attacks in common implementations.\nThe basic idea of rotational cryptanalysis is that both the bit rotation and XOR operations preserve correlations between bit-rotated pairs  of inputs, and that addition of bit-rotated inputs also partially preserves bit rotation correlations. Rotational pairs of inputs can thus be used to \"see through\" the cipher's cascaded ARX operations to a greater degree than might be expected. This ability to \"see\" correlations through rounds of processing can then be exploited to break the cipher in a way that is similar to differential cryptanalysis.\nThe term \"rotational cryptanalysis\" was coined by Dmitry Khovratovich and Ivica Nikoli\u0107\nin 2010 paper \"Rotational Cryptanalysis of ARX\", which presented the best cryptanalytic attacks at that time against a reduced-round Threefish cipher \u2014 part of the Skein hash function, a SHA-3 competition candidate. A follow-up attack from the same authors and Christian Rechberger breaks collision resistance of up to 53 of 72 rounds in Skein-256, and 57 of 72 rounds in Skein-512. It also affects the Threefish cipher.\n\n\n\n\n\nQuestion: How do the bit rotation and XOR operations in ARX cryptographic algorithms preserve correlations between bit-rotated pairs of inputs, and how can this be used to break the cipher in a way similar to differential cryptanalysis?\n\nAnswer:",
    "context": "",
    "output": "Bit rotation and XOR operations in ARX cryptographic algorithms preserve correlations between bit-rotated pairs of inputs because these operations do not destroy the relationships between the bits of the input data. The ability to \"see\" correlations through rounds of processing can then be exploited in a way similar to differential cryptanalysis, where the attacker uses the preserved correlations to make educated guesses about the input data and progressively reduce the number of possible values until the key is revealed.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do the bit rotation and XOR operations in ARX cryptographic algorithms preserve correlations between bit-rotated pairs of inputs, and how can this be used to break the cipher in a way similar to differential cryptanalysis?",
      "answer": "Bit rotation and XOR operations in ARX cryptographic algorithms preserve correlations between bit-rotated pairs of inputs because these operations do not destroy the relationships between the bits of the input data. The ability to \"see\" correlations through rounds of processing can then be exploited in a way similar to differential cryptanalysis, where the attacker uses the preserved correlations to make educated guesses about the input data and progressively reduce the number of possible values until the key is revealed.",
      "context": "Rotational cryptanalysis\n\n==Introduction==\nIn cryptography, rotational cryptanalysis is a generic cryptanalytic attack against algorithms that rely on three operations: modular addition, rotation and XOR \u2014 ARX for short. Algorithms relying on these operations are popular because they are relatively cheap in both hardware and software and run in constant time, making them safe from timing attacks in common implementations.\nThe basic idea of rotational cryptanalysis is that both the bit rotation and XOR operations preserve correlations between bit-rotated pairs  of inputs, and that addition of bit-rotated inputs also partially preserves bit rotation correlations. Rotational pairs of inputs can thus be used to \"see through\" the cipher's cascaded ARX operations to a greater degree than might be expected. This ability to \"see\" correlations through rounds of processing can then be exploited to break the cipher in a way that is similar to differential cryptanalysis.\nThe term \"rotational cryptanalysis\" was coined by Dmitry Khovratovich and Ivica Nikoli\u0107\nin 2010 paper \"Rotational Cryptanalysis of ARX\", which presented the best cryptanalytic attacks at that time against a reduced-round Threefish cipher \u2014 part of the Skein hash function, a SHA-3 competition candidate. A follow-up attack from the same authors and Christian Rechberger breaks collision resistance of up to 53 of 72 rounds in Skein-256, and 57 of 72 rounds in Skein-512. It also affects the Threefish cipher.\n\n\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the Indonesian National Armed Forces Cyber Unit in the country's cyber defense?",
    "context": "",
    "output": "The Indonesian National Armed Forces Cyber Unit is responsible for the defense of the country's military communication and information systems, as well as for conducting cyber intelligence and cyber warfare operations in support of military operations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Indonesian National Armed Forces Cyber Unit in the country's cyber defense?",
      "answer": "The Indonesian National Armed Forces Cyber Unit is responsible for the defense of the country's military communication and information systems, as well as for conducting cyber intelligence and cyber warfare operations in support of military operations."
    }
  },
  {
    "instruction": "context: The International Group of Experts, composed of highly respected legal scholars and practitioners with experience in cyber issues, were the main authors of the Tallinn Manual. They were consulted throughout the duration of the project by information technology specialists.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the role of the International Group of Experts in the drafting process of the Tallinn Manual?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the International Group of Experts in the drafting process of the Tallinn Manual?",
      "answer": "The International Group of Experts, composed of highly respected legal scholars and practitioners with experience in cyber issues, were the main authors of the Tallinn Manual. They were consulted throughout the duration of the project by information technology specialists."
    }
  },
  {
    "instruction": "context: Sony Entertainment's CEO Michael Lynton said that the decision to cancel the wide release was in response to a majority of theaters pulling their showings and not to the hackers' threats, and that they would seek other options to distribute the film in the future.\n\nAsk a question about this context.",
    "context": "",
    "output": "What was the response of Sony Entertainment's CEO Michael Lynton to President Obama's statement that Sony made a mistake in pulling the film The Interview?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the response of Sony Entertainment's CEO Michael Lynton to President Obama's statement that Sony made a mistake in pulling the film The Interview?",
      "answer": "Sony Entertainment's CEO Michael Lynton said that the decision to cancel the wide release was in response to a majority of theaters pulling their showings and not to the hackers' threats, and that they would seek other options to distribute the film in the future."
    }
  },
  {
    "instruction": "The Tor Project\n\n==Introduction==\nThe Tor Project, Inc. is a 501(c)(3) research-education nonprofit organization based in Winchester, New Hampshire. It is founded by computer scientists Roger Dingledine, Nick Mathewson, and five others. The Tor Project is primarily responsible for maintaining software for the Tor anonymity network.\n\n\n\n== Funding ==\nAs of 2012, 80% of the Tor Project's $2 million annual budget came from the United States government, with the U.S. State Department, the Broadcasting Board of Governors, and the National Science Foundation as major contributors, \"to aid democracy advocates in authoritarian states\". The Swedish government and other organizations provided the other 20%, including NGOs and thousands of individual sponsors. Dingledine said that the United States Department of Defense funds are more similar to a research grant than a procurement contract. Tor executive director Andrew Lewman said that even though it accepts funds from the U.S. federal government, the Tor service did not collaborate with the NSA to reveal identities of users.In June 2016, the Tor Project received an award from Mozilla's Open Source Support program (MOSS). The award was \"to significantly enhance the Tor network's metrics infrastructure so that the performance and stability of the network can be monitored and improvements made as appropriate.\"\n\n== Tools ==\nMetrics PortalAnalytics for the Tor network, including graphs of its available bandwidth and estimated userbase. This is a great resource for researchers interested in detailed statistics about Tor.Nyxa terminal (command line) application for monitoring and configuring Tor, intended for command-line enthusiasts and ssh connections. This functions much like top does for system usage, providing real time information on Tor's resource utilization and state.OnionooWeb-based protocol to learn about currently running Tor relays and bridges.OnionShareAn open source tool that allows users to securely and anonymously share a file of any size.OONI (Open Observatory of Network Interference (OONI))a global observation network, monitoring network censorship, which aims to collect high-quality data using open methodologies, using Free and Open Source Software (FL/OSS) to share observations and data about the various types, methods, and amounts of network tampering in the world.OrbotTor for Android and iOS devices, in collaboration with The Guardian ProjectOrliba library for use by any Android application to route Internet traffic through Orbot/Tor.Pluggable Transports (PT)helps circumvent censorship. Transforms the Tor traffic flow between the client and the bridge. This way, censors who monitor traffic between the client and the bridge will see innocent-looking transformed traffic instead of the actual Tor traffic.Relay SearchSite providing an overview of the Tor network.Shadowa discrete-event network simulator that runs the real Tor software as a plug-in. Shadow is open-source software that enables accurate, efficient, controlled, and repeatable Tor experimentation.StemPython Library for writing scripts and applications that interact with Tor.Tails (The Amnesic Incognito Live System)a live CD/USB distribution preconfigured so that everything is safely routed through Tor and leaves no trace on the local system.Torfree software and an open network that helps a user defend against traffic analysis, a form of network surveillance that threatens personal freedom and privacy, confidential business activities and relationships, and state security. The organization has also implemented the software in Rust named Arti.Tor Browsera customization of Mozilla Firefox which uses a Tor circuit for browsing anonymously and with other features consistent with the Tor mission.Tor PhoneA phone that routes its network traffic through tor network. Initially based on a CopperheadOS custom ROM prototype, using Tor with Orbot and Tor Browser are supported by custom Android operating systems CalyxOS and DivestOS. GrapheneOS supports using Orbot VPN but not Tor Browser.TorBirdyTorbutton for Thunderbird and related *bird forks.txtorconPython and Twisted event-based implementation of the Tor control protocol. Unit-tests, state and configuration abstractions, documentation. It is available on PyPI and in Debian.\n\n== Recognition ==\nIn March 2011, the Tor Project received the Free Software Foundation's 2010 Award for Projects of Social Benefit. The citation read, \"Using free software, Tor has enabled roughly 36 million people around the world to experience freedom of access and expression on the Internet while keeping them in control of their privacy and anonymity. Its network has proved pivotal in dissident movements in both Iran and more recently Egypt.\"In September 2012, the Tor Project received the 2012 EFF Pioneer Award, along with J\u00e9r\u00e9mie Zimmermann and Andrew Huang.In November 2012, Foreign Policy magazine named Dingledine, Mathewson, and Syverson among its Top 100 Global Thinkers \"for making the web safe for whistleblowers\".In 2014, Roger Dingledine, Nick Mathewson and Paul Syverson received the USENIX Test of Time Award for their paper titled \"Tor: The Second-Generation Onion Router\", which was published in the Proceedings of the 13th USENIX Security Symposium, August 2004.\nQ: What is the purpose of Pluggable Transports (PT) and how does it help circumvent censorship?",
    "context": "",
    "output": "Pluggable Transports (PT) helps circumvent censorship by transforming the Tor traffic flow between the client and the bridge. This way, censors who monitor traffic between the client and the bridge will see innocent-looking transformed traffic instead of the actual Tor traffic.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of Pluggable Transports (PT) and how does it help circumvent censorship?",
      "answer": "Pluggable Transports (PT) helps circumvent censorship by transforming the Tor traffic flow between the client and the bridge. This way, censors who monitor traffic between the client and the bridge will see innocent-looking transformed traffic instead of the actual Tor traffic.",
      "context": "The Tor Project\n\n==Introduction==\nThe Tor Project, Inc. is a 501(c)(3) research-education nonprofit organization based in Winchester, New Hampshire. It is founded by computer scientists Roger Dingledine, Nick Mathewson, and five others. The Tor Project is primarily responsible for maintaining software for the Tor anonymity network.\n\n\n\n== Funding ==\nAs of 2012, 80% of the Tor Project's $2 million annual budget came from the United States government, with the U.S. State Department, the Broadcasting Board of Governors, and the National Science Foundation as major contributors, \"to aid democracy advocates in authoritarian states\". The Swedish government and other organizations provided the other 20%, including NGOs and thousands of individual sponsors. Dingledine said that the United States Department of Defense funds are more similar to a research grant than a procurement contract. Tor executive director Andrew Lewman said that even though it accepts funds from the U.S. federal government, the Tor service did not collaborate with the NSA to reveal identities of users.In June 2016, the Tor Project received an award from Mozilla's Open Source Support program (MOSS). The award was \"to significantly enhance the Tor network's metrics infrastructure so that the performance and stability of the network can be monitored and improvements made as appropriate.\"\n\n== Tools ==\nMetrics PortalAnalytics for the Tor network, including graphs of its available bandwidth and estimated userbase. This is a great resource for researchers interested in detailed statistics about Tor.Nyxa terminal (command line) application for monitoring and configuring Tor, intended for command-line enthusiasts and ssh connections. This functions much like top does for system usage, providing real time information on Tor's resource utilization and state.OnionooWeb-based protocol to learn about currently running Tor relays and bridges.OnionShareAn open source tool that allows users to securely and anonymously share a file of any size.OONI (Open Observatory of Network Interference (OONI))a global observation network, monitoring network censorship, which aims to collect high-quality data using open methodologies, using Free and Open Source Software (FL/OSS) to share observations and data about the various types, methods, and amounts of network tampering in the world.OrbotTor for Android and iOS devices, in collaboration with The Guardian ProjectOrliba library for use by any Android application to route Internet traffic through Orbot/Tor.Pluggable Transports (PT)helps circumvent censorship. Transforms the Tor traffic flow between the client and the bridge. This way, censors who monitor traffic between the client and the bridge will see innocent-looking transformed traffic instead of the actual Tor traffic.Relay SearchSite providing an overview of the Tor network.Shadowa discrete-event network simulator that runs the real Tor software as a plug-in. Shadow is open-source software that enables accurate, efficient, controlled, and repeatable Tor experimentation.StemPython Library for writing scripts and applications that interact with Tor.Tails (The Amnesic Incognito Live System)a live CD/USB distribution preconfigured so that everything is safely routed through Tor and leaves no trace on the local system.Torfree software and an open network that helps a user defend against traffic analysis, a form of network surveillance that threatens personal freedom and privacy, confidential business activities and relationships, and state security. The organization has also implemented the software in Rust named Arti.Tor Browsera customization of Mozilla Firefox which uses a Tor circuit for browsing anonymously and with other features consistent with the Tor mission.Tor PhoneA phone that routes its network traffic through tor network. Initially based on a CopperheadOS custom ROM prototype, using Tor with Orbot and Tor Browser are supported by custom Android operating systems CalyxOS and DivestOS. GrapheneOS supports using Orbot VPN but not Tor Browser.TorBirdyTorbutton for Thunderbird and related *bird forks.txtorconPython and Twisted event-based implementation of the Tor control protocol. Unit-tests, state and configuration abstractions, documentation. It is available on PyPI and in Debian.\n\n== Recognition ==\nIn March 2011, the Tor Project received the Free Software Foundation's 2010 Award for Projects of Social Benefit. The citation read, \"Using free software, Tor has enabled roughly 36 million people around the world to experience freedom of access and expression on the Internet while keeping them in control of their privacy and anonymity. Its network has proved pivotal in dissident movements in both Iran and more recently Egypt.\"In September 2012, the Tor Project received the 2012 EFF Pioneer Award, along with J\u00e9r\u00e9mie Zimmermann and Andrew Huang.In November 2012, Foreign Policy magazine named Dingledine, Mathewson, and Syverson among its Top 100 Global Thinkers \"for making the web safe for whistleblowers\".In 2014, Roger Dingledine, Nick Mathewson and Paul Syverson received the USENIX Test of Time Award for their paper titled \"Tor: The Second-Generation Onion Router\", which was published in the Proceedings of the 13th USENIX Security Symposium, August 2004."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the self-shrinking generator shrink the output of the LFSR?",
    "context": "",
    "output": "The self-shrinking generator shrinks the output of the LFSR by discarding pairs of bits that do not match either 10 or 11, and only outputting bits based on pairs that match these criteria.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the self-shrinking generator shrink the output of the LFSR?",
      "answer": "The self-shrinking generator shrinks the output of the LFSR by discarding pairs of bits that do not match either 10 or 11, and only outputting bits based on pairs that match these criteria."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does EICAR's work extend beyond computer antivirus research?",
    "context": "",
    "output": "EICAR's work extends beyond computer antivirus research to include research on other types of malicious software and various information security topics like content security, Wireless LAN security, RFID, and information security awareness.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does EICAR's work extend beyond computer antivirus research?",
      "answer": "EICAR's work extends beyond computer antivirus research to include research on other types of malicious software and various information security topics like content security, Wireless LAN security, RFID, and information security awareness."
    }
  },
  {
    "instruction": "Passwordless authentication\n\n==Introduction==\nPasswordless authentication is an authentication method in which a user can log in to a computer system without the entering (and having to remember) a password or any other knowledge-based secret. In most common implementations users are asked to enter their public identifier (username, phone number, email address etc.) and then complete the authentication process by providing a secure proof of identity through a registered device or token.\nPasswordless authentication methods typically rely on public-key cryptography infrastructure where the public key is provided during registration to the authenticating service (remote server, application or website) while the private key is kept on a user\u2019s device (PC, smartphone or an external security token) and can be accessed only by providing a biometric signature or another authentication factor which is not knowledge-based. \nThese factors classically fall into two categories: \n\nOwnership factors (\u201cSomething the user has\u201d) such as a cellular phone, OTP token, smart card or a hardware token.\nInherence factors (\u201cSomething the user is\u201d) like fingerprints, retinal scans, face or voice recognition and other biometric identifiers.Some designs might also accept a combination of other factors such as geo-location, network address, behavioral patterns and gestures, as long as no memorized passwords are involved.\nPasswordless authentication is sometimes confused with multi-factor authentication (MFA), since both use a wide variety of authentication factors, but while MFA is often used as an added layer of security on top of password-based authentication, passwordless authentication does not require a memorized secret and usually uses just one highly secure factor to authenticate identity, making it faster and simpler for users.\n\"Passwordless MFA\" is the term used when both approaches are employed, and the authentication flow is both passwordless and uses multiple factors, providing the highest security level when implemented correctly.\n\n\n\n== Mechanism ==\nA user must first register with a system before their identity can be verified. A passwordless registration flow may include the following steps:\nRegistration request: When a user attempts to register with a website, the server sends a registration request to the user's device.\nAuthentication factor selection: When the user's device receives the registration request, it sets up a method for authenticating the user.  For example, the device may use biometrics like a fingerprint scanner or facial recognition for user identification.\nKey generation: The user's device generates a public/private key pair and sends the public key to the server for future verification.Once they have registered, a user can log in to the system via the following process:\n\nAuthentication challenge: The server sends an authentication to the user's device when the user attempts to log into the site.\nUser authentication: The user proves their identity to their device using the biometric scanner, unlocking their private key.\nChallenge response: The user's device digitally signs a response to the authentication challenge with the user's private key.\nResponse validation: The server uses the device's public key to verify the digital signature and provides access to the user's account.\n\n== Benefits and drawbacks ==\nProponents point out several unique benefits over other authentication methods:\n\nGreater security \u2013 passwords are known to be a weak point in computer systems (due to reuse, sharing, cracking, spraying etc.) and are regarded a top attack vector responsible for a huge percentage of security breaches.\nBetter user experience \u2013 Not only users aren\u2019t required to remember complicated password and comply with different security policies, they are also not required to periodically renew passwords.\nReduced IT costs \u2013 since no password storage and management is needed IT teams are no longer burdened by setting password policies, detecting leaks, resetting forgotten passwords, and complying with password storage regulation.\nBetter visibility of credential use \u2013 since credentials are tied to a specific device or inherent user attribute, they can't be massively used and access management becomes more tight.\nScalability \u2013 managing multiple logins without additional password fatigue or complicated registration.While others point out operational and cost-related disadvantages:\n\nImplementation costs \u2013 Although it is accepted that passwordless authentication leads to savings in the long term, deployment costs are currently a hindering factor for many potential users. Cost is associated with the need to deploy an authentication mechanism on an existing user directory and sometimes the additional hardware deployed to users (e.g. OTPs or security keys).\nTraining and expertise needed \u2013 while most password management systems are built similarly and have been used for many years, passwordless authentication requires adaptation from both IT teams and end users.\nSingle point of failure \u2013 particularly implementations using OTP or push notifications to cellular device applications can create a challenge for the end user if a device is broken, lost, stolen or simply upgraded.\nRead the text above and answer this question: How does passwordless authentication reduce IT costs?",
    "context": "",
    "output": "Passwordless authentication reduces IT costs by eliminating the need for password storage and management, as well as the burdens of setting password policies, detecting leaks, resetting forgotten passwords, and complying with password storage regulations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does passwordless authentication reduce IT costs?",
      "answer": "Passwordless authentication reduces IT costs by eliminating the need for password storage and management, as well as the burdens of setting password policies, detecting leaks, resetting forgotten passwords, and complying with password storage regulations.",
      "context": "Passwordless authentication\n\n==Introduction==\nPasswordless authentication is an authentication method in which a user can log in to a computer system without the entering (and having to remember) a password or any other knowledge-based secret. In most common implementations users are asked to enter their public identifier (username, phone number, email address etc.) and then complete the authentication process by providing a secure proof of identity through a registered device or token.\nPasswordless authentication methods typically rely on public-key cryptography infrastructure where the public key is provided during registration to the authenticating service (remote server, application or website) while the private key is kept on a user\u2019s device (PC, smartphone or an external security token) and can be accessed only by providing a biometric signature or another authentication factor which is not knowledge-based. \nThese factors classically fall into two categories: \n\nOwnership factors (\u201cSomething the user has\u201d) such as a cellular phone, OTP token, smart card or a hardware token.\nInherence factors (\u201cSomething the user is\u201d) like fingerprints, retinal scans, face or voice recognition and other biometric identifiers.Some designs might also accept a combination of other factors such as geo-location, network address, behavioral patterns and gestures, as long as no memorized passwords are involved.\nPasswordless authentication is sometimes confused with multi-factor authentication (MFA), since both use a wide variety of authentication factors, but while MFA is often used as an added layer of security on top of password-based authentication, passwordless authentication does not require a memorized secret and usually uses just one highly secure factor to authenticate identity, making it faster and simpler for users.\n\"Passwordless MFA\" is the term used when both approaches are employed, and the authentication flow is both passwordless and uses multiple factors, providing the highest security level when implemented correctly.\n\n\n\n== Mechanism ==\nA user must first register with a system before their identity can be verified. A passwordless registration flow may include the following steps:\nRegistration request: When a user attempts to register with a website, the server sends a registration request to the user's device.\nAuthentication factor selection: When the user's device receives the registration request, it sets up a method for authenticating the user.  For example, the device may use biometrics like a fingerprint scanner or facial recognition for user identification.\nKey generation: The user's device generates a public/private key pair and sends the public key to the server for future verification.Once they have registered, a user can log in to the system via the following process:\n\nAuthentication challenge: The server sends an authentication to the user's device when the user attempts to log into the site.\nUser authentication: The user proves their identity to their device using the biometric scanner, unlocking their private key.\nChallenge response: The user's device digitally signs a response to the authentication challenge with the user's private key.\nResponse validation: The server uses the device's public key to verify the digital signature and provides access to the user's account.\n\n== Benefits and drawbacks ==\nProponents point out several unique benefits over other authentication methods:\n\nGreater security \u2013 passwords are known to be a weak point in computer systems (due to reuse, sharing, cracking, spraying etc.) and are regarded a top attack vector responsible for a huge percentage of security breaches.\nBetter user experience \u2013 Not only users aren\u2019t required to remember complicated password and comply with different security policies, they are also not required to periodically renew passwords.\nReduced IT costs \u2013 since no password storage and management is needed IT teams are no longer burdened by setting password policies, detecting leaks, resetting forgotten passwords, and complying with password storage regulation.\nBetter visibility of credential use \u2013 since credentials are tied to a specific device or inherent user attribute, they can't be massively used and access management becomes more tight.\nScalability \u2013 managing multiple logins without additional password fatigue or complicated registration.While others point out operational and cost-related disadvantages:\n\nImplementation costs \u2013 Although it is accepted that passwordless authentication leads to savings in the long term, deployment costs are currently a hindering factor for many potential users. Cost is associated with the need to deploy an authentication mechanism on an existing user directory and sometimes the additional hardware deployed to users (e.g. OTPs or security keys).\nTraining and expertise needed \u2013 while most password management systems are built similarly and have been used for many years, passwordless authentication requires adaptation from both IT teams and end users.\nSingle point of failure \u2013 particularly implementations using OTP or push notifications to cellular device applications can create a challenge for the end user if a device is broken, lost, stolen or simply upgraded."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do HTTP verbs affect the susceptibility of a website to CSRF attacks?",
    "context": "",
    "output": "The HTTP request methods vary in their susceptibility to CSRF attacks due to the differences in their handling by the web browsers. Therefore, the protective measures against an attack depend on the method of the HTTP request.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do HTTP verbs affect the susceptibility of a website to CSRF attacks?",
      "answer": "The HTTP request methods vary in their susceptibility to CSRF attacks due to the differences in their handling by the web browsers. Therefore, the protective measures against an attack depend on the method of the HTTP request."
    }
  },
  {
    "instruction": "context: BASHLITE can impact the availability of services by launching DDoS attacks, which involve overwhelming a targeted server or network with traffic, making it difficult or impossible for legitimate users to access the services.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does BASHLITE impact the availability of services?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does BASHLITE impact the availability of services?",
      "answer": "BASHLITE can impact the availability of services by launching DDoS attacks, which involve overwhelming a targeted server or network with traffic, making it difficult or impossible for legitimate users to access the services."
    }
  },
  {
    "instruction": "NuCaptcha\n\n==Introduction==\nNuCaptcha is an early fraud detection service which utilises behavior analytics to provision threat appropriate, animated video CAPTCHAs. NuCaptcha is developed and operated by Canada-based firm NuData Security.Static image-based CAPTCHAs are routinely used to prevent automated sign-ups to websites by using text or images of words disguised so that optical character recognition (OCR) software has trouble reading them. However, in common CAPTCHA systems, users fail to correctly solve the CAPTCHA 7% \u2013 25% of the time. NuCaptcha uses animated video technology that it claims make puzzles easier for humans to solve, but harder for bots and hackers to decipher.\n\n\n\n== Technology ==\nNuCaptcha attempts to solve usability of static image-based CAPTCHAs using video animation to display CAPTCHA puzzles, and a behavior analysis system to monitor interactions with the platform. Video animation. CAPTCHAs are displayed as a video, and rendered in the web browser.  A variety of technologies can be used to display the animated CAPTCHA, such as Flash video, HTML5, or GIF.  Standard CAPTCHA techniques such as character crowding, once animated, are easier for humans to detect because of an innate motion-detecting ability. Behavior analysis. Using machine-learning algorithms, NuCaptcha monitors platform interactions to tune the security of each CAPTCHA delivered to the user. Suspected attackers are given progressively more secure CAPTCHAs.\n\n== Security ==\nSecurity researcher Elie Bursztein demonstrated a practical attack against NuCaptcha's video CAPTCHA scheme by employing optical flow techniques to isolate individual CAPTCHA characters. The proposed attack is able to break the video CAPTCHAs in more than 90% of cases.In response, NuCaptcha noted that Bursztein\u2019s findings underscore the need for CAPTCHA puzzles to be part of a larger security construct, such as behavior monitoring to assess the risk of individual users. NuCaptcha also pointed out that the CAPTCHAs analyzed in Bursztein's blog post were middle-security puzzles focused on usability, and not the stronger puzzles presented to high-risk users. In addition to this, NuCaptcha noted that the optical flow technique relies on static non-animated features of the puzzle.  Changes were made to NuCaptcha puzzles to remove the static non-animated features.\n\n== Application ==\nNuCaptcha APIs are currently available in PHP, .NET, and Java. Plugins are available for WordPress, Drupal, Codelgniter, vBulletin, and phpBB. In October 2011, NuCaptcha announced its CAPTCHA solutions for mobile devices across all platforms, including Android and iOS.\nQ: How do users interact with NuCaptcha's animated CAPTCHAs?",
    "context": "",
    "output": "Users interact with NuCaptcha's animated CAPTCHAs by solving puzzles displayed in a video format within their web browser.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do users interact with NuCaptcha's animated CAPTCHAs?",
      "answer": "Users interact with NuCaptcha's animated CAPTCHAs by solving puzzles displayed in a video format within their web browser.",
      "context": "NuCaptcha\n\n==Introduction==\nNuCaptcha is an early fraud detection service which utilises behavior analytics to provision threat appropriate, animated video CAPTCHAs. NuCaptcha is developed and operated by Canada-based firm NuData Security.Static image-based CAPTCHAs are routinely used to prevent automated sign-ups to websites by using text or images of words disguised so that optical character recognition (OCR) software has trouble reading them. However, in common CAPTCHA systems, users fail to correctly solve the CAPTCHA 7% \u2013 25% of the time. NuCaptcha uses animated video technology that it claims make puzzles easier for humans to solve, but harder for bots and hackers to decipher.\n\n\n\n== Technology ==\nNuCaptcha attempts to solve usability of static image-based CAPTCHAs using video animation to display CAPTCHA puzzles, and a behavior analysis system to monitor interactions with the platform. Video animation. CAPTCHAs are displayed as a video, and rendered in the web browser.  A variety of technologies can be used to display the animated CAPTCHA, such as Flash video, HTML5, or GIF.  Standard CAPTCHA techniques such as character crowding, once animated, are easier for humans to detect because of an innate motion-detecting ability. Behavior analysis. Using machine-learning algorithms, NuCaptcha monitors platform interactions to tune the security of each CAPTCHA delivered to the user. Suspected attackers are given progressively more secure CAPTCHAs.\n\n== Security ==\nSecurity researcher Elie Bursztein demonstrated a practical attack against NuCaptcha's video CAPTCHA scheme by employing optical flow techniques to isolate individual CAPTCHA characters. The proposed attack is able to break the video CAPTCHAs in more than 90% of cases.In response, NuCaptcha noted that Bursztein\u2019s findings underscore the need for CAPTCHA puzzles to be part of a larger security construct, such as behavior monitoring to assess the risk of individual users. NuCaptcha also pointed out that the CAPTCHAs analyzed in Bursztein's blog post were middle-security puzzles focused on usability, and not the stronger puzzles presented to high-risk users. In addition to this, NuCaptcha noted that the optical flow technique relies on static non-animated features of the puzzle.  Changes were made to NuCaptcha puzzles to remove the static non-animated features.\n\n== Application ==\nNuCaptcha APIs are currently available in PHP, .NET, and Java. Plugins are available for WordPress, Drupal, Codelgniter, vBulletin, and phpBB. In October 2011, NuCaptcha announced its CAPTCHA solutions for mobile devices across all platforms, including Android and iOS."
    }
  },
  {
    "instruction": "ISO/IEC 7064\n\n==Introduction==\nISO/IEC 7064 is a standard promulgated by the International Standards Organization (ISO) and International Electrotechnical Commission (IEC) that defines algorithms for calculating check digit characters. The checks should be applicable to alphanumeric strings and should be able to detect all single substitution errors, all or nearly all single local transposition errors, all or nearly all circular shift errors, a high proportion of double substitution errors, a high proportion of all other errors.\n\n\n\n== Standards ==\nStatus: Published - ISO/IEC 7064:2003 Information technology -- Security techniques -- Check character systems\nStatus: Withdrawn - ISO 7064:1983 Data processing -- Check character systems\n\n== Usage ==\nIt is referred to by other ISO standards:\n\nInternational Bank Account Number (IBAN)\nInternational Standard Text Code (ISTC)\nInternational Standard Name Identifier (ISNI)\nLegal Entity Identifier (LEI)and by other systems:\n\nPersonal identification number (Croatia)\nResident Identity Card (People's Republic of China)\nGlobal Release Identifier\nORCID\n\nHow does the ISO/IEC 7064 standard impact the overall security of data in data processing systems?",
    "context": "",
    "output": "A: The ISO/IEC 7064 standard significantly impacts the overall security of data in data processing systems by providing a mechanism for error detection and data integrity assurance, which helps to prevent unauthorized modifications and enhance the security of the data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the ISO/IEC 7064 standard impact the overall security of data in data processing systems?",
      "answer": "The ISO/IEC 7064 standard significantly impacts the overall security of data in data processing systems by providing a mechanism for error detection and data integrity assurance, which helps to prevent unauthorized modifications and enhance the security of the data.",
      "context": "ISO/IEC 7064\n\n==Introduction==\nISO/IEC 7064 is a standard promulgated by the International Standards Organization (ISO) and International Electrotechnical Commission (IEC) that defines algorithms for calculating check digit characters. The checks should be applicable to alphanumeric strings and should be able to detect all single substitution errors, all or nearly all single local transposition errors, all or nearly all circular shift errors, a high proportion of double substitution errors, a high proportion of all other errors.\n\n\n\n== Standards ==\nStatus: Published - ISO/IEC 7064:2003 Information technology -- Security techniques -- Check character systems\nStatus: Withdrawn - ISO 7064:1983 Data processing -- Check character systems\n\n== Usage ==\nIt is referred to by other ISO standards:\n\nInternational Bank Account Number (IBAN)\nInternational Standard Text Code (ISTC)\nInternational Standard Name Identifier (ISNI)\nLegal Entity Identifier (LEI)and by other systems:\n\nPersonal identification number (Croatia)\nResident Identity Card (People's Republic of China)\nGlobal Release Identifier\nORCID"
    }
  },
  {
    "instruction": "context: Timothy Justen French's arrest was allowed due to information provided by a confidential informant.\n\nAsk a question about this context.",
    "context": "",
    "output": "How was Timothy Justen French's arrest allowed?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How was Timothy Justen French's arrest allowed?",
      "answer": "Timothy Justen French's arrest was allowed due to information provided by a confidential informant."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the Wassenaar Arrangement, and how have its restrictions on the export of cryptography changed in recent years?",
    "context": "",
    "output": "The Wassenaar Arrangement is an international agreement aimed at regulating the export of conventional arms and dual-use goods and technologies. In recent years, the Wassenaar restrictions on the export of cryptography have been loosened.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Wassenaar Arrangement, and how have its restrictions on the export of cryptography changed in recent years?",
      "answer": "The Wassenaar Arrangement is an international agreement aimed at regulating the export of conventional arms and dual-use goods and technologies. In recent years, the Wassenaar restrictions on the export of cryptography have been loosened."
    }
  },
  {
    "instruction": "context: Accepting session identifiers from external sources poses a significant risk in the context of session fixation attacks. If a website allows external session identifiers, an attacker can easily fixate a victim's session identifier and gain access to their session. To mitigate this risk, it is recommended to configure the website to only accept internal session identifiers.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the risk of accepting session identifiers from external sources in the context of session fixation attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the risk of accepting session identifiers from external sources in the context of session fixation attacks?",
      "answer": "Accepting session identifiers from external sources poses a significant risk in the context of session fixation attacks. If a website allows external session identifiers, an attacker can easily fixate a victim's session identifier and gain access to their session. To mitigate this risk, it is recommended to configure the website to only accept internal session identifiers."
    }
  },
  {
    "instruction": "context: The U.S. Department of Defense (DoD) Architecture Framework (DoDAF) is one of several commonly-used security architecture frameworks that can be adapted to the individual requirements of an enterprise organization to ensure that business strategy and IT security are aligned.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the U.S. Department of Defense (DoD) Architecture Framework (DoDAF) contribute to enterprise information security architecture?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the U.S. Department of Defense (DoD) Architecture Framework (DoDAF) contribute to enterprise information security architecture?",
      "answer": "The U.S. Department of Defense (DoD) Architecture Framework (DoDAF) is one of several commonly-used security architecture frameworks that can be adapted to the individual requirements of an enterprise organization to ensure that business strategy and IT security are aligned."
    }
  },
  {
    "instruction": "context: LightBasin maintains persistence in the targeted systems by installing a backdoor, known as SLAPSTICK, for the Solaris Pluggable authentication module.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does LightBasin maintain persistence in the targeted systems?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does LightBasin maintain persistence in the targeted systems?",
      "answer": "LightBasin maintains persistence in the targeted systems by installing a backdoor, known as SLAPSTICK, for the Solaris Pluggable authentication module."
    }
  },
  {
    "instruction": "context: NTC Vulkan was founded by Anton Markov and Alexander Irzhavsky, both of whom are graduates of the St Petersburg military academy. Markov served in the Russian army and reached the rank of captain, while Irzhavsky also served in the Russian army and reached the rank of major.\n\nAsk a question about this context.",
    "context": "",
    "output": "Who are the Russian individuals behind the founding of NTC Vulkan and what are their military backgrounds?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who are the Russian individuals behind the founding of NTC Vulkan and what are their military backgrounds?",
      "answer": "NTC Vulkan was founded by Anton Markov and Alexander Irzhavsky, both of whom are graduates of the St Petersburg military academy. Markov served in the Russian army and reached the rank of captain, while Irzhavsky also served in the Russian army and reached the rank of major."
    }
  },
  {
    "instruction": "context: The authentic bluejacking as described here is not the same exploit that was frequently depicted in the television series Person of Interest. The fictional exploit portrayed different and more invasive capabilities.\n\nAsk a question about this context.",
    "context": "",
    "output": "How has bluejacking been depicted in the television series Person of Interest?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has bluejacking been depicted in the television series Person of Interest?",
      "answer": "The authentic bluejacking as described here is not the same exploit that was frequently depicted in the television series Person of Interest. The fictional exploit portrayed different and more invasive capabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does IS5 define the secure disposal of CD media?",
    "context": "",
    "output": "The text does not provide specific details on how IS5 defines the secure disposal of CD media.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does IS5 define the secure disposal of CD media?",
      "answer": "The text does not provide specific details on how IS5 defines the secure disposal of CD media."
    }
  },
  {
    "instruction": "context: The Shamoon virus spreads across a local network by copying itself to network shares and on to other computers.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the Shamoon virus spread across a local network?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Shamoon virus spread across a local network?",
      "answer": "The Shamoon virus spreads across a local network by copying itself to network shares and on to other computers."
    }
  },
  {
    "instruction": "context: Some popular anomaly detection techniques include statistical techniques such as Z-score, Tukey's range test, and Grubbs's test, density-based techniques such as k-nearest neighbor, local outlier factor, and isolation forests, subspace-, correlation-based, and tensor-based outlier detection for high-dimensional data, one-class support vector machines, replicator neural networks, autoencoders, variational autoencoders, long short-term memory neural networks, Bayesian networks, and hidden Markov models (HMMs).\n\nAsk a question about this context.",
    "context": "",
    "output": "What are some popular anomaly detection techniques?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some popular anomaly detection techniques?",
      "answer": "Some popular anomaly detection techniques include statistical techniques such as Z-score, Tukey's range test, and Grubbs's test, density-based techniques such as k-nearest neighbor, local outlier factor, and isolation forests, subspace-, correlation-based, and tensor-based outlier detection for high-dimensional data, one-class support vector machines, replicator neural networks, autoencoders, variational autoencoders, long short-term memory neural networks, Bayesian networks, and hidden Markov models (HMMs)."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does JonDonym handle Mix operators keeping log files?",
    "context": "",
    "output": "JonDonym Mix operators are required to sign a voluntary commitment not to keep log files. Observers would find it challenging to infiltrate all operators in a long cascade.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does JonDonym handle Mix operators keeping log files?",
      "answer": "JonDonym Mix operators are required to sign a voluntary commitment not to keep log files. Observers would find it challenging to infiltrate all operators in a long cascade."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which publication listed Tor Browser as one of the best ad blockers in 2021?",
    "context": "",
    "output": "John Corpuz of Toms Guide listed Tor Browser (Desktop and Android), and Onion Browser (iOS) as two of 16 \"best ad blockers in 2021\".",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which publication listed Tor Browser as one of the best ad blockers in 2021?",
      "answer": "John Corpuz of Toms Guide listed Tor Browser (Desktop and Android), and Onion Browser (iOS) as two of 16 \"best ad blockers in 2021\"."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which web browsers does Pleasant Password Server support?",
    "context": "",
    "output": "Pleasant Password Server supports Chrome, Firefox, Internet Explorer, and Opera, providing businesses with a range of options for accessing their passwords.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which web browsers does Pleasant Password Server support?",
      "answer": "Pleasant Password Server supports Chrome, Firefox, Internet Explorer, and Opera, providing businesses with a range of options for accessing their passwords."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who is believed to be behind the attacks on the Trickbot botnet in late 2020?",
    "context": "",
    "output": "The Trickbot botnet was believed to be attacked by the Cyber Command branch of the US Department of Defense and several security companies in late 2020.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is believed to be behind the attacks on the Trickbot botnet in late 2020?",
      "answer": "The Trickbot botnet was believed to be attacked by the Cyber Command branch of the US Department of Defense and several security companies in late 2020."
    }
  },
  {
    "instruction": "Write an answer to the following question: What charitable organizations did DarkSide claim to have donated to, and what was the response from one of the organizations?",
    "context": "",
    "output": "DarkSide claimed to have donated BTC 0.88 (then worth US$10,000) each to Children International and to The Water Project. However, Children International stated that it will not keep the money.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What charitable organizations did DarkSide claim to have donated to, and what was the response from one of the organizations?",
      "answer": "DarkSide claimed to have donated BTC 0.88 (then worth US$10,000) each to Children International and to The Water Project. However, Children International stated that it will not keep the money."
    }
  },
  {
    "instruction": "context: PURB makes the content indistinguishable from a uniform random bit string by using any encryption and encoding scheme that produces a bit string that appears uniformly random to an observer without an appropriate key, provided the appropriate hardness assumptions are satisfied.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does PURB make the content indistinguishable from a uniform random bit string?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does PURB make the content indistinguishable from a uniform random bit string?",
      "answer": "PURB makes the content indistinguishable from a uniform random bit string by using any encryption and encoding scheme that produces a bit string that appears uniformly random to an observer without an appropriate key, provided the appropriate hardness assumptions are satisfied."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Software Defined Perimeter (SDP) framework determine a list of Accepting Hosts for an Initiating Host?",
    "context": "",
    "output": "The Software Defined Perimeter (SDP) framework determines a list of Accepting Hosts for an Initiating Host by authenticating the Initiating Host and then determining the list of authorized Accepting Hosts based on the authenticated identity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Software Defined Perimeter (SDP) framework determine a list of Accepting Hosts for an Initiating Host?",
      "answer": "The Software Defined Perimeter (SDP) framework determines a list of Accepting Hosts for an Initiating Host by authenticating the Initiating Host and then determining the list of authorized Accepting Hosts based on the authenticated identity."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can a botnet adversary potentially gain knowledge of the control scheme and imitate the bot herder?",
    "context": "",
    "output": "By sniffing IRC traffic, a botnet adversary can potentially gain knowledge of the control scheme and imitate the bot herder by issuing commands correctly.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a botnet adversary potentially gain knowledge of the control scheme and imitate the bot herder?",
      "answer": "By sniffing IRC traffic, a botnet adversary can potentially gain knowledge of the control scheme and imitate the bot herder by issuing commands correctly."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the Pentium F00F bug and what causes it?",
    "context": "",
    "output": "The Pentium F00F bug is a design flaw in certain Intel Pentium, Pentium MMX, and Pentium OverDrive processors that can cause the processor to cease functioning until it is physically rebooted. The bug is caused by the use of the lock cmpxchg8b instruction with an illegal operand, which results in the CPU using locked bus cycles to read the illegal instruction exception-handler descriptor. Since locked reads must be paired with locked writes, and no corresponding writes occur, all CPU activity stops, causing the processor to lock up.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Pentium F00F bug and what causes it?",
      "answer": "The Pentium F00F bug is a design flaw in certain Intel Pentium, Pentium MMX, and Pentium OverDrive processors that can cause the processor to cease functioning until it is physically rebooted. The bug is caused by the use of the lock cmpxchg8b instruction with an illegal operand, which results in the CPU using locked bus cycles to read the illegal instruction exception-handler descriptor. Since locked reads must be paired with locked writes, and no corresponding writes occur, all CPU activity stops, causing the processor to lock up."
    }
  },
  {
    "instruction": "context: VoIP phones have a larger number of vulnerabilities compared to central devices like IP-PBX. However, DoS attacks on VoIP phones are less critical, as they usually only affect the endpoint, while attacks on central devices can affect the entire system.\n\nAsk a question about this context.",
    "context": "",
    "output": "How do VoIP phones differ from central devices like IP-PBX in terms of vulnerabilities?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do VoIP phones differ from central devices like IP-PBX in terms of vulnerabilities?",
      "answer": "VoIP phones have a larger number of vulnerabilities compared to central devices like IP-PBX. However, DoS attacks on VoIP phones are less critical, as they usually only affect the endpoint, while attacks on central devices can affect the entire system."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the United States Cyber Command (USCYBERCOM) in defending the Department of Defense information networks?",
    "context": "",
    "output": "The United States Cyber Command (USCYBERCOM) plans, coordinates, integrates, synchronizes and conducts activities to defend Department of Defense information networks and prepares to conduct full spectrum military cyberspace operations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the United States Cyber Command (USCYBERCOM) in defending the Department of Defense information networks?",
      "answer": "The United States Cyber Command (USCYBERCOM) plans, coordinates, integrates, synchronizes and conducts activities to defend Department of Defense information networks and prepares to conduct full spectrum military cyberspace operations."
    }
  },
  {
    "instruction": "Email-address harvesting\n\n==Introduction==\nEmail harvesting or scraping is the process of obtaining lists of email addresses using various methods. Typically these are then used for bulk email or spam.\n\n\n\n== Methods ==\nThe simplest method involves spammers purchasing or trading lists of email addresses from other spammers.\nAnother common method is the use of special software known as \"harvesting bots\" or \"harvesters\", which spider Web pages, postings on Usenet, mailing list archives, internet forums and other online sources to obtain email addresses from public data.\nSpammers may also use a form of dictionary attack in order to harvest email addresses, known as a directory harvest attack, where valid email addresses at a specific domain are found by guessing email address using common usernames in email addresses at that domain. For example, trying alan@example.com, alana@example.com, alanb@example.com, etc. and any that are accepted for delivery by the recipient email server, instead of rejected, are added to the list of theoretically valid email addresses for that domain.\nAnother method of email address harvesting is to offer a product or service free of charge as long as the user provides a valid email address, and then use the addresses collected from users as spam targets. Common products and services offered are jokes of the day, daily bible quotes, news or stock alerts, free merchandise, or even registered sex offender alerts for one's area. Another technique was used in late 2007 by the company iDate, which used email harvesting directed at subscribers to the Quechup website to spam the victim's friends and contacts.\n\n== Harvesting sources ==\nSpammers may harvest email addresses from a number of sources. A popular method uses email addresses which their owners have published for other purposes. Usenet posts, especially those in archives such as Google Groups, frequently yield addresses. Simply searching the Web for pages with addresses \u2014 such as corporate staff directories or membership lists of professional societies \u2014 using spambots can yield thousands of addresses, most of them deliverable. Spammers have also subscribed to discussion mailing lists for the purpose of gathering the addresses of posters. The DNS and WHOIS systems require the publication of technical contact information for all Internet domains; spammers have illegally trawled these resources for email addresses. Spammers have also concluded that generally, for the domain names of businesses, all of the email addresses will follow the same basic pattern and thus are able to accurately guess the email addresses of employees whose addresses they have not harvested.  Many spammers use programs called web spiders to find email addresses on web pages.  Usenet article message-IDs often look enough like email addresses that they are harvested as well.  Spammers have also harvested email addresses directly from Google search results, without actually spidering the websites found in the search.Spammer viruses may include a function which scans the victimized computer's disk drives (and possibly its network interfaces) for email addresses. These scanners discover email addresses which have never been exposed on the Web or in Whois. A compromised computer located on a shared network segment may capture email addresses from traffic addressed to its network neighbors.  The harvested addresses are then returned to the spammer through the bot-net created by the virus. In addition, sometime the addresses may be appended with other information and cross referenced to extract financial and personal data.A recent, controversial tactic, called \"e-pending\", involves the appending of email addresses to direct-marketing databases. Direct marketers normally obtain lists of prospects from sources such as magazine subscriptions and customer lists. By searching the Web and other resources for email addresses corresponding to the names and street addresses in their records, direct marketers can send targeted spam email. However, as with most spammer \"targeting\", this is imprecise; users have reported, for instance, receiving solicitations to mortgage their house at a specific street address \u2014 with the address being clearly a business address including mail stop and office number.Spammers sometimes use various means to confirm addresses as deliverable. For instance, including a hidden Web bug in a spam message written in HTML may cause the recipient's mail client to transmit the recipient's address, or any other unique key, to the spammer's Web site. Users can defend against such abuses by turning off their mail program's option to display images, or by reading email as plain-text rather than formatted.Likewise, spammers sometimes operate Web pages which purport to remove submitted addresses from spam lists. In several cases, these have been found to subscribe the entered addresses to receive more spam.When persons fill out a form, it is often sold to a spammer using a web service or http post to transfer the data. This is immediate and will drop the email in various spammer databases.  The revenue made from the spammer is shared with the source. For instance, if someone applies online for a mortgage, the owner of this site may have made a deal with a spammer to sell the address.  These are considered the best emails by spammers, because they are fresh and the user has just signed up for a product or service that often is marketed by spam.\n\n== Legality ==\nIn many jurisdictions there are anti-spam laws in place that restrict the harvesting or use of email addresses.In Australia, the creation or use of email-address harvesting programs (address harvesting software) is illegal, according to the 2003 anti-spam legislation, only if it is intended to use the email-address harvesting programs to send unsolicited commercial email. The legislation is intended to prohibit emails with 'an Australian connection' - spam originating in Australia being sent elsewhere, and spam being sent to an Australian address.\nNew Zealand has similar restrictions contained in its Unsolicited Electronic Messages Act 2007.\nIn The United States of America, the CAN-SPAM Act of 2003 made it illegal to initiate commercial email to a recipient where the email address of the recipient was obtained by:\n\nUsing an automated means that generates possible electronic mail addresses by combining names, letters, or numbers into numerous permutations.\nUsing an automated means to extract electronic mail addresses from an Internet website or proprietary online service operated by another person, and such website or online service included, at the time the address was obtained, a notice stating that the operator of such website or online service will not give, sell, or otherwise transfer addresses maintained by such website or online service to any other party for the purposes of initiating, or enabling others to initiate, electronic mail messages.Furthermore, website operators may not distribute their legitimately collected lists. The CAN-SPAM Act of 2003 requires that operators of web sites and online services should include a notice that the site or service will not give, sell, or otherwise transfer addresses, maintained by such website or online service, to any other party for the purposes of initiating, or enabling others to initiate, electronic mail messages.\n\n== Countermeasures ==\nAddress munging\nAddress munging\u2014e.g., changing \"bob@example.com\" to \"bob at example dot com\"\u2014is a common technique to make harvesting email addresses more difficult. Though relatively easy to overcome\u2014see, e.g., this Google search\u2014it is still effective. It is somewhat inconvenient to users, who must examine the address and manually correct it.Images\nUsing images to display part or all of an email address is a very effective harvesting countermeasure. The processing required to automatically extract text from images is not economically viable for spammers. It is very inconvenient for users, who type the address in manually.Contact forms\nEmail contact forms which send an email but do not reveal the recipient's address avoid publishing an email address in the first place. However, this method prevents users from composing in their preferred email client, limits message content to plain text - and does not automatically leave the user with a record of what they've said in their \"sent\" mail folder.JavaScript obfuscation\nJavaScript email obfuscation produces a normal, clickable email link for users while obscuring the address from spiders. In the source code seen by harvesters, the email address is scrambled, encoded, or otherwise obfuscated. While very convenient for most users, it does reduce accessibility, e.g. for text-based browsers and screen readers, or for those not using a JavaScript-enabled browser.HTML obfuscation\nIn HTML, email addresses may be obfuscated in many ways, such as inserting hidden elements within the address or listing parts out of order and using CSS to restore the correct order. Each has the benefit of being transparent to most users, but none support clickable email links and none are accessible to text-based browsers and screen readers.CAPTCHA\nRequiring users to complete a CAPTCHA before giving out an email address is an effective harvesting countermeasure. A popular solution is the reCAPTCHA Mailhide service. (Note, 12.9.18: Mailhide is no longer supported.)CAN-SPAM Notice\nTo enable prosecution of spammers under the CAN-SPAM Act of 2003, a website operator must post a notice that \"the site or service will not give, sell, or otherwise transfer addresses maintained by such website or online service to any other party for the purposes of initiating, or enabling others to initiate, electronic mail messages.\"Mail Server Monitoring\nEmail servers use a variety of methods to combat directory harvesting attacks, including to refuse to communicate with remote senders that have specified more than one invalid recipient address within a short time, but most such measures carry the risk of legitimate email being disrupted.Spider Traps\nA spider trap is a part of a website which is a honeypot designed to combat email harvesting spiders. Well-behaved spiders are unaffected, as the website's robots.txt file will warn spiders to stay away from that area\u2014a warning that malicious spiders do not heed. Some traps block access from the client's IP as soon as the trap is accessed. Others, like a network tarpit, are designed to waste the time and resources of malicious spiders by slowly and endlessly feeding the spider useless information. The \"bait\" content may contain large numbers of fake addresses, a technique known as list poisoning; though some consider this practice harmful.\nRead the text above and answer this question: What is the function of harvesting bots or harvesters in email address harvesting?",
    "context": "",
    "output": "Harvesting bots or harvesters are special software that spider web pages, postings on Usenet, mailing list archives, internet forums, and other online sources to obtain email addresses from public data. These bots are designed to automatically collect email addresses for spamming purposes.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the function of harvesting bots or harvesters in email address harvesting?",
      "answer": "Harvesting bots or harvesters are special software that spider web pages, postings on Usenet, mailing list archives, internet forums, and other online sources to obtain email addresses from public data. These bots are designed to automatically collect email addresses for spamming purposes.",
      "context": "Email-address harvesting\n\n==Introduction==\nEmail harvesting or scraping is the process of obtaining lists of email addresses using various methods. Typically these are then used for bulk email or spam.\n\n\n\n== Methods ==\nThe simplest method involves spammers purchasing or trading lists of email addresses from other spammers.\nAnother common method is the use of special software known as \"harvesting bots\" or \"harvesters\", which spider Web pages, postings on Usenet, mailing list archives, internet forums and other online sources to obtain email addresses from public data.\nSpammers may also use a form of dictionary attack in order to harvest email addresses, known as a directory harvest attack, where valid email addresses at a specific domain are found by guessing email address using common usernames in email addresses at that domain. For example, trying alan@example.com, alana@example.com, alanb@example.com, etc. and any that are accepted for delivery by the recipient email server, instead of rejected, are added to the list of theoretically valid email addresses for that domain.\nAnother method of email address harvesting is to offer a product or service free of charge as long as the user provides a valid email address, and then use the addresses collected from users as spam targets. Common products and services offered are jokes of the day, daily bible quotes, news or stock alerts, free merchandise, or even registered sex offender alerts for one's area. Another technique was used in late 2007 by the company iDate, which used email harvesting directed at subscribers to the Quechup website to spam the victim's friends and contacts.\n\n== Harvesting sources ==\nSpammers may harvest email addresses from a number of sources. A popular method uses email addresses which their owners have published for other purposes. Usenet posts, especially those in archives such as Google Groups, frequently yield addresses. Simply searching the Web for pages with addresses \u2014 such as corporate staff directories or membership lists of professional societies \u2014 using spambots can yield thousands of addresses, most of them deliverable. Spammers have also subscribed to discussion mailing lists for the purpose of gathering the addresses of posters. The DNS and WHOIS systems require the publication of technical contact information for all Internet domains; spammers have illegally trawled these resources for email addresses. Spammers have also concluded that generally, for the domain names of businesses, all of the email addresses will follow the same basic pattern and thus are able to accurately guess the email addresses of employees whose addresses they have not harvested.  Many spammers use programs called web spiders to find email addresses on web pages.  Usenet article message-IDs often look enough like email addresses that they are harvested as well.  Spammers have also harvested email addresses directly from Google search results, without actually spidering the websites found in the search.Spammer viruses may include a function which scans the victimized computer's disk drives (and possibly its network interfaces) for email addresses. These scanners discover email addresses which have never been exposed on the Web or in Whois. A compromised computer located on a shared network segment may capture email addresses from traffic addressed to its network neighbors.  The harvested addresses are then returned to the spammer through the bot-net created by the virus. In addition, sometime the addresses may be appended with other information and cross referenced to extract financial and personal data.A recent, controversial tactic, called \"e-pending\", involves the appending of email addresses to direct-marketing databases. Direct marketers normally obtain lists of prospects from sources such as magazine subscriptions and customer lists. By searching the Web and other resources for email addresses corresponding to the names and street addresses in their records, direct marketers can send targeted spam email. However, as with most spammer \"targeting\", this is imprecise; users have reported, for instance, receiving solicitations to mortgage their house at a specific street address \u2014 with the address being clearly a business address including mail stop and office number.Spammers sometimes use various means to confirm addresses as deliverable. For instance, including a hidden Web bug in a spam message written in HTML may cause the recipient's mail client to transmit the recipient's address, or any other unique key, to the spammer's Web site. Users can defend against such abuses by turning off their mail program's option to display images, or by reading email as plain-text rather than formatted.Likewise, spammers sometimes operate Web pages which purport to remove submitted addresses from spam lists. In several cases, these have been found to subscribe the entered addresses to receive more spam.When persons fill out a form, it is often sold to a spammer using a web service or http post to transfer the data. This is immediate and will drop the email in various spammer databases.  The revenue made from the spammer is shared with the source. For instance, if someone applies online for a mortgage, the owner of this site may have made a deal with a spammer to sell the address.  These are considered the best emails by spammers, because they are fresh and the user has just signed up for a product or service that often is marketed by spam.\n\n== Legality ==\nIn many jurisdictions there are anti-spam laws in place that restrict the harvesting or use of email addresses.In Australia, the creation or use of email-address harvesting programs (address harvesting software) is illegal, according to the 2003 anti-spam legislation, only if it is intended to use the email-address harvesting programs to send unsolicited commercial email. The legislation is intended to prohibit emails with 'an Australian connection' - spam originating in Australia being sent elsewhere, and spam being sent to an Australian address.\nNew Zealand has similar restrictions contained in its Unsolicited Electronic Messages Act 2007.\nIn The United States of America, the CAN-SPAM Act of 2003 made it illegal to initiate commercial email to a recipient where the email address of the recipient was obtained by:\n\nUsing an automated means that generates possible electronic mail addresses by combining names, letters, or numbers into numerous permutations.\nUsing an automated means to extract electronic mail addresses from an Internet website or proprietary online service operated by another person, and such website or online service included, at the time the address was obtained, a notice stating that the operator of such website or online service will not give, sell, or otherwise transfer addresses maintained by such website or online service to any other party for the purposes of initiating, or enabling others to initiate, electronic mail messages.Furthermore, website operators may not distribute their legitimately collected lists. The CAN-SPAM Act of 2003 requires that operators of web sites and online services should include a notice that the site or service will not give, sell, or otherwise transfer addresses, maintained by such website or online service, to any other party for the purposes of initiating, or enabling others to initiate, electronic mail messages.\n\n== Countermeasures ==\nAddress munging\nAddress munging\u2014e.g., changing \"bob@example.com\" to \"bob at example dot com\"\u2014is a common technique to make harvesting email addresses more difficult. Though relatively easy to overcome\u2014see, e.g., this Google search\u2014it is still effective. It is somewhat inconvenient to users, who must examine the address and manually correct it.Images\nUsing images to display part or all of an email address is a very effective harvesting countermeasure. The processing required to automatically extract text from images is not economically viable for spammers. It is very inconvenient for users, who type the address in manually.Contact forms\nEmail contact forms which send an email but do not reveal the recipient's address avoid publishing an email address in the first place. However, this method prevents users from composing in their preferred email client, limits message content to plain text - and does not automatically leave the user with a record of what they've said in their \"sent\" mail folder.JavaScript obfuscation\nJavaScript email obfuscation produces a normal, clickable email link for users while obscuring the address from spiders. In the source code seen by harvesters, the email address is scrambled, encoded, or otherwise obfuscated. While very convenient for most users, it does reduce accessibility, e.g. for text-based browsers and screen readers, or for those not using a JavaScript-enabled browser.HTML obfuscation\nIn HTML, email addresses may be obfuscated in many ways, such as inserting hidden elements within the address or listing parts out of order and using CSS to restore the correct order. Each has the benefit of being transparent to most users, but none support clickable email links and none are accessible to text-based browsers and screen readers.CAPTCHA\nRequiring users to complete a CAPTCHA before giving out an email address is an effective harvesting countermeasure. A popular solution is the reCAPTCHA Mailhide service. (Note, 12.9.18: Mailhide is no longer supported.)CAN-SPAM Notice\nTo enable prosecution of spammers under the CAN-SPAM Act of 2003, a website operator must post a notice that \"the site or service will not give, sell, or otherwise transfer addresses maintained by such website or online service to any other party for the purposes of initiating, or enabling others to initiate, electronic mail messages.\"Mail Server Monitoring\nEmail servers use a variety of methods to combat directory harvesting attacks, including to refuse to communicate with remote senders that have specified more than one invalid recipient address within a short time, but most such measures carry the risk of legitimate email being disrupted.Spider Traps\nA spider trap is a part of a website which is a honeypot designed to combat email harvesting spiders. Well-behaved spiders are unaffected, as the website's robots.txt file will warn spiders to stay away from that area\u2014a warning that malicious spiders do not heed. Some traps block access from the client's IP as soon as the trap is accessed. Others, like a network tarpit, are designed to waste the time and resources of malicious spiders by slowly and endlessly feeding the spider useless information. The \"bait\" content may contain large numbers of fake addresses, a technique known as list poisoning; though some consider this practice harmful."
    }
  },
  {
    "instruction": "Answer based on context:\n\nFORCEDENTRY\n\n==Introduction==\nFORCEDENTRY, also capitalized as ForcedEntry, is a security exploit allegedly developed by NSO Group to deploy their Pegasus spyware. It enables the \"zero-click\" exploit that is prevalent in iOS 13 and below, but also compromises recent safeguards set by Apple's \"BlastDoor\" in iOS 14 and later. In September 2021, Apple released new versions of its operating systems for multiple device families containing a fix for the vulnerability.\n\n\n\n== Exploit ==\nThe exploit was discovered by Citizen Lab, who reported that the vulnerability has been used to target political dissidents and human rights activists. FORCEDENTRY appears to be the same as the attack previously detected and named \"Megalodon\" by Amnesty International.The exploit uses PDF files disguised as GIF files to inject JBIG2-encoded data to provoke an integer overflow in Apple's CoreGraphics system, circumventing Apple's \"BlastDoor\" sandbox for message content. BlastDoor was introduced as part of iOS 14 to defend against KISMET, another zero-click exploit. The FORCEDENTRY exploit has been given the CVE identifier CVE-2021-30860. In December 2021, Google's Project Zero team published a technical breakdown of the exploit based on its collaboration with Apple\u2019s Security Engineering and Architecture (SEAR) group.The exploit was described by Project Zero team:\n\nJBIG2 doesn't have scripting capabilities, but when combined with a vulnerability, it does have the ability to emulate circuits of arbitrary logic gates operating on arbitrary memory. So why not just use that to build your own computer architecture and script that!? That's exactly what this exploit does. Using over 70,000 segment commands defining logical bit operations, they define a small computer architecture with features such as registers and a full 64-bit adder and comparator which they use to search memory and perform arithmetic operations. It's not as fast as Javascript, but it's fundamentally computationally equivalent.\nThe bootstrapping operations for the sandbox escape exploit are written to run on this logic circuit and the whole thing runs in this weird, emulated environment created out of a single decompression pass through a JBIG2 stream. It's pretty incredible, and at the same time, pretty terrifying.\nAccording to Citizen Lab, the FORCEDENTRY vulnerability exists in iOS versions prior to 14.8, macOS versions prior to macOS Big Sur 11.6 and Security Update 2021-005 Catalina, and watchOS versions prior to 7.6.2.\n\n== Apple lawsuit ==\nIn November 2021, Apple Inc. filed a complaint against NSO Group and its parent company Q Cyber Technologies in the United States District Court for the Northern District of California in relation to FORCEDENTRY, requesting injunctive relief, compensatory damages, punitive damages, and disgorgement of profits.\n\nWhat is the significance of the CVE identifier CVE-2021-30860 in relation to FORCEDENTRY?",
    "context": "",
    "output": "The CVE identifier CVE-2021-30860 has been assigned to the FORCEDENTRY exploit, which indicates that it is a recognized vulnerability that has been tracked and documented by the MITRE Corporation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the CVE identifier CVE-2021-30860 in relation to FORCEDENTRY?",
      "answer": "The CVE identifier CVE-2021-30860 has been assigned to the FORCEDENTRY exploit, which indicates that it is a recognized vulnerability that has been tracked and documented by the MITRE Corporation.",
      "context": "FORCEDENTRY\n\n==Introduction==\nFORCEDENTRY, also capitalized as ForcedEntry, is a security exploit allegedly developed by NSO Group to deploy their Pegasus spyware. It enables the \"zero-click\" exploit that is prevalent in iOS 13 and below, but also compromises recent safeguards set by Apple's \"BlastDoor\" in iOS 14 and later. In September 2021, Apple released new versions of its operating systems for multiple device families containing a fix for the vulnerability.\n\n\n\n== Exploit ==\nThe exploit was discovered by Citizen Lab, who reported that the vulnerability has been used to target political dissidents and human rights activists. FORCEDENTRY appears to be the same as the attack previously detected and named \"Megalodon\" by Amnesty International.The exploit uses PDF files disguised as GIF files to inject JBIG2-encoded data to provoke an integer overflow in Apple's CoreGraphics system, circumventing Apple's \"BlastDoor\" sandbox for message content. BlastDoor was introduced as part of iOS 14 to defend against KISMET, another zero-click exploit. The FORCEDENTRY exploit has been given the CVE identifier CVE-2021-30860. In December 2021, Google's Project Zero team published a technical breakdown of the exploit based on its collaboration with Apple\u2019s Security Engineering and Architecture (SEAR) group.The exploit was described by Project Zero team:\n\nJBIG2 doesn't have scripting capabilities, but when combined with a vulnerability, it does have the ability to emulate circuits of arbitrary logic gates operating on arbitrary memory. So why not just use that to build your own computer architecture and script that!? That's exactly what this exploit does. Using over 70,000 segment commands defining logical bit operations, they define a small computer architecture with features such as registers and a full 64-bit adder and comparator which they use to search memory and perform arithmetic operations. It's not as fast as Javascript, but it's fundamentally computationally equivalent.\nThe bootstrapping operations for the sandbox escape exploit are written to run on this logic circuit and the whole thing runs in this weird, emulated environment created out of a single decompression pass through a JBIG2 stream. It's pretty incredible, and at the same time, pretty terrifying.\nAccording to Citizen Lab, the FORCEDENTRY vulnerability exists in iOS versions prior to 14.8, macOS versions prior to macOS Big Sur 11.6 and Security Update 2021-005 Catalina, and watchOS versions prior to 7.6.2.\n\n== Apple lawsuit ==\nIn November 2021, Apple Inc. filed a complaint against NSO Group and its parent company Q Cyber Technologies in the United States District Court for the Northern District of California in relation to FORCEDENTRY, requesting injunctive relief, compensatory damages, punitive damages, and disgorgement of profits."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does OPNsense's web-based interface and plugin architecture contribute to its flexibility and adaptability in various network scenarios?",
    "context": "",
    "output": "OPNsense's web-based interface makes it highly accessible and user-friendly, allowing administrators to easily configure and manage the software on the x86-64 platform. This interface also enables remote management, making it possible for users to access and control the firewall and routing functionalities from any location with internet access.\n\nThe plugin architecture of OPNsense further enhances its adaptability by allowing developers to create and integrate new functionalities tailored to specific network requirements or use cases. These plugins can extend OPNsense's capabilities in various areas, such as traffic shaping, load balancing, and virtual private network support, ensuring that the software can be customized to meet diverse networking needs.\n\nThe combination of the web-based interface and plugin architecture in OPNsense offers users a highly flexible and adaptable solution for managing network security and routing, making it suitable for a wide range of environments and scenarios.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does OPNsense's web-based interface and plugin architecture contribute to its flexibility and adaptability in various network scenarios?",
      "answer": "OPNsense's web-based interface makes it highly accessible and user-friendly, allowing administrators to easily configure and manage the software on the x86-64 platform. This interface also enables remote management, making it possible for users to access and control the firewall and routing functionalities from any location with internet access.\n\nThe plugin architecture of OPNsense further enhances its adaptability by allowing developers to create and integrate new functionalities tailored to specific network requirements or use cases. These plugins can extend OPNsense's capabilities in various areas, such as traffic shaping, load balancing, and virtual private network support, ensuring that the software can be customized to meet diverse networking needs.\n\nThe combination of the web-based interface and plugin architecture in OPNsense offers users a highly flexible and adaptable solution for managing network security and routing, making it suitable for a wide range of environments and scenarios."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the ingest and indexing point in a SIEM system?",
    "context": "",
    "output": "The ingest and indexing point in a SIEM system is responsible for parsing, correlation, and data normalization of the collected logs. It aggregates log data from various sources and performs initial processing to make it easier to analyze and correlate events.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the ingest and indexing point in a SIEM system?",
      "answer": "The ingest and indexing point in a SIEM system is responsible for parsing, correlation, and data normalization of the collected logs. It aggregates log data from various sources and performs initial processing to make it easier to analyze and correlate events."
    }
  },
  {
    "instruction": "context: Archangel and The Stingray, two of PHIRM's founders, co-authored a report on Cleveland's Free-net in 1987.\n\nAsk a question about this context.",
    "context": "",
    "output": "Who were the founders of PHIRM that co-authored a report on Cleveland's Free-net in 1987?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who were the founders of PHIRM that co-authored a report on Cleveland's Free-net in 1987?",
      "answer": "Archangel and The Stingray, two of PHIRM's founders, co-authored a report on Cleveland's Free-net in 1987."
    }
  },
  {
    "instruction": "Write an answer to the following question: What type of networks use key-based routing?",
    "context": "",
    "output": "Key-based routing is used in certain overlay networks, including Freenet, GNUnet, Kademlia, Onion routing, and Garlic routing.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What type of networks use key-based routing?",
      "answer": "Key-based routing is used in certain overlay networks, including Freenet, GNUnet, Kademlia, Onion routing, and Garlic routing."
    }
  },
  {
    "instruction": "context: The objectives of the Common Criteria Evaluation and Validation Scheme are to meet the needs of government and industry for cost-effective evaluation of IT products, encourage the formation of commercial security testing laboratories and the development of a private sector security testing industry, ensure that security evaluations of IT products are performed to consistent standards, and improve the availability of evaluated IT products.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are the objectives of the Common Criteria Evaluation and Validation Scheme?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the objectives of the Common Criteria Evaluation and Validation Scheme?",
      "answer": "The objectives of the Common Criteria Evaluation and Validation Scheme are to meet the needs of government and industry for cost-effective evaluation of IT products, encourage the formation of commercial security testing laboratories and the development of a private sector security testing industry, ensure that security evaluations of IT products are performed to consistent standards, and improve the availability of evaluated IT products."
    }
  },
  {
    "instruction": "Mobile malware\n\n==Introduction==\nMobile malware is malicious software that targets mobile phones or wireless-enabled Personal digital assistants (PDA), by causing the collapse of the system and loss or leakage of confidential information. As wireless phones and PDA networks have become more and more common and have grown in complexity, it has become increasingly difficult to ensure their safety and security against electronic attacks in the form of viruses or other malware.\n\n\n\n== Taxonomy ==\nMany types of common malicious programs are known to affect mobile devices:\n\nExpander: Expanders target mobile meters for additional phone billing and profit\nWorm: The main objective of this stand-alone type of malware is to endlessly reproduce itself and spread to other devices.  Worms may also contain harmful and misleading instructions. Mobile worms may be transmitted via text messages SMS or MMS and typically do not require user interaction for execution.\nTrojan: Unlike worms, a Trojan horse always requires user interaction to be activated. This kind of virus is usually inserted into seemingly attractive and non-malicious executable files or applications that are downloaded to the device and executed by the user. Once activated, the malware can cause serious damage by infecting and deactivating other applications or the phone itself, rendering it paralyzed after a certain period of time or a certain number of operations. Usurpation data (spyware) synchronizes with calendars, email accounts, notes, and any other source of information before it is sent to a remote server.In fact, with increase in creation of viruses & malwares like Trojan Horse, the camera crashing or camfecting issues are becoming quite common.\nSpyware: This malware poses a threat to mobile devices by collecting, using, and spreading a user's personal or sensitive information without the user's consent or knowledge. It is mostly classified into four categories: system monitors, trojans, adware, and tracking cookies.\nBackdoor: Covert method of bypassing security restrictions to gain unauthorized access to a computer system. In simpler words, a backdoor is a piece of code that allows others to go in and out of a system without being detected.\nDropper: A malware designed to install other programs on a device, unbeknownst to the user. These could include other malicious programs or benign applications that the attacker is interested in spreading (often for financial gain in a [malvertising] campaign).\n\n== Notable mobile malicious programs ==\nAutolycos: This is the latest malware family to be discovered that subscribes users against their will and without their knowledge to premium services. Autolycos was identified in July 2022 by malware experts at cybersecurity firm Evina.\nJoker Malware: This malware infects mobile phones running on Android OS and was first identified in June 2017. When a phone is infected, usually information is stolen by malware makers. Few users have reported of unwanted online subscriptions which is because malware is created to steal otp, make online transactions, etc.\nCabir: This malware infects mobile phones running on Symbian OS and was first identified in June 2004. When a phone is infected, the message 'Caribe' is displayed on the phone's screen and is displayed every time the phone is turned on. The worm then attempts to spread to other phones in the area using wireless Bluetooth signals, although the recipient has to confirm this manually.\nDuts: This parasitic file infector virus is the first known virus for the Pocket PC platform. It attempts to infect all EXE files that are larger than 4096 bytes in the current directory.\nSkulls: A trojan horse piece of 0 9amcode that targets mainly Symbian OS. Once downloaded, the virus replaces all phone desktop icons with images of a skull. It also renders all phone applications useless. This malware also tends to mass text messages containing malicious links to all contacts accessible through the device in order to spread the damage. This mass texting can also give rise to high expenses.\nCommwarrior: This malware was identified in 2005. It was the first worm to use MMS messages and can spread through Bluetooth as well. It infects devices running under OS Symbian Series 60. The executable worm file, once launched, hunts for accessible Bluetooth devices and sends the infected files under a random name to various devices.\nFlexiSpy: Stalkerware software that was first developed in 2006. Initially designed for Symbian OS, it was classified as malware by an anti-virus vendor in 2007. It is now available for Android and iOS. It can be used to track locations, read WhatsApp and SMS messages, listen in to ambient conversations, intercept phone calls and other abilities.\nHatiHati: A worm-like software for Symbian OS devices, first identified in 2007. HatiHati was a pirated copy of the beta version of an anti-theft software for Symbian OS called Guardian. It had a number of flaws that meant it acted like a worm by copying itself to any memory card inserted into the mobile, and once in a mobile device the application sent many alerts SMS to a given set of numbers. Volumes of up to 12% of the total SMS in a mobile operator in the Middle East could be attributed to the malware.\nZitMo: This malware was identified in 2010. An abbreviation of Zeus-In-The-Mobile, it is a trojan that is suggested for installation on a mobile phone by a Zeus-infected computer, and redirects incoming SMSs by acting like a man-in-the-mobile. It was the first mobile malware designed to steal mTAN banking codes. It was originally detected on Symbian, before being identified on Windows Mobile, BlackBerry and Android.\nGingermaster: A trojan developed for an Android platform that propagates by installing applications that incorporate a hidden malware for installation in the background. It exploits the frailty in the version Gingerbread (2.3) of the operating system to use super-user permissions by privileged escalation. It then creates a service that steals information from infected terminals (user ID, number SIM, phone number, IMEI, IMSI, screen resolution and local time) by sending it to a remote server through petitions HTTP.\nDroidKungFu: A trojan content in Android applications, which when executed, obtains root privileges and installs the file com.google. ssearch.apk, which contains a back door that allows files to be removed, open home pages to be supplied, and 'open web and download and install' application packages. This virus collects and sends to a remote server all available data on the terminal.\nIkee: The first worm known for iOS platforms, identified in 2009. It only works on terminals that were previously made a process of jailbreak, and spreads by trying to access other devices using the SSH protocol, first through the subnet that is connected to the device. Then, it repeats the process generating a random range and finally uses some preset ranges corresponding to the IP address of certain telephone companies. Once the computer is infected, the wallpaper is replaced by a photograph of the singer Rick Astley, a reference to the Rickroll phenomenon.\nSamsapo: The first worm known for Android platforms, identified in April 2014. The worm was targeted mostly against Russian Android users. Once a device was infected the malware could act like spyware, as well as do other actions like download additional malicious files, send SMSs to premium rate numbers and block phone calls.\nGunpoder: This worm file infector virus is the first known virus that officially infected the Google Play Store in few countries, including Brazil.\nShedun: adware serving malware able to root Android devices.\nHummingBad: Infected over 10 million Android operating systems in 2016. User details were sold and adverts were tapped on without the user's knowledge thereby generating fraudulent advertising revenue.\nPegasus: This spyware was identified in August 2016. It exploited three previously undisclosed vulnerabilities in iOS, which when combined allowed for a remote jailbreak of an iOS device, something which had not been seen before for iOS devices in the wild. Once installed, the spyware was capable of many features including logging encrypted messages, activating the phone microphone and secretly tracking phone movements. It was first identified for iOS platforms, before being later identified for Android devices.\n\nBased on the above text, answer a question. What spyware was identified in August 2016 and exploited three previously undisclosed vulnerabilities in iOS that allowed for a remote jailbreak of an iOS device?",
    "context": "",
    "output": "Pegasus spyware was identified in August 2016 and exploited three previously undisclosed vulnerabilities in iOS, which allowed for a remote jailbreak of an iOS device. It was capable of many features including logging encrypted messages, activating the phone microphone and secretly tracking phone movements.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What spyware was identified in August 2016 and exploited three previously undisclosed vulnerabilities in iOS that allowed for a remote jailbreak of an iOS device?",
      "answer": "Pegasus spyware was identified in August 2016 and exploited three previously undisclosed vulnerabilities in iOS, which allowed for a remote jailbreak of an iOS device. It was capable of many features including logging encrypted messages, activating the phone microphone and secretly tracking phone movements.",
      "context": "Mobile malware\n\n==Introduction==\nMobile malware is malicious software that targets mobile phones or wireless-enabled Personal digital assistants (PDA), by causing the collapse of the system and loss or leakage of confidential information. As wireless phones and PDA networks have become more and more common and have grown in complexity, it has become increasingly difficult to ensure their safety and security against electronic attacks in the form of viruses or other malware.\n\n\n\n== Taxonomy ==\nMany types of common malicious programs are known to affect mobile devices:\n\nExpander: Expanders target mobile meters for additional phone billing and profit\nWorm: The main objective of this stand-alone type of malware is to endlessly reproduce itself and spread to other devices.  Worms may also contain harmful and misleading instructions. Mobile worms may be transmitted via text messages SMS or MMS and typically do not require user interaction for execution.\nTrojan: Unlike worms, a Trojan horse always requires user interaction to be activated. This kind of virus is usually inserted into seemingly attractive and non-malicious executable files or applications that are downloaded to the device and executed by the user. Once activated, the malware can cause serious damage by infecting and deactivating other applications or the phone itself, rendering it paralyzed after a certain period of time or a certain number of operations. Usurpation data (spyware) synchronizes with calendars, email accounts, notes, and any other source of information before it is sent to a remote server.In fact, with increase in creation of viruses & malwares like Trojan Horse, the camera crashing or camfecting issues are becoming quite common.\nSpyware: This malware poses a threat to mobile devices by collecting, using, and spreading a user's personal or sensitive information without the user's consent or knowledge. It is mostly classified into four categories: system monitors, trojans, adware, and tracking cookies.\nBackdoor: Covert method of bypassing security restrictions to gain unauthorized access to a computer system. In simpler words, a backdoor is a piece of code that allows others to go in and out of a system without being detected.\nDropper: A malware designed to install other programs on a device, unbeknownst to the user. These could include other malicious programs or benign applications that the attacker is interested in spreading (often for financial gain in a [malvertising] campaign).\n\n== Notable mobile malicious programs ==\nAutolycos: This is the latest malware family to be discovered that subscribes users against their will and without their knowledge to premium services. Autolycos was identified in July 2022 by malware experts at cybersecurity firm Evina.\nJoker Malware: This malware infects mobile phones running on Android OS and was first identified in June 2017. When a phone is infected, usually information is stolen by malware makers. Few users have reported of unwanted online subscriptions which is because malware is created to steal otp, make online transactions, etc.\nCabir: This malware infects mobile phones running on Symbian OS and was first identified in June 2004. When a phone is infected, the message 'Caribe' is displayed on the phone's screen and is displayed every time the phone is turned on. The worm then attempts to spread to other phones in the area using wireless Bluetooth signals, although the recipient has to confirm this manually.\nDuts: This parasitic file infector virus is the first known virus for the Pocket PC platform. It attempts to infect all EXE files that are larger than 4096 bytes in the current directory.\nSkulls: A trojan horse piece of 0 9amcode that targets mainly Symbian OS. Once downloaded, the virus replaces all phone desktop icons with images of a skull. It also renders all phone applications useless. This malware also tends to mass text messages containing malicious links to all contacts accessible through the device in order to spread the damage. This mass texting can also give rise to high expenses.\nCommwarrior: This malware was identified in 2005. It was the first worm to use MMS messages and can spread through Bluetooth as well. It infects devices running under OS Symbian Series 60. The executable worm file, once launched, hunts for accessible Bluetooth devices and sends the infected files under a random name to various devices.\nFlexiSpy: Stalkerware software that was first developed in 2006. Initially designed for Symbian OS, it was classified as malware by an anti-virus vendor in 2007. It is now available for Android and iOS. It can be used to track locations, read WhatsApp and SMS messages, listen in to ambient conversations, intercept phone calls and other abilities.\nHatiHati: A worm-like software for Symbian OS devices, first identified in 2007. HatiHati was a pirated copy of the beta version of an anti-theft software for Symbian OS called Guardian. It had a number of flaws that meant it acted like a worm by copying itself to any memory card inserted into the mobile, and once in a mobile device the application sent many alerts SMS to a given set of numbers. Volumes of up to 12% of the total SMS in a mobile operator in the Middle East could be attributed to the malware.\nZitMo: This malware was identified in 2010. An abbreviation of Zeus-In-The-Mobile, it is a trojan that is suggested for installation on a mobile phone by a Zeus-infected computer, and redirects incoming SMSs by acting like a man-in-the-mobile. It was the first mobile malware designed to steal mTAN banking codes. It was originally detected on Symbian, before being identified on Windows Mobile, BlackBerry and Android.\nGingermaster: A trojan developed for an Android platform that propagates by installing applications that incorporate a hidden malware for installation in the background. It exploits the frailty in the version Gingerbread (2.3) of the operating system to use super-user permissions by privileged escalation. It then creates a service that steals information from infected terminals (user ID, number SIM, phone number, IMEI, IMSI, screen resolution and local time) by sending it to a remote server through petitions HTTP.\nDroidKungFu: A trojan content in Android applications, which when executed, obtains root privileges and installs the file com.google. ssearch.apk, which contains a back door that allows files to be removed, open home pages to be supplied, and 'open web and download and install' application packages. This virus collects and sends to a remote server all available data on the terminal.\nIkee: The first worm known for iOS platforms, identified in 2009. It only works on terminals that were previously made a process of jailbreak, and spreads by trying to access other devices using the SSH protocol, first through the subnet that is connected to the device. Then, it repeats the process generating a random range and finally uses some preset ranges corresponding to the IP address of certain telephone companies. Once the computer is infected, the wallpaper is replaced by a photograph of the singer Rick Astley, a reference to the Rickroll phenomenon.\nSamsapo: The first worm known for Android platforms, identified in April 2014. The worm was targeted mostly against Russian Android users. Once a device was infected the malware could act like spyware, as well as do other actions like download additional malicious files, send SMSs to premium rate numbers and block phone calls.\nGunpoder: This worm file infector virus is the first known virus that officially infected the Google Play Store in few countries, including Brazil.\nShedun: adware serving malware able to root Android devices.\nHummingBad: Infected over 10 million Android operating systems in 2016. User details were sold and adverts were tapped on without the user's knowledge thereby generating fraudulent advertising revenue.\nPegasus: This spyware was identified in August 2016. It exploited three previously undisclosed vulnerabilities in iOS, which when combined allowed for a remote jailbreak of an iOS device, something which had not been seen before for iOS devices in the wild. Once installed, the spyware was capable of many features including logging encrypted messages, activating the phone microphone and secretly tracking phone movements. It was first identified for iOS platforms, before being later identified for Android devices."
    }
  },
  {
    "instruction": "context: The culture of OGUsers contributes to the normalization of cybercrime by glorifying the acquisition and possession of \"rare\" or \"OG\" online accounts, which are often obtained through illegal means. This can create a culture that views hacking and identity theft as acceptable practices, which can encourage more individuals to engage in such activities.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the culture of OGUsers contribute to the normalization of cybercrime?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the culture of OGUsers contribute to the normalization of cybercrime?",
      "answer": "The culture of OGUsers contributes to the normalization of cybercrime by glorifying the acquisition and possession of \"rare\" or \"OG\" online accounts, which are often obtained through illegal means. This can create a culture that views hacking and identity theft as acceptable practices, which can encourage more individuals to engage in such activities."
    }
  },
  {
    "instruction": "context: Tunneling protocols can be used to \"sneak through\" a firewall by encapsulating the traffic data in a protocol that the firewall does not block. This can allow users to access services that would otherwise be prohibited by the firewall.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can tunneling protocols be used to \"sneak through\" a firewall?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can tunneling protocols be used to \"sneak through\" a firewall?",
      "answer": "Tunneling protocols can be used to \"sneak through\" a firewall by encapsulating the traffic data in a protocol that the firewall does not block. This can allow users to access services that would otherwise be prohibited by the firewall."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which Internet security companies described the Carbanak attacks several months earlier under the name Anunak?",
    "context": "",
    "output": "Group-IB (Singapore) and Fox-IT (The Netherlands) described the Carbanak attacks several months earlier under the name Anunak.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which Internet security companies described the Carbanak attacks several months earlier under the name Anunak?",
      "answer": "Group-IB (Singapore) and Fox-IT (The Netherlands) described the Carbanak attacks several months earlier under the name Anunak."
    }
  },
  {
    "instruction": "context: Users have encountered incompatibilities upgrading to Windows XP Service Pack 3 or Windows Vista Service Pack 1 with Norton 360 version 2.0 installed. These issues have resulted in an empty Device Manager and missing devices such as wireless network adapters. Symantec has acknowledged the issue and has issued a fix intended for users before upgrading.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are some of the issues encountered by users when upgrading to Windows XP Service Pack 3 or Windows Vista Service Pack 1 with Norton 360 version 2.0 installed?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the issues encountered by users when upgrading to Windows XP Service Pack 3 or Windows Vista Service Pack 1 with Norton 360 version 2.0 installed?",
      "answer": "Users have encountered incompatibilities upgrading to Windows XP Service Pack 3 or Windows Vista Service Pack 1 with Norton 360 version 2.0 installed. These issues have resulted in an empty Device Manager and missing devices such as wireless network adapters. Symantec has acknowledged the issue and has issued a fix intended for users before upgrading."
    }
  },
  {
    "instruction": "context: Avira removed their own firewall technology from 2014 onwards because Windows 8 and the Microsoft Certification Program forced developers to use interfaces introduced in Windows Vista. Instead, they now rely on Windows Firewall for protection.\n\nAsk a question about this context.",
    "context": "",
    "output": "Why did Avira remove their own firewall technology from 2014 onwards?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why did Avira remove their own firewall technology from 2014 onwards?",
      "answer": "Avira removed their own firewall technology from 2014 onwards because Windows 8 and the Microsoft Certification Program forced developers to use interfaces introduced in Windows Vista. Instead, they now rely on Windows Firewall for protection."
    }
  },
  {
    "instruction": "Symmetric-key algorithm\n\n==Introduction==\nSymmetric-key algorithms are algorithms for cryptography that use the same cryptographic keys for both the encryption of plaintext and the decryption of ciphertext. The keys may be identical, or there may be a simple transformation to go between the two keys. The keys, in practice, represent a shared secret between two or more parties that can be used to maintain a private information link. The requirement that both parties have access to the secret key is one of the main drawbacks of symmetric-key encryption, in comparison to public-key encryption (also known as asymmetric-key encryption). However, symmetric-key encryption algorithms are usually better for bulk encryption. With exception of the one-time pad they have a smaller key size, which means less storage space and faster transmission. Due to this, asymmetric-key encryption is often used to exchange the secret key for symmetric-key encryption.\n\n== Types ==\nSymmetric-key encryption can use either stream ciphers or block ciphers.\nStream ciphers encrypt the digits (typically bytes), or letters (in substitution ciphers) of a message one at a time. An example is ChaCha20.\nSubstitution ciphers are well-known ciphers, but can be easily decrypted using a frequency table.\nBlock ciphers take a number of bits and encrypt them in a single unit, padding the plaintext to achieve a multiple of the block size. The Advanced Encryption Standard (AES) algorithm, approved by NIST in December 2001, uses 128-bit blocks.\n\n== Implementations ==\nExamples of popular symmetric-key algorithms include Twofish, Serpent, AES (Rijndael), Camellia, Salsa20, ChaCha20, Blowfish, CAST5, Kuznyechik, RC4, DES, 3DES, Skipjack, Safer, and IDEA.\n\n== Use as a cryptographic primitive ==\nSymmetric ciphers are commonly used to achieve other cryptographic primitives than just encryption.Encrypting a message does not guarantee that it will remain unchanged while encrypted. Hence, often a message authentication code is added to a ciphertext to ensure that changes to the ciphertext will be noted by the receiver. Message authentication codes can be constructed from an AEAD cipher (e.g. AES-GCM).\nHowever, symmetric ciphers cannot be used for non-repudiation purposes except by involving additional parties. See the ISO/IEC 13888-2 standard.\nAnother application is to build hash functions from block ciphers. See one-way compression function for descriptions of several such methods.\n\n== Construction of symmetric ciphers ==\n\nMany modern block ciphers are based on a construction proposed by Horst Feistel. Feistel's construction makes it possible to build invertible functions from other functions that are themselves not invertible.\n\n== Security of symmetric ciphers ==\nSymmetric ciphers have historically been susceptible to known-plaintext attacks, chosen-plaintext attacks, differential cryptanalysis and linear cryptanalysis. Careful construction of the functions for each round can greatly reduce the chances of a successful attack. It is also possible to increase the key length or the rounds in the encryption process to better protect against attack. This, however, tends to increase the processing power and decrease the speed at which the process runs due to the amount of operations the system needs to do.Most modern symmetric-key algorithms appear to be resistant to the threat of post-quantum cryptography. Quantum computers would exponentially increase the speed at which these ciphers can be decoded; notably, Grover's algorithm would take the square-root of the time traditionally required for a brute-force attack, although these vulnerabilities can be  compensated for by doubling key length. For example, a 128 bit AES cipher would not be secure against such an attack as it would reduce the time required to test all possible iterations from over 10 quintillion years to about six months. By contrast, it would still take a quantum computer the same amount of time to decode a 256 bit AES cipher as it would a conventional computer to decode a 128 bit AES cipher. For this reason, AES-256 is believed to be \"quantum resistant\".\n\n== Key management ==\n\n== Key establishment ==\n\nSymmetric-key algorithms require both the sender and the recipient of a message to have the same secret key.\nAll early cryptographic systems required either the sender or the recipient to somehow receive a copy of that secret key over a physically secure channel.\nNearly all modern cryptographic systems still use symmetric-key algorithms internally to encrypt the bulk of the messages, but they eliminate the need for a physically secure channel by using Diffie\u2013Hellman key exchange or some other public-key protocol to securely come to agreement on a fresh new secret key for each session/conversation (forward secrecy).\n\n== Key generation ==\n\nWhen used with asymmetric ciphers for key transfer, pseudorandom key generators are nearly always used to generate the symmetric cipher session keys. However, lack of randomness in those generators or in their initialization vectors is disastrous and has led to cryptanalytic breaks in the past. Therefore, it is essential that an implementation use a source of high entropy for its initialization.\n\n== Reciprocal cipher ==\nA reciprocal cipher is a cipher where, just as one enters the plaintext into the cryptography system to get the ciphertext, one could enter the ciphertext into the same place in the system to get the plaintext. A reciprocal cipher is also sometimes referred as self-reciprocal cipher.Practically all mechanical cipher machines implement a reciprocal cipher, a mathematical involution on each typed-in letter.\nInstead of designing two kinds of machines, one for encrypting and one for decrypting, all the machines can be identical and can be set up (keyed) the same way.Examples of reciprocal ciphers include:\n\nAtbash\nBeaufort cipher\nEnigma machine\nMarie Antoinette and Axel von Fersen communicated with a self-reciprocal cipher.\nthe Porta polyalphabetic cipher is self-reciprocal.\nPurple cipher\nRC4\nROT13\nXOR cipher\nVatsyayana cipherThe majority of all modern ciphers can be classified as either a stream cipher, most of which use a reciprocal XOR cipher combiner, or a block cipher, most of which use a Feistel cipher or Lai\u2013Massey scheme with a reciprocal transformation in each round.\nQuestion: How do block ciphers encrypt data in symmetric-key encryption?",
    "context": "",
    "output": "Answer: Block ciphers take a number of bits and encrypt them in a single unit, padding the plaintext to achieve a multiple of the block size in symmetric-key encryption.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do block ciphers encrypt data in symmetric-key encryption?",
      "answer": "Block ciphers take a number of bits and encrypt them in a single unit, padding the plaintext to achieve a multiple of the block size in symmetric-key encryption.",
      "context": "Symmetric-key algorithm\n\n==Introduction==\nSymmetric-key algorithms are algorithms for cryptography that use the same cryptographic keys for both the encryption of plaintext and the decryption of ciphertext. The keys may be identical, or there may be a simple transformation to go between the two keys. The keys, in practice, represent a shared secret between two or more parties that can be used to maintain a private information link. The requirement that both parties have access to the secret key is one of the main drawbacks of symmetric-key encryption, in comparison to public-key encryption (also known as asymmetric-key encryption). However, symmetric-key encryption algorithms are usually better for bulk encryption. With exception of the one-time pad they have a smaller key size, which means less storage space and faster transmission. Due to this, asymmetric-key encryption is often used to exchange the secret key for symmetric-key encryption.\n\n== Types ==\nSymmetric-key encryption can use either stream ciphers or block ciphers.\nStream ciphers encrypt the digits (typically bytes), or letters (in substitution ciphers) of a message one at a time. An example is ChaCha20.\nSubstitution ciphers are well-known ciphers, but can be easily decrypted using a frequency table.\nBlock ciphers take a number of bits and encrypt them in a single unit, padding the plaintext to achieve a multiple of the block size. The Advanced Encryption Standard (AES) algorithm, approved by NIST in December 2001, uses 128-bit blocks.\n\n== Implementations ==\nExamples of popular symmetric-key algorithms include Twofish, Serpent, AES (Rijndael), Camellia, Salsa20, ChaCha20, Blowfish, CAST5, Kuznyechik, RC4, DES, 3DES, Skipjack, Safer, and IDEA.\n\n== Use as a cryptographic primitive ==\nSymmetric ciphers are commonly used to achieve other cryptographic primitives than just encryption.Encrypting a message does not guarantee that it will remain unchanged while encrypted. Hence, often a message authentication code is added to a ciphertext to ensure that changes to the ciphertext will be noted by the receiver. Message authentication codes can be constructed from an AEAD cipher (e.g. AES-GCM).\nHowever, symmetric ciphers cannot be used for non-repudiation purposes except by involving additional parties. See the ISO/IEC 13888-2 standard.\nAnother application is to build hash functions from block ciphers. See one-way compression function for descriptions of several such methods.\n\n== Construction of symmetric ciphers ==\n\nMany modern block ciphers are based on a construction proposed by Horst Feistel. Feistel's construction makes it possible to build invertible functions from other functions that are themselves not invertible.\n\n== Security of symmetric ciphers ==\nSymmetric ciphers have historically been susceptible to known-plaintext attacks, chosen-plaintext attacks, differential cryptanalysis and linear cryptanalysis. Careful construction of the functions for each round can greatly reduce the chances of a successful attack. It is also possible to increase the key length or the rounds in the encryption process to better protect against attack. This, however, tends to increase the processing power and decrease the speed at which the process runs due to the amount of operations the system needs to do.Most modern symmetric-key algorithms appear to be resistant to the threat of post-quantum cryptography. Quantum computers would exponentially increase the speed at which these ciphers can be decoded; notably, Grover's algorithm would take the square-root of the time traditionally required for a brute-force attack, although these vulnerabilities can be  compensated for by doubling key length. For example, a 128 bit AES cipher would not be secure against such an attack as it would reduce the time required to test all possible iterations from over 10 quintillion years to about six months. By contrast, it would still take a quantum computer the same amount of time to decode a 256 bit AES cipher as it would a conventional computer to decode a 128 bit AES cipher. For this reason, AES-256 is believed to be \"quantum resistant\".\n\n== Key management ==\n\n== Key establishment ==\n\nSymmetric-key algorithms require both the sender and the recipient of a message to have the same secret key.\nAll early cryptographic systems required either the sender or the recipient to somehow receive a copy of that secret key over a physically secure channel.\nNearly all modern cryptographic systems still use symmetric-key algorithms internally to encrypt the bulk of the messages, but they eliminate the need for a physically secure channel by using Diffie\u2013Hellman key exchange or some other public-key protocol to securely come to agreement on a fresh new secret key for each session/conversation (forward secrecy).\n\n== Key generation ==\n\nWhen used with asymmetric ciphers for key transfer, pseudorandom key generators are nearly always used to generate the symmetric cipher session keys. However, lack of randomness in those generators or in their initialization vectors is disastrous and has led to cryptanalytic breaks in the past. Therefore, it is essential that an implementation use a source of high entropy for its initialization.\n\n== Reciprocal cipher ==\nA reciprocal cipher is a cipher where, just as one enters the plaintext into the cryptography system to get the ciphertext, one could enter the ciphertext into the same place in the system to get the plaintext. A reciprocal cipher is also sometimes referred as self-reciprocal cipher.Practically all mechanical cipher machines implement a reciprocal cipher, a mathematical involution on each typed-in letter.\nInstead of designing two kinds of machines, one for encrypting and one for decrypting, all the machines can be identical and can be set up (keyed) the same way.Examples of reciprocal ciphers include:\n\nAtbash\nBeaufort cipher\nEnigma machine\nMarie Antoinette and Axel von Fersen communicated with a self-reciprocal cipher.\nthe Porta polyalphabetic cipher is self-reciprocal.\nPurple cipher\nRC4\nROT13\nXOR cipher\nVatsyayana cipherThe majority of all modern ciphers can be classified as either a stream cipher, most of which use a reciprocal XOR cipher combiner, or a block cipher, most of which use a Feistel cipher or Lai\u2013Massey scheme with a reciprocal transformation in each round."
    }
  },
  {
    "instruction": "Write an answer to the following question: How many versions of the Kryha machine were there?",
    "context": "",
    "output": "There were three versions of the Kryha machine: the standard mechanical version, a pocket version called the \"Lilliput\" model, and a more bulky electrical version.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many versions of the Kryha machine were there?",
      "answer": "There were three versions of the Kryha machine: the standard mechanical version, a pocket version called the \"Lilliput\" model, and a more bulky electrical version."
    }
  },
  {
    "instruction": "Process isolation\n\n==Introduction==\nProcess isolation is a set of different hardware and software technologies designed to protect each process from other processes on the operating system. It does so by preventing process A from writing to process B.\nProcess isolation can be implemented with virtual address space, where process A's address space is different from process B's address space \u2013 preventing A from writing onto B.\nSecurity is easier to enforce by disallowing inter-process memory access, in contrast with less secure architectures such as DOS in which any process can write to any memory in any other process.\n\n== Limited inter-process communication ==\nIn a system with process isolation, limited (controlled) interaction between processes may still be allowed over inter-process communication (IPC) channels such as shared memory, local sockets or Internet sockets. In this scheme, all of the process' memory is isolated from other processes except where the process is allowing input from collaborating processes.\nSystem policies may disallow IPC in some circumstances. For example, in mandatory access control systems, subjects with different sensitivity levels may not be allowed to communicate with each other. The security implications in these circumstances are broad and span applications in network key encryption systematics as well as distributed caching algorithms. Interface-defined protocols such as basic cloud access architecture and network sharing are similarly affected.\n\n== Operating systems ==\nNotable operating systems that support process isolation:\n\nUnix, Linux, OS X\nVMS\nMicrosoft Windows from Windows NT 3.1\n\n== Web browsers ==\n\nInternet Explorer 4 used process isolation in order to allow separate windowed instances of the browser their own processes; however, at the height of the browser wars, this was dropped in subsequent versions to compete with Netscape Navigator (which sought to concentrate upon one process for the entire Internet suite). This idea of process-per-instance would not be revisited until a decade afterwards, when tabbed browsing became more commonplace.\nIn Google Chrome's \"Multi-Process Architecture\" and Internet Explorer 8's \"Loosely Coupled IE (LCIE)\", tabs containing webpages are contained within their own semi-separate OS-level processes which are isolated from the core process of the browser so as to prevent the crash of one tab/page from crashing the entire browser. This method (known popularly as multiprocess or process-per-tab) is meant to both manage memory and processing by allowing offending tabs to crash separately from the browser and other tabs and manage security.\n\n\n*** Browsers with process isolation ***\nGoogle Chrome\nInternet Explorer 8 and later\nSafari\nMozilla Firefox (default since 57)\nMaxthon\n\n== Programming languages ==\nErlang (programming language) is providing a similar concept in user space, by realizing strictly separated lightweight processes.\n\n== Related technologies ==\nVirtual memory and virtual address space allows for memory space isolation.\nPolyinstantiation allows mirrors of shared resources, where changes by process A will not be visible to process B.\nRead the text above and answer this question: How can system policies disallow inter-process communication in a system with process isolation?",
    "context": "",
    "output": "System policies can disallow inter-process communication in a system with process isolation by not allowing subjects with different sensitivity levels to communicate with each other.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can system policies disallow inter-process communication in a system with process isolation?",
      "answer": "System policies can disallow inter-process communication in a system with process isolation by not allowing subjects with different sensitivity levels to communicate with each other.",
      "context": "Process isolation\n\n==Introduction==\nProcess isolation is a set of different hardware and software technologies designed to protect each process from other processes on the operating system. It does so by preventing process A from writing to process B.\nProcess isolation can be implemented with virtual address space, where process A's address space is different from process B's address space \u2013 preventing A from writing onto B.\nSecurity is easier to enforce by disallowing inter-process memory access, in contrast with less secure architectures such as DOS in which any process can write to any memory in any other process.\n\n== Limited inter-process communication ==\nIn a system with process isolation, limited (controlled) interaction between processes may still be allowed over inter-process communication (IPC) channels such as shared memory, local sockets or Internet sockets. In this scheme, all of the process' memory is isolated from other processes except where the process is allowing input from collaborating processes.\nSystem policies may disallow IPC in some circumstances. For example, in mandatory access control systems, subjects with different sensitivity levels may not be allowed to communicate with each other. The security implications in these circumstances are broad and span applications in network key encryption systematics as well as distributed caching algorithms. Interface-defined protocols such as basic cloud access architecture and network sharing are similarly affected.\n\n== Operating systems ==\nNotable operating systems that support process isolation:\n\nUnix, Linux, OS X\nVMS\nMicrosoft Windows from Windows NT 3.1\n\n== Web browsers ==\n\nInternet Explorer 4 used process isolation in order to allow separate windowed instances of the browser their own processes; however, at the height of the browser wars, this was dropped in subsequent versions to compete with Netscape Navigator (which sought to concentrate upon one process for the entire Internet suite). This idea of process-per-instance would not be revisited until a decade afterwards, when tabbed browsing became more commonplace.\nIn Google Chrome's \"Multi-Process Architecture\" and Internet Explorer 8's \"Loosely Coupled IE (LCIE)\", tabs containing webpages are contained within their own semi-separate OS-level processes which are isolated from the core process of the browser so as to prevent the crash of one tab/page from crashing the entire browser. This method (known popularly as multiprocess or process-per-tab) is meant to both manage memory and processing by allowing offending tabs to crash separately from the browser and other tabs and manage security.\n\n\n*** Browsers with process isolation ***\nGoogle Chrome\nInternet Explorer 8 and later\nSafari\nMozilla Firefox (default since 57)\nMaxthon\n\n== Programming languages ==\nErlang (programming language) is providing a similar concept in user space, by realizing strictly separated lightweight processes.\n\n== Related technologies ==\nVirtual memory and virtual address space allows for memory space isolation.\nPolyinstantiation allows mirrors of shared resources, where changes by process A will not be visible to process B."
    }
  },
  {
    "instruction": "Enigma machine\n\n==Introduction==\nThe Enigma machine is a cipher device developed and used in the early- to mid-20th century to protect commercial, diplomatic, and military communication. It was employed extensively by Nazi Germany during World War II, in all branches of the German military. The Enigma machine was considered so secure that it was used to encipher the most top-secret messages.The Enigma has an electromechanical rotor mechanism that scrambles the 26 letters of the alphabet. In typical use, one person enters text on the Enigma's keyboard and another person writes down which of the 26 lights above the keyboard illuminated at each key press. If plain text is entered, the illuminated letters are the ciphertext. Entering ciphertext transforms it back into readable plaintext. The rotor mechanism changes the electrical connections between the keys and the lights with each keypress. \nThe security of the system depends on machine settings that were generally changed daily, based on secret key lists distributed in advance, and on other settings that were changed for each message. The receiving station would have to know and use the exact settings employed by the transmitting station to successfully decrypt a message.\nWhile Nazi Germany introduced a series of improvements to the Enigma over the years, and these hampered decryption efforts, they did not prevent Poland from cracking the machine as early as December 1932 and reading messages prior to and into the war. Poland's sharing of her achievements enabled the western Allies to exploit Enigma-enciphered messages as a major source of intelligence. Many commentators say the flow of Ultra communications intelligence from the decrypting of Enigma, Lorenz, and other ciphers shortened the war substantially and may even have altered its outcome.\n\n== Design ==\n\nLike other rotor machines, the Enigma machine is a combination of mechanical and electrical subsystems. The mechanical subsystem consists of a keyboard; a set of rotating disks called rotors arranged adjacently along a spindle; one of various stepping components to turn at least one rotor with each key press, and a series of lamps, one for each letter. These design features are the reason that the Enigma machine was originally referred to as the rotor-based cipher machine during its intellectual inception in 1915.\n\n\n*** Electrical pathway ***\n\nAn electrical pathway is a route for current to travel. By manipulating this phenomenon the Enigma machine was able to scramble messages. The mechanical parts act by forming a varying electrical circuit. When a key is pressed, one or more rotors rotate on the spindle. On the sides of the rotors are a series of electrical contacts that, after rotation, line up with contacts on the other rotors or fixed wiring on either end of the spindle. When the rotors are properly aligned, each key on the keyboard is connected to a unique electrical pathway through the series of contacts and internal wiring. Current, typically from a battery, flows through the pressed key, into the newly configured set of circuits and back out again, ultimately lighting one display lamp, which shows the output letter. For example, when encrypting a message starting ANX..., the operator would first press the A key, and the Z lamp might light, so Z would be the first letter of the ciphertext. The operator would next press N, and then X in the same fashion, and so on.\n\nCurrent flows from the battery (1) through a depressed bi-directional keyboard switch (2) to the plugboard (3). Next, it passes through the (unused in this instance, so shown closed) plug \"A\" (3) via the entry wheel (4), through the wiring of the three (Wehrmacht Enigma) or four (Kriegsmarine M4 and Abwehr variants) installed rotors (5), and enters the reflector (6). The reflector returns the current, via an entirely different path, back through the rotors (5) and entry wheel (4), proceeding through plug \"S\" (7) connected with a cable (8) to plug \"D\", and another bi-directional switch (9) to light the appropriate lamp.The repeated changes of electrical path through an Enigma scrambler implement a polyalphabetic substitution cipher that provides Enigma's security. The diagram on the right shows how the electrical pathway changes with each key depression, which causes rotation of at least the right-hand rotor. Current passes into the set of rotors, into and back out of the reflector, and out through the rotors again. The greyed-out lines are other possible paths within each rotor; these are hard-wired from one side of each rotor to the other. The letter A encrypts differently with consecutive key presses, first to G, and then to C. This is because the right-hand rotor steps (rotates one position) on each key press, sending the signal on a completely different route. Eventually other rotors step with a key press.\n\n\n*** Rotors ***\n\nThe rotors (alternatively wheels or drums, Walzen in German) form the heart of an Enigma machine. Each rotor is a disc approximately 10 cm (3.9 in) in diameter made from Ebonite or Bakelite with 26 brass, spring-loaded, electrical contact pins arranged in a circle on one face, with the other face housing 26 corresponding electrical contacts in the form of circular plates. The pins and contacts represent the alphabet \u2014 typically the 26 letters A\u2013Z, as will be assumed for the rest of this description. When the rotors are mounted side by side on the spindle, the pins of one rotor rest against the plate contacts of the neighbouring rotor, forming an electrical connection. Inside the body of the rotor, 26 wires connect each pin on one side to a contact on the other in a complex pattern. Most of the rotors are identified by Roman numerals, and each issued copy of rotor I, for instance, is wired identically to all others. The same is true for the special thin beta and gamma rotors used in the M4 naval variant.\n\nBy itself, a rotor performs only a very simple type of encryption, a simple substitution cipher. For example, the pin corresponding to the letter E might be wired to the contact for letter T on the opposite face, and so on. Enigma's security comes from using several rotors in series (usually three or four) and the regular stepping movement of the rotors, thus implementing a polyalphabetic substitution cipher.\nEach rotor can be set to one of 26 possible starting positions when placed in an Enigma machine. After insertion, a rotor can be turned to the correct position by hand, using the grooved finger-wheel which protrudes from the internal Enigma cover when closed. In order for the operator to know the rotor's position, each has an alphabet tyre (or letter ring) attached to the outside of the rotor disc, with 26 characters (typically letters); one of these is visible through the window for that slot in the cover, thus indicating the rotational position of the rotor. In early models, the alphabet ring was fixed to the rotor disc. A later improvement was the ability to adjust the alphabet ring relative to the rotor disc. The position of the ring was known as the Ringstellung (\"ring setting\"), and that setting was a part of the initial setup needed prior to an operating session. In modern terms it was a part of the initialization vector.\n\nEach rotor contains one or more notches that control rotor stepping. In the military variants, the notches are located on the alphabet ring.\nThe Army and Air Force Enigmas were used with several rotors, initially three. On 15 December 1938, this changed to five, from which three were chosen for a given session. Rotors were marked with Roman numerals to distinguish them: I, II, III, IV and V, all with single notches located at different points on the alphabet ring. This variation was probably intended as a security measure, but ultimately allowed the Polish Clock Method and British Banburismus attacks.\nThe Naval version of the Wehrmacht Enigma had always been issued with more rotors than the other services: At first six, then seven, and finally eight. The additional rotors were marked VI, VII and VIII, all with different wiring, and had two notches, resulting in more frequent turnover. The four-rotor Naval Enigma (M4) machine accommodated an extra rotor in the same space as the three-rotor version. This was accomplished by replacing the original reflector with a thinner one and by adding a thin fourth rotor. That fourth rotor was one of two types, Beta or Gamma, and never stepped, but could be manually set to any of 26 positions. One of the 26 made the machine perform identically to the three-rotor machine.\n\n\n*** Stepping ***\nTo avoid merely implementing a simple (solvable) substitution cipher, every key press caused one or more rotors to step by one twenty-sixth of a full rotation, before the electrical connections were made. This changed the substitution alphabet used for encryption, ensuring that the cryptographic substitution was different at each new rotor position, producing a more formidable polyalphabetic substitution cipher. The stepping mechanism varied slightly from model to model. The right-hand rotor stepped once with each keystroke, and other rotors stepped less frequently.\n\n\n*** Turnover ***\n\nThe advancement of a rotor other than the left-hand one was called a turnover by the British. This was achieved by a ratchet and pawl mechanism. Each rotor had a ratchet with 26 teeth and every time a key was pressed, the set of spring-loaded pawls moved forward in unison, trying to engage with a ratchet. The alphabet ring of the rotor to the right normally prevented this. As this ring rotated with its rotor, a notch machined into it would eventually align itself with the pawl, allowing it to engage with the ratchet, and advance the rotor on its left. The right-hand pawl, having no rotor and ring to its right, stepped its rotor with every key depression. For a single-notch rotor in the right-hand position, the middle rotor stepped once for every 26 steps of the right-hand rotor. Similarly for rotors two and three. For a two-notch rotor, the rotor to its left would turn over twice for each rotation.\nThe first five rotors to be introduced (I\u2013V) contained one notch each, while the additional naval rotors VI, VII and VIII each had two notches. The position of the notch on each rotor was determined by the letter ring which could be adjusted in relation to the core containing the interconnections. The points on the rings at which they caused the next wheel to move were as follows.\nThe design also included a feature known as double-stepping. This occurred when each pawl aligned with both the ratchet of its rotor and the rotating notched ring of the neighbouring rotor. If a pawl engaged with a ratchet through alignment with a notch, as it moved forward it pushed against both the ratchet and the notch, advancing both rotors. In a three-rotor machine, double-stepping affected rotor two only. If, in moving forward, the ratchet of rotor three was engaged, rotor two would move again on the subsequent keystroke, resulting in two consecutive steps. Rotor two also pushes rotor one forward after 26 steps, but since rotor one moves forward with every keystroke anyway, there is no double-stepping. This double-stepping caused the rotors to deviate from odometer-style regular motion.\nWith three wheels and only single notches in the first and second wheels, the machine had a period of 26\u00d725\u00d726\n\n== Operation ==\n\n\n*** Basic operation ***\n\nA German Enigma operator would be given a plaintext message to encrypt. After setting up his machine, he would type the message on the Enigma keyboard. For each letter pressed, one lamp lit indicating a different letter according to a pseudo-random substitution determined by the electrical pathways inside the machine. The letter indicated by the lamp would be recorded, typically by a second operator, as the cyphertext letter. The action of pressing a key also moved one or more rotors so that the next key press used a different electrical pathway, and thus a different substitution would occur even if the same plaintext letter were entered again. For each key press there was rotation of at least the right hand rotor and less often the other two, resulting in a different substitution alphabet being used for every letter in the message. This process continued until the message was completed. The cyphertext recorded by the second operator would then be transmitted, usually by radio in Morse code, to an operator of another Enigma machine. This operator would type in the cyphertext and \u2014 as long as all the settings of the deciphering machine were identical to those of the enciphering machine \u2014 for every key press the reverse substitution would occur and the plaintext message would emerge.\n\n\n*** Details ***\n\nIn use, the Enigma required a list of daily key settings and auxiliary documents. In German military practice, communications were divided into separate networks, each using different settings. These communication nets were termed keys at Bletchley Park, and were assigned code names, such as Red, Chaffinch, and Shark. Each unit operating in a network was given the same settings list for its Enigma, valid for a period of time. The procedures for German Naval Enigma were more elaborate and more secure than those in other services and employed auxiliary codebooks. Navy codebooks were printed in red, water-soluble ink on pink paper so that they could easily be destroyed if they were endangered or if the vessel was sunk.\nAn Enigma machine's setting (its cryptographic key in modern terms; Schl\u00fcssel in German) specified each operator-adjustable aspect of the machine:\n\nWheel order (Walzenlage) \u2013 the choice of rotors and the order in which they are fitted.\nRing settings (Ringstellung) \u2013 the position of each alphabet ring relative to its rotor wiring.\nPlug connections (Steckerverbindungen) \u2013 the pairs of letters in the plugboard that are connected together.\nIn very late versions, the wiring of the reconfigurable reflector.\nStarting position of the rotors (Grundstellung) \u2013 chosen by the operator, should be different for each message.For a message to be correctly encrypted and decrypted, both sender and receiver had to configure their Enigma in the same way; rotor selection and order, ring positions, plugboard connections and starting rotor positions must be identical. Except for the starting positions, these settings were established beforehand, distributed in key lists and changed daily. For example, the settings for the 18th day of the month in the German Luftwaffe Enigma key list number 649 (see image) were as follows:\n\nWheel order: IV, II, V\nRing settings: 15, 23, 26\nPlugboard connections: EJ OY IV AQ KW FX MT PS LU BD\nReconfigurable reflector wiring: IU AS DV GL FT OX EZ CH MR KN BQ PW\nIndicator groups: lsa zbw vcj rxnEnigma was designed to be secure even if the rotor wiring was known to an opponent, although in practice considerable effort protected the wiring configuration. If the wiring is secret, the total number of possible configurations has been calculated to be around 3\u00d710114 (approximately 380 bits); with known wiring and other operational constraints, this is reduced to around 1023 (76 bits). Because of the large number of possibilities, users of Enigma were confident of its security; it was not then feasible for an adversary to even begin to try a brute-force attack.\n\n\n*** Indicator ***\n\nMost of the key was kept constant for a set time period, typically a day. A different initial rotor position was used for each message, a concept similar to an initialisation vector in modern cryptography. The reason is that encrypting many messages with identical or near-identical settings (termed in cryptanalysis as being in depth), would enable an attack using a statistical procedure such as Friedman's Index of coincidence. The starting position for the rotors was transmitted just before the ciphertext, usually after having been enciphered. The exact method used was termed the indicator procedure. Design weakness and operator sloppiness in these indicator procedures were two of the main weaknesses that made cracking Enigma possible.\n\nOne of the earliest indicator procedures for the Enigma was cryptographically flawed and allowed Polish cryptanalysts to make the initial breaks into the plugboard Enigma. The procedure had the operator set his machine in accordance with the secret settings that all operators on the net shared. The settings included an initial position for the rotors (the Grundstellung), say, AOH. The operator turned his rotors until AOH was visible through the rotor windows. At that point, the operator chose his own arbitrary starting position for the message he would send. An operator might select EIN, and that became the message setting for that encryption session. The operator then typed EIN into the machine twice, this producing the encrypted indicator, for example XHTLOA. This was then transmitted, at which point the operator would turn the rotors to his message settings, EIN in this example, and then type the plaintext of the message.\nAt the receiving end, the operator set the machine to the initial settings (AOH) and typed in the first six letters of the message (XHTLOA). In this example, EINEIN emerged on the lamps, so the operator would learn the message setting that the sender used to encrypt this message. The receiving operator would set his rotors to EIN, type in the rest of the ciphertext, and get the deciphered message.\nThis indicator scheme had two weaknesses. First, the use of a global initial position (Grundstellung) meant all message keys used the same polyalphabetic substitution. In later indicator procedures, the operator selected his initial position for encrypting the indicator and sent that initial position in the clear. The second problem was the repetition of the indicator, which was a serious security flaw. The message setting was encoded twice, resulting in a relation between first and fourth, second and fifth, and third and sixth character. These security flaws enabled the Polish Cipher Bureau to break into the pre-war Enigma system as early as 1932. The early indicator procedure was subsequently described by German cryptanalysts as the \"faulty indicator technique\".During World War II, codebooks were only used each day to set up the rotors, their ring settings and the plugboard. For each message, the operator selected a random start position, let's say WZA, and a random message key, perhaps SXT. He moved the rotors to the WZA start position and encoded the message key SXT. Assume the result was UHL. He then set up the message key, SXT, as the start position and encrypted the message. Next, he transmitted the start position, WZA, the encoded message key, UHL, and then the ciphertext. The receiver set up the start position according to the first trigram, WZA, and decoded the second trigram, UHL, to obtain the SXT message setting. Next, he used this SXT message setting as the start position to decrypt the message. This way, each ground setting was different and the new procedure avoided the security flaw of double encoded message settings.This procedure was used by Wehrmacht and Luftwaffe only. The Kriegsmarine procedures on sending messages with the Enigma were far more complex and elaborate. Prior to encryption the message was encoded using the Kurzsignalheft code book. The Kurzsignalheft contained tables to convert sentences into four-letter groups. A great many choices were included, for example, logistic matters such as refuelling and rendezvous with supply ships, positions and grid lists, harbour names, countries, weapons, weather conditions, enemy positions and ships, date and time tables. Another codebook contained the Kenngruppen and Spruchschl\u00fcssel: the key identification and message key.\n\n\n*** Additional details ***\nThe Army Enigma machine used only the 26 alphabet characters. Punctuation was replaced with rare character combinations. A space was omitted or replaced with an X. The X was generally used as full-stop.\nSome punctuation marks were different in other parts of the armed forces. The Wehrmacht replaced a comma with ZZ and the question mark with FRAGE or FRAQ.\nThe Kriegsmarine replaced the comma with Y and the question mark with UD. The combination CH, as in \"Acht\" (eight) or \"Richtung\" (direction), was replaced with Q (AQT, RIQTUNG). Two, three and four zeros were replaced with CENTA, MILLE and MYRIA.\nThe Wehrmacht and the Luftwaffe transmitted messages in groups of five characters and counted the letters.\nThe Kriegsmarine used four-character groups and counted those groups. \n\nFrequently used names or words were varied as much as possible. Words like Minensuchboot (minesweeper) could be written as MINENSUCHBOOT, MINBOOT or MMMBOOT. To make cryptanalysis harder, messages were limited to 250 characters. Longer messages were divided into several parts, each using a different message key.\n\n\n*** Example enciphering process ***\nThe character substitutions by the Enigma machine as a whole can be expressed as a string of letters with each position occupied by the character that will replace the character at the corresponding position in the alphabet. For example, a given machine configuration that enciphered A to L, B to U, C to S, ..., and Z to J could be represented compactly as\n\nLUSHQOXDMZNAIKFREPCYBWVGTJ\n\nand the enciphering of a particular character by that configuration could be represented by highlighting the enciphered character as in\n\nD > LUS(H)QOXDMZNAIKFREPCYBWVGTJ\n\nSince the operation of an Enigma machine enciphering a message is a series of such configurations, each associated with a single character being enciphered, a sequence of such representations can be used to represent the operation of the machine as it enciphers a message. For example, the process of enciphering the first sentence of the main body of the famous \"D\u00f6nitz message\" to\n\nRBBF PMHP HGCZ XTDY GAHG UFXG EWKB LKGJ\n\ncan be represented as\n\n0001 F > KGWNT(R)BLQPAHYDVJIFXEZOCSMU CDTK 25 15 16 26\n0002 O > UORYTQSLWXZHNM(B)VFCGEAPIJDK CDTL 25 15 16 01\n0003 L > HLNRSKJAMGF(B)ICUQPDEYOZXWTV CDTM 25 15 16 02\n0004 G > KPTXIG(F)MESAUHYQBOVJCLRZDNW CDUN 25 15 17 03\n0005 E > XDYB(P)WOSMUZRIQGENLHVJTFACK CDUO 25 15 17 04\n0006 N > DLIAJUOVCEXBN(M)GQPWZYFHRKTS CDUP 25 15 17 05\n0007 D > LUS(H)QOXDMZNAIKFREPCYBWVGTJ CDUQ 25 15 17 06\n0008 E > JKGO(P)TCIHABRNMDEYLZFXWVUQS CDUR 25 15 17 07\n0009 S > GCBUZRASYXVMLPQNOF(H)WDKTJIE CDUS 25 15 17 08\n0010 I > XPJUOWIY(G)CVRTQEBNLZMDKFAHS CDUT 25 15 17 09\n0011 S > DISAUYOMBPNTHKGJRQ(C)LEZXWFV CDUU 25 15 17 10\n0012 T > FJLVQAKXNBGCPIRMEOY(Z)WDUHST CDUV 25 15 17 11\n0013 S > KTJUQONPZCAMLGFHEW(X)BDYRSVI CDUW 25 15 17 12\n0014 O > ZQXUVGFNWRLKPH(T)MBJYODEICSA CDUX 25 15 17 13\n0015 F > XJWFR(D)ZSQBLKTVPOIEHMYNCAUG CDUY 25 15 17 14\n0016 O > FSKTJARXPECNUL(Y)IZGBDMWVHOQ CDUZ 25 15 17 15\n0017 R > CEAKBMRYUVDNFLTXW(G)ZOIJQPHS CDVA 25 15 18 16\n0018 T > TLJRVQHGUCXBZYSWFDO(A)IEPKNM CDVB 25 15 18 17\n0019 B > Y(H)LPGTEBKWICSVUDRQMFONJZAX CDVC 25 15 18 18\n0020 E > KRUL(G)JEWNFADVIPOYBXZCMHSQT CDVD 25 15 18 19\n0021 K > RCBPQMVZXY(U)OFSLDEANWKGTIJH CDVE 25 15 18 20\n0022 A > (F)CBJQAWTVDYNXLUSEZPHOIGMKR CDVF 25 15 18 21\n0023 N > VFTQSBPORUZWY(X)HGDIECJALNMK CDVG 25 15 18 22\n0024 N > JSRHFENDUAZYQ(G)XTMCBPIWVOLK CDVH 25 15 18 23\n0025 T > RCBUTXVZJINQPKWMLAY(E)DGOFSH CDVI 25 15 18 24\n0026 Z > URFXNCMYLVPIGESKTBOQAJZDH(W) CDVJ 25 15 18 25\n0027 U > JIOZFEWMBAUSHPCNRQLV(K)TGYXD CDVK 25 15 18 26\n0028 G > ZGVRKO(B)XLNEIWJFUSDQYPCMHTA CDVL 25 15 18 01\n0029 E > RMJV(L)YQZKCIEBONUGAWXPDSTFH CDVM 25 15 18 02\n0030 B > G(K)QRFEANZPBMLHVJCDUXSOYTWI CDWN 25 15 19 03\n0031 E > YMZT(G)VEKQOHPBSJLIUNDRFXWAC CDWO 25 15 19 04\n0032 N > PDSBTIUQFNOVW(J)KAHZCEGLMYXR CDWP 25 15 19 05\n\nwhere the letters following each mapping are the letters that appear at the windows at that stage (the only state changes visible to the operator) and the numbers show the underlying physical position of each rotor.\nThe character mappings for a given configuration of the machine are in turn the result of a series of such mappings applied by each pass through a component of the machine: the enciphering of a character resulting from the application of a given component's mapping serves as the input to the mapping of the subsequent component.  For example, the 4th step in the enciphering above can be expanded to show each of these stages using the same representation of mappings and highlighting for the enciphered character:\n\n G > ABCDEF(G)HIJKLMNOPQRSTUVWXYZ\n   P EFMQAB(G)UINKXCJORDPZTHWVLYS         AE.BF.CM.DQ.HU.JN.LX.PR.SZ.VW\n   1 OFRJVM(A)ZHQNBXPYKCULGSWETDI  N  03  VIII\n   2 (N)UKCHVSMDGTZQFYEWPIALOXRJB  U  17  VI\n   3 XJMIYVCARQOWH(L)NDSUFKGBEPZT  D  15  V\n   4 QUNGALXEPKZ(Y)RDSOFTVCMBIHWJ  C  25  \u03b2\n   R RDOBJNTKVEHMLFCWZAXGYIPS(U)Q         c\n   4 EVTNHQDXWZJFUCPIAMOR(B)SYGLK         \u03b2\n   3 H(V)GPWSUMDBTNCOKXJIQZRFLAEY         V\n   2 TZDIPNJESYCUHAVRMXGKB(F)QWOL         VI\n   1 GLQYW(B)TIZDPSFKANJCUXREVMOH         VIII\n   P E(F)MQABGUINKXCJORDPZTHWVLYS         AE.BF.CM.DQ.HU.JN.LX.PR.SZ.VW\n F < KPTXIG(F)MESAUHYQBOVJCLRZDNW\n\nHere the enciphering begins trivially with the first \"mapping\" representing the keyboard (which has no effect), followed by the plugboard, configured as AE.BF.CM.DQ.HU.JN.LX.PR.SZ.VW which has no effect on 'G', followed by the VIII rotor in the 03 position, which maps G to A, then the VI rotor in the 17 position, which maps A to N, ..., and finally the plugboard again, which maps B to F, producing the overall mapping indicated at the final step: G to F.\nNote that this model has 4 rotors (lines 1 through 4) and that the reflector (line R) also permutes (garbles) letters.\n\n== Models ==\nThe Enigma family included multiple designs. The earliest were commercial models dating from the early 1920s. Starting in the mid-1920s, the German military began to use Enigma, making a number of security-related changes. Various nations either adopted or adapted the design for their own cipher machines.\n\nAn estimated 40,000 Enigma machines were constructed. After the end of World War II, the Allies sold captured Enigma machines, still widely considered secure, to developing countries.\n\n\n*** Commercial Enigma ***\n\nOn 23 February 1918, Arthur Scherbius applied for a patent for a ciphering machine that used rotors. Scherbius and E. Richard Ritter founded the firm of Scherbius & Ritter. They approached the German Navy and Foreign Office with their design, but neither agency was interested. Scherbius & Ritter then assigned the patent rights to Gewerkschaft Securitas, who founded the Chiffriermaschinen Aktien-Gesellschaft (Cipher Machines Stock Corporation) on 9 July 1923; Scherbius and Ritter were on the board of directors.\n\n\n**** Enigma Handelsmaschine (1923) ****\nChiffriermaschinen AG began advertising a rotor machine, Enigma Handelsmaschine, which was exhibited at the Congress of the International Postal Union in 1924. The machine was heavy and bulky, incorporating a typewriter. It measured 65\u00d745\u00d738 cm and weighed about 50 kilograms (110 lb).\n\n\n**** Schreibende Enigma (1924) ****\nThis was also a model with a type writer. There where a number of problems associated with the printer and the construction was not stable until 1926. Both early versions of Enigma lacked the reflector and had to be switched between chiffering and dechiffering.\n\n\n**** Gl\u00fchlampenmaschine, Enigma A (1924) ****\nThe reflector, suggested by Scherbius' colleague Willi Korn, was introduced with the glow lamp version.\nThe machine was also known as the military Enigma. It had two rotors and a manually rotatable reflector. The typewriter was omitted and glow lamps were used for output. The operation was somewhat different from later models. Before the next key pressure, the operator had to press a button to advance the right rotor one step.\n\n\n**** Enigma B (1924) ****\n\nEnigma model B was introduced late in 1924, and was of a similar construction. While bearing the Enigma name, both models A and B were quite unlike later versions: They differed in physical size and shape, but also cryptographically, in that they lacked the reflector. This model of Enigma machine was referred to as the Glowlamp Enigma or Gl\u00fchlampenmaschine since it produced its output on a lamp panel rather than paper. This method of output was much more reliable and cost effective. Hence this machine was 1/8th the price of its predecessor.\n\n\n**** Enigma C (1926) ****\nModel C was the third model of the so-called \u2033glowlamp Enigmas\u2033 (after A and B) and it again lacked a typewriter.\n\n\n**** Enigma D (1927) ****\nThe Enigma C quickly gave way to Enigma D (1927). This version was widely used, with shipments to Sweden, the Netherlands, United Kingdom, Japan, Italy, Spain, United States and Poland. In 1927 Hugh Foss at the British Government Code and Cypher School was able to show that commercial Enigma machines could be broken, provided suitable cribs were available. Soon, the Enigma D would pioneer the use of a standard keyboard layout to be used in German computing.  This \"QWERTZ\" layout is very similar to the American QWERTY keyboard format used in many languages. \n\n\n***** \"Navy Cipher D\"*****\nOther countries used Enigma machines. The Italian Navy adopted the commercial Enigma as \"Navy Cipher D\". The Spanish also used commercial Enigma machines during their Civil War. British codebreakers succeeded in breaking these machines, which lacked a plugboard. Enigma machines were also used by diplomatic services.\n\n\n**** Enigma H (1929) ****\n\nThere was also a large, eight-rotor printing model, the Enigma H, called Enigma II by the Reichswehr. In 1933 the Polish Cipher Bureau detected that it was in use for high-level military communication, but it was soon withdrawn, as it was unreliable and jammed frequently.\n\n\n**** Enigma K ****\nThe Swiss used a version of Enigma called Model K or Swiss K for military and diplomatic use, which was very similar to commercial Enigma D. The machine's code was cracked by Poland, France, the United Kingdom and the United States; the latter code-named it INDIGO. An Enigma T model, code-named Tirpitz, was used by Japan.\n\n\n*** Military Enigma ***\nThe various services of the Wehrmacht used various Enigma versions, and replaced them frequently, sometimes with ones adapted from other services. Enigma seldom carried high-level strategic messages, which when not urgent went by courier, and when urgent went by other cryptographic systems including the Geheimschreiber.\n\n\n**** Funkschl\u00fcssel C ****\nThe Reichsmarine was the first military branch to adopt Enigma. This version, named Funkschl\u00fcssel C (\"Radio cipher C\"), had been put into production by 1925 and was introduced into service in 1926.The keyboard and lampboard contained 29 letters \u2014 A-Z, \u00c4, \u00d6 and \u00dc \u2014 that were arranged alphabetically, as opposed to the QWERTZUI ordering. The rotors had 28 contacts, with the letter X wired to bypass the rotors unencrypted. Three rotors were chosen from a set of five and the reflector could be inserted in one of four different positions, denoted \u03b1, \u03b2, \u03b3 and \u03b4. The machine was revised slightly in July 1933.\n\n\n**** Enigma G (1928\u20131930) ****\nBy 15 July 1928, the German Army (Reichswehr) had introduced their own exclusive version of the Enigma machine, the Enigma G.\nThe Abwehr used the Enigma G (the Abwehr Enigma). This Enigma variant was a four-wheel unsteckered machine with multiple notches on the rotors. This model was equipped with a counter that incremented upon each key press, and so is also known as the \"counter machine\" or the Z\u00e4hlwerk Enigma.\n\n\n**** Wehrmacht Enigma I (1930\u20131938) ****\nEnigma machine G was modified to the Enigma I by June 1930. Enigma I is also known as the Wehrmacht, or \"Services\" Enigma, and was used extensively by German military services and other government organisations (such as the railways) before and during World War II.\n\nThe major difference between Enigma I (German Army version from 1930), and commercial Enigma models was the addition of a plugboard to swap pairs of letters, greatly increasing cryptographic strength.\nOther differences included the use of a fixed reflector and the relocation of the stepping notches from the rotor body to the movable letter rings. The machine measured 28 cm \u00d7 34 cm \u00d7 15 cm (11.0 in \u00d7 13.4 in \u00d7 5.9 in) and weighed around 12 kg (26 lb).In August 1935, the Air Force introduced the Wehrmacht Enigma for their communications.\n\n\n**** M3 (1934) ****\nBy 1930, the Reichswehr had suggested that the Navy adopt their machine, citing the benefits of increased security (with the plugboard) and easier interservice communications. The Reichsmarine eventually agreed and in 1934 brought into service the Navy version of the Army Enigma, designated Funkschl\u00fcssel ' or M3. While the Army used only three rotors at that time, the Navy specified a choice of three from a possible five.\n\n\n**** Two extra rotors (1938) ****\nIn December 1938, the Army issued two extra rotors so that the three rotors were chosen from a set of five. In 1938, the Navy added two more rotors, and then another in 1939 to allow a choice of three rotors from a set of eight.\n\n\n**** M4 (1942) ****\n\nA four-rotor Enigma was introduced by the Navy for U-boat traffic on 1 February 1942, called M4 (the network was known as Triton, or Shark to the Allies). The extra rotor was fitted in the same space by splitting the reflector into a combination of a thin reflector and a thin fourth rotor.\n\n== Surviving machines ==\n\nThe effort to break the Enigma was not disclosed until the 1970s. Since then, interest in the Enigma machine has grown. Enigmas are on public display in museums around the world, and several are in the hands of private collectors and computer history enthusiasts.The Deutsches Museum in Munich has both the three- and four-rotor German military variants, as well as several civilian versions. Enigma machines are exhibited at the National Codes Centre in Bletchley Park, the Government Communications Headquarters, the Science Museum in London, Discovery Park of America in Tennessee, the Polish Army Museum in Warsaw, the Swedish Army Museum (Arm\u00e9museum) in Stockholm, the Military Museum of A Coru\u00f1a in Spain, the Nordland Red Cross War Memorial Museum in Narvik, Norway, The Artillery, Engineers and Signals Museum in H\u00e4meenlinna, Finland the Technical University of Denmark in Lyngby, Denmark, in Skanderborg Bunkerne at Skanderborg, Denmark, and at the Australian War Memorial and in the foyer of the Australian Signals Directorate, both in Canberra, Australia. The Jozef Pilsudski Institute in London exhibited a rare Polish Enigma double assembled in France in 1940. In 2020, thanks to the support of the Ministry of Culture and National Heritage, it became the property of the Polish History Museum.\n\nIn the United States, Enigma machines can be seen at the Computer History Museum in Mountain View, California, and at the National Security Agency's National Cryptologic Museum in Fort Meade, Maryland, where visitors can try their hand at enciphering and deciphering messages. Two machines that were acquired after the capture of U-505 during World War II are on display alongside the submarine at the Museum of Science and Industry in Chicago, Illinois. A three-rotor Enigma is on display at Discovery Park of America in Union City, Tennessee. A four-rotor device is on display in the ANZUS Corridor of the Pentagon on the second floor, A ring, between corridors 8 and 9. This machine is on loan from Australia. The United States Air Force Academy in Colorado Springs has a machine on display in the Computer Science Department. There is also a machine located at The National WWII Museum in New Orleans. The International Museum of World War II near Boston has seven Enigma machines on display, including a U-Boat four-rotor model, one of three surviving examples of an Enigma machine with a printer, one of fewer than ten surviving ten-rotor code machines, an example blown up by a retreating German Army unit, and two three-rotor Enigmas that visitors can operate to encode and decode messages. Computer Museum of America in Roswell, Georgia has a three-rotor model with two additional rotors. The machine is fully restored and CMoA has the original paperwork for the purchase on 7 March 1936 by the German Army. The National Museum of Computing also contains surviving Enigma machines in Bletchley, England.\n\nIn Canada, a Swiss Army issue Enigma-K, is in Calgary, Alberta. It is on permanent display at the Naval Museum of Alberta inside the Military Museums of Calgary. A four-rotor Enigma machine is on display at the Military Communications and Electronics Museum at Canadian Forces Base (CFB) Kingston in Kingston, Ontario.\nOccasionally, Enigma machines are sold at auction; prices have in recent years ranged from US$40,000 to US$547,500 in 2017. Replicas are available in various forms, including an exact reconstructed copy of the Naval M4 model, an Enigma implemented in electronics (Enigma-E), various simulators and paper-and-scissors analogues.\nA rare Abwehr Enigma machine, designated G312, was stolen from the Bletchley Park museum on 1 April 2000. In September, a man identifying himself as \"The Master\" sent a note demanding \u00a325,000 and threatening to destroy the machine if the ransom was not paid. In early October 2000, Bletchley Park officials announced that they would pay the ransom, but the stated deadline passed with no word from the blackmailer. Shortly afterward, the machine was sent anonymously to BBC journalist Jeremy Paxman, missing three rotors.\nIn November 2000, an antiques dealer named Dennis Yates was arrested after telephoning The Sunday Times to arrange the return of the missing parts. The Enigma machine was returned to Bletchley Park after the incident. In October 2001, Yates was sentenced to ten months in prison and served three months.In October 2008, the Spanish daily newspaper El Pa\u00eds reported that 28 Enigma machines had been discovered by chance in an attic of Army headquarters in Madrid. These four-rotor commercial machines had helped Franco's Nationalists win the Spanish Civil War, because, though the British cryptologist Alfred Dilwyn Knox in 1937 broke the cipher generated by Franco's Enigma machines, this was not disclosed to the Republicans, who failed to break the cipher. The Nationalist government continued using its 50 Enigmas into the 1950s. Some machines have gone on display in Spanish military museums, including one at the National Museum of Science and Technology (MUNCYT) in La Coru\u00f1a and one at the Spanish Army Museum. Two have been given to Britain's GCHQ.The Bulgarian military used Enigma machines with a Cyrillic keyboard; one is on display in the National Museum of Military History in Sofia.On 3 December 2020, German divers working on behalf of the World Wide Fund for Nature discovered a destroyed Enigma machine in Flensburg Firth (part of the Baltic Sea) which is believed to be from a scuttled U-Boat. This Enigma machine will be restored by and be the property of the Archaeology Museum of Schleswig Holstein.An M4 Enigma was salvaged in the 1980s from the German minesweeper R15, which was sunk off the Istrian coast in 1945. The machine was put on display in the Pivka Park of Military History in Slovenia on 13 April 2023.\n\n== Derivatives ==\nThe Enigma was influential in the field of cipher machine design, spinning off other rotor machines. Once the British discovered Enigma's principle of operation, they created the Typex rotor cipher, which the Germans believed to be unsolvable. Typex was originally derived from the Enigma patents; Typex even includes features from the patent descriptions that were omitted from the actual Enigma machine. The British paid no royalties for the use of the patents. In the United States, cryptologist William Friedman designed the M-325 machine, starting in 1936, that is logically similar.Machines like the SIGABA, NEMA, Typex, and so forth, are not considered to be Enigma derivatives as their internal ciphering functions are not mathematically identical to the Enigma transform.\nA unique rotor machine called Cryptograph was constructed in 2002 by Netherlands-based Tatjana van Vark. This device makes use of 40-point rotors, allowing letters, numbers and some punctuation to be used; each rotor contains 509 parts.\n\n== Simulators ==\n\n== Explanatory notes ==\n\nHow were messages transmitted using the Enigma machine?",
    "context": "",
    "output": "A: Messages transmitted using the Enigma machine were recorded by a second operator and then transmitted, usually by radio in Morse code, to an operator of another Enigma machine.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How were messages transmitted using the Enigma machine?",
      "answer": "Messages transmitted using the Enigma machine were recorded by a second operator and then transmitted, usually by radio in Morse code, to an operator of another Enigma machine.",
      "context": "Enigma machine\n\n==Introduction==\nThe Enigma machine is a cipher device developed and used in the early- to mid-20th century to protect commercial, diplomatic, and military communication. It was employed extensively by Nazi Germany during World War II, in all branches of the German military. The Enigma machine was considered so secure that it was used to encipher the most top-secret messages.The Enigma has an electromechanical rotor mechanism that scrambles the 26 letters of the alphabet. In typical use, one person enters text on the Enigma's keyboard and another person writes down which of the 26 lights above the keyboard illuminated at each key press. If plain text is entered, the illuminated letters are the ciphertext. Entering ciphertext transforms it back into readable plaintext. The rotor mechanism changes the electrical connections between the keys and the lights with each keypress. \nThe security of the system depends on machine settings that were generally changed daily, based on secret key lists distributed in advance, and on other settings that were changed for each message. The receiving station would have to know and use the exact settings employed by the transmitting station to successfully decrypt a message.\nWhile Nazi Germany introduced a series of improvements to the Enigma over the years, and these hampered decryption efforts, they did not prevent Poland from cracking the machine as early as December 1932 and reading messages prior to and into the war. Poland's sharing of her achievements enabled the western Allies to exploit Enigma-enciphered messages as a major source of intelligence. Many commentators say the flow of Ultra communications intelligence from the decrypting of Enigma, Lorenz, and other ciphers shortened the war substantially and may even have altered its outcome.\n\n== Design ==\n\nLike other rotor machines, the Enigma machine is a combination of mechanical and electrical subsystems. The mechanical subsystem consists of a keyboard; a set of rotating disks called rotors arranged adjacently along a spindle; one of various stepping components to turn at least one rotor with each key press, and a series of lamps, one for each letter. These design features are the reason that the Enigma machine was originally referred to as the rotor-based cipher machine during its intellectual inception in 1915.\n\n\n*** Electrical pathway ***\n\nAn electrical pathway is a route for current to travel. By manipulating this phenomenon the Enigma machine was able to scramble messages. The mechanical parts act by forming a varying electrical circuit. When a key is pressed, one or more rotors rotate on the spindle. On the sides of the rotors are a series of electrical contacts that, after rotation, line up with contacts on the other rotors or fixed wiring on either end of the spindle. When the rotors are properly aligned, each key on the keyboard is connected to a unique electrical pathway through the series of contacts and internal wiring. Current, typically from a battery, flows through the pressed key, into the newly configured set of circuits and back out again, ultimately lighting one display lamp, which shows the output letter. For example, when encrypting a message starting ANX..., the operator would first press the A key, and the Z lamp might light, so Z would be the first letter of the ciphertext. The operator would next press N, and then X in the same fashion, and so on.\n\nCurrent flows from the battery (1) through a depressed bi-directional keyboard switch (2) to the plugboard (3). Next, it passes through the (unused in this instance, so shown closed) plug \"A\" (3) via the entry wheel (4), through the wiring of the three (Wehrmacht Enigma) or four (Kriegsmarine M4 and Abwehr variants) installed rotors (5), and enters the reflector (6). The reflector returns the current, via an entirely different path, back through the rotors (5) and entry wheel (4), proceeding through plug \"S\" (7) connected with a cable (8) to plug \"D\", and another bi-directional switch (9) to light the appropriate lamp.The repeated changes of electrical path through an Enigma scrambler implement a polyalphabetic substitution cipher that provides Enigma's security. The diagram on the right shows how the electrical pathway changes with each key depression, which causes rotation of at least the right-hand rotor. Current passes into the set of rotors, into and back out of the reflector, and out through the rotors again. The greyed-out lines are other possible paths within each rotor; these are hard-wired from one side of each rotor to the other. The letter A encrypts differently with consecutive key presses, first to G, and then to C. This is because the right-hand rotor steps (rotates one position) on each key press, sending the signal on a completely different route. Eventually other rotors step with a key press.\n\n\n*** Rotors ***\n\nThe rotors (alternatively wheels or drums, Walzen in German) form the heart of an Enigma machine. Each rotor is a disc approximately 10 cm (3.9 in) in diameter made from Ebonite or Bakelite with 26 brass, spring-loaded, electrical contact pins arranged in a circle on one face, with the other face housing 26 corresponding electrical contacts in the form of circular plates. The pins and contacts represent the alphabet \u2014 typically the 26 letters A\u2013Z, as will be assumed for the rest of this description. When the rotors are mounted side by side on the spindle, the pins of one rotor rest against the plate contacts of the neighbouring rotor, forming an electrical connection. Inside the body of the rotor, 26 wires connect each pin on one side to a contact on the other in a complex pattern. Most of the rotors are identified by Roman numerals, and each issued copy of rotor I, for instance, is wired identically to all others. The same is true for the special thin beta and gamma rotors used in the M4 naval variant.\n\nBy itself, a rotor performs only a very simple type of encryption, a simple substitution cipher. For example, the pin corresponding to the letter E might be wired to the contact for letter T on the opposite face, and so on. Enigma's security comes from using several rotors in series (usually three or four) and the regular stepping movement of the rotors, thus implementing a polyalphabetic substitution cipher.\nEach rotor can be set to one of 26 possible starting positions when placed in an Enigma machine. After insertion, a rotor can be turned to the correct position by hand, using the grooved finger-wheel which protrudes from the internal Enigma cover when closed. In order for the operator to know the rotor's position, each has an alphabet tyre (or letter ring) attached to the outside of the rotor disc, with 26 characters (typically letters); one of these is visible through the window for that slot in the cover, thus indicating the rotational position of the rotor. In early models, the alphabet ring was fixed to the rotor disc. A later improvement was the ability to adjust the alphabet ring relative to the rotor disc. The position of the ring was known as the Ringstellung (\"ring setting\"), and that setting was a part of the initial setup needed prior to an operating session. In modern terms it was a part of the initialization vector.\n\nEach rotor contains one or more notches that control rotor stepping. In the military variants, the notches are located on the alphabet ring.\nThe Army and Air Force Enigmas were used with several rotors, initially three. On 15 December 1938, this changed to five, from which three were chosen for a given session. Rotors were marked with Roman numerals to distinguish them: I, II, III, IV and V, all with single notches located at different points on the alphabet ring. This variation was probably intended as a security measure, but ultimately allowed the Polish Clock Method and British Banburismus attacks.\nThe Naval version of the Wehrmacht Enigma had always been issued with more rotors than the other services: At first six, then seven, and finally eight. The additional rotors were marked VI, VII and VIII, all with different wiring, and had two notches, resulting in more frequent turnover. The four-rotor Naval Enigma (M4) machine accommodated an extra rotor in the same space as the three-rotor version. This was accomplished by replacing the original reflector with a thinner one and by adding a thin fourth rotor. That fourth rotor was one of two types, Beta or Gamma, and never stepped, but could be manually set to any of 26 positions. One of the 26 made the machine perform identically to the three-rotor machine.\n\n\n*** Stepping ***\nTo avoid merely implementing a simple (solvable) substitution cipher, every key press caused one or more rotors to step by one twenty-sixth of a full rotation, before the electrical connections were made. This changed the substitution alphabet used for encryption, ensuring that the cryptographic substitution was different at each new rotor position, producing a more formidable polyalphabetic substitution cipher. The stepping mechanism varied slightly from model to model. The right-hand rotor stepped once with each keystroke, and other rotors stepped less frequently.\n\n\n*** Turnover ***\n\nThe advancement of a rotor other than the left-hand one was called a turnover by the British. This was achieved by a ratchet and pawl mechanism. Each rotor had a ratchet with 26 teeth and every time a key was pressed, the set of spring-loaded pawls moved forward in unison, trying to engage with a ratchet. The alphabet ring of the rotor to the right normally prevented this. As this ring rotated with its rotor, a notch machined into it would eventually align itself with the pawl, allowing it to engage with the ratchet, and advance the rotor on its left. The right-hand pawl, having no rotor and ring to its right, stepped its rotor with every key depression. For a single-notch rotor in the right-hand position, the middle rotor stepped once for every 26 steps of the right-hand rotor. Similarly for rotors two and three. For a two-notch rotor, the rotor to its left would turn over twice for each rotation.\nThe first five rotors to be introduced (I\u2013V) contained one notch each, while the additional naval rotors VI, VII and VIII each had two notches. The position of the notch on each rotor was determined by the letter ring which could be adjusted in relation to the core containing the interconnections. The points on the rings at which they caused the next wheel to move were as follows.\nThe design also included a feature known as double-stepping. This occurred when each pawl aligned with both the ratchet of its rotor and the rotating notched ring of the neighbouring rotor. If a pawl engaged with a ratchet through alignment with a notch, as it moved forward it pushed against both the ratchet and the notch, advancing both rotors. In a three-rotor machine, double-stepping affected rotor two only. If, in moving forward, the ratchet of rotor three was engaged, rotor two would move again on the subsequent keystroke, resulting in two consecutive steps. Rotor two also pushes rotor one forward after 26 steps, but since rotor one moves forward with every keystroke anyway, there is no double-stepping. This double-stepping caused the rotors to deviate from odometer-style regular motion.\nWith three wheels and only single notches in the first and second wheels, the machine had a period of 26\u00d725\u00d726\n\n== Operation ==\n\n\n*** Basic operation ***\n\nA German Enigma operator would be given a plaintext message to encrypt. After setting up his machine, he would type the message on the Enigma keyboard. For each letter pressed, one lamp lit indicating a different letter according to a pseudo-random substitution determined by the electrical pathways inside the machine. The letter indicated by the lamp would be recorded, typically by a second operator, as the cyphertext letter. The action of pressing a key also moved one or more rotors so that the next key press used a different electrical pathway, and thus a different substitution would occur even if the same plaintext letter were entered again. For each key press there was rotation of at least the right hand rotor and less often the other two, resulting in a different substitution alphabet being used for every letter in the message. This process continued until the message was completed. The cyphertext recorded by the second operator would then be transmitted, usually by radio in Morse code, to an operator of another Enigma machine. This operator would type in the cyphertext and \u2014 as long as all the settings of the deciphering machine were identical to those of the enciphering machine \u2014 for every key press the reverse substitution would occur and the plaintext message would emerge.\n\n\n*** Details ***\n\nIn use, the Enigma required a list of daily key settings and auxiliary documents. In German military practice, communications were divided into separate networks, each using different settings. These communication nets were termed keys at Bletchley Park, and were assigned code names, such as Red, Chaffinch, and Shark. Each unit operating in a network was given the same settings list for its Enigma, valid for a period of time. The procedures for German Naval Enigma were more elaborate and more secure than those in other services and employed auxiliary codebooks. Navy codebooks were printed in red, water-soluble ink on pink paper so that they could easily be destroyed if they were endangered or if the vessel was sunk.\nAn Enigma machine's setting (its cryptographic key in modern terms; Schl\u00fcssel in German) specified each operator-adjustable aspect of the machine:\n\nWheel order (Walzenlage) \u2013 the choice of rotors and the order in which they are fitted.\nRing settings (Ringstellung) \u2013 the position of each alphabet ring relative to its rotor wiring.\nPlug connections (Steckerverbindungen) \u2013 the pairs of letters in the plugboard that are connected together.\nIn very late versions, the wiring of the reconfigurable reflector.\nStarting position of the rotors (Grundstellung) \u2013 chosen by the operator, should be different for each message.For a message to be correctly encrypted and decrypted, both sender and receiver had to configure their Enigma in the same way; rotor selection and order, ring positions, plugboard connections and starting rotor positions must be identical. Except for the starting positions, these settings were established beforehand, distributed in key lists and changed daily. For example, the settings for the 18th day of the month in the German Luftwaffe Enigma key list number 649 (see image) were as follows:\n\nWheel order: IV, II, V\nRing settings: 15, 23, 26\nPlugboard connections: EJ OY IV AQ KW FX MT PS LU BD\nReconfigurable reflector wiring: IU AS DV GL FT OX EZ CH MR KN BQ PW\nIndicator groups: lsa zbw vcj rxnEnigma was designed to be secure even if the rotor wiring was known to an opponent, although in practice considerable effort protected the wiring configuration. If the wiring is secret, the total number of possible configurations has been calculated to be around 3\u00d710114 (approximately 380 bits); with known wiring and other operational constraints, this is reduced to around 1023 (76 bits). Because of the large number of possibilities, users of Enigma were confident of its security; it was not then feasible for an adversary to even begin to try a brute-force attack.\n\n\n*** Indicator ***\n\nMost of the key was kept constant for a set time period, typically a day. A different initial rotor position was used for each message, a concept similar to an initialisation vector in modern cryptography. The reason is that encrypting many messages with identical or near-identical settings (termed in cryptanalysis as being in depth), would enable an attack using a statistical procedure such as Friedman's Index of coincidence. The starting position for the rotors was transmitted just before the ciphertext, usually after having been enciphered. The exact method used was termed the indicator procedure. Design weakness and operator sloppiness in these indicator procedures were two of the main weaknesses that made cracking Enigma possible.\n\nOne of the earliest indicator procedures for the Enigma was cryptographically flawed and allowed Polish cryptanalysts to make the initial breaks into the plugboard Enigma. The procedure had the operator set his machine in accordance with the secret settings that all operators on the net shared. The settings included an initial position for the rotors (the Grundstellung), say, AOH. The operator turned his rotors until AOH was visible through the rotor windows. At that point, the operator chose his own arbitrary starting position for the message he would send. An operator might select EIN, and that became the message setting for that encryption session. The operator then typed EIN into the machine twice, this producing the encrypted indicator, for example XHTLOA. This was then transmitted, at which point the operator would turn the rotors to his message settings, EIN in this example, and then type the plaintext of the message.\nAt the receiving end, the operator set the machine to the initial settings (AOH) and typed in the first six letters of the message (XHTLOA). In this example, EINEIN emerged on the lamps, so the operator would learn the message setting that the sender used to encrypt this message. The receiving operator would set his rotors to EIN, type in the rest of the ciphertext, and get the deciphered message.\nThis indicator scheme had two weaknesses. First, the use of a global initial position (Grundstellung) meant all message keys used the same polyalphabetic substitution. In later indicator procedures, the operator selected his initial position for encrypting the indicator and sent that initial position in the clear. The second problem was the repetition of the indicator, which was a serious security flaw. The message setting was encoded twice, resulting in a relation between first and fourth, second and fifth, and third and sixth character. These security flaws enabled the Polish Cipher Bureau to break into the pre-war Enigma system as early as 1932. The early indicator procedure was subsequently described by German cryptanalysts as the \"faulty indicator technique\".During World War II, codebooks were only used each day to set up the rotors, their ring settings and the plugboard. For each message, the operator selected a random start position, let's say WZA, and a random message key, perhaps SXT. He moved the rotors to the WZA start position and encoded the message key SXT. Assume the result was UHL. He then set up the message key, SXT, as the start position and encrypted the message. Next, he transmitted the start position, WZA, the encoded message key, UHL, and then the ciphertext. The receiver set up the start position according to the first trigram, WZA, and decoded the second trigram, UHL, to obtain the SXT message setting. Next, he used this SXT message setting as the start position to decrypt the message. This way, each ground setting was different and the new procedure avoided the security flaw of double encoded message settings.This procedure was used by Wehrmacht and Luftwaffe only. The Kriegsmarine procedures on sending messages with the Enigma were far more complex and elaborate. Prior to encryption the message was encoded using the Kurzsignalheft code book. The Kurzsignalheft contained tables to convert sentences into four-letter groups. A great many choices were included, for example, logistic matters such as refuelling and rendezvous with supply ships, positions and grid lists, harbour names, countries, weapons, weather conditions, enemy positions and ships, date and time tables. Another codebook contained the Kenngruppen and Spruchschl\u00fcssel: the key identification and message key.\n\n\n*** Additional details ***\nThe Army Enigma machine used only the 26 alphabet characters. Punctuation was replaced with rare character combinations. A space was omitted or replaced with an X. The X was generally used as full-stop.\nSome punctuation marks were different in other parts of the armed forces. The Wehrmacht replaced a comma with ZZ and the question mark with FRAGE or FRAQ.\nThe Kriegsmarine replaced the comma with Y and the question mark with UD. The combination CH, as in \"Acht\" (eight) or \"Richtung\" (direction), was replaced with Q (AQT, RIQTUNG). Two, three and four zeros were replaced with CENTA, MILLE and MYRIA.\nThe Wehrmacht and the Luftwaffe transmitted messages in groups of five characters and counted the letters.\nThe Kriegsmarine used four-character groups and counted those groups. \n\nFrequently used names or words were varied as much as possible. Words like Minensuchboot (minesweeper) could be written as MINENSUCHBOOT, MINBOOT or MMMBOOT. To make cryptanalysis harder, messages were limited to 250 characters. Longer messages were divided into several parts, each using a different message key.\n\n\n*** Example enciphering process ***\nThe character substitutions by the Enigma machine as a whole can be expressed as a string of letters with each position occupied by the character that will replace the character at the corresponding position in the alphabet. For example, a given machine configuration that enciphered A to L, B to U, C to S, ..., and Z to J could be represented compactly as\n\nLUSHQOXDMZNAIKFREPCYBWVGTJ\n\nand the enciphering of a particular character by that configuration could be represented by highlighting the enciphered character as in\n\nD > LUS(H)QOXDMZNAIKFREPCYBWVGTJ\n\nSince the operation of an Enigma machine enciphering a message is a series of such configurations, each associated with a single character being enciphered, a sequence of such representations can be used to represent the operation of the machine as it enciphers a message. For example, the process of enciphering the first sentence of the main body of the famous \"D\u00f6nitz message\" to\n\nRBBF PMHP HGCZ XTDY GAHG UFXG EWKB LKGJ\n\ncan be represented as\n\n0001 F > KGWNT(R)BLQPAHYDVJIFXEZOCSMU CDTK 25 15 16 26\n0002 O > UORYTQSLWXZHNM(B)VFCGEAPIJDK CDTL 25 15 16 01\n0003 L > HLNRSKJAMGF(B)ICUQPDEYOZXWTV CDTM 25 15 16 02\n0004 G > KPTXIG(F)MESAUHYQBOVJCLRZDNW CDUN 25 15 17 03\n0005 E > XDYB(P)WOSMUZRIQGENLHVJTFACK CDUO 25 15 17 04\n0006 N > DLIAJUOVCEXBN(M)GQPWZYFHRKTS CDUP 25 15 17 05\n0007 D > LUS(H)QOXDMZNAIKFREPCYBWVGTJ CDUQ 25 15 17 06\n0008 E > JKGO(P)TCIHABRNMDEYLZFXWVUQS CDUR 25 15 17 07\n0009 S > GCBUZRASYXVMLPQNOF(H)WDKTJIE CDUS 25 15 17 08\n0010 I > XPJUOWIY(G)CVRTQEBNLZMDKFAHS CDUT 25 15 17 09\n0011 S > DISAUYOMBPNTHKGJRQ(C)LEZXWFV CDUU 25 15 17 10\n0012 T > FJLVQAKXNBGCPIRMEOY(Z)WDUHST CDUV 25 15 17 11\n0013 S > KTJUQONPZCAMLGFHEW(X)BDYRSVI CDUW 25 15 17 12\n0014 O > ZQXUVGFNWRLKPH(T)MBJYODEICSA CDUX 25 15 17 13\n0015 F > XJWFR(D)ZSQBLKTVPOIEHMYNCAUG CDUY 25 15 17 14\n0016 O > FSKTJARXPECNUL(Y)IZGBDMWVHOQ CDUZ 25 15 17 15\n0017 R > CEAKBMRYUVDNFLTXW(G)ZOIJQPHS CDVA 25 15 18 16\n0018 T > TLJRVQHGUCXBZYSWFDO(A)IEPKNM CDVB 25 15 18 17\n0019 B > Y(H)LPGTEBKWICSVUDRQMFONJZAX CDVC 25 15 18 18\n0020 E > KRUL(G)JEWNFADVIPOYBXZCMHSQT CDVD 25 15 18 19\n0021 K > RCBPQMVZXY(U)OFSLDEANWKGTIJH CDVE 25 15 18 20\n0022 A > (F)CBJQAWTVDYNXLUSEZPHOIGMKR CDVF 25 15 18 21\n0023 N > VFTQSBPORUZWY(X)HGDIECJALNMK CDVG 25 15 18 22\n0024 N > JSRHFENDUAZYQ(G)XTMCBPIWVOLK CDVH 25 15 18 23\n0025 T > RCBUTXVZJINQPKWMLAY(E)DGOFSH CDVI 25 15 18 24\n0026 Z > URFXNCMYLVPIGESKTBOQAJZDH(W) CDVJ 25 15 18 25\n0027 U > JIOZFEWMBAUSHPCNRQLV(K)TGYXD CDVK 25 15 18 26\n0028 G > ZGVRKO(B)XLNEIWJFUSDQYPCMHTA CDVL 25 15 18 01\n0029 E > RMJV(L)YQZKCIEBONUGAWXPDSTFH CDVM 25 15 18 02\n0030 B > G(K)QRFEANZPBMLHVJCDUXSOYTWI CDWN 25 15 19 03\n0031 E > YMZT(G)VEKQOHPBSJLIUNDRFXWAC CDWO 25 15 19 04\n0032 N > PDSBTIUQFNOVW(J)KAHZCEGLMYXR CDWP 25 15 19 05\n\nwhere the letters following each mapping are the letters that appear at the windows at that stage (the only state changes visible to the operator) and the numbers show the underlying physical position of each rotor.\nThe character mappings for a given configuration of the machine are in turn the result of a series of such mappings applied by each pass through a component of the machine: the enciphering of a character resulting from the application of a given component's mapping serves as the input to the mapping of the subsequent component.  For example, the 4th step in the enciphering above can be expanded to show each of these stages using the same representation of mappings and highlighting for the enciphered character:\n\n G > ABCDEF(G)HIJKLMNOPQRSTUVWXYZ\n   P EFMQAB(G)UINKXCJORDPZTHWVLYS         AE.BF.CM.DQ.HU.JN.LX.PR.SZ.VW\n   1 OFRJVM(A)ZHQNBXPYKCULGSWETDI  N  03  VIII\n   2 (N)UKCHVSMDGTZQFYEWPIALOXRJB  U  17  VI\n   3 XJMIYVCARQOWH(L)NDSUFKGBEPZT  D  15  V\n   4 QUNGALXEPKZ(Y)RDSOFTVCMBIHWJ  C  25  \u03b2\n   R RDOBJNTKVEHMLFCWZAXGYIPS(U)Q         c\n   4 EVTNHQDXWZJFUCPIAMOR(B)SYGLK         \u03b2\n   3 H(V)GPWSUMDBTNCOKXJIQZRFLAEY         V\n   2 TZDIPNJESYCUHAVRMXGKB(F)QWOL         VI\n   1 GLQYW(B)TIZDPSFKANJCUXREVMOH         VIII\n   P E(F)MQABGUINKXCJORDPZTHWVLYS         AE.BF.CM.DQ.HU.JN.LX.PR.SZ.VW\n F < KPTXIG(F)MESAUHYQBOVJCLRZDNW\n\nHere the enciphering begins trivially with the first \"mapping\" representing the keyboard (which has no effect), followed by the plugboard, configured as AE.BF.CM.DQ.HU.JN.LX.PR.SZ.VW which has no effect on 'G', followed by the VIII rotor in the 03 position, which maps G to A, then the VI rotor in the 17 position, which maps A to N, ..., and finally the plugboard again, which maps B to F, producing the overall mapping indicated at the final step: G to F.\nNote that this model has 4 rotors (lines 1 through 4) and that the reflector (line R) also permutes (garbles) letters.\n\n== Models ==\nThe Enigma family included multiple designs. The earliest were commercial models dating from the early 1920s. Starting in the mid-1920s, the German military began to use Enigma, making a number of security-related changes. Various nations either adopted or adapted the design for their own cipher machines.\n\nAn estimated 40,000 Enigma machines were constructed. After the end of World War II, the Allies sold captured Enigma machines, still widely considered secure, to developing countries.\n\n\n*** Commercial Enigma ***\n\nOn 23 February 1918, Arthur Scherbius applied for a patent for a ciphering machine that used rotors. Scherbius and E. Richard Ritter founded the firm of Scherbius & Ritter. They approached the German Navy and Foreign Office with their design, but neither agency was interested. Scherbius & Ritter then assigned the patent rights to Gewerkschaft Securitas, who founded the Chiffriermaschinen Aktien-Gesellschaft (Cipher Machines Stock Corporation) on 9 July 1923; Scherbius and Ritter were on the board of directors.\n\n\n**** Enigma Handelsmaschine (1923) ****\nChiffriermaschinen AG began advertising a rotor machine, Enigma Handelsmaschine, which was exhibited at the Congress of the International Postal Union in 1924. The machine was heavy and bulky, incorporating a typewriter. It measured 65\u00d745\u00d738 cm and weighed about 50 kilograms (110 lb).\n\n\n**** Schreibende Enigma (1924) ****\nThis was also a model with a type writer. There where a number of problems associated with the printer and the construction was not stable until 1926. Both early versions of Enigma lacked the reflector and had to be switched between chiffering and dechiffering.\n\n\n**** Gl\u00fchlampenmaschine, Enigma A (1924) ****\nThe reflector, suggested by Scherbius' colleague Willi Korn, was introduced with the glow lamp version.\nThe machine was also known as the military Enigma. It had two rotors and a manually rotatable reflector. The typewriter was omitted and glow lamps were used for output. The operation was somewhat different from later models. Before the next key pressure, the operator had to press a button to advance the right rotor one step.\n\n\n**** Enigma B (1924) ****\n\nEnigma model B was introduced late in 1924, and was of a similar construction. While bearing the Enigma name, both models A and B were quite unlike later versions: They differed in physical size and shape, but also cryptographically, in that they lacked the reflector. This model of Enigma machine was referred to as the Glowlamp Enigma or Gl\u00fchlampenmaschine since it produced its output on a lamp panel rather than paper. This method of output was much more reliable and cost effective. Hence this machine was 1/8th the price of its predecessor.\n\n\n**** Enigma C (1926) ****\nModel C was the third model of the so-called \u2033glowlamp Enigmas\u2033 (after A and B) and it again lacked a typewriter.\n\n\n**** Enigma D (1927) ****\nThe Enigma C quickly gave way to Enigma D (1927). This version was widely used, with shipments to Sweden, the Netherlands, United Kingdom, Japan, Italy, Spain, United States and Poland. In 1927 Hugh Foss at the British Government Code and Cypher School was able to show that commercial Enigma machines could be broken, provided suitable cribs were available. Soon, the Enigma D would pioneer the use of a standard keyboard layout to be used in German computing.  This \"QWERTZ\" layout is very similar to the American QWERTY keyboard format used in many languages. \n\n\n***** \"Navy Cipher D\"*****\nOther countries used Enigma machines. The Italian Navy adopted the commercial Enigma as \"Navy Cipher D\". The Spanish also used commercial Enigma machines during their Civil War. British codebreakers succeeded in breaking these machines, which lacked a plugboard. Enigma machines were also used by diplomatic services.\n\n\n**** Enigma H (1929) ****\n\nThere was also a large, eight-rotor printing model, the Enigma H, called Enigma II by the Reichswehr. In 1933 the Polish Cipher Bureau detected that it was in use for high-level military communication, but it was soon withdrawn, as it was unreliable and jammed frequently.\n\n\n**** Enigma K ****\nThe Swiss used a version of Enigma called Model K or Swiss K for military and diplomatic use, which was very similar to commercial Enigma D. The machine's code was cracked by Poland, France, the United Kingdom and the United States; the latter code-named it INDIGO. An Enigma T model, code-named Tirpitz, was used by Japan.\n\n\n*** Military Enigma ***\nThe various services of the Wehrmacht used various Enigma versions, and replaced them frequently, sometimes with ones adapted from other services. Enigma seldom carried high-level strategic messages, which when not urgent went by courier, and when urgent went by other cryptographic systems including the Geheimschreiber.\n\n\n**** Funkschl\u00fcssel C ****\nThe Reichsmarine was the first military branch to adopt Enigma. This version, named Funkschl\u00fcssel C (\"Radio cipher C\"), had been put into production by 1925 and was introduced into service in 1926.The keyboard and lampboard contained 29 letters \u2014 A-Z, \u00c4, \u00d6 and \u00dc \u2014 that were arranged alphabetically, as opposed to the QWERTZUI ordering. The rotors had 28 contacts, with the letter X wired to bypass the rotors unencrypted. Three rotors were chosen from a set of five and the reflector could be inserted in one of four different positions, denoted \u03b1, \u03b2, \u03b3 and \u03b4. The machine was revised slightly in July 1933.\n\n\n**** Enigma G (1928\u20131930) ****\nBy 15 July 1928, the German Army (Reichswehr) had introduced their own exclusive version of the Enigma machine, the Enigma G.\nThe Abwehr used the Enigma G (the Abwehr Enigma). This Enigma variant was a four-wheel unsteckered machine with multiple notches on the rotors. This model was equipped with a counter that incremented upon each key press, and so is also known as the \"counter machine\" or the Z\u00e4hlwerk Enigma.\n\n\n**** Wehrmacht Enigma I (1930\u20131938) ****\nEnigma machine G was modified to the Enigma I by June 1930. Enigma I is also known as the Wehrmacht, or \"Services\" Enigma, and was used extensively by German military services and other government organisations (such as the railways) before and during World War II.\n\nThe major difference between Enigma I (German Army version from 1930), and commercial Enigma models was the addition of a plugboard to swap pairs of letters, greatly increasing cryptographic strength.\nOther differences included the use of a fixed reflector and the relocation of the stepping notches from the rotor body to the movable letter rings. The machine measured 28 cm \u00d7 34 cm \u00d7 15 cm (11.0 in \u00d7 13.4 in \u00d7 5.9 in) and weighed around 12 kg (26 lb).In August 1935, the Air Force introduced the Wehrmacht Enigma for their communications.\n\n\n**** M3 (1934) ****\nBy 1930, the Reichswehr had suggested that the Navy adopt their machine, citing the benefits of increased security (with the plugboard) and easier interservice communications. The Reichsmarine eventually agreed and in 1934 brought into service the Navy version of the Army Enigma, designated Funkschl\u00fcssel ' or M3. While the Army used only three rotors at that time, the Navy specified a choice of three from a possible five.\n\n\n**** Two extra rotors (1938) ****\nIn December 1938, the Army issued two extra rotors so that the three rotors were chosen from a set of five. In 1938, the Navy added two more rotors, and then another in 1939 to allow a choice of three rotors from a set of eight.\n\n\n**** M4 (1942) ****\n\nA four-rotor Enigma was introduced by the Navy for U-boat traffic on 1 February 1942, called M4 (the network was known as Triton, or Shark to the Allies). The extra rotor was fitted in the same space by splitting the reflector into a combination of a thin reflector and a thin fourth rotor.\n\n== Surviving machines ==\n\nThe effort to break the Enigma was not disclosed until the 1970s. Since then, interest in the Enigma machine has grown. Enigmas are on public display in museums around the world, and several are in the hands of private collectors and computer history enthusiasts.The Deutsches Museum in Munich has both the three- and four-rotor German military variants, as well as several civilian versions. Enigma machines are exhibited at the National Codes Centre in Bletchley Park, the Government Communications Headquarters, the Science Museum in London, Discovery Park of America in Tennessee, the Polish Army Museum in Warsaw, the Swedish Army Museum (Arm\u00e9museum) in Stockholm, the Military Museum of A Coru\u00f1a in Spain, the Nordland Red Cross War Memorial Museum in Narvik, Norway, The Artillery, Engineers and Signals Museum in H\u00e4meenlinna, Finland the Technical University of Denmark in Lyngby, Denmark, in Skanderborg Bunkerne at Skanderborg, Denmark, and at the Australian War Memorial and in the foyer of the Australian Signals Directorate, both in Canberra, Australia. The Jozef Pilsudski Institute in London exhibited a rare Polish Enigma double assembled in France in 1940. In 2020, thanks to the support of the Ministry of Culture and National Heritage, it became the property of the Polish History Museum.\n\nIn the United States, Enigma machines can be seen at the Computer History Museum in Mountain View, California, and at the National Security Agency's National Cryptologic Museum in Fort Meade, Maryland, where visitors can try their hand at enciphering and deciphering messages. Two machines that were acquired after the capture of U-505 during World War II are on display alongside the submarine at the Museum of Science and Industry in Chicago, Illinois. A three-rotor Enigma is on display at Discovery Park of America in Union City, Tennessee. A four-rotor device is on display in the ANZUS Corridor of the Pentagon on the second floor, A ring, between corridors 8 and 9. This machine is on loan from Australia. The United States Air Force Academy in Colorado Springs has a machine on display in the Computer Science Department. There is also a machine located at The National WWII Museum in New Orleans. The International Museum of World War II near Boston has seven Enigma machines on display, including a U-Boat four-rotor model, one of three surviving examples of an Enigma machine with a printer, one of fewer than ten surviving ten-rotor code machines, an example blown up by a retreating German Army unit, and two three-rotor Enigmas that visitors can operate to encode and decode messages. Computer Museum of America in Roswell, Georgia has a three-rotor model with two additional rotors. The machine is fully restored and CMoA has the original paperwork for the purchase on 7 March 1936 by the German Army. The National Museum of Computing also contains surviving Enigma machines in Bletchley, England.\n\nIn Canada, a Swiss Army issue Enigma-K, is in Calgary, Alberta. It is on permanent display at the Naval Museum of Alberta inside the Military Museums of Calgary. A four-rotor Enigma machine is on display at the Military Communications and Electronics Museum at Canadian Forces Base (CFB) Kingston in Kingston, Ontario.\nOccasionally, Enigma machines are sold at auction; prices have in recent years ranged from US$40,000 to US$547,500 in 2017. Replicas are available in various forms, including an exact reconstructed copy of the Naval M4 model, an Enigma implemented in electronics (Enigma-E), various simulators and paper-and-scissors analogues.\nA rare Abwehr Enigma machine, designated G312, was stolen from the Bletchley Park museum on 1 April 2000. In September, a man identifying himself as \"The Master\" sent a note demanding \u00a325,000 and threatening to destroy the machine if the ransom was not paid. In early October 2000, Bletchley Park officials announced that they would pay the ransom, but the stated deadline passed with no word from the blackmailer. Shortly afterward, the machine was sent anonymously to BBC journalist Jeremy Paxman, missing three rotors.\nIn November 2000, an antiques dealer named Dennis Yates was arrested after telephoning The Sunday Times to arrange the return of the missing parts. The Enigma machine was returned to Bletchley Park after the incident. In October 2001, Yates was sentenced to ten months in prison and served three months.In October 2008, the Spanish daily newspaper El Pa\u00eds reported that 28 Enigma machines had been discovered by chance in an attic of Army headquarters in Madrid. These four-rotor commercial machines had helped Franco's Nationalists win the Spanish Civil War, because, though the British cryptologist Alfred Dilwyn Knox in 1937 broke the cipher generated by Franco's Enigma machines, this was not disclosed to the Republicans, who failed to break the cipher. The Nationalist government continued using its 50 Enigmas into the 1950s. Some machines have gone on display in Spanish military museums, including one at the National Museum of Science and Technology (MUNCYT) in La Coru\u00f1a and one at the Spanish Army Museum. Two have been given to Britain's GCHQ.The Bulgarian military used Enigma machines with a Cyrillic keyboard; one is on display in the National Museum of Military History in Sofia.On 3 December 2020, German divers working on behalf of the World Wide Fund for Nature discovered a destroyed Enigma machine in Flensburg Firth (part of the Baltic Sea) which is believed to be from a scuttled U-Boat. This Enigma machine will be restored by and be the property of the Archaeology Museum of Schleswig Holstein.An M4 Enigma was salvaged in the 1980s from the German minesweeper R15, which was sunk off the Istrian coast in 1945. The machine was put on display in the Pivka Park of Military History in Slovenia on 13 April 2023.\n\n== Derivatives ==\nThe Enigma was influential in the field of cipher machine design, spinning off other rotor machines. Once the British discovered Enigma's principle of operation, they created the Typex rotor cipher, which the Germans believed to be unsolvable. Typex was originally derived from the Enigma patents; Typex even includes features from the patent descriptions that were omitted from the actual Enigma machine. The British paid no royalties for the use of the patents. In the United States, cryptologist William Friedman designed the M-325 machine, starting in 1936, that is logically similar.Machines like the SIGABA, NEMA, Typex, and so forth, are not considered to be Enigma derivatives as their internal ciphering functions are not mathematically identical to the Enigma transform.\nA unique rotor machine called Cryptograph was constructed in 2002 by Netherlands-based Tatjana van Vark. This device makes use of 40-point rotors, allowing letters, numbers and some punctuation to be used; each rotor contains 509 parts.\n\n== Simulators ==\n\n== Explanatory notes =="
    }
  },
  {
    "instruction": "Browser security\n\n==Introduction==\nBrowser security is the application of Internet security to web browsers in order to protect networked data and computer systems from breaches of privacy or malware. Security exploits of browsers often use JavaScript, sometimes with cross-site scripting (XSS) with a secondary payload using Adobe Flash. Security exploits can also take advantage of vulnerabilities (security holes) that are commonly exploited in all browsers (including Mozilla Firefox, Google Chrome, Opera, Microsoft Internet Explorer, and Safari).\n\n== Security ==\nWeb browsers can be breached in one or more of the following ways:\n\nOperating system is breached and malware is reading/modifying the browser memory space in privilege mode\nOperating system has a malware running as a background process, which is reading/modifying the browser memory space in privileged mode\nMain browser executable can be hacked\nBrowser components may be hacked\nBrowser plugins can be hacked\nBrowser network communications could be intercepted outside the machineThe browser may not be aware of any of the breaches above and may show user a safe connection is made.\nWhenever a browser communicates with a website, the website, as part of that communication, collects some information about the browser (in order to process the formatting of the page to be delivered, if nothing else).  If malicious code has been inserted into the website's content, or in a worst-case scenario, if that website has been specifically designed to host malicious code, then vulnerabilities specific to a particular browser can allow this malicious code to run processes within the browser application in unintended ways (and remember, one of the bits of information that a website collects from a browser communication is the browser's identity- allowing specific vulnerabilities to be exploited). Once an attacker is able to run processes on the visitor's machine, then exploiting known security vulnerabilities can allow the attacker to gain privileged access (if the browser isn't already running with privileged access) to the \"infected\" system in order to perform an even greater variety of malicious processes and activities on the machine or even the victim's whole network.Breaches of web browser security are usually for the purpose of bypassing protections to display pop-up advertising collecting personally identifiable information (PII) for either Internet marketing or identity theft, website tracking or web analytics about a user against their will using tools such as web bugs, Clickjacking, Likejacking (where Facebook's like button is targeted), HTTP cookies, zombie cookies or Flash cookies (Local Shared Objects or LSOs); installing adware, viruses, spyware such as Trojan horses (to gain access to users' personal computers via cracking) or other malware including online banking theft using man-in-the-browser attacks.\nIn depth study of vulnerabilities in Chromium web-browser indicates that, Improper Input Validation (CWE-20) and Improper Access Control (CWE-284) are the most occurring root causes for security vulnerabilities. Furthermore, among vulnerabilities examined at the time of this study, 106 vulnerabilities occurred in Chromium because of reusing or importing vulnerable versions of third party libraries.\nVulnerabilities in the web browser software itself can be minimized by keeping browser software updated, but will not be sufficient if the underlying operating system is compromised, for example, by a rootkit.  Some subcomponents of browsers such as scripting, add-ons, and cookies are particularly vulnerable (\"the confused deputy problem\") and also need to be addressed.\nFollowing the principle of defence in depth, a fully patched and correctly configured browser may not be sufficient to ensure that browser-related security issues cannot occur. For example, a rootkit can capture keystrokes while someone logs into a banking website, or carry out a man-in-the-middle attack by modifying network traffic to and from a web browser. DNS hijacking or DNS spoofing may be used to return false positives for mistyped website names, or to subvert search results for popular search engines. Malware such as RSPlug simply modifies a system's configuration to point at rogue DNS servers.\nBrowsers can use more secure methods of network communication to help prevent some of these attacks:\n\nDNS: DNSSec and DNSCrypt, for example with non-default DNS servers such as Google Public DNS or OpenDNS.\nHTTP: HTTP Secure and SPDY with digitally signed public key certificates or Extended Validation Certificates.Perimeter defenses, typically through firewalls and the use of filtering proxy servers that block malicious websites and perform antivirus scans of any file downloads, are commonly implemented as a best practice in large organizations to block malicious network traffic before it reaches a browser.\nThe topic of browser security has grown to the point of spawning the creation of entire organizations, such as The Browser Exploitation Framework Project,  creating platforms to collect tools to breach browser security, ostensibly in order to test browsers and network systems for vulnerabilities.\n\n\n*** Plugins and extensions ***\nAlthough not part of the browser per se, browser plugins and extensions extend the attack surface, exposing vulnerabilities in Adobe Flash Player, Adobe (Acrobat) Reader, Java plugin, and ActiveX that are commonly exploited. Researchers have extensively studied the security architecture of various web-browsers in particular those relying on plug-and-play designs. This study has identified 16 common vulnerability types, and 19 potential mitigations. Malware may also be implemented as a browser extension, such as a browser helper object in the case of Internet Explorer. In various other exploits websites which were designed to look authentic and included rogue 'update Adobe Flash' popups designed as visual cues to download malware payloads in their place. Some browsers like Google Chrome and Mozilla Firefox can block\u2014or warn users of\u2014insecure plugins.\n\n\n*** Adobe Flash ***\n\nAn August 2009 study by the Social Science Research Network found that 50% of websites using Flash were also employing Flash cookies, yet privacy policies rarely disclosed them, and user controls for privacy preferences were lacking. Most browsers' cache and history delete functions do not affect Flash Player's writing Local Shared Objects to its own cache, and the user community is much less aware of the existence and function of Flash cookies than HTTP cookies. Thus, users having deleted HTTP cookies and purged browser history files and caches may believe that they have purged all tracking data from their computers while in fact Flash browsing history remains. As well as manual removal, the BetterPrivacy add-on for Firefox can remove Flash cookies. Adblock Plus can be used to filter out specific threats and Flashblock can be used to give an option before allowing content on otherwise trusted sites.Charlie Miller recommended \"not to install Flash\" at the computer security conference CanSecWest. Several other security experts also recommend to either not install Adobe Flash Player or to block it.\n\n== Password security model ==\nThe contents of a web page are arbitrary and controlled by the entity owning the domain named displayed in the address bar. If HTTPS is used, then encryption is used to secure against attackers with access to the network from changing the page contents en route. When presented with a password field on a web page, a user is supposed to look at the address bar to determine whether the domain name in the address bar is the correct place to send the password. For example, for Google's single sign-on system (used on e.g. youtube.com), the user should always check that the address bar says \"https://accounts.google.com\" before inputting their password.\nAn un-compromised browser guarantees that the address bar is correct. This guarantee is one reason why browsers will generally display a warning when entering fullscreen mode, on top of where the address bar would normally be, so that a fullscreen website cannot make a fake browser user interface with a fake address bar.\n\n== Hardware browser ==\nThere have been attempts to market hardware-based browsers running from non-writable, read-only file systems. Data cannot be stored on the device and the media cannot be overwritten, presenting a clean executable each time it loads. The first such device was the ZeusGard Secure Hardware Browser, released in late 2013. The ZeusGard website has not been functional since mid-2016. Another device, the iCloak\u00ae Stik from the iCloak website provides a complete Live OS which completely replaces the computer's entire operating system and offers two web browsers from the read-only system. With iCloak they provide the Tor browser for Anonymous browsing as well as a regular Firefox browser for non-anonymous browsing. Any non-secured web traffic (not using https, for example), could still be subject to man-in-the-middle alteration or other network traffic-based manipulations.\n\n== LiveCD ==\nLiveCDs, which run an operating system from a non-writable source, typically come with Web browsers as part of their default image. If the original LiveCD image is free of malware, all of the software used, including the Web browser, will load free of malware every time the LiveCD image is booted.\n\n== Browser hardening ==\nBrowsing the Internet as a least-privilege user account (i.e. without administrator privileges) limits the ability of a security exploit in a web browser from compromising the whole operating system.Internet Explorer 4 and later allows the blacklisting and whitelisting of ActiveX controls, add-ons and browser extensions in various ways.\nInternet Explorer 7 added \"protected mode\", a technology that hardens the browser through the application of a security sandboxing feature of Windows Vista called Mandatory Integrity Control.Google Chrome provides a sandbox to limit web page access to the operating system.Suspected malware sites reported to Google, and confirmed by Google, are flagged as hosting malware in certain browsers.There are third-party extensions and plugins available to harden even the latest browsers, and some for older browsers and operating systems. Whitelist-based software such as NoScript can block JavaScript and Adobe Flash which is used for most attacks on privacy, allowing users to choose only sites they know are safe - AdBlock Plus also uses whitelist ad filtering rules subscriptions, though both the software itself and the filtering list maintainers have come under controversy for by-default allowing some sites to pass the pre-set filters. The US-CERT recommends to block Flash using NoScript.\n\n== Fuzzing ==\nModern web browsers undergo extensive fuzzing to uncover vulnerabilities. The Chromium code of Google Chrome is continuously fuzzed by the Chrome Security Team with 15,000 cores. For Microsoft Edge and Internet Explorer, Microsoft performed fuzzed testing with 670 machine-years during product development, generating more than 400 billion DOM manipulations from 1 billion HTML files.\n\n== Best practice ==\nLoad clean software: Boot from a known clean OS that has a known clean Web browser\nAdopt adequate countermeasures against the Cross-Origin Resource Sharing (CORS) vulnerability (example patches are provided for WebKit-based browsers)\nPrevent attacks via third-party software: Use a hardened Web browser or add-on-free-browsing mode\nPrevent DNS manipulation: Use trusted and secure DNS\nAvoid website-based exploits: Employ link-checking browser plug-ins commonly found in internet security software\nAvoid malicious content: Employ perimeter defenses and anti-malware software\n\nHow can LiveCDs improve web browser security?",
    "context": "",
    "output": "A: LiveCDs can improve web browser security by running an operating system and Web browser from a non-writable source, ensuring that the software is free of malware every time the LiveCD image is booted.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can LiveCDs improve web browser security?",
      "answer": "LiveCDs can improve web browser security by running an operating system and Web browser from a non-writable source, ensuring that the software is free of malware every time the LiveCD image is booted.",
      "context": "Browser security\n\n==Introduction==\nBrowser security is the application of Internet security to web browsers in order to protect networked data and computer systems from breaches of privacy or malware. Security exploits of browsers often use JavaScript, sometimes with cross-site scripting (XSS) with a secondary payload using Adobe Flash. Security exploits can also take advantage of vulnerabilities (security holes) that are commonly exploited in all browsers (including Mozilla Firefox, Google Chrome, Opera, Microsoft Internet Explorer, and Safari).\n\n== Security ==\nWeb browsers can be breached in one or more of the following ways:\n\nOperating system is breached and malware is reading/modifying the browser memory space in privilege mode\nOperating system has a malware running as a background process, which is reading/modifying the browser memory space in privileged mode\nMain browser executable can be hacked\nBrowser components may be hacked\nBrowser plugins can be hacked\nBrowser network communications could be intercepted outside the machineThe browser may not be aware of any of the breaches above and may show user a safe connection is made.\nWhenever a browser communicates with a website, the website, as part of that communication, collects some information about the browser (in order to process the formatting of the page to be delivered, if nothing else).  If malicious code has been inserted into the website's content, or in a worst-case scenario, if that website has been specifically designed to host malicious code, then vulnerabilities specific to a particular browser can allow this malicious code to run processes within the browser application in unintended ways (and remember, one of the bits of information that a website collects from a browser communication is the browser's identity- allowing specific vulnerabilities to be exploited). Once an attacker is able to run processes on the visitor's machine, then exploiting known security vulnerabilities can allow the attacker to gain privileged access (if the browser isn't already running with privileged access) to the \"infected\" system in order to perform an even greater variety of malicious processes and activities on the machine or even the victim's whole network.Breaches of web browser security are usually for the purpose of bypassing protections to display pop-up advertising collecting personally identifiable information (PII) for either Internet marketing or identity theft, website tracking or web analytics about a user against their will using tools such as web bugs, Clickjacking, Likejacking (where Facebook's like button is targeted), HTTP cookies, zombie cookies or Flash cookies (Local Shared Objects or LSOs); installing adware, viruses, spyware such as Trojan horses (to gain access to users' personal computers via cracking) or other malware including online banking theft using man-in-the-browser attacks.\nIn depth study of vulnerabilities in Chromium web-browser indicates that, Improper Input Validation (CWE-20) and Improper Access Control (CWE-284) are the most occurring root causes for security vulnerabilities. Furthermore, among vulnerabilities examined at the time of this study, 106 vulnerabilities occurred in Chromium because of reusing or importing vulnerable versions of third party libraries.\nVulnerabilities in the web browser software itself can be minimized by keeping browser software updated, but will not be sufficient if the underlying operating system is compromised, for example, by a rootkit.  Some subcomponents of browsers such as scripting, add-ons, and cookies are particularly vulnerable (\"the confused deputy problem\") and also need to be addressed.\nFollowing the principle of defence in depth, a fully patched and correctly configured browser may not be sufficient to ensure that browser-related security issues cannot occur. For example, a rootkit can capture keystrokes while someone logs into a banking website, or carry out a man-in-the-middle attack by modifying network traffic to and from a web browser. DNS hijacking or DNS spoofing may be used to return false positives for mistyped website names, or to subvert search results for popular search engines. Malware such as RSPlug simply modifies a system's configuration to point at rogue DNS servers.\nBrowsers can use more secure methods of network communication to help prevent some of these attacks:\n\nDNS: DNSSec and DNSCrypt, for example with non-default DNS servers such as Google Public DNS or OpenDNS.\nHTTP: HTTP Secure and SPDY with digitally signed public key certificates or Extended Validation Certificates.Perimeter defenses, typically through firewalls and the use of filtering proxy servers that block malicious websites and perform antivirus scans of any file downloads, are commonly implemented as a best practice in large organizations to block malicious network traffic before it reaches a browser.\nThe topic of browser security has grown to the point of spawning the creation of entire organizations, such as The Browser Exploitation Framework Project,  creating platforms to collect tools to breach browser security, ostensibly in order to test browsers and network systems for vulnerabilities.\n\n\n*** Plugins and extensions ***\nAlthough not part of the browser per se, browser plugins and extensions extend the attack surface, exposing vulnerabilities in Adobe Flash Player, Adobe (Acrobat) Reader, Java plugin, and ActiveX that are commonly exploited. Researchers have extensively studied the security architecture of various web-browsers in particular those relying on plug-and-play designs. This study has identified 16 common vulnerability types, and 19 potential mitigations. Malware may also be implemented as a browser extension, such as a browser helper object in the case of Internet Explorer. In various other exploits websites which were designed to look authentic and included rogue 'update Adobe Flash' popups designed as visual cues to download malware payloads in their place. Some browsers like Google Chrome and Mozilla Firefox can block\u2014or warn users of\u2014insecure plugins.\n\n\n*** Adobe Flash ***\n\nAn August 2009 study by the Social Science Research Network found that 50% of websites using Flash were also employing Flash cookies, yet privacy policies rarely disclosed them, and user controls for privacy preferences were lacking. Most browsers' cache and history delete functions do not affect Flash Player's writing Local Shared Objects to its own cache, and the user community is much less aware of the existence and function of Flash cookies than HTTP cookies. Thus, users having deleted HTTP cookies and purged browser history files and caches may believe that they have purged all tracking data from their computers while in fact Flash browsing history remains. As well as manual removal, the BetterPrivacy add-on for Firefox can remove Flash cookies. Adblock Plus can be used to filter out specific threats and Flashblock can be used to give an option before allowing content on otherwise trusted sites.Charlie Miller recommended \"not to install Flash\" at the computer security conference CanSecWest. Several other security experts also recommend to either not install Adobe Flash Player or to block it.\n\n== Password security model ==\nThe contents of a web page are arbitrary and controlled by the entity owning the domain named displayed in the address bar. If HTTPS is used, then encryption is used to secure against attackers with access to the network from changing the page contents en route. When presented with a password field on a web page, a user is supposed to look at the address bar to determine whether the domain name in the address bar is the correct place to send the password. For example, for Google's single sign-on system (used on e.g. youtube.com), the user should always check that the address bar says \"https://accounts.google.com\" before inputting their password.\nAn un-compromised browser guarantees that the address bar is correct. This guarantee is one reason why browsers will generally display a warning when entering fullscreen mode, on top of where the address bar would normally be, so that a fullscreen website cannot make a fake browser user interface with a fake address bar.\n\n== Hardware browser ==\nThere have been attempts to market hardware-based browsers running from non-writable, read-only file systems. Data cannot be stored on the device and the media cannot be overwritten, presenting a clean executable each time it loads. The first such device was the ZeusGard Secure Hardware Browser, released in late 2013. The ZeusGard website has not been functional since mid-2016. Another device, the iCloak\u00ae Stik from the iCloak website provides a complete Live OS which completely replaces the computer's entire operating system and offers two web browsers from the read-only system. With iCloak they provide the Tor browser for Anonymous browsing as well as a regular Firefox browser for non-anonymous browsing. Any non-secured web traffic (not using https, for example), could still be subject to man-in-the-middle alteration or other network traffic-based manipulations.\n\n== LiveCD ==\nLiveCDs, which run an operating system from a non-writable source, typically come with Web browsers as part of their default image. If the original LiveCD image is free of malware, all of the software used, including the Web browser, will load free of malware every time the LiveCD image is booted.\n\n== Browser hardening ==\nBrowsing the Internet as a least-privilege user account (i.e. without administrator privileges) limits the ability of a security exploit in a web browser from compromising the whole operating system.Internet Explorer 4 and later allows the blacklisting and whitelisting of ActiveX controls, add-ons and browser extensions in various ways.\nInternet Explorer 7 added \"protected mode\", a technology that hardens the browser through the application of a security sandboxing feature of Windows Vista called Mandatory Integrity Control.Google Chrome provides a sandbox to limit web page access to the operating system.Suspected malware sites reported to Google, and confirmed by Google, are flagged as hosting malware in certain browsers.There are third-party extensions and plugins available to harden even the latest browsers, and some for older browsers and operating systems. Whitelist-based software such as NoScript can block JavaScript and Adobe Flash which is used for most attacks on privacy, allowing users to choose only sites they know are safe - AdBlock Plus also uses whitelist ad filtering rules subscriptions, though both the software itself and the filtering list maintainers have come under controversy for by-default allowing some sites to pass the pre-set filters. The US-CERT recommends to block Flash using NoScript.\n\n== Fuzzing ==\nModern web browsers undergo extensive fuzzing to uncover vulnerabilities. The Chromium code of Google Chrome is continuously fuzzed by the Chrome Security Team with 15,000 cores. For Microsoft Edge and Internet Explorer, Microsoft performed fuzzed testing with 670 machine-years during product development, generating more than 400 billion DOM manipulations from 1 billion HTML files.\n\n== Best practice ==\nLoad clean software: Boot from a known clean OS that has a known clean Web browser\nAdopt adequate countermeasures against the Cross-Origin Resource Sharing (CORS) vulnerability (example patches are provided for WebKit-based browsers)\nPrevent attacks via third-party software: Use a hardened Web browser or add-on-free-browsing mode\nPrevent DNS manipulation: Use trusted and secure DNS\nAvoid website-based exploits: Employ link-checking browser plug-ins commonly found in internet security software\nAvoid malicious content: Employ perimeter defenses and anti-malware software"
    }
  },
  {
    "instruction": "context: A Secure Web Browser is part of a two-factor security solution where the user executes a hardened browser from their two-factor security device rather than executing the potentially infected browser from their own machine.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is a Secure Web Browser and how does it protect against MitB attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a Secure Web Browser and how does it protect against MitB attacks?",
      "answer": "A Secure Web Browser is part of a two-factor security solution where the user executes a hardened browser from their two-factor security device rather than executing the potentially infected browser from their own machine."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is Vera's IRM-as-a-service (IRMaaS) platform made accessible to developers?",
    "context": "",
    "output": "Vera's IRM-as-a-service (IRMaaS) platform is made accessible to developers via a REST API and a downloadable software development kit (SDK).",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is Vera's IRM-as-a-service (IRMaaS) platform made accessible to developers?",
      "answer": "Vera's IRM-as-a-service (IRMaaS) platform is made accessible to developers via a REST API and a downloadable software development kit (SDK)."
    }
  },
  {
    "instruction": "context: During the Russian invasion of Ukraine, state news agency Xinhua and other Chinese state media outlets paid for digital ads on Facebook supporting pro-Kremlin disinformation and propaganda after Meta Platforms banned Russian state media advertisement buys. In March 2022, China Global Television Network repeated unsubstantiated Russian claims of biological weapons labs in Ukraine. The CCP-owned tabloid Global Times also echoed Russian state media claims that the Bucha massacre was staged.\n\nAsk a question about this context.",
    "context": "",
    "output": "How has China used digital ads on Facebook to support pro-Kremlin disinformation and propaganda during the Russian invasion of Ukraine?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has China used digital ads on Facebook to support pro-Kremlin disinformation and propaganda during the Russian invasion of Ukraine?",
      "answer": "During the Russian invasion of Ukraine, state news agency Xinhua and other Chinese state media outlets paid for digital ads on Facebook supporting pro-Kremlin disinformation and propaganda after Meta Platforms banned Russian state media advertisement buys. In March 2022, China Global Television Network repeated unsubstantiated Russian claims of biological weapons labs in Ukraine. The CCP-owned tabloid Global Times also echoed Russian state media claims that the Bucha massacre was staged."
    }
  },
  {
    "instruction": "Answer based on context:\n\nList of cyber warfare forces\n\n==Introduction==\nMany countries around the world maintain military units that are specifically trained to operate in a cyberwarfare environment. In several cases this units acts also as the national computer emergency response team for civilian cybersecurity threats.\n\n== Albania ==\nMilitary Cyber Security Unit (Nj\u00eb e Siguris\u00eb Kibernetike)\n\n== Argentina ==\nJoint Cyber Defense Command of the Armed Forces Joint Staff (Comando Conjunto de Ciberdefensa del Estado Mayor Conjunto de las Fuerzas Armadas)Cyberdefense Operations Center (Centro de Operaciones de Ciberdefensa)\nCyberdefense Engineering Center (Centro de Ingenieria de Ciberdefensa)\nSecurity Operations Intelligent Center (Centro Inteligente de Operaciones de Seguridad)\nNational Cyberdefense Center (Centro Nacional de Ciberdefensa)Informatic Energencies Response Center of the Defense Ministry (Centro de Respuesta ante Emergencias Inform\u00e1ticas del Minisetrio de Defensa)\nCybernetic Analysis Laboratory (Laboratorio de An\u00e1lisis Cibern\u00e9ticos)\n\n== Armenia ==\nSubdivision 1991 (1991 \u054d\u057f\u0578\u0580\u0561\u0562\u0561\u056a\u0561\u0576\u0578\u0582\u0574 - 1991 Storabazhanum)\n\n== Australia ==\nInformation Warfare DivisionDefence Signals Intelligence and Cyber Command\nJoint Cyber UnitArmy\n138th Signal Squadron\nNavy\nFleet Cyber Unit\nAir Force\nNo. 462 Information Warfare Squadron\n\n== Austria ==\nInformation Communications Technologies and Cybersecurity Center (Informations-Kommunikations-Technologie und Cybersicherheitszentrum)\n\n== Azerbaijan ==\nSpecial State Protection Service - State Agency for Special Communications and Information Security (X\u00fcsusi D\u00f6vl\u0259t M\u00fchafiz\u0259 - Xidm\u0259ti X\u00fcsusi Rabit\u0259 v\u0259 \u0130nformasiya T\u0259hl\u00fck\u0259sizliyi D\u00f6vl\u0259t Agentliyi)\n\n== Belarus ==\nInformation Technology Specialized Company (\u0421\u043f\u0435\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0443\u044e \u0440\u043e\u0442\u0443 \u043f\u043e \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0431\u0435\u0437\u043e\u043f\u0430\u0441\u043d\u043e\u0441\u0442\u0438 - Spetsializirovannuyu Rotu po Informatsionnoy Bezopasnosti)\n\n== Belgium ==\nDefense Cyber Directorate\nCyber Command\n\n== Bolivia ==\nCybersecurity and Cyberdefense Center (Centro de Ciberseguridad y Ciberdefensa)\n\n== Brazil ==\nCybernetic Defense Command (Comando de Defesa Cibern\u00e9tica)National Cybernetic Defense School (Escola Nacional de Defesa Cibern\u00e9tica)\nCybernetic Defense Center (Centro de Defesa Cibern\u00e9tica)\n\n== Brunei ==\nAir Force\nCyber Defence Unit\n\n== Bulgaria ==\nStationary Communication Information System (\u0421\u0442\u0430\u0446\u0438\u043e\u043d\u0430\u0440\u043d\u0430 \u041a\u043e\u043c\u0443\u043d\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u0430 \u0418\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u0430 \u0421\u0438\u0441\u0442\u0435\u043c\u0430 - Statsionarna Komunikatsionna Informatsionna Sistema)\n\n== Canada ==\nCanadian Forces Network Operation Centre\nArmy Reserve\nCyber Group, 32 Signal Regiment\nCyber Group, 34 Signal Regiment\n\n== Chile ==\nCyberdefense Incidents Response Center (Centro de Respuesta a Incidencias de Ciberdefensa)\n\n== China ==\nPeople's Liberation Army Strategic Support Force (\u4eba\u6c11\u89e3\u653e\u519b\u6218\u7565\u652f\u63f4\u90e8\u961f - R\u00e9nm\u00edn Ji\u011bf\u00e0ngj\u016bn Zh\u00e0nl\u00fc\u00e8 Zh\u012byu\u00e1n B\u00f9du\u00ec)People's Liberation Army Network System Department (\u4eba\u6c11\u89e3\u653e\u519b\u7f51\u7edc\u7cfb\u7edf\u90e8 - R\u00e9nm\u00edn Ji\u011bf\u00e0ngj\u016bn W\u01cenglu\u00f2 X\u00ect\u01d2ng B\u00f9)Unit 61489 (61489\u90e8\u961f - 61489 B\u00f9du\u00ec)\nUnit 61786 (61786\u90e8\u961f - 61786 B\u00f9du\u00ec)\n56th Jiangan Computing Technologies Research Institute (\u7b2c56\u6c5f\u5357\u8ba1\u7b97\u6280\u672f\u7814\u7a76\u6240 - D\u00ec 56 Ji\u0101ngn\u00e1n J\u00ecsu\u00e0n J\u00ecsh\u00f9 Y\u00e1nji\u016b Su\u01d2)\n57th Research Institute (\u7b2c57\u7814\u7a76\u6240 - D\u00ec 57 Y\u00e1nji\u016b Su\u01d2)\n58th Research Institute (\u7b2c58\u7814\u7a76\u6240 - D\u00ec 58 Y\u00e1nji\u016b Su\u01d2)\nCyberspace Security Academy (\u7f51\u7edc\u7a7a\u95f4\u5b89\u5168\u5b66\u9662 - W\u01cenglu\u00f2 K\u014dngji\u0101n \u0100nqu\u00e1n Xu\u00e9yu\u00e0n)\n\n== Colombia ==\nJoint Cybernetic Command (Comando Conjunto Cibernetico)National Army Cybernetic Unit (Unidad Cibern\u00e9tica Ej\u00e9rcito Nacional)\nNational Navy Cibernetic Unit (Unidad Cibern\u00e9tica Armada Nacional)\nAir Force Cybernetic Unit (Unidad Cibern\u00e9tica Fuerza A\u00e9rea)\nCommunications and Cyberdefense Operational Support Command (Comando de Apoyo Operacional de Comunicaciones y Ciberdefensa)\n\n== Croatia ==\nCybernetic Domain Command of the General Staff (Zapovjedni\u0161tvo za Kiberneti\u010dki Prostor General\u0161taba)\n\n== Cuba ==\nMilitary Cyberdefense Command (Mando Militar de Ciberdefensa)\n\n== Cyprus ==\nCyber Defense Command of the General Staff of National Defense (\u0394\u03b9\u03bf\u03af\u03ba\u03b7\u03c3\u03b7 \u039a\u03c5\u03b2\u03b5\u03c1\u03bd\u03bf\u03ac\u03bc\u03c5\u03bd\u03b1\u03c2 \u03c4\u03bf\u03c5 \u0393\u03b5\u03bd\u03b9\u03ba\u03bf\u03cd \u0395\u03c0\u03b9\u03c4\u03b5\u03bb\u03b5\u03af\u03bf\u03c5 \u0395\u03b8\u03bd\u03b9\u03ba\u03ae\u03c2 \u0386\u03bc\u03c5\u03bd\u03b1\u03c2 - Dio\u00edkisi Kyverno\u00e1mynas tou Geniko\u00fa Epitele\u00edou Ethnik\u00eds \u00c1mynas)\n\n== Czech Republic ==\nNational Cyber Operations Centre (N\u00e1rodn\u00ed Centrum Kybernetick\u00fdch Operac\u00ed)\n\n== Denmark ==\nCyber Security Center (Center for Cybersikkerhed)\n\n== Dominican Republic ==\nArmed Forces Command, Control, Communications, Computers, Cybersecurity and Intelligence Center (Centro de Comando, Control, Comunicaciones, Computadoras, Ciberseguridad e Inteligencia de las Fuerzas Armadas)\n\n== Ecuador ==\nCyberdefense Command (Comando de Ciberdefensa)\n\n== Estonia ==\nCyber Command (K\u00fcberv\u00e4ejuhatus)\nDefence League Cyberdefense Unit (Kaitseliidu K\u00fcberkaitse \u0170ksus)\n\n== Finland ==\nDefense Forces Command System Center (Puolustusvoimien Johtamisj\u00e4rjestelm\u00e4keskus)\n\n== France ==\nInter-service\nCyberdefence Command (Commandement de la Cyberd\u00e9fense)Armed Forces Cyberdefence Group (Groupement de la Cyberd\u00e9fense des Arm\u00e9es)Information Systems Security Audit Center (Centre d\u2019Audits de la S\u00e9curit\u00e9 des Syst\u00e8mes d\u2019Information)\nDefensive Computer Fighting Analysis Center (Centre d\u2019Analyse en Lutte Informatique D\u00e9fensive)\nCyberdefense Reserve and Operational Readiness Center (Centre de la R\u00e9serve et de la Pr\u00e9paration Op\u00e9rationnelle de Cyberd\u00e9fense)\nMain Inter-services Standardization Center(Centre d\u2019Homologation Principale Interarm\u00e9es)\nArmy\nOperational Center for Land Information and Communication Systems and Cybersecurity Networks (Centre Op\u00e9rationnel des R\u00e9seaux SIC (Syst\u00e8mes d\u2019Information et de Communication) Terre et de Cybers\u00e9curit\u00e9)\n807th Signal Company ( 807e Compagnie de Transmission)\nNavy\nCyber Defense Support Center (Centre Support de Cyber-D\u00e9fense)\nCyber Defense Platoon, Commando Kieffer (Section de Cyberd\u00e9fense, Commando Kieffer)\nAir Force\nAerospace Environment Cyberdefence Center of Excellence (Centre d\u2019Excellence en Cyberd\u00e9fense du Milieu A\u00e9rospatial)\n\n== Georgia ==\nCyber Security Bureau\n\n== Germany ==\nCyber and Information Domain Command (Kommando Cyber- und Informationsraum)Armed Forces Information Technology Command (Kommando Informationstechnik der Bundeswehr)Armed Forces Cyber Security Center (Zentrum f\u00fcr Cyber-Sicherheit der Bundeswehr)\nStrategic Reconnaissance Command (Kommando Strategische Aufkl\u00e4rung)Cyber Operations Center (Zentrum Cyber-Operationen)\n\n== Greece ==\nCyber Defense Directorate of the General Staff of National Defense (\u0394\u03b9\u03b5\u03cd\u03b8\u03c5\u03bd\u03c3\u03b7 \u039a\u03c5\u03b2\u03b5\u03c1\u03bd\u03bf\u03ac\u03bc\u03c5\u03bd\u03b1\u03c2 \u03c4\u03bf\u03c5 \u0393\u03b5\u03bd\u03b9\u03ba\u03bf\u03cd \u0395\u03c0\u03b9\u03c4\u03b5\u03bb\u03b5\u03af\u03bf\u03c5 \u0395\u03b8\u03bd\u03b9\u03ba\u03ae\u03c2 \u0386\u03bc\u03c5\u03bd\u03b1\u03c2 - Di\u00e9fthynsi Kyverno\u00e1mynas tou Geniko\u00fa Epitele\u00edou Ethnik\u00eds \u00c1mynas)\n\n== Guatemala ==\nComputing and Technology Command (Comando de Inform\u00e1tica y Tecnolog\u00eda)\n\n== Hungary ==\nCyber Defense Center - Military National Security Service (Kiberv\u00e9delmi K\u00f6zpont - Katonai Nemzetbiztons\u00e1gi Szolg\u00e1lat)\n\n== India ==\nDefence Cyber Agency (\u0930\u0915\u094d\u0937\u093e \u0938\u093e\u0907\u092c\u0930 \u090f\u091c\u0947\u0902\u0938\u0940 - Raksha Saibar Ejensee)\n\n== Indonesia ==\nIndonesian National Armed Forces Cyber Unit (Satuan Siber Tentara Nasional Indonesia)\nIndonesian Air Force Cyber Unit (Satuan Siber Tentara Nasional Indonesia-Angkatan Udara)\n\n== Iran ==\nCyber Defense Command (\u0642\u0631\u0627\u0631\u06af\u0627\u0647 \u062f\u0641\u0627\u0639 \u0633\u0627\u06cc\u0628\u0631\u06cc; - Gharargah-e Defa-e Saiberi)\n\n== Ireland ==\nCommunications and Information Services Corps (An C\u00f3r Seirbh\u00eds\u00ed Cumars\u00e1ide agus Eolais)\n\n== Israel ==\nInter-services\nC4I and Cyber Defense Directorate\nUnit 8200 (\u05d9\u05d7\u05d9\u05d3\u05d4 8200 - Yehida Shmonae Matayim)\nAir Force\nUnit \"Horizon 324\" (\u05d9\u05d7\u05d9\u05d3\u05ea \"\u05d0\u05d5\u05e4\u05e7 324 - Yehidat \"Ofek 324\" )\n\n== Italy ==\nInter-service\n\nNetwork Operations Command (Comando per le Operazioni in Rete)Security and Cyber Defence Unit (Reparto Sicurezza e Cyber Defence)\nCyber Operations Unit (Reparto Cyber Operations)Army\n\nCybernetic Security Unit (Reparto Sicurezza Cibernetica)\nComputer Incident Response Team - 3rd Signal Regiment (Nucleo CIRT - 3\u00b0 Reggimento Trasmissioni)\nComputer Incident Response Team - 32nd Signal Regiment (Nucleo CIRT - 32\u00b0 Reggimento Trasmissioni)\nComputer Incident Response Team - 46th Signal Regiment (Nucleo CIRT - 46\u00b0 Reggimento Trasmissioni)Navy\n\nCybernetic, Informatic and Signal Security Office (Ufficio Sicurezza Cibernetica, Informatica e delle Comunicazioni)Air Force\n\nAutomated Information Systems Unit (Reparto Sistemi Informativi Automatizzati)\n\n== Japan ==\nJapan Air Self-Defense Force (\u822a\u7a7a\u81ea\u885b\u968a - K\u014dk\u016b Jieitai)\nSelf Defence Force Command and Communication System Department (\u81ea\u885b\u968a\u6307\u63ee\u901a\u4fe1\u30b7\u30b9\u30c6\u30e0\u968a - Jieitai Shiki Ts\u016bshin Shisutemu-Tai)Cyber Defense Team (\u30b5\u30a4\u30d0\u30fc\u9632\u885b\u968a - Saib\u0101 B\u014dei-Tai)\nNetwork Operations Team (\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u904b\u7528\u968a - Nettow\u0101ku Un'y\u014d-Tai)\n\n== Jordan ==\nArmed Forces Computer Emergency Response Team\n\n== Latvia ==\nNational Guard Cyber Defence Unit (Zemessardzes Kiberaizsardz\u012bbas Vien\u012bba)\n\n== Lithuania ==\nArmy Cyber Incidents Rapid Response Command (Kariuomen\u0117s Greitojo Reagavimo \u012e Kibernetinius Incidentus Komanda)\n\n== Malaysia ==\nCyber and Electromagnetic Command (Pemerintahan Siber dan Elektromagnetik)\n\n== Mexico ==\nInter-service\n\nCyberspace Operations Center (Centro de Operaciones del Ciberespacio)Navy\n\nCybersecurity Unit (Unidad de Ciberseguridad)\n\n== Moldova ==\nArmed Forces Cybernetic Incidents Reaction Center (Centru de Reac\u021bie la Incidente Cibernetice a For\u021belor Armate)\n\n== Morocco ==\nRoyal Armed Forces Cyber Center of Excellence\n\n== NATO ==\nCyber Operations Centre\nNATO Cyber Range\nCooperative Cyber Defence Centre of Excellence\nEuropean Centre of Excellence for Countering Hybrid Threats\n\n== Netherlands ==\nDefense Cyber Command (Defensie Cyber Commando)\nDefense Computer Emergency Response Team\nJoint Signal Intelligence (SIGINT) Cyber Unit\n\n== New Zealand ==\nCyber Cell, 1st Command Support Regiment\n\n== Nigeria ==\nCyber Warfare Command\n\n== North Korea ==\nResearch Institute 110 (110\ud638 \uc5f0\uad6c\uc18c - 110ho Yeonguso)31st Technical Reconnaissance Office (\uae30\uc220\uc815\ucc30\uc870 31\uc18c - Gisuljeongchaljo 31so)\n32nd Technical Reconnaissance Office (\uae30\uc220\uc815\ucc30\uc870 32\uc18c - Gisuljeongchaljo 32so)\n56th Technical Reconnaissance Office (\uae30\uc220\uc815\ucc30\uc870 56\uc18c - Gisuljeongchaljo 56so)General Staff Department of the Korean People's Army:\nOperation Bureau\nCommunications Bureau\nElectronic Warfare Bureau\nEnemy Collapse Sabotage Bureau:Unit 204\nCommand Automation Bureau/Department:(General Staff's) Office 31/unit (develops hacking tools)\n(General Staff's) Office/unit 32 (develops military-related software)\n(General Staff's) Office/unit 56 (develops software for command and control)Reconnaissance General Bureau:\nBureau 325 (stealing information on vaccine technology related to COVID-19)\nBureau 121 (network attacks and exfiltration operations)Lab 110 (Technology Reconnaissance Team)Office 98\nOffice 414\nOffice 35\nOffice/Unit 91:Unit 110 (AKA Technology Reconnaissance Team)\nUnit 35 (Central Party's Investigations Department)\nUnit 121 (NKPA Joint Chiefs Cyber Warfare Unit 121)\nUnit 204 (Cyber PSYOPS)\nUnit 180\n128 Liaison Office\n413 Liaison Office\nThe Andariel Group\nThe Bluenoroff Group\nan Electronic Warfare Jamming Regiment\nLazarus Group\nComputer Technology Research Lab\n6th Technical Bureau of the Reconnaissance General BureauBureau/Lab 110 / 110 Institute (Technology Reconnaissance Team, conducts computer network operations against military units and strategic organizations.)\n3rd Bureau of the RGB (AKA 3rd Technical Surveillance Bureau, responsible for North Korea's cyber operations)110th Research CenterLazarus GroupBluenoroff (earn revenue illicitly in response to increased global sanctions...)\nAndariel (See source for details)Others:\n\nThe Data Investigation Examination Office (conducts cyber espionage to collect intelligence on politics, economics, and societies abroad)\nKWP's Unification and United Front Department (cyber influence operations through social media and websites such as Uriminzokkiri, which is maintained by the party's Committee for the Peaceful Reunification of the Fatherland.)\nThe KWP Central Party Investigative GroupUnit 35 (education and training).\nThe State Security Department's (secret police) communications monitoring and computer hacking group conducts cyber warfare, presumably in support of its mission of internal state security.\n\n== Norway ==\nCyber Defence Force (Cyberforsvarets)Cyber Defense Computer Information Services (CIS) Regiment (Cyberforsvarets CIS-regiment) \nCyber Security Center (Cybersikkerhetssenteret) \nCyber Defense Weapons School (Cyberforsvarets V\u00e5penskole) \nCyber Defense Information and Communication Technologies (ICT) Service (Cyberforsvarets IKT-tjenester) \nCyber Defense Base and Alarm Service (Cyberforsvarets Base- og Alarmtjenester)\n\n== Paraguay ==\nGeneral Directorate of Information and Communication Technologies of the Armed Forces (Direcci\u00f3n General de Tecnolog\u00edas de la Informaci\u00f3n y Comunicaci\u00f3n de las Fuerzas Armadas)\n\n== Peru ==\nCyberdefense Operational Command (Comando Operacional de Ciberdefensa)\n\n== Philippines ==\nArmy Cyber Defense Team\n\n== Poland ==\nCybernetic Operations Center (Centrum Operacji Cybernetycznych)\nNational Center for Cyberspace Security (Narodowe Centrum Bezpiecze\u0144stwa Cyberprzestrzeni)\nDefense Ministry Coordination Center for Computer Incident Response - Military Counterintelligence Service (Centrum Koordynacyjnego Systemu Reagowania na Incydenty Komputerowe Obrony Narodowej - S\u0142u\u017cba Kontrwywiadu Wojskowego)\nCyberspace Defense Forces (Wojska Obrony Cyberprzestrzeni)\n\n== Portugal ==\nCyberdefense Center - Armed Forces General Staff (Centro de Ciberdefesa \u2013 Estado Maior General das For\u00e7as Armadas)Computer Incident Response Capability - Army (CIRC Exercito)\nComputer Incident Response Capability - Navy (CIRC Marinha)\nComputer Incident Response Capability - Air Force (CIRC For\u00e7a Aerea)\n\n== Romania ==\nCybernetic Defense Command (Comandamentul Ap\u0103r\u0103rii Cibernetice)Informatic Technology Agency (Agen\u0163ia de Tehnologia Informa\u0163iei)\nCybernetic Defense Agency (Agen\u0163ia de Ap\u0103r\u0103re Cibernetic\u0103)\n\n== Russian Federation ==\nInformation Operations Troops (\u0412\u043e\u0439\u0441\u043a\u0430 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0439 - Voyska Informatsionnykh Operatsiy)Western Military District Cybersecurity Center (\u0417\u0430\u043f\u0430\u0434\u043d\u044b\u0439 \u0432\u043e\u0435\u043d\u043d\u044b\u0439 \u043e\u043a\u0440\u0443\u0433 \u0446\u0435\u043d\u0442\u0440 \u043a\u0438\u0431\u0435\u0440\u0437\u0430\u0449\u0438\u0442\u044b \u2013 Zapadnyy Voyenny Okrug Tsentr Kiberzashchity)\nSouthern Military District Cybersecurity Center (\u042e\u0436\u043d\u044b\u0439 \u0432\u043e\u0435\u043d\u043d\u044b\u0439 \u043e\u043a\u0440\u0443\u0433 \u0446\u0435\u043d\u0442\u0440 \u043a\u0438\u0431\u0435\u0440\u0437\u0430\u0449\u0438\u0442\u044b \u2013 Yuzhnyy Voyenny Okrug Tsentr Kiberzashchity)\nCentral Military District Cybersecurity Center (\u0426\u0435\u043d\u0442\u0440\u0430\u043b\u044c\u043d\u044b\u0439 \u0432\u043e\u0435\u043d\u043d\u044b\u0439 \u043e\u043a\u0440\u0443\u0433 \u0446\u0435\u043d\u0442\u0440 \u043a\u0438\u0431\u0435\u0440\u0437\u0430\u0449\u0438\u0442\u044b \u2013 Tsentral'nyy Voyenny Okrug Tsentr Kiberzashchity)\nEastern Military District Cybersecurity Center (\u0412\u043e\u0441\u0442\u043e\u0447\u043d\u044b\u0439 \u0432\u043e\u0435\u043d\u043d\u044b\u0439 \u043e\u043a\u0440\u0443\u0433 \u0446\u0435\u043d\u0442\u0440 \u043a\u0438\u0431\u0435\u0440\u0437\u0430\u0449\u0438\u0442\u044b \u2013 Vostochnyy Voyenny Okrug Tsentr Kiberzashchity)\nJoint Strategic Command \u201cNorthern Fleet\u201d Cybersecurity Center (\u041e\u0431\u044a\u0435\u0434\u0438\u043d\u0451\u043d\u043d\u043e\u0435 \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u043a\u043e\u043c\u0430\u043d\u0434\u043e\u0432\u0430\u043d\u0438\u0435 \u201c\u0421\u0435\u0432\u0435\u0440\u043d\u044b\u0439 \u0444\u043b\u043e\u0442\u201d \u0446\u0435\u043d\u0442\u0440 \u043a\u0438\u0431\u0435\u0440\u0437\u0430\u0449\u0438\u0442\u044b - Ob\"yedinonnoye Strategicheskoye Komandovaniye \u201cSevernyy flot\u201d Tsentr Kiberzashchity)\nSpecial Development Center of the Ministry of Defense (\u0426\u0435\u043d\u0442\u0440 \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u043e\u043a \u041c\u0438\u043d\u0438\u0441\u0442\u0435\u0440\u0441\u0442\u0432\u0430 \u043e\u0431\u043e\u0440\u043e\u043d\u044b - Tsentr Spetsial'nykh Razrabotok Ministerstva Oborony)\n6th Directorate - General Directorate of the General Staff (\u0428\u0435\u0441\u0442\u043e\u0435 \u0423\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435-\u0413\u043b\u0430\u0432\u043d\u043e\u0435 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0413\u0435\u043d\u0435\u0440\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0448\u0442\u0430\u0431\u0430 - Shestoye Upravleniye-Glavnoye Upravleniye General'nogo Shtaba)85th Special Service Main Center \u2013 Military Unit 26165 (85-\u0439 \u0433\u043b\u0430\u0432\u043d\u044b\u0439 \u0446\u0435\u043d\u0442\u0440 \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0439 \u0441\u043b\u0443\u0436\u0431\u044b-\u0412\u043e\u0435\u043d\u043d\u0430\u044f \u0447\u0430\u0441\u0442\u044c 26165 - 85-y Glavnyy Tsentr Spetsial'noy Sluzhby-Voyennaya Chast' 26165)) \nSpecial Technologies Main Center \u2013 Military Unit 74455 (\u0413\u043b\u0430\u0432\u043d\u044b\u0439 \u0446\u0435\u043d\u0442\u0440 \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0442\u0435\u0445\u043d\u043e\u043b\u043e\u0433\u0438\u0439-\u0412\u043e\u0435\u043d\u043d\u0430\u044f \u0447\u0430\u0441\u0442\u044c 74455 - Glavnyy Tsentr Spetsial'nykh Tekhnologiy-Voyennaya Chast' 74455)\n\n== Serbia ==\n224th Center for Electronic Action (224. \u0426\u0435\u043d\u0442\u0430\u0440 \u0437\u0430 \u0435\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u0441\u043a\u0430 \u0434\u0435\u0458\u0441\u0442\u0432\u0430 - 224. Centar za Elektronska Dejstva)\n\n== Singapore ==\nDefence Cyber OrganisationCyber Defence School\nCyber Defence Group\nDigital and Intelligence Service\n\n== Slovakia ==\nMilitary Intelligence Cybernetic Defense Center (Centrum pre Kybernetick\u00fa Obranu - Vojensk\u00e9ho Spravodajstva )\n\n== South Africa ==\nDirectorate Information Warfare\n\n== Slovenia ==\nCommunication and Information Systems Unit (Enota za Komunikacijske in Informacijske Sisteme)Cyber Defence Centre (Center za Kibernetsko Obrambo)\nThreat Research Centre (Center za Raziskovanje Gro\u017eenj)\n\n== South Korea ==\nCyber Operations Command (\uc0ac\uc774\ubc84 \uc791\uc804 \uc0ac\ub839\ubd80 - Saibeo Jagjeon Salyeongbu)500th Center (Cyber Defense Operations Office) (500\uc13c\ud130(\uc0ac\uc774\ubc84\ubc29\uc5b4\uc791\uc804 \ub2f4\ub2f9) \u2013 500 Senteo Saibeobang-Eojagjeon Damdang)) \n700th Center (Cyber Threats Information Management Office) (700\uc13c\ud130(\uc0ac\uc774\ubc84\uc704\ud611\uc815\ubcf4 \ub2f4\ub2f9) \u2013 700 Senteo (Saibeo Wihyeob Jeongbo Damdang))\n\n== Spain ==\nInter-service\n\nJoint Cyberspace Command (Mando Conjunto del Ciberespacio)Cyberspace Operations Force (Fuerza de Operaciones en el Ciberespacio)\nCyberdefense Systems Command (Jefatura de Sistemas de Ciberdefensa)\nArmy\n32nd Electronic Warfare Regiment (Regimiento de Guerra Electr\u00f3nica n\u00ba 32)\nNavy\nCyberdefense Section (Secci\u00f3n de Ciberdefensa)\nAir Force\nCyberdefense Security Operations Center (Centro de Operaciones de Seguridad de Ciberdefensa)\n\n== Sri Lanka ==\nMinistry of Defence Cyber Operations Centre (MoD COC) - SLAF Colombo\n12th Regiment (Cyber Security), Sri Lanka Signal Corps\n\n== Sweden ==\nInformation TechnologiesDefense Forces (Informationsteknikf\u00f6rsvarsf\u00f6rbandet)\nInformation Systems Defense Force (Informationssystemf\u00f6rband)\n\n== Switzerland ==\nCommand Support Base (F\u00fchrungsunterst\u00fctzungsbasis - Base d'Aide au Commandement - Base d'Aiuto alla Condotta)Cyber Security Division\nCyber Fusion Center\nCyber Battalion 42\n\n== Taiwan ==\nInformation Communication and Electronic Warfare Command (\u4fe1\u606f\u548c\u7535\u5b50\u6218\u53f8\u4ee4\u90e8 - X\u00ecnx\u012b H\u00e9 Di\u00e0nz\u01d0 Zh\u00e0n S\u012bl\u00ecng B\u00f9)\n\n== Thailand ==\nArmy Cyber Center (\u0e28\u0e39\u0e19\u0e22\u0e4c\u0e44\u0e0b\u0e40\u0e1a\u0e2d\u0e23\u0e4c\u0e01\u0e2d\u0e07\u0e17\u0e31\u0e1e\u0e1a\u0e01 - \u1e62\u0304\u016bny\u0312 S\u1ecbbexr\u0312 Kxngth\u1ea1ph Bk)\n\n== Turkey ==\nCyber Defence Command (Siber Savunma Komutanl\u0131\u011f\u0131)Cyber Defence Center (Siber Savunma Merkezi)\n\n== Ukraine ==\nCommand of the Communications and Cyber Security Troops of the Armed Forces of Ukraine (\u041a\u043e\u043c\u0430\u043d\u0434\u0443\u0432\u0430\u043d\u043d\u044f \u0432\u0456\u0439\u0441\u044c\u043a \u0437\u0432\u2019\u044f\u0437\u043a\u0443 \u0442\u0430 \u043a\u0456\u0431\u0435\u0440\u043d\u0435\u0442\u0438\u0447\u043d\u043e\u0457 \u0431\u0435\u0437\u043f\u0435\u043a\u0438 \u0417\u0431\u0440\u043e\u0439\u043d\u0438\u0445 \u0421\u0438\u043b \u0423\u043a\u0440\u0430\u0457\u043d\u0438 - Komanduvannya vijsk zvyazku ta kibernetychnoyi bezpeky Zbroynykh Syl Ukrayiny)\n\n== United Kingdom ==\nArmy\n\n13th Signal Regiment224 (Defensive Cyber Operations) Signal Squadron\n233 (Global Communication Networks) Signal Squadron\n259 (Global Information Services) Signal SquadronNavy\n\nCyber Defence Operations CenterAir Force\n\nAir Cyber and Information Services Operations CentreNo. 5 (Information Services) Squadron\n591 Defensive Cyber Air Combat Service Support UnitInter-service\n\nJoint Forces Cyber GroupJoint Cyber Unit (Cheltenham)\nJoint Cyber Unit (Corsham)Cyber Information Systems Operations Centre\nCyber Security Operations Centre\nDefense Cyber School\nJoint Cyber Unit (Reserve)Army Reserve\nLand Information Assurance Group (Reserve)\n254th Specialist Group Information Services (SIGIS) Signal Squadron, 15th Signals Regiment (Reserve)\nNavy Reserve\nReserve Cyber Unit\nRoyal Auxiliary Air Force\nCyberspace Communications Specialists Section, No. 600 (City of London) Squadron (Royal Auxiliary Air Force)\nCyberspace Communications Specialists Section, No. 614 (County of Glamorgan) Squadron (Royal Auxiliary Air Force)\n\n== United States ==\nInter-service\n\nUnited States Cyber Command\nJoint Task Force ARESArmy\n\nU.S. Army Cyber CommandU.S. Army Network Enterprise Technology Command\n1st Information Operations Command (Land)1st Information Operations Battalion\n2nd Information Operations Battalion\n780th Military Intelligence Brigade (Cyber) \u201cPretorians\u201d781st Military Intelligence Battalion \u201cVanguard\u201d\n782nd Military Intelligence Battalion \u201cCyber Legion\u201d \n915th Cyber Warfare Battalion\nCyber Solutions Development Detachment\nTask Force Echo (Army Reserve) \nU.S. Army Cyber Center of ExcellenceU.S. Army Cyber School\nU.S. Army Cyber Technical College\nU.S. Army Cyber Leader College\nCyber Training Battalion - 15th Signal Brigade\nMulti-Domain Task Force 1Multi-Domain Effects Battalion (previously Intelligence, Information, Cyber, Electronic Warfare and Space Battalion)Information Defense Company\nArmy Reserve\nCyber Protection BrigadeNorth East Cyber Protection CenterCyber Protection Team 180\nCyber Protection Team 181\nNational Capital Region Cyber Protection CenterCyber Protection Team 182\nCyber Protection Team 183\nSouth West Cyber Protection CenterCyber Protection Team 184\nCyber Protection Team 185\nNorth Central Cyber Protection CenterCyber Protection Team 186\nCyber Protection Team 187\nWestern Cyber Protection CenterCyber Protection Team 188\nCyber Protection Team 189\nArizona Cyber Warfare Range\nArmy National Guard\n91st Cyber Brigade (Virginia NG)123rd Cyber Protection Battalion (Virginia NG)\n124th Cyber Protection Battalion (Virginia NG)\n125th Cyber Protection Battalion (South Carolina NG)\n126th Cyber Protection Battalion (Massachusetts NG)\n127th Cyber Protection Battalion (Indiana NG)\nCyber Protection Team 169 (Maryland NG)\nCyber Protection Team 170 (Georgia NG)\nCyber Protection Team 171 (California NG)\nCyber Protection Team 172 (Michigan NG)\nCyber Protection Team 173 (New York NG)\nCyber Protection Team 174 (Colorado and Utah NG)\nCyber Protection Team 175 (Alabama, Kentucky and Tennessee NG)\nCyber Protection Team 176 (Illinois and Wisconsin NG)\nCyber Protection Team 177 (Minnesota NG)\nCyber Protection Team 178 (Mississippi NG)\nCyber Protection Team 179 (Nebraska NG)\nDefensive Cyber Operations Element (Colorado NG)\nDefensive Cyber Operations Element (Florida NG)\nDefensive Cyber Operations Element (Oklahoma NG)\nDefensive Cyber Operations Element (Pennsylvania NG)\nDefensive Cyber Operations Element (West Virginia NG)\nCyber Mission Assurance Team (Ohio NG)\nCyber Mission Assurance Team (Hawaii NG)\nCyber Mission Assurance Team (Washington NG)Navy\n\nU.S. Fleet Cyber Command \u2013 Tenth FleetNaval Network Warfare Command (Task Force 1010)\nNavy Cyber Defense Operations Command (Task Force 1020)Air Force\n\n Sixteenth Air Force (Air Force Cyber)Cyberspace Capabilities Center\nAir Force Cyber College\n67th Cyberspace Wing67th Operations Support Squadron (ACC)\n67th Cyberspace Operations Group91st Cyberspace Operations Squadron\n305th Cyberspace Operations Squadron\n352nd Cyberspace Operations Squadron\n390th Cyberspace Operations Squadron\n375th Cyberspace Operations Squadron\n318th Cyberspace Operations Group39th Information Operations Squadron\n90th Cyberspace Operations Squadron \u201dShadow Warriors\u201d\n318th Range Squadron\n346th Test Squadron\n567th Cyberspace Operations Group92nd Cyberspace Operations Squadron\n834th Cyberspace Operations Squadron\n835th Cyberspace Operations Squadron\n837th Cyberspace Operations Squadron\n867th Cyberspace Operations Group315th Cyberspace Operations Squadron\n341st Cyberspace Operations Squadron\n833rd Cyberspace Operations Squadron\n836th Cyberspace Operations Squadron\n688th Cyberspace Wing688th Operations Support Squadron\n26th Cyberspace Operations Group26th Network Operations Squadron\n33rd Network Warfare Squadron\n68th Network Warfare Squadron\n690th Cyberspace Operations Group83rd Network Operations Squadron\n561st Network Operations Squadron\n690th Cyberspace Operations Squadron\n690th Intelligence Support Squadron\n690th Network Support Squadron\n691st Cyberspace Operations Squadron\nAir Force Materiel Command\n96th Cyberspace Test Group47th Cyberspace Test Squadron\nAir Force Institute of Technology\nAir Force Cyberspace Technical Center of ExcellenceCenter for Cyberspace Research\nAir Force Reserve\n960th Cyberspace Wing860th Cyberspace Operations Group51st Network Operations Squadron\n53rd Network Operations Squadron\n710th Network Operations Squadron\n717th Information Operations Squadron\n960th Cyberspace Operations Group42nd Cyberspace Operations Squadron\n50th Network Warfare Squadron\n52nd Network Warfare Squadron\n426th Network Warfare Squadron \u201cGuardians of the Grid\u201d\n689th Network Operations Squadron\nAir National Guard\n175th Cyberspace Operations Group (Maryland ANG)275th Cyberspace Operations Squadron (Maryland ANG)\n276th Cyberspace Operations Squadron (Maryland ANG)\n184th Cyberspace Operations Group (Kansas ANG) 127th Cyberspace Operations Squadron (Kansas ANG)\n177th Information Warfare Aggressor Squadron \u201cJayhawkers\u201d (Kansas ANG)\n299th Network Operations Security Squadron (Kansas ANG)\n252d Cyberspace Operations Group (Washington ANG)143rd Information Operations Squadron (Washington ANG)\n262nd Cyberspace Operations Squadron (Washington ANG)\n102nd Network Warfare Squadron (Rhode Island ANG)\n112th Cyberspace Operations Squadron (Pennsylvania ANG)\n119th Cyberspace Operations Squadron (Tennessee ANG)\n140th Cyberspace Operations Squadron (New Jersey ANG) \n166th Network Warfare Squadron (Delaware ANG)\n168th Cyberspace Operations Squadron (Iowa ANG)\n185th Cyberspace Operations Squadron (Virginia ANG)\n224th Cyberspace Operations Squadron (Idaho ANG)\n229th Cyberspace Operations Squadron (Vermont ANG)\n261st Cyberspace Operations Squadron (California ANG)\n272nd Cyberspace Operations Squadron (Michigan ANG) \n273rd Information Operations Squadron (Texas ANG)Marines\n\nMarine Corps Forces Cyberspace CommandMarine Corps Cyberspace Operations Group\nMarine Corps Cyberspace Warfare Group\nMarine Forces Reserve\nDefensive Cybersecurity Operations Company A\nDefensive Cybersecurity Operations Company BCoast Guard\n\nU.S. Coast Guard Cyber Command\nU.S. Coast Guard Office of Cyberspace ForcesSpace Force\n\nSpace Delta 621st Space Operations Squadron\n61st Cyberspace Squadron\n62nd Cyberspace Squadron\n65th Cyberspace Squadron\n\n== Uruguay ==\nDefense Informatic Security Incidents Response Team (Equipo de Respuesta a Incidentes de Seguridad Inform\u00e1tica de Defensa)\n\n== Venezuela ==\nJoint Cyberdefense Directorate (Direcci\u00f3n Conjunta de Ciberdefensa)Cyberdefense Operations Division (Divisi\u00f3n de Operaciones de Ciberdefensa)\nInformation Security Management Division (Divisi\u00f3n de Gesti\u00f3n de Seguridad Inform\u00e1tica)\nInvestigation and Development Division (Divisi\u00f3n de Investigaci\u00f3n y Desarrollo)\n\n== Vietnam ==\nCyber Operations Command (B\u1ed9 T\u01b0 l\u1ec7nh T\u00e1c chi\u1ebfn kh\u00f4ng gian m\u1ea1ng)1st Brigade (L\u1eef \u0111o\u00e0n 1)\n2nd Brigade (L\u1eef \u0111o\u00e0n 2)\n3rd Brigade (L\u1eef \u0111o\u00e0n 3)\n10th Laboratory (Vi\u1ec7n 10)\nForce 47 (L\u1ef1c L\u01b0\u1ee3ng 47)\n\nHow does the Japanese Self Defense Force Command and Communication System Department contribute to the country's cyber defense?",
    "context": "",
    "output": "The Self Defense Force Command and Communication System Department is responsible for the communication and information systems of the Japanese Self Defense Force, ensuring their security and availability in the face of cyber threats. It also conducts cyber defense exercises and training to enhance the cyber defense capabilities of the Self Defense Force.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Japanese Self Defense Force Command and Communication System Department contribute to the country's cyber defense?",
      "answer": "The Self Defense Force Command and Communication System Department is responsible for the communication and information systems of the Japanese Self Defense Force, ensuring their security and availability in the face of cyber threats. It also conducts cyber defense exercises and training to enhance the cyber defense capabilities of the Self Defense Force.",
      "context": "List of cyber warfare forces\n\n==Introduction==\nMany countries around the world maintain military units that are specifically trained to operate in a cyberwarfare environment. In several cases this units acts also as the national computer emergency response team for civilian cybersecurity threats.\n\n== Albania ==\nMilitary Cyber Security Unit (Nj\u00eb e Siguris\u00eb Kibernetike)\n\n== Argentina ==\nJoint Cyber Defense Command of the Armed Forces Joint Staff (Comando Conjunto de Ciberdefensa del Estado Mayor Conjunto de las Fuerzas Armadas)Cyberdefense Operations Center (Centro de Operaciones de Ciberdefensa)\nCyberdefense Engineering Center (Centro de Ingenieria de Ciberdefensa)\nSecurity Operations Intelligent Center (Centro Inteligente de Operaciones de Seguridad)\nNational Cyberdefense Center (Centro Nacional de Ciberdefensa)Informatic Energencies Response Center of the Defense Ministry (Centro de Respuesta ante Emergencias Inform\u00e1ticas del Minisetrio de Defensa)\nCybernetic Analysis Laboratory (Laboratorio de An\u00e1lisis Cibern\u00e9ticos)\n\n== Armenia ==\nSubdivision 1991 (1991 \u054d\u057f\u0578\u0580\u0561\u0562\u0561\u056a\u0561\u0576\u0578\u0582\u0574 - 1991 Storabazhanum)\n\n== Australia ==\nInformation Warfare DivisionDefence Signals Intelligence and Cyber Command\nJoint Cyber UnitArmy\n138th Signal Squadron\nNavy\nFleet Cyber Unit\nAir Force\nNo. 462 Information Warfare Squadron\n\n== Austria ==\nInformation Communications Technologies and Cybersecurity Center (Informations-Kommunikations-Technologie und Cybersicherheitszentrum)\n\n== Azerbaijan ==\nSpecial State Protection Service - State Agency for Special Communications and Information Security (X\u00fcsusi D\u00f6vl\u0259t M\u00fchafiz\u0259 - Xidm\u0259ti X\u00fcsusi Rabit\u0259 v\u0259 \u0130nformasiya T\u0259hl\u00fck\u0259sizliyi D\u00f6vl\u0259t Agentliyi)\n\n== Belarus ==\nInformation Technology Specialized Company (\u0421\u043f\u0435\u0446\u0438\u0430\u043b\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u0443\u044e \u0440\u043e\u0442\u0443 \u043f\u043e \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0431\u0435\u0437\u043e\u043f\u0430\u0441\u043d\u043e\u0441\u0442\u0438 - Spetsializirovannuyu Rotu po Informatsionnoy Bezopasnosti)\n\n== Belgium ==\nDefense Cyber Directorate\nCyber Command\n\n== Bolivia ==\nCybersecurity and Cyberdefense Center (Centro de Ciberseguridad y Ciberdefensa)\n\n== Brazil ==\nCybernetic Defense Command (Comando de Defesa Cibern\u00e9tica)National Cybernetic Defense School (Escola Nacional de Defesa Cibern\u00e9tica)\nCybernetic Defense Center (Centro de Defesa Cibern\u00e9tica)\n\n== Brunei ==\nAir Force\nCyber Defence Unit\n\n== Bulgaria ==\nStationary Communication Information System (\u0421\u0442\u0430\u0446\u0438\u043e\u043d\u0430\u0440\u043d\u0430 \u041a\u043e\u043c\u0443\u043d\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u0430 \u0418\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u0430 \u0421\u0438\u0441\u0442\u0435\u043c\u0430 - Statsionarna Komunikatsionna Informatsionna Sistema)\n\n== Canada ==\nCanadian Forces Network Operation Centre\nArmy Reserve\nCyber Group, 32 Signal Regiment\nCyber Group, 34 Signal Regiment\n\n== Chile ==\nCyberdefense Incidents Response Center (Centro de Respuesta a Incidencias de Ciberdefensa)\n\n== China ==\nPeople's Liberation Army Strategic Support Force (\u4eba\u6c11\u89e3\u653e\u519b\u6218\u7565\u652f\u63f4\u90e8\u961f - R\u00e9nm\u00edn Ji\u011bf\u00e0ngj\u016bn Zh\u00e0nl\u00fc\u00e8 Zh\u012byu\u00e1n B\u00f9du\u00ec)People's Liberation Army Network System Department (\u4eba\u6c11\u89e3\u653e\u519b\u7f51\u7edc\u7cfb\u7edf\u90e8 - R\u00e9nm\u00edn Ji\u011bf\u00e0ngj\u016bn W\u01cenglu\u00f2 X\u00ect\u01d2ng B\u00f9)Unit 61489 (61489\u90e8\u961f - 61489 B\u00f9du\u00ec)\nUnit 61786 (61786\u90e8\u961f - 61786 B\u00f9du\u00ec)\n56th Jiangan Computing Technologies Research Institute (\u7b2c56\u6c5f\u5357\u8ba1\u7b97\u6280\u672f\u7814\u7a76\u6240 - D\u00ec 56 Ji\u0101ngn\u00e1n J\u00ecsu\u00e0n J\u00ecsh\u00f9 Y\u00e1nji\u016b Su\u01d2)\n57th Research Institute (\u7b2c57\u7814\u7a76\u6240 - D\u00ec 57 Y\u00e1nji\u016b Su\u01d2)\n58th Research Institute (\u7b2c58\u7814\u7a76\u6240 - D\u00ec 58 Y\u00e1nji\u016b Su\u01d2)\nCyberspace Security Academy (\u7f51\u7edc\u7a7a\u95f4\u5b89\u5168\u5b66\u9662 - W\u01cenglu\u00f2 K\u014dngji\u0101n \u0100nqu\u00e1n Xu\u00e9yu\u00e0n)\n\n== Colombia ==\nJoint Cybernetic Command (Comando Conjunto Cibernetico)National Army Cybernetic Unit (Unidad Cibern\u00e9tica Ej\u00e9rcito Nacional)\nNational Navy Cibernetic Unit (Unidad Cibern\u00e9tica Armada Nacional)\nAir Force Cybernetic Unit (Unidad Cibern\u00e9tica Fuerza A\u00e9rea)\nCommunications and Cyberdefense Operational Support Command (Comando de Apoyo Operacional de Comunicaciones y Ciberdefensa)\n\n== Croatia ==\nCybernetic Domain Command of the General Staff (Zapovjedni\u0161tvo za Kiberneti\u010dki Prostor General\u0161taba)\n\n== Cuba ==\nMilitary Cyberdefense Command (Mando Militar de Ciberdefensa)\n\n== Cyprus ==\nCyber Defense Command of the General Staff of National Defense (\u0394\u03b9\u03bf\u03af\u03ba\u03b7\u03c3\u03b7 \u039a\u03c5\u03b2\u03b5\u03c1\u03bd\u03bf\u03ac\u03bc\u03c5\u03bd\u03b1\u03c2 \u03c4\u03bf\u03c5 \u0393\u03b5\u03bd\u03b9\u03ba\u03bf\u03cd \u0395\u03c0\u03b9\u03c4\u03b5\u03bb\u03b5\u03af\u03bf\u03c5 \u0395\u03b8\u03bd\u03b9\u03ba\u03ae\u03c2 \u0386\u03bc\u03c5\u03bd\u03b1\u03c2 - Dio\u00edkisi Kyverno\u00e1mynas tou Geniko\u00fa Epitele\u00edou Ethnik\u00eds \u00c1mynas)\n\n== Czech Republic ==\nNational Cyber Operations Centre (N\u00e1rodn\u00ed Centrum Kybernetick\u00fdch Operac\u00ed)\n\n== Denmark ==\nCyber Security Center (Center for Cybersikkerhed)\n\n== Dominican Republic ==\nArmed Forces Command, Control, Communications, Computers, Cybersecurity and Intelligence Center (Centro de Comando, Control, Comunicaciones, Computadoras, Ciberseguridad e Inteligencia de las Fuerzas Armadas)\n\n== Ecuador ==\nCyberdefense Command (Comando de Ciberdefensa)\n\n== Estonia ==\nCyber Command (K\u00fcberv\u00e4ejuhatus)\nDefence League Cyberdefense Unit (Kaitseliidu K\u00fcberkaitse \u0170ksus)\n\n== Finland ==\nDefense Forces Command System Center (Puolustusvoimien Johtamisj\u00e4rjestelm\u00e4keskus)\n\n== France ==\nInter-service\nCyberdefence Command (Commandement de la Cyberd\u00e9fense)Armed Forces Cyberdefence Group (Groupement de la Cyberd\u00e9fense des Arm\u00e9es)Information Systems Security Audit Center (Centre d\u2019Audits de la S\u00e9curit\u00e9 des Syst\u00e8mes d\u2019Information)\nDefensive Computer Fighting Analysis Center (Centre d\u2019Analyse en Lutte Informatique D\u00e9fensive)\nCyberdefense Reserve and Operational Readiness Center (Centre de la R\u00e9serve et de la Pr\u00e9paration Op\u00e9rationnelle de Cyberd\u00e9fense)\nMain Inter-services Standardization Center(Centre d\u2019Homologation Principale Interarm\u00e9es)\nArmy\nOperational Center for Land Information and Communication Systems and Cybersecurity Networks (Centre Op\u00e9rationnel des R\u00e9seaux SIC (Syst\u00e8mes d\u2019Information et de Communication) Terre et de Cybers\u00e9curit\u00e9)\n807th Signal Company ( 807e Compagnie de Transmission)\nNavy\nCyber Defense Support Center (Centre Support de Cyber-D\u00e9fense)\nCyber Defense Platoon, Commando Kieffer (Section de Cyberd\u00e9fense, Commando Kieffer)\nAir Force\nAerospace Environment Cyberdefence Center of Excellence (Centre d\u2019Excellence en Cyberd\u00e9fense du Milieu A\u00e9rospatial)\n\n== Georgia ==\nCyber Security Bureau\n\n== Germany ==\nCyber and Information Domain Command (Kommando Cyber- und Informationsraum)Armed Forces Information Technology Command (Kommando Informationstechnik der Bundeswehr)Armed Forces Cyber Security Center (Zentrum f\u00fcr Cyber-Sicherheit der Bundeswehr)\nStrategic Reconnaissance Command (Kommando Strategische Aufkl\u00e4rung)Cyber Operations Center (Zentrum Cyber-Operationen)\n\n== Greece ==\nCyber Defense Directorate of the General Staff of National Defense (\u0394\u03b9\u03b5\u03cd\u03b8\u03c5\u03bd\u03c3\u03b7 \u039a\u03c5\u03b2\u03b5\u03c1\u03bd\u03bf\u03ac\u03bc\u03c5\u03bd\u03b1\u03c2 \u03c4\u03bf\u03c5 \u0393\u03b5\u03bd\u03b9\u03ba\u03bf\u03cd \u0395\u03c0\u03b9\u03c4\u03b5\u03bb\u03b5\u03af\u03bf\u03c5 \u0395\u03b8\u03bd\u03b9\u03ba\u03ae\u03c2 \u0386\u03bc\u03c5\u03bd\u03b1\u03c2 - Di\u00e9fthynsi Kyverno\u00e1mynas tou Geniko\u00fa Epitele\u00edou Ethnik\u00eds \u00c1mynas)\n\n== Guatemala ==\nComputing and Technology Command (Comando de Inform\u00e1tica y Tecnolog\u00eda)\n\n== Hungary ==\nCyber Defense Center - Military National Security Service (Kiberv\u00e9delmi K\u00f6zpont - Katonai Nemzetbiztons\u00e1gi Szolg\u00e1lat)\n\n== India ==\nDefence Cyber Agency (\u0930\u0915\u094d\u0937\u093e \u0938\u093e\u0907\u092c\u0930 \u090f\u091c\u0947\u0902\u0938\u0940 - Raksha Saibar Ejensee)\n\n== Indonesia ==\nIndonesian National Armed Forces Cyber Unit (Satuan Siber Tentara Nasional Indonesia)\nIndonesian Air Force Cyber Unit (Satuan Siber Tentara Nasional Indonesia-Angkatan Udara)\n\n== Iran ==\nCyber Defense Command (\u0642\u0631\u0627\u0631\u06af\u0627\u0647 \u062f\u0641\u0627\u0639 \u0633\u0627\u06cc\u0628\u0631\u06cc; - Gharargah-e Defa-e Saiberi)\n\n== Ireland ==\nCommunications and Information Services Corps (An C\u00f3r Seirbh\u00eds\u00ed Cumars\u00e1ide agus Eolais)\n\n== Israel ==\nInter-services\nC4I and Cyber Defense Directorate\nUnit 8200 (\u05d9\u05d7\u05d9\u05d3\u05d4 8200 - Yehida Shmonae Matayim)\nAir Force\nUnit \"Horizon 324\" (\u05d9\u05d7\u05d9\u05d3\u05ea \"\u05d0\u05d5\u05e4\u05e7 324 - Yehidat \"Ofek 324\" )\n\n== Italy ==\nInter-service\n\nNetwork Operations Command (Comando per le Operazioni in Rete)Security and Cyber Defence Unit (Reparto Sicurezza e Cyber Defence)\nCyber Operations Unit (Reparto Cyber Operations)Army\n\nCybernetic Security Unit (Reparto Sicurezza Cibernetica)\nComputer Incident Response Team - 3rd Signal Regiment (Nucleo CIRT - 3\u00b0 Reggimento Trasmissioni)\nComputer Incident Response Team - 32nd Signal Regiment (Nucleo CIRT - 32\u00b0 Reggimento Trasmissioni)\nComputer Incident Response Team - 46th Signal Regiment (Nucleo CIRT - 46\u00b0 Reggimento Trasmissioni)Navy\n\nCybernetic, Informatic and Signal Security Office (Ufficio Sicurezza Cibernetica, Informatica e delle Comunicazioni)Air Force\n\nAutomated Information Systems Unit (Reparto Sistemi Informativi Automatizzati)\n\n== Japan ==\nJapan Air Self-Defense Force (\u822a\u7a7a\u81ea\u885b\u968a - K\u014dk\u016b Jieitai)\nSelf Defence Force Command and Communication System Department (\u81ea\u885b\u968a\u6307\u63ee\u901a\u4fe1\u30b7\u30b9\u30c6\u30e0\u968a - Jieitai Shiki Ts\u016bshin Shisutemu-Tai)Cyber Defense Team (\u30b5\u30a4\u30d0\u30fc\u9632\u885b\u968a - Saib\u0101 B\u014dei-Tai)\nNetwork Operations Team (\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u904b\u7528\u968a - Nettow\u0101ku Un'y\u014d-Tai)\n\n== Jordan ==\nArmed Forces Computer Emergency Response Team\n\n== Latvia ==\nNational Guard Cyber Defence Unit (Zemessardzes Kiberaizsardz\u012bbas Vien\u012bba)\n\n== Lithuania ==\nArmy Cyber Incidents Rapid Response Command (Kariuomen\u0117s Greitojo Reagavimo \u012e Kibernetinius Incidentus Komanda)\n\n== Malaysia ==\nCyber and Electromagnetic Command (Pemerintahan Siber dan Elektromagnetik)\n\n== Mexico ==\nInter-service\n\nCyberspace Operations Center (Centro de Operaciones del Ciberespacio)Navy\n\nCybersecurity Unit (Unidad de Ciberseguridad)\n\n== Moldova ==\nArmed Forces Cybernetic Incidents Reaction Center (Centru de Reac\u021bie la Incidente Cibernetice a For\u021belor Armate)\n\n== Morocco ==\nRoyal Armed Forces Cyber Center of Excellence\n\n== NATO ==\nCyber Operations Centre\nNATO Cyber Range\nCooperative Cyber Defence Centre of Excellence\nEuropean Centre of Excellence for Countering Hybrid Threats\n\n== Netherlands ==\nDefense Cyber Command (Defensie Cyber Commando)\nDefense Computer Emergency Response Team\nJoint Signal Intelligence (SIGINT) Cyber Unit\n\n== New Zealand ==\nCyber Cell, 1st Command Support Regiment\n\n== Nigeria ==\nCyber Warfare Command\n\n== North Korea ==\nResearch Institute 110 (110\ud638 \uc5f0\uad6c\uc18c - 110ho Yeonguso)31st Technical Reconnaissance Office (\uae30\uc220\uc815\ucc30\uc870 31\uc18c - Gisuljeongchaljo 31so)\n32nd Technical Reconnaissance Office (\uae30\uc220\uc815\ucc30\uc870 32\uc18c - Gisuljeongchaljo 32so)\n56th Technical Reconnaissance Office (\uae30\uc220\uc815\ucc30\uc870 56\uc18c - Gisuljeongchaljo 56so)General Staff Department of the Korean People's Army:\nOperation Bureau\nCommunications Bureau\nElectronic Warfare Bureau\nEnemy Collapse Sabotage Bureau:Unit 204\nCommand Automation Bureau/Department:(General Staff's) Office 31/unit (develops hacking tools)\n(General Staff's) Office/unit 32 (develops military-related software)\n(General Staff's) Office/unit 56 (develops software for command and control)Reconnaissance General Bureau:\nBureau 325 (stealing information on vaccine technology related to COVID-19)\nBureau 121 (network attacks and exfiltration operations)Lab 110 (Technology Reconnaissance Team)Office 98\nOffice 414\nOffice 35\nOffice/Unit 91:Unit 110 (AKA Technology Reconnaissance Team)\nUnit 35 (Central Party's Investigations Department)\nUnit 121 (NKPA Joint Chiefs Cyber Warfare Unit 121)\nUnit 204 (Cyber PSYOPS)\nUnit 180\n128 Liaison Office\n413 Liaison Office\nThe Andariel Group\nThe Bluenoroff Group\nan Electronic Warfare Jamming Regiment\nLazarus Group\nComputer Technology Research Lab\n6th Technical Bureau of the Reconnaissance General BureauBureau/Lab 110 / 110 Institute (Technology Reconnaissance Team, conducts computer network operations against military units and strategic organizations.)\n3rd Bureau of the RGB (AKA 3rd Technical Surveillance Bureau, responsible for North Korea's cyber operations)110th Research CenterLazarus GroupBluenoroff (earn revenue illicitly in response to increased global sanctions...)\nAndariel (See source for details)Others:\n\nThe Data Investigation Examination Office (conducts cyber espionage to collect intelligence on politics, economics, and societies abroad)\nKWP's Unification and United Front Department (cyber influence operations through social media and websites such as Uriminzokkiri, which is maintained by the party's Committee for the Peaceful Reunification of the Fatherland.)\nThe KWP Central Party Investigative GroupUnit 35 (education and training).\nThe State Security Department's (secret police) communications monitoring and computer hacking group conducts cyber warfare, presumably in support of its mission of internal state security.\n\n== Norway ==\nCyber Defence Force (Cyberforsvarets)Cyber Defense Computer Information Services (CIS) Regiment (Cyberforsvarets CIS-regiment) \nCyber Security Center (Cybersikkerhetssenteret) \nCyber Defense Weapons School (Cyberforsvarets V\u00e5penskole) \nCyber Defense Information and Communication Technologies (ICT) Service (Cyberforsvarets IKT-tjenester) \nCyber Defense Base and Alarm Service (Cyberforsvarets Base- og Alarmtjenester)\n\n== Paraguay ==\nGeneral Directorate of Information and Communication Technologies of the Armed Forces (Direcci\u00f3n General de Tecnolog\u00edas de la Informaci\u00f3n y Comunicaci\u00f3n de las Fuerzas Armadas)\n\n== Peru ==\nCyberdefense Operational Command (Comando Operacional de Ciberdefensa)\n\n== Philippines ==\nArmy Cyber Defense Team\n\n== Poland ==\nCybernetic Operations Center (Centrum Operacji Cybernetycznych)\nNational Center for Cyberspace Security (Narodowe Centrum Bezpiecze\u0144stwa Cyberprzestrzeni)\nDefense Ministry Coordination Center for Computer Incident Response - Military Counterintelligence Service (Centrum Koordynacyjnego Systemu Reagowania na Incydenty Komputerowe Obrony Narodowej - S\u0142u\u017cba Kontrwywiadu Wojskowego)\nCyberspace Defense Forces (Wojska Obrony Cyberprzestrzeni)\n\n== Portugal ==\nCyberdefense Center - Armed Forces General Staff (Centro de Ciberdefesa \u2013 Estado Maior General das For\u00e7as Armadas)Computer Incident Response Capability - Army (CIRC Exercito)\nComputer Incident Response Capability - Navy (CIRC Marinha)\nComputer Incident Response Capability - Air Force (CIRC For\u00e7a Aerea)\n\n== Romania ==\nCybernetic Defense Command (Comandamentul Ap\u0103r\u0103rii Cibernetice)Informatic Technology Agency (Agen\u0163ia de Tehnologia Informa\u0163iei)\nCybernetic Defense Agency (Agen\u0163ia de Ap\u0103r\u0103re Cibernetic\u0103)\n\n== Russian Federation ==\nInformation Operations Troops (\u0412\u043e\u0439\u0441\u043a\u0430 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0439 - Voyska Informatsionnykh Operatsiy)Western Military District Cybersecurity Center (\u0417\u0430\u043f\u0430\u0434\u043d\u044b\u0439 \u0432\u043e\u0435\u043d\u043d\u044b\u0439 \u043e\u043a\u0440\u0443\u0433 \u0446\u0435\u043d\u0442\u0440 \u043a\u0438\u0431\u0435\u0440\u0437\u0430\u0449\u0438\u0442\u044b \u2013 Zapadnyy Voyenny Okrug Tsentr Kiberzashchity)\nSouthern Military District Cybersecurity Center (\u042e\u0436\u043d\u044b\u0439 \u0432\u043e\u0435\u043d\u043d\u044b\u0439 \u043e\u043a\u0440\u0443\u0433 \u0446\u0435\u043d\u0442\u0440 \u043a\u0438\u0431\u0435\u0440\u0437\u0430\u0449\u0438\u0442\u044b \u2013 Yuzhnyy Voyenny Okrug Tsentr Kiberzashchity)\nCentral Military District Cybersecurity Center (\u0426\u0435\u043d\u0442\u0440\u0430\u043b\u044c\u043d\u044b\u0439 \u0432\u043e\u0435\u043d\u043d\u044b\u0439 \u043e\u043a\u0440\u0443\u0433 \u0446\u0435\u043d\u0442\u0440 \u043a\u0438\u0431\u0435\u0440\u0437\u0430\u0449\u0438\u0442\u044b \u2013 Tsentral'nyy Voyenny Okrug Tsentr Kiberzashchity)\nEastern Military District Cybersecurity Center (\u0412\u043e\u0441\u0442\u043e\u0447\u043d\u044b\u0439 \u0432\u043e\u0435\u043d\u043d\u044b\u0439 \u043e\u043a\u0440\u0443\u0433 \u0446\u0435\u043d\u0442\u0440 \u043a\u0438\u0431\u0435\u0440\u0437\u0430\u0449\u0438\u0442\u044b \u2013 Vostochnyy Voyenny Okrug Tsentr Kiberzashchity)\nJoint Strategic Command \u201cNorthern Fleet\u201d Cybersecurity Center (\u041e\u0431\u044a\u0435\u0434\u0438\u043d\u0451\u043d\u043d\u043e\u0435 \u0441\u0442\u0440\u0430\u0442\u0435\u0433\u0438\u0447\u0435\u0441\u043a\u043e\u0435 \u043a\u043e\u043c\u0430\u043d\u0434\u043e\u0432\u0430\u043d\u0438\u0435 \u201c\u0421\u0435\u0432\u0435\u0440\u043d\u044b\u0439 \u0444\u043b\u043e\u0442\u201d \u0446\u0435\u043d\u0442\u0440 \u043a\u0438\u0431\u0435\u0440\u0437\u0430\u0449\u0438\u0442\u044b - Ob\"yedinonnoye Strategicheskoye Komandovaniye \u201cSevernyy flot\u201d Tsentr Kiberzashchity)\nSpecial Development Center of the Ministry of Defense (\u0426\u0435\u043d\u0442\u0440 \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0440\u0430\u0437\u0440\u0430\u0431\u043e\u0442\u043e\u043a \u041c\u0438\u043d\u0438\u0441\u0442\u0435\u0440\u0441\u0442\u0432\u0430 \u043e\u0431\u043e\u0440\u043e\u043d\u044b - Tsentr Spetsial'nykh Razrabotok Ministerstva Oborony)\n6th Directorate - General Directorate of the General Staff (\u0428\u0435\u0441\u0442\u043e\u0435 \u0423\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435-\u0413\u043b\u0430\u0432\u043d\u043e\u0435 \u0443\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u0435 \u0413\u0435\u043d\u0435\u0440\u0430\u043b\u044c\u043d\u043e\u0433\u043e \u0448\u0442\u0430\u0431\u0430 - Shestoye Upravleniye-Glavnoye Upravleniye General'nogo Shtaba)85th Special Service Main Center \u2013 Military Unit 26165 (85-\u0439 \u0433\u043b\u0430\u0432\u043d\u044b\u0439 \u0446\u0435\u043d\u0442\u0440 \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u043e\u0439 \u0441\u043b\u0443\u0436\u0431\u044b-\u0412\u043e\u0435\u043d\u043d\u0430\u044f \u0447\u0430\u0441\u0442\u044c 26165 - 85-y Glavnyy Tsentr Spetsial'noy Sluzhby-Voyennaya Chast' 26165)) \nSpecial Technologies Main Center \u2013 Military Unit 74455 (\u0413\u043b\u0430\u0432\u043d\u044b\u0439 \u0446\u0435\u043d\u0442\u0440 \u0441\u043f\u0435\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0442\u0435\u0445\u043d\u043e\u043b\u043e\u0433\u0438\u0439-\u0412\u043e\u0435\u043d\u043d\u0430\u044f \u0447\u0430\u0441\u0442\u044c 74455 - Glavnyy Tsentr Spetsial'nykh Tekhnologiy-Voyennaya Chast' 74455)\n\n== Serbia ==\n224th Center for Electronic Action (224. \u0426\u0435\u043d\u0442\u0430\u0440 \u0437\u0430 \u0435\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u0441\u043a\u0430 \u0434\u0435\u0458\u0441\u0442\u0432\u0430 - 224. Centar za Elektronska Dejstva)\n\n== Singapore ==\nDefence Cyber OrganisationCyber Defence School\nCyber Defence Group\nDigital and Intelligence Service\n\n== Slovakia ==\nMilitary Intelligence Cybernetic Defense Center (Centrum pre Kybernetick\u00fa Obranu - Vojensk\u00e9ho Spravodajstva )\n\n== South Africa ==\nDirectorate Information Warfare\n\n== Slovenia ==\nCommunication and Information Systems Unit (Enota za Komunikacijske in Informacijske Sisteme)Cyber Defence Centre (Center za Kibernetsko Obrambo)\nThreat Research Centre (Center za Raziskovanje Gro\u017eenj)\n\n== South Korea ==\nCyber Operations Command (\uc0ac\uc774\ubc84 \uc791\uc804 \uc0ac\ub839\ubd80 - Saibeo Jagjeon Salyeongbu)500th Center (Cyber Defense Operations Office) (500\uc13c\ud130(\uc0ac\uc774\ubc84\ubc29\uc5b4\uc791\uc804 \ub2f4\ub2f9) \u2013 500 Senteo Saibeobang-Eojagjeon Damdang)) \n700th Center (Cyber Threats Information Management Office) (700\uc13c\ud130(\uc0ac\uc774\ubc84\uc704\ud611\uc815\ubcf4 \ub2f4\ub2f9) \u2013 700 Senteo (Saibeo Wihyeob Jeongbo Damdang))\n\n== Spain ==\nInter-service\n\nJoint Cyberspace Command (Mando Conjunto del Ciberespacio)Cyberspace Operations Force (Fuerza de Operaciones en el Ciberespacio)\nCyberdefense Systems Command (Jefatura de Sistemas de Ciberdefensa)\nArmy\n32nd Electronic Warfare Regiment (Regimiento de Guerra Electr\u00f3nica n\u00ba 32)\nNavy\nCyberdefense Section (Secci\u00f3n de Ciberdefensa)\nAir Force\nCyberdefense Security Operations Center (Centro de Operaciones de Seguridad de Ciberdefensa)\n\n== Sri Lanka ==\nMinistry of Defence Cyber Operations Centre (MoD COC) - SLAF Colombo\n12th Regiment (Cyber Security), Sri Lanka Signal Corps\n\n== Sweden ==\nInformation TechnologiesDefense Forces (Informationsteknikf\u00f6rsvarsf\u00f6rbandet)\nInformation Systems Defense Force (Informationssystemf\u00f6rband)\n\n== Switzerland ==\nCommand Support Base (F\u00fchrungsunterst\u00fctzungsbasis - Base d'Aide au Commandement - Base d'Aiuto alla Condotta)Cyber Security Division\nCyber Fusion Center\nCyber Battalion 42\n\n== Taiwan ==\nInformation Communication and Electronic Warfare Command (\u4fe1\u606f\u548c\u7535\u5b50\u6218\u53f8\u4ee4\u90e8 - X\u00ecnx\u012b H\u00e9 Di\u00e0nz\u01d0 Zh\u00e0n S\u012bl\u00ecng B\u00f9)\n\n== Thailand ==\nArmy Cyber Center (\u0e28\u0e39\u0e19\u0e22\u0e4c\u0e44\u0e0b\u0e40\u0e1a\u0e2d\u0e23\u0e4c\u0e01\u0e2d\u0e07\u0e17\u0e31\u0e1e\u0e1a\u0e01 - \u1e62\u0304\u016bny\u0312 S\u1ecbbexr\u0312 Kxngth\u1ea1ph Bk)\n\n== Turkey ==\nCyber Defence Command (Siber Savunma Komutanl\u0131\u011f\u0131)Cyber Defence Center (Siber Savunma Merkezi)\n\n== Ukraine ==\nCommand of the Communications and Cyber Security Troops of the Armed Forces of Ukraine (\u041a\u043e\u043c\u0430\u043d\u0434\u0443\u0432\u0430\u043d\u043d\u044f \u0432\u0456\u0439\u0441\u044c\u043a \u0437\u0432\u2019\u044f\u0437\u043a\u0443 \u0442\u0430 \u043a\u0456\u0431\u0435\u0440\u043d\u0435\u0442\u0438\u0447\u043d\u043e\u0457 \u0431\u0435\u0437\u043f\u0435\u043a\u0438 \u0417\u0431\u0440\u043e\u0439\u043d\u0438\u0445 \u0421\u0438\u043b \u0423\u043a\u0440\u0430\u0457\u043d\u0438 - Komanduvannya vijsk zvyazku ta kibernetychnoyi bezpeky Zbroynykh Syl Ukrayiny)\n\n== United Kingdom ==\nArmy\n\n13th Signal Regiment224 (Defensive Cyber Operations) Signal Squadron\n233 (Global Communication Networks) Signal Squadron\n259 (Global Information Services) Signal SquadronNavy\n\nCyber Defence Operations CenterAir Force\n\nAir Cyber and Information Services Operations CentreNo. 5 (Information Services) Squadron\n591 Defensive Cyber Air Combat Service Support UnitInter-service\n\nJoint Forces Cyber GroupJoint Cyber Unit (Cheltenham)\nJoint Cyber Unit (Corsham)Cyber Information Systems Operations Centre\nCyber Security Operations Centre\nDefense Cyber School\nJoint Cyber Unit (Reserve)Army Reserve\nLand Information Assurance Group (Reserve)\n254th Specialist Group Information Services (SIGIS) Signal Squadron, 15th Signals Regiment (Reserve)\nNavy Reserve\nReserve Cyber Unit\nRoyal Auxiliary Air Force\nCyberspace Communications Specialists Section, No. 600 (City of London) Squadron (Royal Auxiliary Air Force)\nCyberspace Communications Specialists Section, No. 614 (County of Glamorgan) Squadron (Royal Auxiliary Air Force)\n\n== United States ==\nInter-service\n\nUnited States Cyber Command\nJoint Task Force ARESArmy\n\nU.S. Army Cyber CommandU.S. Army Network Enterprise Technology Command\n1st Information Operations Command (Land)1st Information Operations Battalion\n2nd Information Operations Battalion\n780th Military Intelligence Brigade (Cyber) \u201cPretorians\u201d781st Military Intelligence Battalion \u201cVanguard\u201d\n782nd Military Intelligence Battalion \u201cCyber Legion\u201d \n915th Cyber Warfare Battalion\nCyber Solutions Development Detachment\nTask Force Echo (Army Reserve) \nU.S. Army Cyber Center of ExcellenceU.S. Army Cyber School\nU.S. Army Cyber Technical College\nU.S. Army Cyber Leader College\nCyber Training Battalion - 15th Signal Brigade\nMulti-Domain Task Force 1Multi-Domain Effects Battalion (previously Intelligence, Information, Cyber, Electronic Warfare and Space Battalion)Information Defense Company\nArmy Reserve\nCyber Protection BrigadeNorth East Cyber Protection CenterCyber Protection Team 180\nCyber Protection Team 181\nNational Capital Region Cyber Protection CenterCyber Protection Team 182\nCyber Protection Team 183\nSouth West Cyber Protection CenterCyber Protection Team 184\nCyber Protection Team 185\nNorth Central Cyber Protection CenterCyber Protection Team 186\nCyber Protection Team 187\nWestern Cyber Protection CenterCyber Protection Team 188\nCyber Protection Team 189\nArizona Cyber Warfare Range\nArmy National Guard\n91st Cyber Brigade (Virginia NG)123rd Cyber Protection Battalion (Virginia NG)\n124th Cyber Protection Battalion (Virginia NG)\n125th Cyber Protection Battalion (South Carolina NG)\n126th Cyber Protection Battalion (Massachusetts NG)\n127th Cyber Protection Battalion (Indiana NG)\nCyber Protection Team 169 (Maryland NG)\nCyber Protection Team 170 (Georgia NG)\nCyber Protection Team 171 (California NG)\nCyber Protection Team 172 (Michigan NG)\nCyber Protection Team 173 (New York NG)\nCyber Protection Team 174 (Colorado and Utah NG)\nCyber Protection Team 175 (Alabama, Kentucky and Tennessee NG)\nCyber Protection Team 176 (Illinois and Wisconsin NG)\nCyber Protection Team 177 (Minnesota NG)\nCyber Protection Team 178 (Mississippi NG)\nCyber Protection Team 179 (Nebraska NG)\nDefensive Cyber Operations Element (Colorado NG)\nDefensive Cyber Operations Element (Florida NG)\nDefensive Cyber Operations Element (Oklahoma NG)\nDefensive Cyber Operations Element (Pennsylvania NG)\nDefensive Cyber Operations Element (West Virginia NG)\nCyber Mission Assurance Team (Ohio NG)\nCyber Mission Assurance Team (Hawaii NG)\nCyber Mission Assurance Team (Washington NG)Navy\n\nU.S. Fleet Cyber Command \u2013 Tenth FleetNaval Network Warfare Command (Task Force 1010)\nNavy Cyber Defense Operations Command (Task Force 1020)Air Force\n\n Sixteenth Air Force (Air Force Cyber)Cyberspace Capabilities Center\nAir Force Cyber College\n67th Cyberspace Wing67th Operations Support Squadron (ACC)\n67th Cyberspace Operations Group91st Cyberspace Operations Squadron\n305th Cyberspace Operations Squadron\n352nd Cyberspace Operations Squadron\n390th Cyberspace Operations Squadron\n375th Cyberspace Operations Squadron\n318th Cyberspace Operations Group39th Information Operations Squadron\n90th Cyberspace Operations Squadron \u201dShadow Warriors\u201d\n318th Range Squadron\n346th Test Squadron\n567th Cyberspace Operations Group92nd Cyberspace Operations Squadron\n834th Cyberspace Operations Squadron\n835th Cyberspace Operations Squadron\n837th Cyberspace Operations Squadron\n867th Cyberspace Operations Group315th Cyberspace Operations Squadron\n341st Cyberspace Operations Squadron\n833rd Cyberspace Operations Squadron\n836th Cyberspace Operations Squadron\n688th Cyberspace Wing688th Operations Support Squadron\n26th Cyberspace Operations Group26th Network Operations Squadron\n33rd Network Warfare Squadron\n68th Network Warfare Squadron\n690th Cyberspace Operations Group83rd Network Operations Squadron\n561st Network Operations Squadron\n690th Cyberspace Operations Squadron\n690th Intelligence Support Squadron\n690th Network Support Squadron\n691st Cyberspace Operations Squadron\nAir Force Materiel Command\n96th Cyberspace Test Group47th Cyberspace Test Squadron\nAir Force Institute of Technology\nAir Force Cyberspace Technical Center of ExcellenceCenter for Cyberspace Research\nAir Force Reserve\n960th Cyberspace Wing860th Cyberspace Operations Group51st Network Operations Squadron\n53rd Network Operations Squadron\n710th Network Operations Squadron\n717th Information Operations Squadron\n960th Cyberspace Operations Group42nd Cyberspace Operations Squadron\n50th Network Warfare Squadron\n52nd Network Warfare Squadron\n426th Network Warfare Squadron \u201cGuardians of the Grid\u201d\n689th Network Operations Squadron\nAir National Guard\n175th Cyberspace Operations Group (Maryland ANG)275th Cyberspace Operations Squadron (Maryland ANG)\n276th Cyberspace Operations Squadron (Maryland ANG)\n184th Cyberspace Operations Group (Kansas ANG) 127th Cyberspace Operations Squadron (Kansas ANG)\n177th Information Warfare Aggressor Squadron \u201cJayhawkers\u201d (Kansas ANG)\n299th Network Operations Security Squadron (Kansas ANG)\n252d Cyberspace Operations Group (Washington ANG)143rd Information Operations Squadron (Washington ANG)\n262nd Cyberspace Operations Squadron (Washington ANG)\n102nd Network Warfare Squadron (Rhode Island ANG)\n112th Cyberspace Operations Squadron (Pennsylvania ANG)\n119th Cyberspace Operations Squadron (Tennessee ANG)\n140th Cyberspace Operations Squadron (New Jersey ANG) \n166th Network Warfare Squadron (Delaware ANG)\n168th Cyberspace Operations Squadron (Iowa ANG)\n185th Cyberspace Operations Squadron (Virginia ANG)\n224th Cyberspace Operations Squadron (Idaho ANG)\n229th Cyberspace Operations Squadron (Vermont ANG)\n261st Cyberspace Operations Squadron (California ANG)\n272nd Cyberspace Operations Squadron (Michigan ANG) \n273rd Information Operations Squadron (Texas ANG)Marines\n\nMarine Corps Forces Cyberspace CommandMarine Corps Cyberspace Operations Group\nMarine Corps Cyberspace Warfare Group\nMarine Forces Reserve\nDefensive Cybersecurity Operations Company A\nDefensive Cybersecurity Operations Company BCoast Guard\n\nU.S. Coast Guard Cyber Command\nU.S. Coast Guard Office of Cyberspace ForcesSpace Force\n\nSpace Delta 621st Space Operations Squadron\n61st Cyberspace Squadron\n62nd Cyberspace Squadron\n65th Cyberspace Squadron\n\n== Uruguay ==\nDefense Informatic Security Incidents Response Team (Equipo de Respuesta a Incidentes de Seguridad Inform\u00e1tica de Defensa)\n\n== Venezuela ==\nJoint Cyberdefense Directorate (Direcci\u00f3n Conjunta de Ciberdefensa)Cyberdefense Operations Division (Divisi\u00f3n de Operaciones de Ciberdefensa)\nInformation Security Management Division (Divisi\u00f3n de Gesti\u00f3n de Seguridad Inform\u00e1tica)\nInvestigation and Development Division (Divisi\u00f3n de Investigaci\u00f3n y Desarrollo)\n\n== Vietnam ==\nCyber Operations Command (B\u1ed9 T\u01b0 l\u1ec7nh T\u00e1c chi\u1ebfn kh\u00f4ng gian m\u1ea1ng)1st Brigade (L\u1eef \u0111o\u00e0n 1)\n2nd Brigade (L\u1eef \u0111o\u00e0n 2)\n3rd Brigade (L\u1eef \u0111o\u00e0n 3)\n10th Laboratory (Vi\u1ec7n 10)\nForce 47 (L\u1ef1c L\u01b0\u1ee3ng 47)"
    }
  },
  {
    "instruction": "2019 Baltimore ransomware attack\n\n==Introduction==\nDuring the Baltimore ransomware attack of May 2019, the American city of Baltimore, Maryland had its servers largely compromised by a variant of ransomware called RobbinHood. Baltimore became the second U.S. city to fall victim to this new variant of ransomware after Greenville, North Carolina and was the second major US city with a population of over 500,000 people to be hacked by ransomware in two years, after Atlanta was attacked the previous year.\n\n\n\n== Background ==\nBaltimore had been targeted by ransomware once prior to the May 2019 attack in 2018, though that attack was smaller in comparison and took down the city's emergency dispatch system for a short duration. On May 2, just days before the first infection, mayor Catherine Pugh resigned amidst a corruption scandal and was ultimately convicted and sentenced to 3 years in prison. She was replaced by Jack Young.\n\n== Attack ==\nOn May 7, 2019, most of Baltimore's government computer systems were infected with the aggressive ransomware variant RobbinHood. All servers, with the exception of essential services, were taken offline. In a ransom note, hackers demanded 13 bitcoin (roughly $76,280) in exchange for keys to restore access. The note stated that if the demands were not met within four days, the price would increase and within ten days the city would permanently lose all of the data. On May 25, security expert Nicole Perlroth speculated that the stolen NSA exploit EternalBlue was used to infiltrate the city's network vulnerabilities and initiate the attack, though in a memoir published in February 2021, Perlroth recanted her original statement after concluding that the exploit was not in fact responsible.Baltimore was susceptible to such an attack due to its IT practices, which included decentralized control of its technology budget and a failure to allocate money its information security manager wanted to fund cyberattack insurance. The attack has been compared to a ransomware attack on Atlanta the previous year, and was the second major use of the RobbinHood ransomware on an American city in 2019, as Greenville, North Carolina was also affected in April.\n\n== Aftermath ==\nThe attack had a negative impact on the real estate market as property transfers could not be completed digitally due to the system being down, as the city's card payment system and debt checking application were rendered inaccessible. In addition, city employees were unable to use their email system and resorted to creating Gmail accounts as workaround. Google automatically blocked their accounts at first due to the large number of accounts created in that timespan, though the company later restored the Gmail accounts.The recovery, initially estimated to take several more weeks on May 20, ultimately lasted until September. Frank Johnson, Baltimore's IT director, was put on unpaid leave following the ransomware attack. Since becoming the city's IT director during the Pugh administration, Johnson had been criticized for not having a written disaster recovery plan and for his handling of the 2019 attack, which was estimated to cost the city $18 million. He was replaced by deputy director Todd Carter, who later became the permanent IT director in February 2020 after Johnson left the role in October.\n\nQ: How many times was Baltimore targeted by ransomware attacks prior to May 2019?",
    "context": "",
    "output": "A: Baltimore was targeted by ransomware attacks twice before May 2019. The first attack occurred in 2018 and affected the city's emergency dispatch system for a short duration.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many times was Baltimore targeted by ransomware attacks prior to May 2019?",
      "answer": "Baltimore was targeted by ransomware attacks twice before May 2019. The first attack occurred in 2018 and affected the city's emergency dispatch system for a short duration.",
      "context": "2019 Baltimore ransomware attack\n\n==Introduction==\nDuring the Baltimore ransomware attack of May 2019, the American city of Baltimore, Maryland had its servers largely compromised by a variant of ransomware called RobbinHood. Baltimore became the second U.S. city to fall victim to this new variant of ransomware after Greenville, North Carolina and was the second major US city with a population of over 500,000 people to be hacked by ransomware in two years, after Atlanta was attacked the previous year.\n\n\n\n== Background ==\nBaltimore had been targeted by ransomware once prior to the May 2019 attack in 2018, though that attack was smaller in comparison and took down the city's emergency dispatch system for a short duration. On May 2, just days before the first infection, mayor Catherine Pugh resigned amidst a corruption scandal and was ultimately convicted and sentenced to 3 years in prison. She was replaced by Jack Young.\n\n== Attack ==\nOn May 7, 2019, most of Baltimore's government computer systems were infected with the aggressive ransomware variant RobbinHood. All servers, with the exception of essential services, were taken offline. In a ransom note, hackers demanded 13 bitcoin (roughly $76,280) in exchange for keys to restore access. The note stated that if the demands were not met within four days, the price would increase and within ten days the city would permanently lose all of the data. On May 25, security expert Nicole Perlroth speculated that the stolen NSA exploit EternalBlue was used to infiltrate the city's network vulnerabilities and initiate the attack, though in a memoir published in February 2021, Perlroth recanted her original statement after concluding that the exploit was not in fact responsible.Baltimore was susceptible to such an attack due to its IT practices, which included decentralized control of its technology budget and a failure to allocate money its information security manager wanted to fund cyberattack insurance. The attack has been compared to a ransomware attack on Atlanta the previous year, and was the second major use of the RobbinHood ransomware on an American city in 2019, as Greenville, North Carolina was also affected in April.\n\n== Aftermath ==\nThe attack had a negative impact on the real estate market as property transfers could not be completed digitally due to the system being down, as the city's card payment system and debt checking application were rendered inaccessible. In addition, city employees were unable to use their email system and resorted to creating Gmail accounts as workaround. Google automatically blocked their accounts at first due to the large number of accounts created in that timespan, though the company later restored the Gmail accounts.The recovery, initially estimated to take several more weeks on May 20, ultimately lasted until September. Frank Johnson, Baltimore's IT director, was put on unpaid leave following the ransomware attack. Since becoming the city's IT director during the Pugh administration, Johnson had been criticized for not having a written disaster recovery plan and for his handling of the 2019 attack, which was estimated to cost the city $18 million. He was replaced by deputy director Todd Carter, who later became the permanent IT director in February 2020 after Johnson left the role in October."
    }
  },
  {
    "instruction": "XSS worm\n\n==Introduction==\nAn XSS worm, sometimes referred to as a cross site scripting virus, is a malicious (or sometimes non-malicious) payload, usually written in JavaScript, that breaches browser security to propagate among visitors of a website in the attempt to progressively infect other visitors. They were first mentioned in 2002 in relation to a cross site scripting vulnerability in Hotmail.\n\n== Concept ==\nXSS worms exploit a security vulnerability known as cross site scripting (or XSS for short) within a website, infecting users in a variety of ways depending on the vulnerability. Such site features as profiles and chat systems can be affected by XSS worms when implemented improperly or without regard to security. Often, these worms are specific to a single web site, spreading quickly by exploiting specific vulnerabilities.\nCross-site scripting vulnerabilities are commonly exploited in the form of worms on popular social or commercial websites, such as MySpace, Yahoo!, Orkut, Justin.tv, Facebook and Twitter. These worms can be used for malicious intent, giving an attacker the basis to steal personal information provided to the web site, such as passwords or credit card numbers.\n\n== Examples ==\nSeveral XSS worms have affected popular web sites.\n\n\n*** Samy worm ***\n\nThe Samy worm, the largest known XSS worm, infected over 1 million MySpace profiles in less than 20 hours. The virus' author was sued and entered a plea agreement to a felony charge.\n\n\n*** Justin.tv worm ***\n\nJustin.tv was a video casting website with an active user base of approximately 20 thousand users. The cross-site scripting vulnerability that was exploited was that the \"Location\" profile field was not properly sanitized before its inclusion in a profile page.\nThe \"Location\" profile field was sanitized when included in the title of a profile page but not within the actual field in the page's body. This meant that the authors of the worm, in order to achieve stealth to boost the lifetime and spread of the worm, had to automatically remove the XSS payload from the title of the page from within the worm's code, which was already hidden by comments.\nAfter proper development of the worm, it was executed approximately Saturday, 28 Jun 2008 21:52:33 UTC, and finished on Sun, 29 Jun 2008 21:12:21 UTC. Since the social website that was targeted was not particularly active (compared to other popular XSS worm targets), the worm infected a total of 2525 profiles within roughly 24 hours.\nThe worm was found a few hours before it was successfully removed, and based on data that was recorded (due to the worm's original intent for research purposes) the worm was able to infect uninfected profiles after they were sanitized forcefully by developers of Justin.tv. The worm was sanitized once more after the vulnerability was patched, and it was able to be removed easily. However, this shows the ability for the worm to adapt and spread even after counter-attack.\nOther particular factors which are indicated by the graphs and data released by attackers include social activity and lack of new, uninfected users during periods of time.\n\n\n*** Orkut \"Bom Sabado\" worm ***\nOrkut, a social networking Site, was also hit by a XSS worm. Infected users receive a scrap containing the words \"Bom Sabado\" (Portuguese, \"Happy Saturday\"). Google has yet to comment on the situation.\n\nWhat was the location of the sanitization in the Justin.tv worm's code?",
    "context": "",
    "output": "A: The \"Location\" profile field was sanitized when included in the title of a profile page but not within the actual field in the page's body.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the location of the sanitization in the Justin.tv worm's code?",
      "answer": "The \"Location\" profile field was sanitized when included in the title of a profile page but not within the actual field in the page's body.",
      "context": "XSS worm\n\n==Introduction==\nAn XSS worm, sometimes referred to as a cross site scripting virus, is a malicious (or sometimes non-malicious) payload, usually written in JavaScript, that breaches browser security to propagate among visitors of a website in the attempt to progressively infect other visitors. They were first mentioned in 2002 in relation to a cross site scripting vulnerability in Hotmail.\n\n== Concept ==\nXSS worms exploit a security vulnerability known as cross site scripting (or XSS for short) within a website, infecting users in a variety of ways depending on the vulnerability. Such site features as profiles and chat systems can be affected by XSS worms when implemented improperly or without regard to security. Often, these worms are specific to a single web site, spreading quickly by exploiting specific vulnerabilities.\nCross-site scripting vulnerabilities are commonly exploited in the form of worms on popular social or commercial websites, such as MySpace, Yahoo!, Orkut, Justin.tv, Facebook and Twitter. These worms can be used for malicious intent, giving an attacker the basis to steal personal information provided to the web site, such as passwords or credit card numbers.\n\n== Examples ==\nSeveral XSS worms have affected popular web sites.\n\n\n*** Samy worm ***\n\nThe Samy worm, the largest known XSS worm, infected over 1 million MySpace profiles in less than 20 hours. The virus' author was sued and entered a plea agreement to a felony charge.\n\n\n*** Justin.tv worm ***\n\nJustin.tv was a video casting website with an active user base of approximately 20 thousand users. The cross-site scripting vulnerability that was exploited was that the \"Location\" profile field was not properly sanitized before its inclusion in a profile page.\nThe \"Location\" profile field was sanitized when included in the title of a profile page but not within the actual field in the page's body. This meant that the authors of the worm, in order to achieve stealth to boost the lifetime and spread of the worm, had to automatically remove the XSS payload from the title of the page from within the worm's code, which was already hidden by comments.\nAfter proper development of the worm, it was executed approximately Saturday, 28 Jun 2008 21:52:33 UTC, and finished on Sun, 29 Jun 2008 21:12:21 UTC. Since the social website that was targeted was not particularly active (compared to other popular XSS worm targets), the worm infected a total of 2525 profiles within roughly 24 hours.\nThe worm was found a few hours before it was successfully removed, and based on data that was recorded (due to the worm's original intent for research purposes) the worm was able to infect uninfected profiles after they were sanitized forcefully by developers of Justin.tv. The worm was sanitized once more after the vulnerability was patched, and it was able to be removed easily. However, this shows the ability for the worm to adapt and spread even after counter-attack.\nOther particular factors which are indicated by the graphs and data released by attackers include social activity and lack of new, uninfected users during periods of time.\n\n\n*** Orkut \"Bom Sabado\" worm ***\nOrkut, a social networking Site, was also hit by a XSS worm. Infected users receive a scrap containing the words \"Bom Sabado\" (Portuguese, \"Happy Saturday\"). Google has yet to comment on the situation."
    }
  },
  {
    "instruction": "Answer based on context:\n\nMAC flooding\n\n==Introduction==\nIn computer networking, a media access control attack or MAC flooding is a technique employed to compromise the security of network switches. The attack works by forcing legitimate MAC table contents out of the switch and forcing a unicast flooding behavior potentially sending sensitive information to portions of the network where it is not normally intended to go.\n\n== Attack method ==\nSwitches maintain a MAC table that maps individual MAC addresses on the network to the physical ports on the switch.  This allows the switch to direct data out of the physical port where the recipient is located, as opposed to indiscriminately broadcasting the data out of all ports as an Ethernet hub does.  The advantage of this method is that data is bridged exclusively to the network segment containing the computer that the data is specifically destined for.\nIn a typical MAC flooding attack, a switch is fed many Ethernet frames, each containing different source MAC addresses, by the attacker.  The intention is to consume the limited memory set aside in the switch to store the MAC address table.The effect of this attack may vary across implementations, however the desired effect (by the attacker) is to force legitimate MAC addresses out of the MAC address table, causing significant quantities of incoming frames to be flooded out on all ports.  It is from this flooding behavior that the MAC flooding attack gets its name.\nAfter launching a successful MAC flooding attack, a malicious user can use a packet analyzer to capture sensitive data being transmitted between other computers, which would not be accessible were the switch operating normally. The attacker may also follow up with an ARP spoofing attack which will allow them to retain access to privileged data after switches recover from the initial MAC flooding attack.\nMAC flooding can also be used as a rudimentary VLAN hopping attack.\n\n== Counter measures ==\nTo prevent MAC flooding attacks, network operators usually rely on the presence of one or more features in their network equipment:\n\nWith a feature often called \"port security\" by vendors, many advanced switches can be configured to limit the number of MAC addresses that can be learned on ports connected to end stations.  A smaller table of secure MAC addresses is maintained in addition to (and as a subset to) the traditional MAC address table.\nMany vendors allow discovered MAC addresses to be authenticated against an authentication, authorization and accounting (AAA) server and subsequently filtered.\nImplementations of IEEE 802.1X suites often allow packet filtering rules to be installed explicitly by an AAA server based on dynamically learned information about clients, including the MAC address.\nSecurity features to prevent ARP spoofing or IP address spoofing in some cases may also perform additional MAC address filtering on unicast packets, however this is an implementation-dependent side-effect.\nAdditional security measures are sometimes applied along with the above to prevent normal unicast flooding for unknown MAC addresses. This feature usually relies on the \"port security\" feature to retain all secure MAC addresses for at least as long as they remain in the ARP table of layer 3 devices.  Hence, the aging time of learned secure MAC addresses is separately adjustable.  This feature prevents packets from flooding under normal operational circumstances, as well as mitigating the effects of a MAC flood attack.\n\nHow can packet filtering rules be installed in a network switch?",
    "context": "",
    "output": "Packet filtering rules can be installed in a network switch by an AAA server based on dynamically learned information about clients, including the MAC address.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can packet filtering rules be installed in a network switch?",
      "answer": "Packet filtering rules can be installed in a network switch by an AAA server based on dynamically learned information about clients, including the MAC address.",
      "context": "MAC flooding\n\n==Introduction==\nIn computer networking, a media access control attack or MAC flooding is a technique employed to compromise the security of network switches. The attack works by forcing legitimate MAC table contents out of the switch and forcing a unicast flooding behavior potentially sending sensitive information to portions of the network where it is not normally intended to go.\n\n== Attack method ==\nSwitches maintain a MAC table that maps individual MAC addresses on the network to the physical ports on the switch.  This allows the switch to direct data out of the physical port where the recipient is located, as opposed to indiscriminately broadcasting the data out of all ports as an Ethernet hub does.  The advantage of this method is that data is bridged exclusively to the network segment containing the computer that the data is specifically destined for.\nIn a typical MAC flooding attack, a switch is fed many Ethernet frames, each containing different source MAC addresses, by the attacker.  The intention is to consume the limited memory set aside in the switch to store the MAC address table.The effect of this attack may vary across implementations, however the desired effect (by the attacker) is to force legitimate MAC addresses out of the MAC address table, causing significant quantities of incoming frames to be flooded out on all ports.  It is from this flooding behavior that the MAC flooding attack gets its name.\nAfter launching a successful MAC flooding attack, a malicious user can use a packet analyzer to capture sensitive data being transmitted between other computers, which would not be accessible were the switch operating normally. The attacker may also follow up with an ARP spoofing attack which will allow them to retain access to privileged data after switches recover from the initial MAC flooding attack.\nMAC flooding can also be used as a rudimentary VLAN hopping attack.\n\n== Counter measures ==\nTo prevent MAC flooding attacks, network operators usually rely on the presence of one or more features in their network equipment:\n\nWith a feature often called \"port security\" by vendors, many advanced switches can be configured to limit the number of MAC addresses that can be learned on ports connected to end stations.  A smaller table of secure MAC addresses is maintained in addition to (and as a subset to) the traditional MAC address table.\nMany vendors allow discovered MAC addresses to be authenticated against an authentication, authorization and accounting (AAA) server and subsequently filtered.\nImplementations of IEEE 802.1X suites often allow packet filtering rules to be installed explicitly by an AAA server based on dynamically learned information about clients, including the MAC address.\nSecurity features to prevent ARP spoofing or IP address spoofing in some cases may also perform additional MAC address filtering on unicast packets, however this is an implementation-dependent side-effect.\nAdditional security measures are sometimes applied along with the above to prevent normal unicast flooding for unknown MAC addresses. This feature usually relies on the \"port security\" feature to retain all secure MAC addresses for at least as long as they remain in the ARP table of layer 3 devices.  Hence, the aging time of learned secure MAC addresses is separately adjustable.  This feature prevents packets from flooding under normal operational circumstances, as well as mitigating the effects of a MAC flood attack."
    }
  },
  {
    "instruction": "Context: TCP reset attack\n\n==Introduction==\nTCP reset attack, also known as a \"forged TCP reset\" or \"spoofed TCP reset\", is a way to terminate a TCP connection by sending a forged TCP reset packet. This tampering technique can be used by a firewall or abused by a malicious attacker to interrupt Internet connections.\nThe Great Firewall of China, and Iranian Internet censors are known to use TCP reset attacks to interfere with and block connections, as a major method to carry out Internet censorship.\n\n\n\n== Background ==\nThe Internet is a system for individual computers to exchange electronic messages, or packets of data. This system includes hardware to carry the messages (such as copper and fiber optics cables) and a formalized system for formatting the messages, called \"protocols\". The basic protocol used on the Internet is the Internet Protocol (IP), which is usually coupled with additional protocols such as TCP (Transmission Control Protocol) or UDP (User Datagram Protocol). TCP/IP is the protocol set used for email and web browsing. Each protocol has a block of information, called a header, included near the front of each packet. Headers contain information about which computer sent the packet, which computer should receive it, the packet size, etc.\nTCP is used with IP when a two-way virtual connection is required between two computers. TCP is a connection-oriented protocol and requires a logical connection to be established between two processes before data is exchanged (UDP on the other hand is a connectionless IP protocol.) A TCP/IP socket is used when communication between two computers (for example a workstation with a browser and a web server) by exchanging a stream of packets. Using a TCP connection gives the computers an easy way to exchange data items too big for a single packet, such as video clips, email attachments, or music files. Although some web pages are small enough for a single packet, they are sent over TCP connections for convenience.\n\n== TCP resets ==\nIn a stream of packets of a TCP connection, each packet contains a TCP header. Each of these headers contains a bit known as the \"reset\" (RST) flag. In most packets, this bit is set to 0 and has no effect; however, if this bit is set to 1, it indicates to the receiving computer that the computer should immediately stop using the TCP connection; it should not send any more packets using the connection's identifying numbers, called ports, and discard any further packets it receives with headers indicating they belong to that connection. A TCP reset basically kills a TCP connection instantly.\nWhen used as designed, this can be a useful tool. One common application is the scenario where a computer (computer A) crashes while a TCP connection is in progress. The computer on the other end (computer B) will continue to send TCP packets since it does not know that computer A has crashed. When computer A reboots, it will then receive packets from the old pre-crash connection. Computer A has no context for these packets and no way of knowing what to do with them, so it might send a TCP reset to computer B. This reset lets computer B know that the connection is no longer working. The user on computer B can now try another connection or take other action.\n\n\n*** Forging TCP resets ***\nIn the scenario above, the TCP reset bit was sent by a computer that was one of the connection endpoints. It is possible for a third computer to monitor the TCP packets on the connection and then send a \"forged\" packet containing a TCP reset to one or both endpoints. The headers in the forged packet must indicate, falsely, that it came from an endpoint, not the forger. This information includes the endpoint IP addresses and port numbers. Every field in the IP and TCP headers must be set to a convincing forged value for the fake reset to trick the endpoint into closing the TCP connection. Properly formatted forged TCP resets can be a very effective way to disrupt any TCP connection that the forger can monitor.\n\n== Legitimate use ==\nOne application of a forged TCP reset is to maliciously disrupt TCP connections without the consent of the two parties that own the endpoints. However, network security systems using forged TCP resets have been designed as well. A prototype \"Buster\" software package was demonstrated in 1995 that would send forged resets to any TCP connection that used port numbers in a short list. Linux volunteers proposed doing something similar with Linux firewalls in 2000, and the open source Snort used TCP resets to disrupt suspicious connections as early as 2003.\n\n== Comcast Controversy ==\nBy late 2007, Comcast began using forged TCP resets to cripple peer-to-peer and certain groupware applications on their customers' computers. This started a controversy, which was followed by the creation of the Network Neutrality Squad (NNSquad) by Lauren Weinstein, Vint Cerf, David Farber, Craig Newmark and other well-known founders and champions of openness on the Internet. In 2008, the NNSquad released the NNSquad Network Measurement Agent, a Windows software program written by John Bartas, which could detect Comcast's forged TCP resets and distinguish them from real endpoint-generated resets. The technology to detect the resets was developed from the earlier open-source \"Buster\" software which used forged resets to block malware and ads in web pages.\nIn January 2008, the FCC announced it would investigate Comcast's use of forged resets, and, on August 21, 2008, it ordered Comcast to terminate the practice.\n\n== Prevention ==\nBy encrypting connections using a VPN, the attacker has to do a TCP reset attack on all encrypted connections, causing collateral damage.\n\nQuestion: What is the use of the \"Buster\" software package and its impact on detecting forged TCP resets?\n\nAnswer:",
    "context": "",
    "output": "The \"Buster\" software package, demonstrated in 1995, was designed to send forged resets to any TCP connection using specific port numbers in a short list. This technology was later used to develop the NNSquad Network Measurement Agent in 2008, which could detect Comcast's forged TCP resets and distinguish them from legitimate endpoint-generated resets.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the use of the \"Buster\" software package and its impact on detecting forged TCP resets?",
      "answer": "The \"Buster\" software package, demonstrated in 1995, was designed to send forged resets to any TCP connection using specific port numbers in a short list. This technology was later used to develop the NNSquad Network Measurement Agent in 2008, which could detect Comcast's forged TCP resets and distinguish them from legitimate endpoint-generated resets.",
      "context": "TCP reset attack\n\n==Introduction==\nTCP reset attack, also known as a \"forged TCP reset\" or \"spoofed TCP reset\", is a way to terminate a TCP connection by sending a forged TCP reset packet. This tampering technique can be used by a firewall or abused by a malicious attacker to interrupt Internet connections.\nThe Great Firewall of China, and Iranian Internet censors are known to use TCP reset attacks to interfere with and block connections, as a major method to carry out Internet censorship.\n\n\n\n== Background ==\nThe Internet is a system for individual computers to exchange electronic messages, or packets of data. This system includes hardware to carry the messages (such as copper and fiber optics cables) and a formalized system for formatting the messages, called \"protocols\". The basic protocol used on the Internet is the Internet Protocol (IP), which is usually coupled with additional protocols such as TCP (Transmission Control Protocol) or UDP (User Datagram Protocol). TCP/IP is the protocol set used for email and web browsing. Each protocol has a block of information, called a header, included near the front of each packet. Headers contain information about which computer sent the packet, which computer should receive it, the packet size, etc.\nTCP is used with IP when a two-way virtual connection is required between two computers. TCP is a connection-oriented protocol and requires a logical connection to be established between two processes before data is exchanged (UDP on the other hand is a connectionless IP protocol.) A TCP/IP socket is used when communication between two computers (for example a workstation with a browser and a web server) by exchanging a stream of packets. Using a TCP connection gives the computers an easy way to exchange data items too big for a single packet, such as video clips, email attachments, or music files. Although some web pages are small enough for a single packet, they are sent over TCP connections for convenience.\n\n== TCP resets ==\nIn a stream of packets of a TCP connection, each packet contains a TCP header. Each of these headers contains a bit known as the \"reset\" (RST) flag. In most packets, this bit is set to 0 and has no effect; however, if this bit is set to 1, it indicates to the receiving computer that the computer should immediately stop using the TCP connection; it should not send any more packets using the connection's identifying numbers, called ports, and discard any further packets it receives with headers indicating they belong to that connection. A TCP reset basically kills a TCP connection instantly.\nWhen used as designed, this can be a useful tool. One common application is the scenario where a computer (computer A) crashes while a TCP connection is in progress. The computer on the other end (computer B) will continue to send TCP packets since it does not know that computer A has crashed. When computer A reboots, it will then receive packets from the old pre-crash connection. Computer A has no context for these packets and no way of knowing what to do with them, so it might send a TCP reset to computer B. This reset lets computer B know that the connection is no longer working. The user on computer B can now try another connection or take other action.\n\n\n*** Forging TCP resets ***\nIn the scenario above, the TCP reset bit was sent by a computer that was one of the connection endpoints. It is possible for a third computer to monitor the TCP packets on the connection and then send a \"forged\" packet containing a TCP reset to one or both endpoints. The headers in the forged packet must indicate, falsely, that it came from an endpoint, not the forger. This information includes the endpoint IP addresses and port numbers. Every field in the IP and TCP headers must be set to a convincing forged value for the fake reset to trick the endpoint into closing the TCP connection. Properly formatted forged TCP resets can be a very effective way to disrupt any TCP connection that the forger can monitor.\n\n== Legitimate use ==\nOne application of a forged TCP reset is to maliciously disrupt TCP connections without the consent of the two parties that own the endpoints. However, network security systems using forged TCP resets have been designed as well. A prototype \"Buster\" software package was demonstrated in 1995 that would send forged resets to any TCP connection that used port numbers in a short list. Linux volunteers proposed doing something similar with Linux firewalls in 2000, and the open source Snort used TCP resets to disrupt suspicious connections as early as 2003.\n\n== Comcast Controversy ==\nBy late 2007, Comcast began using forged TCP resets to cripple peer-to-peer and certain groupware applications on their customers' computers. This started a controversy, which was followed by the creation of the Network Neutrality Squad (NNSquad) by Lauren Weinstein, Vint Cerf, David Farber, Craig Newmark and other well-known founders and champions of openness on the Internet. In 2008, the NNSquad released the NNSquad Network Measurement Agent, a Windows software program written by John Bartas, which could detect Comcast's forged TCP resets and distinguish them from real endpoint-generated resets. The technology to detect the resets was developed from the earlier open-source \"Buster\" software which used forged resets to block malware and ads in web pages.\nIn January 2008, the FCC announced it would investigate Comcast's use of forged resets, and, on August 21, 2008, it ordered Comcast to terminate the practice.\n\n== Prevention ==\nBy encrypting connections using a VPN, the attacker has to do a TCP reset attack on all encrypted connections, causing collateral damage."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is the term \"personal data\" defined in EU directive 95/46/EC for the purposes of the directive?",
    "context": "",
    "output": "In EU directive 95/46/EC, \"personal data\" is defined as any information relating to an identified or identifiable natural person ('data subject'); an identifiable person is one who can be identified, directly or indirectly, in particular by reference to an identification number or to one or more factors specific to his physical, physiological, mental, economic, cultural or social identity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the term \"personal data\" defined in EU directive 95/46/EC for the purposes of the directive?",
      "answer": "In EU directive 95/46/EC, \"personal data\" is defined as any information relating to an identified or identifiable natural person ('data subject'); an identifiable person is one who can be identified, directly or indirectly, in particular by reference to an identification number or to one or more factors specific to his physical, physiological, mental, economic, cultural or social identity."
    }
  },
  {
    "instruction": "Context-based access control\n\n==Introduction==\nContext-based access control (CBAC) is a feature of firewall software, which intelligently filters TCP and UDP packets based on application layer protocol session information. It can be used for intranets, extranets and internets.CBAC can be configured to permit specified TCP and UDP traffic through a firewall only when the connection is initiated from within the network needing protection. (In other words, CBAC can inspect traffic for sessions that originate from the external network.) However, while this example discusses inspecting traffic for sessions that originate from the external network, CBAC can inspect traffic for sessions that originate from either side of the firewall. This is the basic function of a stateful inspection firewall.Without CBAC, traffic filtering is limited to access list implementations that examine packets at the network layer, or at most, the transport layer. However, CBAC examines not only network layer and transport layer information but also examines the application-layer protocol information (such as FTP connection information) to learn about the state of the TCP or UDP session. This allows support of protocols that involve multiple channels created as a result of negotiations in the FTP control channel. Most of the multimedia protocols as well as some other protocols (such as FTP, RPC, and SQL*Net) involve multiple control channels.\nCBAC inspects traffic that travels through the firewall to discover and manage state information for TCP and UDP sessions. This state information is used to create temporary openings in the firewall's access lists to allow return traffic and additional data connections for permissible sessions (sessions that originated from within the protected internal network).\nCBAC works through deep packet inspection and hence Cisco calls it 'IOS firewall' in their Internetwork Operating System (IOS).\nCBAC also provides the following benefits:\n\nDenial-of-service prevention and detection\nReal-time alerts and audit trails\n\n\nQ: How does CBAC manage state information for TCP and UDP sessions?",
    "context": "",
    "output": "CBAC inspects traffic that travels through the firewall to discover and manage state information for TCP and UDP sessions. This state information is used to create temporary openings in the firewall's access lists to allow return traffic and additional data connections for permissible sessions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does CBAC manage state information for TCP and UDP sessions?",
      "answer": "CBAC inspects traffic that travels through the firewall to discover and manage state information for TCP and UDP sessions. This state information is used to create temporary openings in the firewall's access lists to allow return traffic and additional data connections for permissible sessions.",
      "context": "Context-based access control\n\n==Introduction==\nContext-based access control (CBAC) is a feature of firewall software, which intelligently filters TCP and UDP packets based on application layer protocol session information. It can be used for intranets, extranets and internets.CBAC can be configured to permit specified TCP and UDP traffic through a firewall only when the connection is initiated from within the network needing protection. (In other words, CBAC can inspect traffic for sessions that originate from the external network.) However, while this example discusses inspecting traffic for sessions that originate from the external network, CBAC can inspect traffic for sessions that originate from either side of the firewall. This is the basic function of a stateful inspection firewall.Without CBAC, traffic filtering is limited to access list implementations that examine packets at the network layer, or at most, the transport layer. However, CBAC examines not only network layer and transport layer information but also examines the application-layer protocol information (such as FTP connection information) to learn about the state of the TCP or UDP session. This allows support of protocols that involve multiple channels created as a result of negotiations in the FTP control channel. Most of the multimedia protocols as well as some other protocols (such as FTP, RPC, and SQL*Net) involve multiple control channels.\nCBAC inspects traffic that travels through the firewall to discover and manage state information for TCP and UDP sessions. This state information is used to create temporary openings in the firewall's access lists to allow return traffic and additional data connections for permissible sessions (sessions that originated from within the protected internal network).\nCBAC works through deep packet inspection and hence Cisco calls it 'IOS firewall' in their Internetwork Operating System (IOS).\nCBAC also provides the following benefits:\n\nDenial-of-service prevention and detection\nReal-time alerts and audit trails\n\n"
    }
  },
  {
    "instruction": "Context: Akbot\n\n==Introduction==\nAkbot was a computer virus that infected an estimated 1.3 million computers and added them to a botnet. It was created by an 18-year-old named Owen Walker, who was charged but unconvicted in 2008.\n\n== Infection ==\nAkbot is an IRC controlled backdoor program. It allows an outside user to take control of the infected computer. Akbot operates by joining IRC servers and the waiting for further instructions. Once installed, Akbot can be used to gather data, kill processes, or perform DDOS attacks.\nAnswer this question: Can Akbot infect Mac computers?",
    "context": "",
    "output": "The text does not provide information on whether Akbot can infect Mac computers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can Akbot infect Mac computers?",
      "answer": "The text does not provide information on whether Akbot can infect Mac computers.",
      "context": "Akbot\n\n==Introduction==\nAkbot was a computer virus that infected an estimated 1.3 million computers and added them to a botnet. It was created by an 18-year-old named Owen Walker, who was charged but unconvicted in 2008.\n\n== Infection ==\nAkbot is an IRC controlled backdoor program. It allows an outside user to take control of the infected computer. Akbot operates by joining IRC servers and the waiting for further instructions. Once installed, Akbot can be used to gather data, kill processes, or perform DDOS attacks."
    }
  },
  {
    "instruction": "TESO (Austrian hacker group)\n\n==Introduction==\nTESO was a  hacker group, which originated in Austria. It was active from 1998 to 2004, and during its peak around 2000, it was responsible for a significant share of the exploits on the bugtraq mailing list.\n\n\n\n== Achievements ==\nIn 2000, developed hellkit, the first shellcode generator.\nIn 2000, wrote TesoGCC, the first format string vulnerability scanner, and the first comprehensive guide on format string exploitation.\nBurnEye team member is widely believed to be one of the first proper ELF executable crypters.\n\n== Quotes ==\nADM and TESO made almost inappropriately large splashes in the community when they were active. Almost all their exploits were beyond the standard, and at times it seemed they were the ones finding all the new bug-classes. But at their peak, they couldn't have been very large groups. Certainly smaller than the reverse engineering and security group at a good sized IDS/IPS company these days.\n\n== Members and name ==\n\nThe name originally was an acronym of the nicknames of the original founders (typo, edi, stanly, oxigen), but as many of the most skilled members joined later, this interpretation quickly became meaningless. Teso originally and during its peak was a small and tightly knit group. A full list of members does not appear to exist, but if public sources can be trusted, at least the following members existed:\n\nAbdullah Khann\ncaddis\nedi\nhalvar\nhendy\nlorian\noxigen\npalmers\nrandomizer\nscut, published in September 2001 Exploiting format strings vulnerabilies paper\nsmiler\nskyper\nstealth/S.Krahmer\nstanly\ntypo aka Paul Bohm\nxdr/mdr\nzip\nQ: Who was widely believed to be one of the first proper ELF executable crypters in the BurnEye team?",
    "context": "",
    "output": "A member of the BurnEye team, who was widely believed to be one of the first proper ELF executable crypters, is not explicitly named in the text.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who was widely believed to be one of the first proper ELF executable crypters in the BurnEye team?",
      "answer": "A member of the BurnEye team, who was widely believed to be one of the first proper ELF executable crypters, is not explicitly named in the text.",
      "context": "TESO (Austrian hacker group)\n\n==Introduction==\nTESO was a  hacker group, which originated in Austria. It was active from 1998 to 2004, and during its peak around 2000, it was responsible for a significant share of the exploits on the bugtraq mailing list.\n\n\n\n== Achievements ==\nIn 2000, developed hellkit, the first shellcode generator.\nIn 2000, wrote TesoGCC, the first format string vulnerability scanner, and the first comprehensive guide on format string exploitation.\nBurnEye team member is widely believed to be one of the first proper ELF executable crypters.\n\n== Quotes ==\nADM and TESO made almost inappropriately large splashes in the community when they were active. Almost all their exploits were beyond the standard, and at times it seemed they were the ones finding all the new bug-classes. But at their peak, they couldn't have been very large groups. Certainly smaller than the reverse engineering and security group at a good sized IDS/IPS company these days.\n\n== Members and name ==\n\nThe name originally was an acronym of the nicknames of the original founders (typo, edi, stanly, oxigen), but as many of the most skilled members joined later, this interpretation quickly became meaningless. Teso originally and during its peak was a small and tightly knit group. A full list of members does not appear to exist, but if public sources can be trusted, at least the following members existed:\n\nAbdullah Khann\ncaddis\nedi\nhalvar\nhendy\nlorian\noxigen\npalmers\nrandomizer\nscut, published in September 2001 Exploiting format strings vulnerabilies paper\nsmiler\nskyper\nstealth/S.Krahmer\nstanly\ntypo aka Paul Bohm\nxdr/mdr\nzip"
    }
  },
  {
    "instruction": "Write an answer to the following question: What can be inferred about Novell's commitment to the development and maintenance of Immunix's products after the acquisition and subsequent layoff of the AppArmor team?",
    "context": "",
    "output": "Novell's commitment to the development and maintenance of Immunix's products appears to have been reduced after the acquisition and layoff of the AppArmor team. Although Novell initially adopted AppArmor and integrated it into their portfolio, the layoff of the dedicated team might have implied a decreased focus on this product, potentially leading to slower development cycles, less frequent updates, or reduced user support.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What can be inferred about Novell's commitment to the development and maintenance of Immunix's products after the acquisition and subsequent layoff of the AppArmor team?",
      "answer": "Novell's commitment to the development and maintenance of Immunix's products appears to have been reduced after the acquisition and layoff of the AppArmor team. Although Novell initially adopted AppArmor and integrated it into their portfolio, the layoff of the dedicated team might have implied a decreased focus on this product, potentially leading to slower development cycles, less frequent updates, or reduced user support."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do most protocols in the noisy-storage model proceed?",
    "context": "",
    "output": "Most protocols in the noisy-storage model proceed in two steps. The first step is the exchange of qubits encoded in two or three mutually unbiased bases, and the second step is classical post-processing of the measurement data obtained in step one.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do most protocols in the noisy-storage model proceed?",
      "answer": "Most protocols in the noisy-storage model proceed in two steps. The first step is the exchange of qubits encoded in two or three mutually unbiased bases, and the second step is classical post-processing of the measurement data obtained in step one."
    }
  },
  {
    "instruction": "Answer based on context:\n\nInitiative for Open Authentication\n\n==Introduction==\nInitiative for Open Authentication (OATH) is an industry-wide collaboration to develop an open reference architecture using open standards to promote the adoption of strong authentication. It has close to thirty coordinating and contributing members and is proposing standards for a variety of authentication technologies, with the aim of lowering costs and simplifying their functions.\n\n== Terminology ==\nThe name OATH is an acronym from the phrase \"open authentication\", and is pronounced as the English word \"oath\".OATH is not related to OAuth, an open standard for authorization.\n\nHow does the Initiative for Open Authentication contribute to the global adoption of robust authentication methods?",
    "context": "",
    "output": "OATH facilitates the global adoption of robust authentication methods by establishing open standards, reducing costs, and simplifying the functions of various authentication technologies, making them more accessible and practical for businesses and organizations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Initiative for Open Authentication contribute to the global adoption of robust authentication methods?",
      "answer": "OATH facilitates the global adoption of robust authentication methods by establishing open standards, reducing costs, and simplifying the functions of various authentication technologies, making them more accessible and practical for businesses and organizations.",
      "context": "Initiative for Open Authentication\n\n==Introduction==\nInitiative for Open Authentication (OATH) is an industry-wide collaboration to develop an open reference architecture using open standards to promote the adoption of strong authentication. It has close to thirty coordinating and contributing members and is proposing standards for a variety of authentication technologies, with the aim of lowering costs and simplifying their functions.\n\n== Terminology ==\nThe name OATH is an acronym from the phrase \"open authentication\", and is pronounced as the English word \"oath\".OATH is not related to OAuth, an open standard for authorization."
    }
  },
  {
    "instruction": "context: Reality hacking is the nonviolent use of illegal or legally ambiguous digital tools in pursuit of politically, socially, or culturally subversive ends. These tools include website defacements, URL redirections, denial-of-service attacks, information theft, web-site parodies, virtual sit-ins, and virtual sabotage. Reality hacking relies on tweaking everyday communications to awaken the political and community conscience of the larger population.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is reality hacking and how does it relate to hacktivism?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is reality hacking and how does it relate to hacktivism?",
      "answer": "Reality hacking is the nonviolent use of illegal or legally ambiguous digital tools in pursuit of politically, socially, or culturally subversive ends. These tools include website defacements, URL redirections, denial-of-service attacks, information theft, web-site parodies, virtual sit-ins, and virtual sabotage. Reality hacking relies on tweaking everyday communications to awaken the political and community conscience of the larger population."
    }
  },
  {
    "instruction": "Qualified digital certificate\n\n==Introduction==\nIn the context of Regulation (EU) No 910/2014 (eIDAS), a qualified digital certificate is a public key certificate issued by a trust service provider which has government-issued qualifications. The certificate is designed to ensure the authenticity and data integrity of an electronic signature and its accompanying message and/or attached data.\n\n== Description ==\neIDAS defines several tiers of electronic signatures that can be used in conducting public sector and private transactions within and across the borders of EU member states. A qualified digital certificate, in addition to other specific services provided by a qualified trust service provider, is required to elevate the status of an electronic signature to that of being considered a qualified electronic signature. Using cryptography, the digital certificate, also known as a public key certificate, contains information to link it to its owner and the digital signature of the trust entity that verifies the authenticity of the content that has been signed.\nAccording to eIDAS, to be considered a qualified digital certificate, the certificate must meet the requirements provided in Annex I of Regulation (EU) No 910/2014, including, but not limited to:\nIdentification that the certificate is a qualified certificate for electronic signature\nIdentification of the qualified trust service provider who issued the qualified certificate, including such information\nCorresponding electronic signature validation data and electronic signature creation data\nIndication of the certificate's period of validity\nUnique certificate identity code of the trust service provider\nQualified trust service provider's advanced electronic signature or electronic seal\n\n== Vision ==\nThe need for non-repudiation and authentication of electronic signatures was originally addressed in the Electronic Signatures Directive 1999/93/EC to help facilitate secure transactions, specifically those that occur across the borders of EU Member states. The eIDAS Regulation later replaced the Directive and defined the standards to be used in the creation of qualified digital certificates by trust service providers.\n\n== Role of a qualified trust service provider ==\nA qualified digital certificate can only be issued by a qualified trust service provider that has received authorization from their member state's supervisory body to provide qualified trust services for creating qualified electronic signatures. The provider must be listed upon the EU Trust List; otherwise, they are not permitted to provide qualified digital certificates or other qualified trust services.\nThe trust service provider is required to abide by the guidelines established under eIDAS for creating qualified digital certificate, which include:\nProviding a valid date and time stamp of when the certificate was created,\nimmediate revocation of any signature that has an expired certificate,\nproviding appropriate training to all their employees who are involved with providing trust services,\nany equipment or software that is used for trust services must be trustworthy and capable of preventing certificates from being forged.\n\n== Legal implications of electronic signatures with qualified digital certificates ==\nIn court, a qualified electronic signature provided the highest level of probative value, which makes it difficult to refute its authorship. A qualified electronic signature, along with its qualified certificate is given the same consideration as a handwritten signature when used as evidence in legal proceedings. The validity of a qualified electronic signature that has been created with a qualified certificate must be accepted by other EU member states regardless of which member state the signature was produced in.\n\n== Global perspective ==\nIn other parts of the world, similar concepts have been created to define standards for electronic signatures. In Switzerland, the digital signing standard ZertES has comparable standards that address the conformity and regulation of trust service providers who product digital certificates.In the United States, the NIST Digital Signature Standard (DSS) does not provide a comparable standard for regulating qualified certificates that would address non-repudiation of a signatory's qualified certificate. An amendment to NIST DSS is currently being discussed that would be more in-line with how eIDAS and ZertES handle trusted services.\n\nWhat is the significance of a qualified digital certificate's unique certificate identity code?",
    "context": "",
    "output": "A: The unique certificate identity code of the trust service provider in a qualified digital certificate is one of the requirements for the certificate to be considered qualified under eIDAS. It helps to identify the qualified trust service provider who issued the qualified certificate.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of a qualified digital certificate's unique certificate identity code?",
      "answer": "The unique certificate identity code of the trust service provider in a qualified digital certificate is one of the requirements for the certificate to be considered qualified under eIDAS. It helps to identify the qualified trust service provider who issued the qualified certificate.",
      "context": "Qualified digital certificate\n\n==Introduction==\nIn the context of Regulation (EU) No 910/2014 (eIDAS), a qualified digital certificate is a public key certificate issued by a trust service provider which has government-issued qualifications. The certificate is designed to ensure the authenticity and data integrity of an electronic signature and its accompanying message and/or attached data.\n\n== Description ==\neIDAS defines several tiers of electronic signatures that can be used in conducting public sector and private transactions within and across the borders of EU member states. A qualified digital certificate, in addition to other specific services provided by a qualified trust service provider, is required to elevate the status of an electronic signature to that of being considered a qualified electronic signature. Using cryptography, the digital certificate, also known as a public key certificate, contains information to link it to its owner and the digital signature of the trust entity that verifies the authenticity of the content that has been signed.\nAccording to eIDAS, to be considered a qualified digital certificate, the certificate must meet the requirements provided in Annex I of Regulation (EU) No 910/2014, including, but not limited to:\nIdentification that the certificate is a qualified certificate for electronic signature\nIdentification of the qualified trust service provider who issued the qualified certificate, including such information\nCorresponding electronic signature validation data and electronic signature creation data\nIndication of the certificate's period of validity\nUnique certificate identity code of the trust service provider\nQualified trust service provider's advanced electronic signature or electronic seal\n\n== Vision ==\nThe need for non-repudiation and authentication of electronic signatures was originally addressed in the Electronic Signatures Directive 1999/93/EC to help facilitate secure transactions, specifically those that occur across the borders of EU Member states. The eIDAS Regulation later replaced the Directive and defined the standards to be used in the creation of qualified digital certificates by trust service providers.\n\n== Role of a qualified trust service provider ==\nA qualified digital certificate can only be issued by a qualified trust service provider that has received authorization from their member state's supervisory body to provide qualified trust services for creating qualified electronic signatures. The provider must be listed upon the EU Trust List; otherwise, they are not permitted to provide qualified digital certificates or other qualified trust services.\nThe trust service provider is required to abide by the guidelines established under eIDAS for creating qualified digital certificate, which include:\nProviding a valid date and time stamp of when the certificate was created,\nimmediate revocation of any signature that has an expired certificate,\nproviding appropriate training to all their employees who are involved with providing trust services,\nany equipment or software that is used for trust services must be trustworthy and capable of preventing certificates from being forged.\n\n== Legal implications of electronic signatures with qualified digital certificates ==\nIn court, a qualified electronic signature provided the highest level of probative value, which makes it difficult to refute its authorship. A qualified electronic signature, along with its qualified certificate is given the same consideration as a handwritten signature when used as evidence in legal proceedings. The validity of a qualified electronic signature that has been created with a qualified certificate must be accepted by other EU member states regardless of which member state the signature was produced in.\n\n== Global perspective ==\nIn other parts of the world, similar concepts have been created to define standards for electronic signatures. In Switzerland, the digital signing standard ZertES has comparable standards that address the conformity and regulation of trust service providers who product digital certificates.In the United States, the NIST Digital Signature Standard (DSS) does not provide a comparable standard for regulating qualified certificates that would address non-repudiation of a signatory's qualified certificate. An amendment to NIST DSS is currently being discussed that would be more in-line with how eIDAS and ZertES handle trusted services."
    }
  },
  {
    "instruction": "Generic Security Services Application Program Interface\n\n==Introduction==\nThe Generic Security Service Application Program Interface (GSSAPI, also GSS-API) is an application programming interface for programs to access security services.\nThe GSSAPI is an IETF standard that addresses the problem of many similar but incompatible security services in use as of 2005.\n\n== Operation ==\nThe GSSAPI, by itself, does not provide any security. Instead, security-service vendors provide GSSAPI implementations - usually in the form of libraries installed with their security software. These libraries present a GSSAPI-compatible interface to application writers who can write their application to use only the vendor-independent GSSAPI.\nIf the security implementation ever needs replacing, the application need not be rewritten.\nThe definitive feature of GSSAPI applications is the exchange of opaque messages (tokens) which hide the implementation detail from the higher-level application.\nThe client and server sides of the application are written to convey the tokens given to them by\ntheir respective GSSAPI implementations.\nGSSAPI tokens can usually travel over an insecure network as the mechanisms provide inherent message security.\nAfter the exchange of some number of tokens, the GSSAPI implementations at both ends inform their local application that a security context is established.\nOnce a security context is established, sensitive application messages can be wrapped (encrypted) by the GSSAPI for secure communication between client and server.\nTypical protections guaranteed by GSSAPI wrapping include confidentiality (secrecy) and integrity (authenticity). The GSSAPI can also provide local guarantees about the identity of the remote user or remote host.\nThe GSSAPI describes about 45 procedure calls. Significant ones include:\n\nGSS_Acquire_cred\nObtains the user's identity proof, often a secret cryptographic key\nGSS_Import_name\nConverts a username or hostname into a form that identifies a security entity\nGSS_Init_sec_context\nGenerates a client token to send to the server, usually a challenge\nGSS_Accept_sec_context\nProcesses a token from GSS_Init_sec_context and can generate a response token to return\nGSS_Wrap\nConverts application data into a secure message token (typically encrypted)\nGSS_Unwrap\nConverts a secure message token back into application dataThe GSSAPI is standardized for the C (RFC 2744) language. Java implements the GSSAPI\nas JGSS,\nthe Java Generic Security Services Application Program Interface.Some limitations of GSSAPI are:\n\nstandardizing only authentication, rather not authorization too;\nassuming a client\u2013server architecture.Anticipating new security mechanisms, the GSSAPI includes a negotiating pseudo mechanism, SPNEGO, that can discover and use new mechanisms not present when the original application was built.\n\n== Relationship to Kerberos ==\nThe dominant GSSAPI mechanism implementation in use is Kerberos.\nUnlike the GSSAPI, the Kerberos API has not been standardized\nand various existing implementations use incompatible APIs.\nThe GSSAPI allows Kerberos implementations to be API compatible.\n\n== Related technologies ==\nRADIUS\nSASL\nTLS\nSSPI\nSPNEGO\nRPCSEC GSS\n\n== Key concepts ==\nName\nA binary string that labels a security principal (i.e., user or service program) - see access control and identity. For example, Kerberos uses names like user@REALM for users and service/hostname@REALM for programs.\nCredentials\nInformation that proves an identity; used by an entity to act as the named principal. Credentials typically involve a secret cryptographic key.\nContext\nThe state of one end of the authenticating/authenticated protocol. May provide message protection services, which can be used to compose a secure channel.\nTokens\nOpaque messages exchanged either as part of the initial authentication protocol (context-level tokens), or as part of a protected communication (per-message tokens)\nMechanism\nAn underlying GSSAPI implementation that provides actual names, tokens and credentials. Known mechanisms include Kerberos, NTLM, Distributed Computing Environment (DCE), SESAME, SPKM, LIPKEY.\nInitiator/acceptor\nThe peer that sends the first token is the initiator; the other is the acceptor. Generally, the client program is the initiator while the server is the acceptor.\nQuestion: What is the role of security-service vendors in the GSSAPI?",
    "context": "",
    "output": "Answer: Security-service vendors provide GSSAPI implementations, usually in the form of libraries installed with their security software. These libraries present a GSSAPI-compatible interface to application writers who can write their application to use only the vendor-independent GSSAPI. This means that if the security implementation ever needs replacing, the application need not be rewritten.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of security-service vendors in the GSSAPI?",
      "answer": "Security-service vendors provide GSSAPI implementations, usually in the form of libraries installed with their security software. These libraries present a GSSAPI-compatible interface to application writers who can write their application to use only the vendor-independent GSSAPI. This means that if the security implementation ever needs replacing, the application need not be rewritten.",
      "context": "Generic Security Services Application Program Interface\n\n==Introduction==\nThe Generic Security Service Application Program Interface (GSSAPI, also GSS-API) is an application programming interface for programs to access security services.\nThe GSSAPI is an IETF standard that addresses the problem of many similar but incompatible security services in use as of 2005.\n\n== Operation ==\nThe GSSAPI, by itself, does not provide any security. Instead, security-service vendors provide GSSAPI implementations - usually in the form of libraries installed with their security software. These libraries present a GSSAPI-compatible interface to application writers who can write their application to use only the vendor-independent GSSAPI.\nIf the security implementation ever needs replacing, the application need not be rewritten.\nThe definitive feature of GSSAPI applications is the exchange of opaque messages (tokens) which hide the implementation detail from the higher-level application.\nThe client and server sides of the application are written to convey the tokens given to them by\ntheir respective GSSAPI implementations.\nGSSAPI tokens can usually travel over an insecure network as the mechanisms provide inherent message security.\nAfter the exchange of some number of tokens, the GSSAPI implementations at both ends inform their local application that a security context is established.\nOnce a security context is established, sensitive application messages can be wrapped (encrypted) by the GSSAPI for secure communication between client and server.\nTypical protections guaranteed by GSSAPI wrapping include confidentiality (secrecy) and integrity (authenticity). The GSSAPI can also provide local guarantees about the identity of the remote user or remote host.\nThe GSSAPI describes about 45 procedure calls. Significant ones include:\n\nGSS_Acquire_cred\nObtains the user's identity proof, often a secret cryptographic key\nGSS_Import_name\nConverts a username or hostname into a form that identifies a security entity\nGSS_Init_sec_context\nGenerates a client token to send to the server, usually a challenge\nGSS_Accept_sec_context\nProcesses a token from GSS_Init_sec_context and can generate a response token to return\nGSS_Wrap\nConverts application data into a secure message token (typically encrypted)\nGSS_Unwrap\nConverts a secure message token back into application dataThe GSSAPI is standardized for the C (RFC 2744) language. Java implements the GSSAPI\nas JGSS,\nthe Java Generic Security Services Application Program Interface.Some limitations of GSSAPI are:\n\nstandardizing only authentication, rather not authorization too;\nassuming a client\u2013server architecture.Anticipating new security mechanisms, the GSSAPI includes a negotiating pseudo mechanism, SPNEGO, that can discover and use new mechanisms not present when the original application was built.\n\n== Relationship to Kerberos ==\nThe dominant GSSAPI mechanism implementation in use is Kerberos.\nUnlike the GSSAPI, the Kerberos API has not been standardized\nand various existing implementations use incompatible APIs.\nThe GSSAPI allows Kerberos implementations to be API compatible.\n\n== Related technologies ==\nRADIUS\nSASL\nTLS\nSSPI\nSPNEGO\nRPCSEC GSS\n\n== Key concepts ==\nName\nA binary string that labels a security principal (i.e., user or service program) - see access control and identity. For example, Kerberos uses names like user@REALM for users and service/hostname@REALM for programs.\nCredentials\nInformation that proves an identity; used by an entity to act as the named principal. Credentials typically involve a secret cryptographic key.\nContext\nThe state of one end of the authenticating/authenticated protocol. May provide message protection services, which can be used to compose a secure channel.\nTokens\nOpaque messages exchanged either as part of the initial authentication protocol (context-level tokens), or as part of a protected communication (per-message tokens)\nMechanism\nAn underlying GSSAPI implementation that provides actual names, tokens and credentials. Known mechanisms include Kerberos, NTLM, Distributed Computing Environment (DCE), SESAME, SPKM, LIPKEY.\nInitiator/acceptor\nThe peer that sends the first token is the initiator; the other is the acceptor. Generally, the client program is the initiator while the server is the acceptor."
    }
  },
  {
    "instruction": "Pseudonymous remailer\n\n==Introduction==\nA pseudonymous remailer or nym server, as opposed to an anonymous remailer, is an Internet software program designed to allow people to write pseudonymous messages on Usenet newsgroups and send pseudonymous email.  Unlike purely anonymous remailers, it assigns its users a user name, and it keeps a database of instructions on how to return messages to the real user.   These instructions usually involve the anonymous remailer network itself, thus protecting the true identity of the user.\nPrimordial pseudonymous remailers once recorded enough information to trace the identity of the real user, making it possible for someone to obtain the identity of the real user through legal or illegal means. This form of pseudonymous remailer is no longer common.\nDavid Chaum wrote an article in 1981 that described many of the features present in  modern pseudonymous remailers.The Penet remailer, which lasted from 1993 to 1996, was a popular pseudonymous remailer.\n\n\n\n== Contemporary nym servers ==\nA nym server (short for \"pseudonym server\") is a server that provides an untraceable e-mail address, such that neither the nym server operator nor the operators of the remailers involved can discover which nym corresponds to which real identity.\nTo set up a nym, you create a PGP keypair and submit it to the nym server, along with instructions (called a reply block) to anonymous remailers (such as Cypherpunk or Mixmaster) on how to send a message to your real address. The nym server returns a confirmation through this reply block. You then send a message to the address in the confirmation.\nTo send a message through the nym server so that the From address is the nym, you add a few headers, sign the message with your nym key, encrypt it with the nym server key, and send the message to the nym server, probably routed through some anonymous remailers. When the nym server gets the message, it decrypts the message and sends it on to the intended recipient, with the From: address being your nym.\nWhen the nym server gets a message addressed to the nym, it appends it to the nym's reply block and sends it to the first remailer in the chain, which sends it to the next and so on until it reaches your real address. It is considered good practice to include instructions to encrypt it on the way, so that someone (or some organization) doing in/out traffic analysis on the nym server cannot easily match the message received by you to the one sent by the nym server.\nExisting \"multi-use reply block\" nym servers were shown to be susceptible to passive traffic analysis with one month's worth of incoming spam (based on 2005 figures) in a paper by Bram Cohen, Len Sassaman, and Nick Mathewson.\n\nBased on the above text, answer a question. What information did primordial pseudonymous remailers once record that made it possible for someone to obtain the identity of the real user?",
    "context": "",
    "output": "Primordial pseudonymous remailers once recorded enough information such as the real user's identity, making it possible for someone to obtain the identity of the real user through legal or illegal means.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What information did primordial pseudonymous remailers once record that made it possible for someone to obtain the identity of the real user?",
      "answer": "Primordial pseudonymous remailers once recorded enough information such as the real user's identity, making it possible for someone to obtain the identity of the real user through legal or illegal means.",
      "context": "Pseudonymous remailer\n\n==Introduction==\nA pseudonymous remailer or nym server, as opposed to an anonymous remailer, is an Internet software program designed to allow people to write pseudonymous messages on Usenet newsgroups and send pseudonymous email.  Unlike purely anonymous remailers, it assigns its users a user name, and it keeps a database of instructions on how to return messages to the real user.   These instructions usually involve the anonymous remailer network itself, thus protecting the true identity of the user.\nPrimordial pseudonymous remailers once recorded enough information to trace the identity of the real user, making it possible for someone to obtain the identity of the real user through legal or illegal means. This form of pseudonymous remailer is no longer common.\nDavid Chaum wrote an article in 1981 that described many of the features present in  modern pseudonymous remailers.The Penet remailer, which lasted from 1993 to 1996, was a popular pseudonymous remailer.\n\n\n\n== Contemporary nym servers ==\nA nym server (short for \"pseudonym server\") is a server that provides an untraceable e-mail address, such that neither the nym server operator nor the operators of the remailers involved can discover which nym corresponds to which real identity.\nTo set up a nym, you create a PGP keypair and submit it to the nym server, along with instructions (called a reply block) to anonymous remailers (such as Cypherpunk or Mixmaster) on how to send a message to your real address. The nym server returns a confirmation through this reply block. You then send a message to the address in the confirmation.\nTo send a message through the nym server so that the From address is the nym, you add a few headers, sign the message with your nym key, encrypt it with the nym server key, and send the message to the nym server, probably routed through some anonymous remailers. When the nym server gets the message, it decrypts the message and sends it on to the intended recipient, with the From: address being your nym.\nWhen the nym server gets a message addressed to the nym, it appends it to the nym's reply block and sends it to the first remailer in the chain, which sends it to the next and so on until it reaches your real address. It is considered good practice to include instructions to encrypt it on the way, so that someone (or some organization) doing in/out traffic analysis on the nym server cannot easily match the message received by you to the one sent by the nym server.\nExisting \"multi-use reply block\" nym servers were shown to be susceptible to passive traffic analysis with one month's worth of incoming spam (based on 2005 figures) in a paper by Bram Cohen, Len Sassaman, and Nick Mathewson."
    }
  },
  {
    "instruction": "BPCS-steganography\n\n==Introduction==\nBPCS-steganography (Bit-Plane Complexity Segmentation steganography)  is a type of digital steganography.\nDigital steganography can hide confidential data (i.e. secret files) very securely by embedding them into some media data called \"vessel data.\" The vessel data is also referred to as \"carrier, cover, or dummy data\". In BPCS-steganography true color images (i.e., 24-bit color images) are mostly used for vessel data. The embedding operation in practice is to replace the \"complex areas\" on the bit planes of the vessel image with the confidential data. The most important aspect of BPCS-steganography is that the embedding capacity is very large. In comparison to simple image based steganography which uses solely the least important bit of data, and thus (for a 24-bit color image) can only embed data equivalent to 1/8 of the total size, BPCS-steganography uses multiple bit-planes, and so can embed a much higher amount of data, though this is dependent on the individual image. For a 'normal' image, roughly 50% of the data might be replaceable with secret data before image degradation becomes apparent.\n\n\n\n== Principle of embedding ==\nThe Human visual system has such a special property that a too-complicated visual pattern can not be perceived as \"shape-informative.\" For example, on a very flat beach shore every single square-foot area looks the same - it is just a sandy area, no shape is observed. However, if you look carefully, two same-looking areas are entirely different in their sand particle shapes. BPCS-steganography makes use of this property. It replaces complex areas on the bit-planes of the vessel image with other complex data patterns (i.e., pieces of secret files). This replacing operation is called \"embedding.\" No one can see any difference between the two vessel images of before and after the embedding operation.\nAn issue arises where the data to be embedded appears visually as simple information, if this simple information replaces the complex information in the original image it may create spurious 'real image information'. In this case the data is passed through a [binary image conjugation transformation], in order to create a reciprocal complex representation.\n\n== Present status of research and development ==\nThis form of steganography was proposed jointly by Eiji Kawaguchi and Richard O. Eason in 1998. Their experimental program (titled Qtech Hide & View) is freely available for educational purposes. Recently, many researchers are tackling its algorithm improvement and applications as well as resistibility studies against steganalysis.\nQ: What is the impact of image degradation on BPCS-steganography's embedding capacity?",
    "context": "",
    "output": "Image degradation due to excessive data embedding reduces BPCS-steganography's embedding capacity. The principle behind BPCS-steganography ensures that up to 50% of a 'normal' image can be replaced with secret data before degradation becomes apparent.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the impact of image degradation on BPCS-steganography's embedding capacity?",
      "answer": "Image degradation due to excessive data embedding reduces BPCS-steganography's embedding capacity. The principle behind BPCS-steganography ensures that up to 50% of a 'normal' image can be replaced with secret data before degradation becomes apparent.",
      "context": "BPCS-steganography\n\n==Introduction==\nBPCS-steganography (Bit-Plane Complexity Segmentation steganography)  is a type of digital steganography.\nDigital steganography can hide confidential data (i.e. secret files) very securely by embedding them into some media data called \"vessel data.\" The vessel data is also referred to as \"carrier, cover, or dummy data\". In BPCS-steganography true color images (i.e., 24-bit color images) are mostly used for vessel data. The embedding operation in practice is to replace the \"complex areas\" on the bit planes of the vessel image with the confidential data. The most important aspect of BPCS-steganography is that the embedding capacity is very large. In comparison to simple image based steganography which uses solely the least important bit of data, and thus (for a 24-bit color image) can only embed data equivalent to 1/8 of the total size, BPCS-steganography uses multiple bit-planes, and so can embed a much higher amount of data, though this is dependent on the individual image. For a 'normal' image, roughly 50% of the data might be replaceable with secret data before image degradation becomes apparent.\n\n\n\n== Principle of embedding ==\nThe Human visual system has such a special property that a too-complicated visual pattern can not be perceived as \"shape-informative.\" For example, on a very flat beach shore every single square-foot area looks the same - it is just a sandy area, no shape is observed. However, if you look carefully, two same-looking areas are entirely different in their sand particle shapes. BPCS-steganography makes use of this property. It replaces complex areas on the bit-planes of the vessel image with other complex data patterns (i.e., pieces of secret files). This replacing operation is called \"embedding.\" No one can see any difference between the two vessel images of before and after the embedding operation.\nAn issue arises where the data to be embedded appears visually as simple information, if this simple information replaces the complex information in the original image it may create spurious 'real image information'. In this case the data is passed through a [binary image conjugation transformation], in order to create a reciprocal complex representation.\n\n== Present status of research and development ==\nThis form of steganography was proposed jointly by Eiji Kawaguchi and Richard O. Eason in 1998. Their experimental program (titled Qtech Hide & View) is freely available for educational purposes. Recently, many researchers are tackling its algorithm improvement and applications as well as resistibility studies against steganalysis."
    }
  },
  {
    "instruction": "Context: Dropbear (software)\n\n==Introduction==\nDropbear is a software package written by Matt Johnston that provides a Secure Shell-compatible server and client. It is designed as a replacement for standard OpenSSH for environments with low memory and processor resources, such as embedded systems. It is a core component of OpenWrt and other router distributions.\nDropbear was originally released in April 2003.\n\n== Technology ==\nDropbear implements version 2 of the Secure Shell (SSH) protocol.The cryptographic algorithms are implemented using third-party cryptographic libraries like LibTomCrypt  included internally in the Dropbear distribution. It derives some parts from OpenSSH to handle BSD-style pseudo terminals.\n\n== Features ==\nDropbear implements the complete SSH version 2 protocol in both the client and the server. It does not support SSH version 1 backwards-compatibility in order to save space and resources, and to avoid the inherent security vulnerabilities in SSH version 1. SCP is also implemented. SFTP support relies on a binary file which can be provided by OpenSSH or similar programs. FISH works in any case and is supported by Konqueror. \nDropbear supports elliptic curve cryptography for key exchange, as of version 2013.61test and beyond.\nAnswer this question: Since when does Dropbear support elliptic curve cryptography for key exchange?",
    "context": "",
    "output": "Dropbear has supported elliptic curve cryptography for key exchange since version 2013.61test.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Since when does Dropbear support elliptic curve cryptography for key exchange?",
      "answer": "Dropbear has supported elliptic curve cryptography for key exchange since version 2013.61test.",
      "context": "Dropbear (software)\n\n==Introduction==\nDropbear is a software package written by Matt Johnston that provides a Secure Shell-compatible server and client. It is designed as a replacement for standard OpenSSH for environments with low memory and processor resources, such as embedded systems. It is a core component of OpenWrt and other router distributions.\nDropbear was originally released in April 2003.\n\n== Technology ==\nDropbear implements version 2 of the Secure Shell (SSH) protocol.The cryptographic algorithms are implemented using third-party cryptographic libraries like LibTomCrypt  included internally in the Dropbear distribution. It derives some parts from OpenSSH to handle BSD-style pseudo terminals.\n\n== Features ==\nDropbear implements the complete SSH version 2 protocol in both the client and the server. It does not support SSH version 1 backwards-compatibility in order to save space and resources, and to avoid the inherent security vulnerabilities in SSH version 1. SCP is also implemented. SFTP support relies on a binary file which can be provided by OpenSSH or similar programs. FISH works in any case and is supported by Konqueror. \nDropbear supports elliptic curve cryptography for key exchange, as of version 2013.61test and beyond."
    }
  },
  {
    "instruction": "context: The challenge is that it becomes an immense task when thousands of sources of data or voice may be present, and all signals from every communications source being routed through the fiber must be sorted for relevant data.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the challenge in sorting signals from every communications source in a tapped fiber?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the challenge in sorting signals from every communications source in a tapped fiber?",
      "answer": "The challenge is that it becomes an immense task when thousands of sources of data or voice may be present, and all signals from every communications source being routed through the fiber must be sorted for relevant data."
    }
  },
  {
    "instruction": "context: The advantages and disadvantages of these approaches depend on the specific implementation and use case. However, the Encrypt-then-MAC approach is generally considered to be the most secure, while the MAC-then-Encrypt approach may be more vulnerable to certain types of attacks such as padding oracle attacks. The Encrypt-and-MAC approach may require additional modifications to ensure strong unforgeability.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are the advantages and disadvantages of the Encrypt-then-MAC, Encrypt-and-MAC, and MAC-then-Encrypt approaches to authenticated encryption?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the advantages and disadvantages of the Encrypt-then-MAC, Encrypt-and-MAC, and MAC-then-Encrypt approaches to authenticated encryption?",
      "answer": "The advantages and disadvantages of these approaches depend on the specific implementation and use case. However, the Encrypt-then-MAC approach is generally considered to be the most secure, while the MAC-then-Encrypt approach may be more vulnerable to certain types of attacks such as padding oracle attacks. The Encrypt-and-MAC approach may require additional modifications to ensure strong unforgeability."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some solutions that fall under the category of identity management?",
    "context": "",
    "output": "Solutions that fall under the category of identity management include management of identities, user account provisioning and de-provisioning, workflow automation, delegated administration, password synchronization, self-service password reset, access control, password manager, single sign-on (SSO), Web single sign-on (Web SSO), role-based access control (RBAC), attribute-based access control (ABAC), directory services, x.500 and LDAP, Microsoft Active Directory, Microsoft Azure Active Directory, NetIQ eDirectory, identity repository, metadata replication and synchronization, directory virtualization, e-Business scale directory systems, next-generation systems, and federation of user access rights on web applications across otherwise untrusted networks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some solutions that fall under the category of identity management?",
      "answer": "Solutions that fall under the category of identity management include management of identities, user account provisioning and de-provisioning, workflow automation, delegated administration, password synchronization, self-service password reset, access control, password manager, single sign-on (SSO), Web single sign-on (Web SSO), role-based access control (RBAC), attribute-based access control (ABAC), directory services, x.500 and LDAP, Microsoft Active Directory, Microsoft Azure Active Directory, NetIQ eDirectory, identity repository, metadata replication and synchronization, directory virtualization, e-Business scale directory systems, next-generation systems, and federation of user access rights on web applications across otherwise untrusted networks."
    }
  },
  {
    "instruction": "Identity driven networking\n\n==Introduction==\nIdentity driven networking (IDN) is the process of applying network controls to a network device access based on the identity of an individual or a group of individuals responsible to or operating the device. Individuals are identified, and the network is tuned to respond to their presence by context.\nThe OSI model provides a method to deliver network traffic, not only to the system but to the application that requested or is listening for data. These applications can operate either as a system based user-daemon process, or as a user application such as a web browser.\nInternet security is built around the idea that the ability to request or respond to requests should be subjected to some degree of authentication, validation, authorization, and policy enforcement. Identity driven networking endeavors to resolve user and system based policy into a single management paradigm.\nSince the internet comprises a vast range of devices and applications there are also many boundaries and therefore ideas on how to resolve connectivity to users within those boundaries. An endeavor to overlay the system with an identity framework must first decide what an Identity is, determine it, and only then use existing controls to decide what is intended with this new information.\n\n\n\n== The Identity ==\nA digital identity represents the connectedness between the real and some projection of an identity; and it may incorporate references to devices as well as resources and policies.\nIn some systems, policies provide the entitlements that an identity can claim at any particular point in time and space. For example, a person may be entitled to some privileges during work from their workplace that may be denied from home out of hours.\n\n== How it might work ==\nBefore a user gets to the network there is usually some form of machine authentication, this probably verifies and configures the system for some basic level of access. Short of mapping a user to a MAC address prior or during this process (802.1x) it is not simple to have users authenticate at this point. It is more usual for a user to attempt to authenticate once the system processes (daemons) are started, and this may well require the network configuration to have already been performed.\nIt follows that, in principle, the network identity of a device should be established before permitting network connectivity, for example by using digital certificates in place of hardware addresses which are trivial to spoof as device identifiers.  Furthermore, a consistent identity model has to account for typical network devices such as routers and switches which can't depend on user identity, since no distinctive user is associated with the device.  Absent this capability in practice, however, strong identity is not asserted at the network level.\nThe first task when seeking to apply Identity Driven Network controls comprises some form of authentication, if not at the device level then further up the stack.  Since the first piece of infrastructure placed upon a network is often a network operating system (NOS) there will often be an Identity Authority that controls the resources that the NOS contains (usually printers and file shares). There will also be procedures to authenticate users onto it. Incorporating some form of single sign-on means that the flow on effect to other controls can be seamless.\nMany network capabilities can be made to rely upon authentication technologies for the provisioning of an access control policy.\nFor instance; Packet filtering -firewall, content-control software, Quota Management systems and Quality of service (QoS) systems are good examples of where controls can be made dependent upon authentication.\nQ: Why is it important to account for typical network devices such as routers and switches in IDN?",
    "context": "",
    "output": "It is important to account for typical network devices such as routers and switches in IDN because they can't depend on user identity, and they need to be authenticated and authorized to access the network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why is it important to account for typical network devices such as routers and switches in IDN?",
      "answer": "It is important to account for typical network devices such as routers and switches in IDN because they can't depend on user identity, and they need to be authenticated and authorized to access the network.",
      "context": "Identity driven networking\n\n==Introduction==\nIdentity driven networking (IDN) is the process of applying network controls to a network device access based on the identity of an individual or a group of individuals responsible to or operating the device. Individuals are identified, and the network is tuned to respond to their presence by context.\nThe OSI model provides a method to deliver network traffic, not only to the system but to the application that requested or is listening for data. These applications can operate either as a system based user-daemon process, or as a user application such as a web browser.\nInternet security is built around the idea that the ability to request or respond to requests should be subjected to some degree of authentication, validation, authorization, and policy enforcement. Identity driven networking endeavors to resolve user and system based policy into a single management paradigm.\nSince the internet comprises a vast range of devices and applications there are also many boundaries and therefore ideas on how to resolve connectivity to users within those boundaries. An endeavor to overlay the system with an identity framework must first decide what an Identity is, determine it, and only then use existing controls to decide what is intended with this new information.\n\n\n\n== The Identity ==\nA digital identity represents the connectedness between the real and some projection of an identity; and it may incorporate references to devices as well as resources and policies.\nIn some systems, policies provide the entitlements that an identity can claim at any particular point in time and space. For example, a person may be entitled to some privileges during work from their workplace that may be denied from home out of hours.\n\n== How it might work ==\nBefore a user gets to the network there is usually some form of machine authentication, this probably verifies and configures the system for some basic level of access. Short of mapping a user to a MAC address prior or during this process (802.1x) it is not simple to have users authenticate at this point. It is more usual for a user to attempt to authenticate once the system processes (daemons) are started, and this may well require the network configuration to have already been performed.\nIt follows that, in principle, the network identity of a device should be established before permitting network connectivity, for example by using digital certificates in place of hardware addresses which are trivial to spoof as device identifiers.  Furthermore, a consistent identity model has to account for typical network devices such as routers and switches which can't depend on user identity, since no distinctive user is associated with the device.  Absent this capability in practice, however, strong identity is not asserted at the network level.\nThe first task when seeking to apply Identity Driven Network controls comprises some form of authentication, if not at the device level then further up the stack.  Since the first piece of infrastructure placed upon a network is often a network operating system (NOS) there will often be an Identity Authority that controls the resources that the NOS contains (usually printers and file shares). There will also be procedures to authenticate users onto it. Incorporating some form of single sign-on means that the flow on effect to other controls can be seamless.\nMany network capabilities can be made to rely upon authentication technologies for the provisioning of an access control policy.\nFor instance; Packet filtering -firewall, content-control software, Quota Management systems and Quality of service (QoS) systems are good examples of where controls can be made dependent upon authentication."
    }
  },
  {
    "instruction": "context: Factorization is the process of decomposing a polynomial into a product of irreducible factors. This decomposition is theoretically possible and unique for polynomials with coefficients in any field. However, specific algorithms have been designed only for polynomials with coefficients in a finite field, the field of rationals, or in a finitely generated field extension of one of them.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the process of factorization in mathematics and computer algebra?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the process of factorization in mathematics and computer algebra?",
      "answer": "Factorization is the process of decomposing a polynomial into a product of irreducible factors. This decomposition is theoretically possible and unique for polynomials with coefficients in any field. However, specific algorithms have been designed only for polynomials with coefficients in a finite field, the field of rationals, or in a finitely generated field extension of one of them."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the ShadowCrew group operate and what kind of items were sold on their website?",
    "context": "",
    "output": "The ShadowCrew group operated a website where members could buy stolen account numbers or counterfeit documents at auction, or read tutorials and how-to's describing the use of cryptography in magnetic strips on credit cards, debit cards, and ATM cards. The website also featured moderators who punished members who did not abide by the site's rules, including providing refunds to buyers if the stolen card numbers proved invalid. In addition to card numbers, numerous other objects of identity theft were sold at auction, including counterfeit passports, drivers\u2019 licenses, Social Security cards, credit cards, debit cards, birth certificates, college student identification cards, and health insurance cards.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the ShadowCrew group operate and what kind of items were sold on their website?",
      "answer": "The ShadowCrew group operated a website where members could buy stolen account numbers or counterfeit documents at auction, or read tutorials and how-to's describing the use of cryptography in magnetic strips on credit cards, debit cards, and ATM cards. The website also featured moderators who punished members who did not abide by the site's rules, including providing refunds to buyers if the stolen card numbers proved invalid. In addition to card numbers, numerous other objects of identity theft were sold at auction, including counterfeit passports, drivers\u2019 licenses, Social Security cards, credit cards, debit cards, birth certificates, college student identification cards, and health insurance cards."
    }
  },
  {
    "instruction": "Internet Security Awareness Training\n\n==Introduction==\nInternet Security Awareness Training (ISAT) is the training given to members of an organization regarding the protection of various information assets of that organization. ISAT is a subset of general security awareness training (SAT).\nEven small and medium enterprises are generally recommended to provide such training, but organizations that need to comply with government regulations (e.g., the Gramm\u2013Leach\u2013Bliley Act, the Payment Card Industry Data Security Standard, Health Insurance Portability and Accountability Act, Sarbox) normally require formal ISAT for annually for all employees. Often such training is provided in the form of online courses.\n\nISAT, also referred to as Security Education, Training, and Awareness (SETA), organizations train and create awareness of information security management within their environment. It is beneficial to organizations when employees are well trained and feel empowered to take important actions to protect themselves and organizational data. The SETA program target must be based on user roles within organizations and for positions that expose the organizations to increased risk levels, specialized courses must be required.\n\n\n\n== Coverage ==\nThere are general topics to cover for the training, but it is necessary for each organization to have a coverage strategy based on its needs, as this will ensure the training is practical and captures critical topics relevant to the organization. As the threat landscape changes very frequently, organizations should continuously review their training programs to ensure relevance with current trends.Topics covered in ISAT include:\n\nAppropriate methods for protecting sensitive information on personal computer systems, including password policy\nVarious computer security concerns, including spam, malware, phishing, social engineering, etc.\nConsequences of failure to properly protect information, including potential job loss, economic consequences to the firm, damage to individuals whose private records are divulged, and possible civil and criminal law penalties.Being Internet Security Aware means you understand that there are people actively trying to steal data that is stored within your organization's computers.  (This often focuses on user names and passwords, so that criminal elements can ultimately get access to bank accounts and other high-value IT assets.) That is why it is important to protect the assets of the organization and stop that from happening.The general scope should include topics such as password security, Email phishing, Social engineering, Mobile device security, Sensitive data security, and Business communications. In contrast, those requiring specialized knowledge are usually required to take technical and in-depth training courses. Suppose an organization determines that it is best to use one of the available training tools on the market, it must ensure it sets objectives that the training can meet, including confirming the training will provide employees with the knowledge to understand risks and the behaviors needed in managing them, actions to take to prevent or detect security incidents, using language easily understandable by the trainees, and ensuring the pricing is reasonable.Organizations are recommended to base ISAT training content on employee roles and their culture; the policy should guide that training for all employees and gave the following as examples of sources of reference materials:\nNational Institute of Standards and Technology (NIST) Special Publication 800-50, Building an Information Technology Security Awareness and Training Program\nInternational Standards Organization (ISO) 27002:2013, Information technology\u2014Security techniques\u2014Code of practice for information security controls\nInternational Standards Organization (ISO) 27001:2013, Information technology \u2014 Security techniques \u2014 Information security management systems\nCOBIT 5 Appendix F.2, Detailed Guidance: Services, Infrastructure and Applications Enabler, Security AwarenessThe training must focus on current threats specific to an organization and the impacts if that materializes as a result of user actions. Including practical examples and ways of dealing with scenarios help users know the appropriate measures to take. It is a good practice to periodically train customers of specific organizations on threats they face from people with malicious intentions.Coverage strategy for SAT should be driven by an organization\u2019s policy. It can help truly determine the level of depth of the training and where it should be conducted at a global level or business unit level, or a combination of both. A policy also empowers a responsible party within the organization to run the training.\n\n== Importance ==\nEmployees are key in whether organizations are breached or not; there must be a policy on creating awareness and training them on emerging threats and actions to take in safeguarding sensitive information and reporting any observed unusual activity within the corporate environment.Research has shown that SAT has helped reduce cyber-attacks within organizations, especially when it comes to phishing, as trainees learned to identify these attack modes and give them the self-assurance to take action appropriately.There is an increase in phishing attacks, and it has become increasingly important for people to understand how to these attacks work, and the actions required to prevent these and SAT has shown a significant impact on the number of successful phishing attacks against organizations.\n\n== Compliance Requirements ==\nVarious regulations and laws mandate SAT for organizations in specific industries, including the Gramm\u2013Leach\u2013Bliley Act (GLBA) for the financial services, the Federal Information Security Modernization Act of 2014 for federal agencies, and the European Union\u2019s General Data Protection Regulation (GDPR).\n\n\n*** Federal Information Security Modernization Act ***\nEmployees and contractors in federal agencies are required to receive Security Awareness Training annually, and the program needs to address job-related information security risks linked that provide them with the knowledge to lessen security risks.\n\n\n*** Health Insurance Portability and Accountability Act ***\nThe Health Insurance Portability and Accountability Act has the Security Rule, and Privacy Rule requiring the creation of a security awareness training program and ensuring employees are trained accordingly.\n\n\n*** Payment Card Industry Data Security Standard ***\nThe Payment Card Industry Security Standards Council, the governing council for stakeholders in the payment industry, formed by American Express, Discover, JCB International, MasterCard, and Visa that developed the DSS as a requirement for the payment industry. Requirement 12.6 requires member organizations to institute a formal security awareness program. There is a published guide for organizations to adhere to when setting up the program.\n\n\n*** US States Training Regulations ***\nSome States mandate Security Awareness Training whiles other do not but simply recommend voluntary training. Among states that require the training for its employees include:\n\nColorado (The Colorado Information Security Act, Colorado Revised Statutes 24-37.5-401 et seq.)\nConnecticut (13 FAM 301.1-1 Cyber Security Awareness Training (PS800))\nFlorida (Florida Statutes Chapter 282)\nGeorgia (Executive Order GA E.O.182 mandated training within 90 days of issue)\nIllinois (Cook County)\nIndiana (IN H 1240)\nLouisiana (Louisiana Division of Administration, Office of Technology Services p. 52: LA H 633)\nMaryland (20-07 IT Security Policy)\nMontana (Mandatory cyber training for executive branch state employees)\nNebraska\nNevada (agency-by-agency state employee requirement - State Security Standard 123 \u2013 IT Security)\nNew Hampshire\nNew Jersey ( NJ A 1654)\nNorth Carolina\nOhio (IT-15 - Security Awareness and Training)\nPennsylvania\nTexas\nUtah\nVermont\nVirginia\nWest Virginia (WV Code Section 5A-6-4a)\n\n== Training Techniques ==\nBelow are some common training techniques, even though some can be blended depending on the operating environment:\nInteractive video training  \u2013 This technique allows users to be trained using two-way interactive audio and video instruction.\nWeb-based training \u2013 This method allows employees or users to take the training independently and usually has a testing component to determine if learning has taken place. If not, users can be allowed to retake the course and test to ensure there is a complete understanding of the material.  \nNon-web, computer-based training \u2013 Some organizations prefer not to use the internet or have locations without internet connectivity; hence this technique provides them an effective way to load training programs onto computers for users.\nOnsite, instructor-led training \u2013 This is a very popular technique for security awareness training but not efficient for large organizations. Some organizations use this method for the initial on-boarding training with employees as most require them to be onsite for on-boarding.Training should be conducted during on-boarding and at least annually for employees or other third parties with access to organizational information systems; the medium is either through face-to-face instruction or online, typically focusing on recognizing attack symptoms and safeguarding sensitive data using several security mechanisms, including passwords, encryption, and secure sessions.ISAT also teaches and refreshes the memory of participants on various present threats, emerging security threats, attack vectors, organizational policies related information security, and basic principles or norms to maintain security on the internet.Organizations consider several options when it comes to training media to deliver the security awareness training to users, but research using learning theory, media richness theory, and cognitive load theory has shown that organizations do not need to invest heavily in highly-rich media as that does not lead to improved user behavior; the training content is most important.SAT services are often coupled with additional tools and services related to a company\u2019s employees including: \n\nDark Web Monitoring Services \u2013 Detecting if any company email addresses or domains involved in a data breach, notifying administrators of data exposed tied to an employee's email address.\nPolicy Compliance \u2013 Guiding users through cybersecurity governance policies. Send out policies to your users to acknowledge and to track and report on compliance.\nRisk Assessments \u2013 Assess and identify your company or customer\u2019s threats and vulnerabilities.\n\nWhat states mandate Security Awareness Training for their employees?",
    "context": "",
    "output": "Some of the states that mandate Security Awareness Training for their employees include Colorado, Connecticut, Florida, Georgia, Illinois (Cook County), Indiana, Louisiana, Maryland, Montana, Nebraska, Nevada, New Hampshire, New Jersey, North Carolina, Ohio, Pennsylvania, Texas, Utah, Vermont, Virginia, and West Virginia.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What states mandate Security Awareness Training for their employees?",
      "answer": "Some of the states that mandate Security Awareness Training for their employees include Colorado, Connecticut, Florida, Georgia, Illinois (Cook County), Indiana, Louisiana, Maryland, Montana, Nebraska, Nevada, New Hampshire, New Jersey, North Carolina, Ohio, Pennsylvania, Texas, Utah, Vermont, Virginia, and West Virginia.",
      "context": "Internet Security Awareness Training\n\n==Introduction==\nInternet Security Awareness Training (ISAT) is the training given to members of an organization regarding the protection of various information assets of that organization. ISAT is a subset of general security awareness training (SAT).\nEven small and medium enterprises are generally recommended to provide such training, but organizations that need to comply with government regulations (e.g., the Gramm\u2013Leach\u2013Bliley Act, the Payment Card Industry Data Security Standard, Health Insurance Portability and Accountability Act, Sarbox) normally require formal ISAT for annually for all employees. Often such training is provided in the form of online courses.\n\nISAT, also referred to as Security Education, Training, and Awareness (SETA), organizations train and create awareness of information security management within their environment. It is beneficial to organizations when employees are well trained and feel empowered to take important actions to protect themselves and organizational data. The SETA program target must be based on user roles within organizations and for positions that expose the organizations to increased risk levels, specialized courses must be required.\n\n\n\n== Coverage ==\nThere are general topics to cover for the training, but it is necessary for each organization to have a coverage strategy based on its needs, as this will ensure the training is practical and captures critical topics relevant to the organization. As the threat landscape changes very frequently, organizations should continuously review their training programs to ensure relevance with current trends.Topics covered in ISAT include:\n\nAppropriate methods for protecting sensitive information on personal computer systems, including password policy\nVarious computer security concerns, including spam, malware, phishing, social engineering, etc.\nConsequences of failure to properly protect information, including potential job loss, economic consequences to the firm, damage to individuals whose private records are divulged, and possible civil and criminal law penalties.Being Internet Security Aware means you understand that there are people actively trying to steal data that is stored within your organization's computers.  (This often focuses on user names and passwords, so that criminal elements can ultimately get access to bank accounts and other high-value IT assets.) That is why it is important to protect the assets of the organization and stop that from happening.The general scope should include topics such as password security, Email phishing, Social engineering, Mobile device security, Sensitive data security, and Business communications. In contrast, those requiring specialized knowledge are usually required to take technical and in-depth training courses. Suppose an organization determines that it is best to use one of the available training tools on the market, it must ensure it sets objectives that the training can meet, including confirming the training will provide employees with the knowledge to understand risks and the behaviors needed in managing them, actions to take to prevent or detect security incidents, using language easily understandable by the trainees, and ensuring the pricing is reasonable.Organizations are recommended to base ISAT training content on employee roles and their culture; the policy should guide that training for all employees and gave the following as examples of sources of reference materials:\nNational Institute of Standards and Technology (NIST) Special Publication 800-50, Building an Information Technology Security Awareness and Training Program\nInternational Standards Organization (ISO) 27002:2013, Information technology\u2014Security techniques\u2014Code of practice for information security controls\nInternational Standards Organization (ISO) 27001:2013, Information technology \u2014 Security techniques \u2014 Information security management systems\nCOBIT 5 Appendix F.2, Detailed Guidance: Services, Infrastructure and Applications Enabler, Security AwarenessThe training must focus on current threats specific to an organization and the impacts if that materializes as a result of user actions. Including practical examples and ways of dealing with scenarios help users know the appropriate measures to take. It is a good practice to periodically train customers of specific organizations on threats they face from people with malicious intentions.Coverage strategy for SAT should be driven by an organization\u2019s policy. It can help truly determine the level of depth of the training and where it should be conducted at a global level or business unit level, or a combination of both. A policy also empowers a responsible party within the organization to run the training.\n\n== Importance ==\nEmployees are key in whether organizations are breached or not; there must be a policy on creating awareness and training them on emerging threats and actions to take in safeguarding sensitive information and reporting any observed unusual activity within the corporate environment.Research has shown that SAT has helped reduce cyber-attacks within organizations, especially when it comes to phishing, as trainees learned to identify these attack modes and give them the self-assurance to take action appropriately.There is an increase in phishing attacks, and it has become increasingly important for people to understand how to these attacks work, and the actions required to prevent these and SAT has shown a significant impact on the number of successful phishing attacks against organizations.\n\n== Compliance Requirements ==\nVarious regulations and laws mandate SAT for organizations in specific industries, including the Gramm\u2013Leach\u2013Bliley Act (GLBA) for the financial services, the Federal Information Security Modernization Act of 2014 for federal agencies, and the European Union\u2019s General Data Protection Regulation (GDPR).\n\n\n*** Federal Information Security Modernization Act ***\nEmployees and contractors in federal agencies are required to receive Security Awareness Training annually, and the program needs to address job-related information security risks linked that provide them with the knowledge to lessen security risks.\n\n\n*** Health Insurance Portability and Accountability Act ***\nThe Health Insurance Portability and Accountability Act has the Security Rule, and Privacy Rule requiring the creation of a security awareness training program and ensuring employees are trained accordingly.\n\n\n*** Payment Card Industry Data Security Standard ***\nThe Payment Card Industry Security Standards Council, the governing council for stakeholders in the payment industry, formed by American Express, Discover, JCB International, MasterCard, and Visa that developed the DSS as a requirement for the payment industry. Requirement 12.6 requires member organizations to institute a formal security awareness program. There is a published guide for organizations to adhere to when setting up the program.\n\n\n*** US States Training Regulations ***\nSome States mandate Security Awareness Training whiles other do not but simply recommend voluntary training. Among states that require the training for its employees include:\n\nColorado (The Colorado Information Security Act, Colorado Revised Statutes 24-37.5-401 et seq.)\nConnecticut (13 FAM 301.1-1 Cyber Security Awareness Training (PS800))\nFlorida (Florida Statutes Chapter 282)\nGeorgia (Executive Order GA E.O.182 mandated training within 90 days of issue)\nIllinois (Cook County)\nIndiana (IN H 1240)\nLouisiana (Louisiana Division of Administration, Office of Technology Services p. 52: LA H 633)\nMaryland (20-07 IT Security Policy)\nMontana (Mandatory cyber training for executive branch state employees)\nNebraska\nNevada (agency-by-agency state employee requirement - State Security Standard 123 \u2013 IT Security)\nNew Hampshire\nNew Jersey ( NJ A 1654)\nNorth Carolina\nOhio (IT-15 - Security Awareness and Training)\nPennsylvania\nTexas\nUtah\nVermont\nVirginia\nWest Virginia (WV Code Section 5A-6-4a)\n\n== Training Techniques ==\nBelow are some common training techniques, even though some can be blended depending on the operating environment:\nInteractive video training  \u2013 This technique allows users to be trained using two-way interactive audio and video instruction.\nWeb-based training \u2013 This method allows employees or users to take the training independently and usually has a testing component to determine if learning has taken place. If not, users can be allowed to retake the course and test to ensure there is a complete understanding of the material.  \nNon-web, computer-based training \u2013 Some organizations prefer not to use the internet or have locations without internet connectivity; hence this technique provides them an effective way to load training programs onto computers for users.\nOnsite, instructor-led training \u2013 This is a very popular technique for security awareness training but not efficient for large organizations. Some organizations use this method for the initial on-boarding training with employees as most require them to be onsite for on-boarding.Training should be conducted during on-boarding and at least annually for employees or other third parties with access to organizational information systems; the medium is either through face-to-face instruction or online, typically focusing on recognizing attack symptoms and safeguarding sensitive data using several security mechanisms, including passwords, encryption, and secure sessions.ISAT also teaches and refreshes the memory of participants on various present threats, emerging security threats, attack vectors, organizational policies related information security, and basic principles or norms to maintain security on the internet.Organizations consider several options when it comes to training media to deliver the security awareness training to users, but research using learning theory, media richness theory, and cognitive load theory has shown that organizations do not need to invest heavily in highly-rich media as that does not lead to improved user behavior; the training content is most important.SAT services are often coupled with additional tools and services related to a company\u2019s employees including: \n\nDark Web Monitoring Services \u2013 Detecting if any company email addresses or domains involved in a data breach, notifying administrators of data exposed tied to an employee's email address.\nPolicy Compliance \u2013 Guiding users through cybersecurity governance policies. Send out policies to your users to acknowledge and to track and report on compliance.\nRisk Assessments \u2013 Assess and identify your company or customer\u2019s threats and vulnerabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the CGA verification method work?",
    "context": "",
    "output": "The CGA verification method verifies that the key pair used for signing a received message has been bound to the CGA, thus verifying the authenticity of the public key without the need for a public key infrastructure.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the CGA verification method work?",
      "answer": "The CGA verification method verifies that the key pair used for signing a received message has been bound to the CGA, thus verifying the authenticity of the public key without the need for a public key infrastructure."
    }
  },
  {
    "instruction": "Write an answer to the following question: What additional security features does the Pentoo kernel include?",
    "context": "",
    "output": "The Pentoo kernel includes grsecurity and PAX hardening, which are both designed to protect the system against various types of vulnerabilities and attacks. These features, combined with extra patches, make the Pentoo kernel more resilient to security threats compared to a standard Linux kernel.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What additional security features does the Pentoo kernel include?",
      "answer": "The Pentoo kernel includes grsecurity and PAX hardening, which are both designed to protect the system against various types of vulnerabilities and attacks. These features, combined with extra patches, make the Pentoo kernel more resilient to security threats compared to a standard Linux kernel."
    }
  },
  {
    "instruction": "context: Metadata can include information such as details on file authors, file creation and modification dates, geographical location, document revision history, thumbnail images, and comments. This information can be found in documents, spreadsheets, presentations, images, and audio files.\n\nAsk a question about this context.",
    "context": "",
    "output": "What information can metadata include in different types of files?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What information can metadata include in different types of files?",
      "answer": "Metadata can include information such as details on file authors, file creation and modification dates, geographical location, document revision history, thumbnail images, and comments. This information can be found in documents, spreadsheets, presentations, images, and audio files."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the link in an encrypting PIN pad apparatus communicatively couple the pad and the encrypting circuit?",
    "context": "",
    "output": "The link in an encrypting PIN pad apparatus allows for the communication of the entered identifier from the pad to the encrypting circuit, enabling the encrypting circuit to encrypt the identifier.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the link in an encrypting PIN pad apparatus communicatively couple the pad and the encrypting circuit?",
      "answer": "The link in an encrypting PIN pad apparatus allows for the communication of the entered identifier from the pad to the encrypting circuit, enabling the encrypting circuit to encrypt the identifier."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the three properties of a one-way hash function proposed by Benaloh and de Mare?",
    "context": "",
    "output": "The three properties of a one-way hash function proposed by Benaloh and de Mare are: (1) it can be computed efficiently, (2) no efficient algorithm can find a second input that maps to the same hash value for a given input, and (3) the hash function is collision-resistant.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the three properties of a one-way hash function proposed by Benaloh and de Mare?",
      "answer": "The three properties of a one-way hash function proposed by Benaloh and de Mare are: (1) it can be computed efficiently, (2) no efficient algorithm can find a second input that maps to the same hash value for a given input, and (3) the hash function is collision-resistant."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which Linux distribution is Kali Linux based on?",
    "context": "",
    "output": "Kali Linux is based on the Debian Testing branch.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which Linux distribution is Kali Linux based on?",
      "answer": "Kali Linux is based on the Debian Testing branch."
    }
  },
  {
    "instruction": "context: Archangel and The Stingray, two of PHIRM's founders, were the ones who broke up the group in 1990 due to becoming too high-profile after the Legion of Doom arrests and the scrutiny they faced following the publication of a definitive guide to breaking security on Bank of America home banking systems.\n\nAsk a question about this context.",
    "context": "",
    "output": "Who were the founders of PHIRM that broke up the group in 1990 due to becoming too high-profile after the Legion of Doom arrests and the scrutiny they faced following the publication of a definitive guide to breaking security on Bank of America home banking systems?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who were the founders of PHIRM that broke up the group in 1990 due to becoming too high-profile after the Legion of Doom arrests and the scrutiny they faced following the publication of a definitive guide to breaking security on Bank of America home banking systems?",
      "answer": "Archangel and The Stingray, two of PHIRM's founders, were the ones who broke up the group in 1990 due to becoming too high-profile after the Legion of Doom arrests and the scrutiny they faced following the publication of a definitive guide to breaking security on Bank of America home banking systems."
    }
  },
  {
    "instruction": "Secure Hypertext Transfer Protocol\n\n==Introduction==\nSecure Hypertext Transfer Protocol (S-HTTP) is an obsolete alternative to the HTTPS protocol for encrypting web communications carried over the Internet. It was developed by Eric Rescorla and Allan M. Schiffman at EIT in 1994  and published in 1999 as RFC 2660.\nEven though S-HTTP was first to market, Netscape's dominance of the browser market led to HTTPS becoming the de facto method for securing web communications.\n\n\n\n== Comparison to HTTP over TLS ==\nS-HTTP encrypts only the served page data and submitted data like POST fields, leaving the initiation of the protocol unchanged. Because of this, S-HTTP could be used concurrently with HTTP (unsecured) on the same port, as the unencrypted header would determine whether the rest of the transmission is encrypted.\nIn contrast, HTTP over TLS wraps the entire communication within Transport Layer Security (TLS; formerly SSL), so the encryption starts before any protocol data is sent. This creates a name-based virtual hosting \"chicken and egg\" issue with determining which DNS name was intended for the request.\nThis means that HTTPS implementations without Server Name Indication (SNI) support require a separate IP address per DNS name, and all HTTPS implementations require a separate port (usually 443 vs. HTTP's standard 80) for unambiguous use of encryption (treated in most browsers as a separate URI scheme, https://).\nAs documented in RFC 2817, HTTP can also be secured by implementing HTTP/1.1 Upgrade headers and upgrading to TLS. Running HTTP over TLS negotiated in this way does not have the implications of HTTPS with regards to name-based virtual hosting (no extra IP addresses, ports, or URI space). However, few implementations support this method.\nIn S-HTTP, the desired URL is not transmitted in the cleartext headers, but left blank; another set of headers is present inside the encrypted payload. In HTTP over TLS, all headers are inside the encrypted payload and the server application does not generally have the opportunity to gracefully recover from TLS fatal errors (including 'client certificate is untrusted' and 'client certificate is expired').\n\nAnswer this question based on the above context: What is the implication of HTTPS for name-based virtual hosting?",
    "context": "",
    "output": "HTTPS implementations require a separate port for unambiguous use of encryption, which can be a limitation for name-based virtual hosting.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the implication of HTTPS for name-based virtual hosting?",
      "answer": "HTTPS implementations require a separate port for unambiguous use of encryption, which can be a limitation for name-based virtual hosting.",
      "context": "Secure Hypertext Transfer Protocol\n\n==Introduction==\nSecure Hypertext Transfer Protocol (S-HTTP) is an obsolete alternative to the HTTPS protocol for encrypting web communications carried over the Internet. It was developed by Eric Rescorla and Allan M. Schiffman at EIT in 1994  and published in 1999 as RFC 2660.\nEven though S-HTTP was first to market, Netscape's dominance of the browser market led to HTTPS becoming the de facto method for securing web communications.\n\n\n\n== Comparison to HTTP over TLS ==\nS-HTTP encrypts only the served page data and submitted data like POST fields, leaving the initiation of the protocol unchanged. Because of this, S-HTTP could be used concurrently with HTTP (unsecured) on the same port, as the unencrypted header would determine whether the rest of the transmission is encrypted.\nIn contrast, HTTP over TLS wraps the entire communication within Transport Layer Security (TLS; formerly SSL), so the encryption starts before any protocol data is sent. This creates a name-based virtual hosting \"chicken and egg\" issue with determining which DNS name was intended for the request.\nThis means that HTTPS implementations without Server Name Indication (SNI) support require a separate IP address per DNS name, and all HTTPS implementations require a separate port (usually 443 vs. HTTP's standard 80) for unambiguous use of encryption (treated in most browsers as a separate URI scheme, https://).\nAs documented in RFC 2817, HTTP can also be secured by implementing HTTP/1.1 Upgrade headers and upgrading to TLS. Running HTTP over TLS negotiated in this way does not have the implications of HTTPS with regards to name-based virtual hosting (no extra IP addresses, ports, or URI space). However, few implementations support this method.\nIn S-HTTP, the desired URL is not transmitted in the cleartext headers, but left blank; another set of headers is present inside the encrypted payload. In HTTP over TLS, all headers are inside the encrypted payload and the server application does not generally have the opportunity to gracefully recover from TLS fatal errors (including 'client certificate is untrusted' and 'client certificate is expired')."
    }
  },
  {
    "instruction": "context: The U.S. National Security Agency (NSA), the U.S. Central Intelligence Agency (CIA), and Britain's Government Communications Headquarters (GCHQ) are conducting surveillance on the networks of many online games, including massively multiplayer online role-playing games (MMORPGs) such as World of Warcraft, as well as virtual worlds such as Second Life, and the Xbox gaming console.\n\nAsk a question about this context.",
    "context": "",
    "output": "Which networks of online games, virtual worlds, and gaming consoles are the U.S. National Security Agency (NSA), the U.S. Central Intelligence Agency (CIA), and Britain's Government Communications Headquarters (GCHQ) conducting surveillance on?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which networks of online games, virtual worlds, and gaming consoles are the U.S. National Security Agency (NSA), the U.S. Central Intelligence Agency (CIA), and Britain's Government Communications Headquarters (GCHQ) conducting surveillance on?",
      "answer": "The U.S. National Security Agency (NSA), the U.S. Central Intelligence Agency (CIA), and Britain's Government Communications Headquarters (GCHQ) are conducting surveillance on the networks of many online games, including massively multiplayer online role-playing games (MMORPGs) such as World of Warcraft, as well as virtual worlds such as Second Life, and the Xbox gaming console."
    }
  },
  {
    "instruction": "Write an answer to the following question: What command line interface is available in the ASA software for querying, operating, or configuring the device?",
    "context": "",
    "output": "The ASA software provides a command line interface (CLI) for users to query, operate, or configure the device.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What command line interface is available in the ASA software for querying, operating, or configuring the device?",
      "answer": "The ASA software provides a command line interface (CLI) for users to query, operate, or configure the device."
    }
  },
  {
    "instruction": "Employee monitoring software\n\n==Introduction==\nEmployee monitoring software is a means of employee monitoring, and allows company administrators to monitor and supervise all their employee computers from a central location. It is normally deployed over a business network and allows for easy centralized log viewing via one central networked PC. Sometimes, companies opt to monitor their employees using remote desktop software instead.\n\n\n\n== Purpose ==\nEmployee monitoring software is used to supervise employees' performance, prevent illegal activities, avoid confidential info leakage, and catch insider threats. Nowadays employee monitoring software is widely used in technology companies.\n\n== Features ==\nAn employee monitoring program can monitor almost everything on a computer, such as keystrokes and passwords inputted, websites visited, chats in Facebook Messenger, Skype and other social chats. A piece of monitoring software can also capture screenshots of mobile activities. E-mail monitoring includes employers having access to records of employee\u2019s e-mails that are sent through the company\u2019s servers. Companies may use keyword searches to natural language processing to analyze e-mails. The administrator can view the logs through a cloud panel, or receive the logs by email.\n\n== Criticism ==\nBossware, also known as tattleware, is software that allows supervisors to automatically monitor the productivity of their employees. Common features of bossware include activity monitoring, screenshotting and/or screen recording, keystroke logging, webcam and/or microphone activation, and \"invisible\" monitoring. Bossware has been called a form of spyware. During the COVID-19 pandemic, the use of bossware by companies to monitor their employees increased.The Electronic Frontier Foundation (EFF) denounced bossware as a violation of privacy. The Center for Democracy and Technology (CDT) denounced bossware as a threat to the safety and health of employees.During the COVID-19 pandemic, members of the r/antiwork subreddit shared various mouse jiggler strategies to combat bossware intended to monitor the productivity of remote workers.A study by Reports and Data predicts that the global market for employee remote monitoring software will hit $1.3 billion by 2027.\n\nAnswer this question based on the above context: Is there any legal restriction on the use of employee monitoring software or bossware?",
    "context": "",
    "output": "I don't have the information about the legal restriction on the use of employee monitoring software or bossware, it may vary based on the jurisdiction and the specific use case.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is there any legal restriction on the use of employee monitoring software or bossware?",
      "answer": "I don't have the information about the legal restriction on the use of employee monitoring software or bossware, it may vary based on the jurisdiction and the specific use case.",
      "context": "Employee monitoring software\n\n==Introduction==\nEmployee monitoring software is a means of employee monitoring, and allows company administrators to monitor and supervise all their employee computers from a central location. It is normally deployed over a business network and allows for easy centralized log viewing via one central networked PC. Sometimes, companies opt to monitor their employees using remote desktop software instead.\n\n\n\n== Purpose ==\nEmployee monitoring software is used to supervise employees' performance, prevent illegal activities, avoid confidential info leakage, and catch insider threats. Nowadays employee monitoring software is widely used in technology companies.\n\n== Features ==\nAn employee monitoring program can monitor almost everything on a computer, such as keystrokes and passwords inputted, websites visited, chats in Facebook Messenger, Skype and other social chats. A piece of monitoring software can also capture screenshots of mobile activities. E-mail monitoring includes employers having access to records of employee\u2019s e-mails that are sent through the company\u2019s servers. Companies may use keyword searches to natural language processing to analyze e-mails. The administrator can view the logs through a cloud panel, or receive the logs by email.\n\n== Criticism ==\nBossware, also known as tattleware, is software that allows supervisors to automatically monitor the productivity of their employees. Common features of bossware include activity monitoring, screenshotting and/or screen recording, keystroke logging, webcam and/or microphone activation, and \"invisible\" monitoring. Bossware has been called a form of spyware. During the COVID-19 pandemic, the use of bossware by companies to monitor their employees increased.The Electronic Frontier Foundation (EFF) denounced bossware as a violation of privacy. The Center for Democracy and Technology (CDT) denounced bossware as a threat to the safety and health of employees.During the COVID-19 pandemic, members of the r/antiwork subreddit shared various mouse jiggler strategies to combat bossware intended to monitor the productivity of remote workers.A study by Reports and Data predicts that the global market for employee remote monitoring software will hit $1.3 billion by 2027."
    }
  },
  {
    "instruction": "context: Measures to improve ballot accounting and reconciliation include implementing universal use of paper ballots, marked by hand and read by optical scanner, ensuring a voter-verified paper audit trail (VVPAT), and conducting risk-limiting audits. These measures can help ensure that all ballots are accounted for and that voting results are accurate.\n\nAsk a question about this context.",
    "context": "",
    "output": "What measures have been proposed to improve ballot accounting and reconciliation?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What measures have been proposed to improve ballot accounting and reconciliation?",
      "answer": "Measures to improve ballot accounting and reconciliation include implementing universal use of paper ballots, marked by hand and read by optical scanner, ensuring a voter-verified paper audit trail (VVPAT), and conducting risk-limiting audits. These measures can help ensure that all ballots are accounted for and that voting results are accurate."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the management console snap-in named in Windows Vista's improved firewall?",
    "context": "",
    "output": "The management console snap-in named in Windows Vista's improved firewall is Windows Firewall with Advanced Security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the management console snap-in named in Windows Vista's improved firewall?",
      "answer": "The management console snap-in named in Windows Vista's improved firewall is Windows Firewall with Advanced Security."
    }
  },
  {
    "instruction": "context: Context collapse, where multiple social groups occur in one space, causes confusion in managing one's online identity. Users must decide which aspect of their personality to present when posting on social media, as they are often connected with a wide range of social groups such as family, colleagues, and friends. This phenomenon has become increasingly significant, forcing users to implement strategies such as stricter privacy settings and engaging in more ephemeral mediums like Instagram stories and Snapchat.\n\nAsk a question about this context.",
    "context": "",
    "output": "What challenges do users face in managing their online identities due to context collapse?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What challenges do users face in managing their online identities due to context collapse?",
      "answer": "Context collapse, where multiple social groups occur in one space, causes confusion in managing one's online identity. Users must decide which aspect of their personality to present when posting on social media, as they are often connected with a wide range of social groups such as family, colleagues, and friends. This phenomenon has become increasingly significant, forcing users to implement strategies such as stricter privacy settings and engaging in more ephemeral mediums like Instagram stories and Snapchat."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do TOTP and HOTP algorithms compare to other OTP algorithms, such as SMS-based OTPs or email-based OTPs?",
    "context": "",
    "output": "TOTP and HOTP algorithms provide stronger security than SMS-based or email-based OTPs, as they are less susceptible to interception or theft. However, they require more complex implementation and may be more difficult for users to use.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do TOTP and HOTP algorithms compare to other OTP algorithms, such as SMS-based OTPs or email-based OTPs?",
      "answer": "TOTP and HOTP algorithms provide stronger security than SMS-based or email-based OTPs, as they are less susceptible to interception or theft. However, they require more complex implementation and may be more difficult for users to use."
    }
  },
  {
    "instruction": "Stratfor email leak\n\n==Introduction==\nEmails by strategic intelligence company Stratfor, referred to by WikiLeaks as the Global Intelligence Files, began appearing on WikiLeaks on February 27, 2012, with 5,543,061 emails published as of July 18, 2014.Stratfor is a security group based in Austin, Texas. On December 24, 2011, hackers took control of Stratfor's website and released a list of names, credit card numbers, passwords, and home and email addresses. Those listed were affiliated with organizations such as Bank of America, the United States Department of Defense, M\u00e9decins Sans Fronti\u00e8res, Lockheed Martin, Los Alamos National Laboratory, and the United Nations. The hackers included Jeremy Hammond, who worked with Anonymous to release Stratfor's emails to WikiLeaks. The emails revealed Stratfor's surveillance of groups such as Occupy Wall Street and protestors of the Bhopal disaster.The e-mails are alleged to include client information, notes between Stratfor employees and internal procedural documentation on securing intelligence data. These communications date from July 2004 through to December 2011. \nStratfor said the emails appeared to be those that were stolen by hackers in December 2011. In an initial announcement, WikiLeaks stated that they opened up a database of the emails to two dozen media organizations operating in several countries, including the McClatchy Company, l'Espresso, la Repubblica, ARD, the Russia Reporter, and Rolling Stone, along with a \"sneak preview\" to the Yes Men.In June 2012, Stratfor settled a class action lawsuit regarding the hack.\n\n== Content ==\nStratfor stated that some of the leaked emails \"may be forged or altered to include inaccuracies; some may be authentic\", pointing to a phony email saying that Stratfor's CEO George Friedman had resigned. They stated that the emails represented candid internal language that would probably be ripe for misinterpretation.One of the first items released was an email containing a glossary titled \"The Stratfor Glossary of Useful, Baffling and Strange Intelligence Terms\", which contained concise and sometimes humorously candid definitions, along with pointed assessments of U.S. intelligence and law enforcement. The glossary included items on how \"background checks\" can help \"run up clients\u2019 bill and makes it appear that you are busy\" and how \"briefs\" for customers need to \"make sh*t smell good\".\n\n\n*** Julian Assange ***\nJulian Assange was a frequent topic of discussion in emails from Stratfor staff in the period 2010\u20132012.  Emails from Fred Burton, who was Stratfor's Vice-President for Counterterrorism and Corporate Security and former Deputy Chief of the counterterrorism division of the Diplomatic Security Service, indicated that he knew in January 2011 about a United States Government secret indictment against Assange. Internal Stratfor emails gave a suggested strategy for dealing with Assange: \"Pile on. Move him from country to country to face various charges for the next 25 years\". Burton wrote that his strategy would be \"Bankrupt the arsehole first, ruin his life. Give him 7-12 yrs for conspiracy\". In one published email Burton allegedly wrote \"Assange is going to make a nice bride in prison. Screw the terrorist. He'll be eating cat food forever.\" In another leaked email, a Stratfor employee wanted Assange waterboarded.\n\n\n*** Governmental ***\nThe emails show Stratfor had contracts with Homeland Security. Mark LeVine, professor of history at the University of California, Irvine, described this as \"troubling\" because Homeland Security had coordinated police attacks on the Occupy movement.An email from a Stratfor analyst indicated that up to 12 officials in Pakistan's Inter-Services Intelligence (ISI) agency knew of Osama bin-Laden's safe house.Ynetnews reported that, according to internal emails between Stratfor employees, Israel and Russia were engaged in an exchange of information in 2008. Israel gave Russia \"data link codes\" for unmanned aerial vehicles (Elbit Hermes 450) that Israel sold to Georgia and in return Russia gave Israel \"the codes for Tor-M1 missile defense systems that Russia sold Iran\". Ynetnews also stated that, during the 2008 South Ossetia war, the leaked emails revealed  Georgia \"realized that their UAVs were compromised and were looking for a replacement for the Israeli made drones\".Business Insider reported that Israeli Prime Minister Benjamin Netanyahu was an intelligence source for Stratfor between 2007 and 2010. In emails, Fred Burton discussed his personal communications with Netanyahu. Burton stated by email that Netanyahu informed him of his success in consolidating power within the Likud party ahead of regaining the position of prime minister, shared thoughts regarding his distrust of US President Barack Obama, threatened assassination of Hezbollah leader Hasan Nasrallah, and declared intentions to unilaterally start a war against Iran.Al Akhbar, citing internal emails from the Stratfor hack, reported former Blackwater director James F. Smith had a relationship with Stratfor and was for a time considered one of their major sources.\nThe emails indicate that Stratfor was receiving information about Venezuelan president Hugo Chavez's medical condition from an Israeli intelligence source.\n\n\n*** Companies ***\nMultinational corporations use Statfor to obtain intelligence on their critics. Dow Chemical, Lockheed Martin, Northrop Grumman, Raytheon and Coca-Cola have used Stratfor's services.The Times of India reported that some emails indicate Stratfor was hired by Dow Chemical to spy on activists seeking compensation from Dow for the Bhopal disaster. Dow Chemical Company responded with a written statement that read: \"Major companies are often required to take appropriate action to protect their people and safeguard their facilities,\" and that it had not broken any laws.The released emails indicated that the Coca-Cola paid Stratfor to determine \"to what extent will US-based PETA supporters travel to Canada to support activism\" at the 2010 Olympics. The Coca-Cola Company responded to the emails with a statement saying that they \"consider it prudent to monitor for protest activities at any major event we sponsor\". Stratfor offered its services to Bank of America to investigate journalist Glenn Greenwald.\n\n\n*** Other ***\nStratfor received information from an informant at Occupy Austin, who was working as an undercover operative for the Texas Department of Public Safety.A memo from Friedman to his staff stated that Stratfor was partnering with Shea Morenz from Goldman Sachs, to create its own hedge fund. The memo said that the fund \"would allow us to utilize the intelligence we were gathering about the world in a new but related venue\u2014an investment fund. Where we had previously advised other hedge funds, we would now have our own, itself fully funded by Shea. Shea invested over $2 million in Stratfor\".\n\n== Responses ==\n\n\n*** Stratfor ***\nAround midnight on February 27, Stratfor released a statement saying that \"the release of its stolen emails was an attempt to silence and intimidate it.\" It also dismissed rumors of CEO and founder George Friedman's resignation.\n\n\n*** Others ***\nWikiLeaks founder Julian Assange told Reuters that his concerns with Stratfor stem from it being a private intelligence firm relying on informants from government agencies with dubious reputations and especially its monitoring of activist organizations. He also accused Stratfor of making investments based on the intelligence it obtained.Former NSA Director Bobby Inman stated that the leak would be damaging to Stratfor's business. He had previously stated that Stratfor was competent, delivering high-quality intelligence analyses.After the release was announced, analysts questioned the value of the firm's emails, since they mostly used reports from newspapers, think tanks and political science university departments. Max Fisher, the associate director of The Atlantic, argued that Stratfor has a poor reputation \"among foreign policy writers, analysts, and practitioners\" and that as a result Anonymous and Wikileaks have exaggerated the significance of the information they released. He also suggested that Assange may have targeted a relatively unimportant firm and over-hyped the results in order to \"regain some of his former glory\". Australian Broadcasting Corporation foreign correspondent and Stratfor subscriber Mark Corcoran also wrote that the e-mails showed Stratfor's methods used to gather information are similar to those employed by journalists, though he wrote that the quality of its reports are often inferior to news reports.\nRead the text above and answer this question: How did Julian Assange become a frequent topic of discussion in Stratfor emails in the period 2010-2012?",
    "context": "",
    "output": "Julian Assange became a frequent topic of discussion in Stratfor emails in the period 2010-2012 after Fred Burton, Stratfor's Vice-President for Counterterrorism and Corporate Security, learned about a United States Government secret indictment against Assange. Internal Stratfor emails discussed a suggested strategy for dealing with Assange, including \"pile on. Move him from country to country to face various charges for the next 25 years\" and \"Bankrupt the arsehole first, ruin his life. Give him 7-12 yrs for conspiracy\".",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Julian Assange become a frequent topic of discussion in Stratfor emails in the period 2010-2012?",
      "answer": "Julian Assange became a frequent topic of discussion in Stratfor emails in the period 2010-2012 after Fred Burton, Stratfor's Vice-President for Counterterrorism and Corporate Security, learned about a United States Government secret indictment against Assange. Internal Stratfor emails discussed a suggested strategy for dealing with Assange, including \"pile on. Move him from country to country to face various charges for the next 25 years\" and \"Bankrupt the arsehole first, ruin his life. Give him 7-12 yrs for conspiracy\".",
      "context": "Stratfor email leak\n\n==Introduction==\nEmails by strategic intelligence company Stratfor, referred to by WikiLeaks as the Global Intelligence Files, began appearing on WikiLeaks on February 27, 2012, with 5,543,061 emails published as of July 18, 2014.Stratfor is a security group based in Austin, Texas. On December 24, 2011, hackers took control of Stratfor's website and released a list of names, credit card numbers, passwords, and home and email addresses. Those listed were affiliated with organizations such as Bank of America, the United States Department of Defense, M\u00e9decins Sans Fronti\u00e8res, Lockheed Martin, Los Alamos National Laboratory, and the United Nations. The hackers included Jeremy Hammond, who worked with Anonymous to release Stratfor's emails to WikiLeaks. The emails revealed Stratfor's surveillance of groups such as Occupy Wall Street and protestors of the Bhopal disaster.The e-mails are alleged to include client information, notes between Stratfor employees and internal procedural documentation on securing intelligence data. These communications date from July 2004 through to December 2011. \nStratfor said the emails appeared to be those that were stolen by hackers in December 2011. In an initial announcement, WikiLeaks stated that they opened up a database of the emails to two dozen media organizations operating in several countries, including the McClatchy Company, l'Espresso, la Repubblica, ARD, the Russia Reporter, and Rolling Stone, along with a \"sneak preview\" to the Yes Men.In June 2012, Stratfor settled a class action lawsuit regarding the hack.\n\n== Content ==\nStratfor stated that some of the leaked emails \"may be forged or altered to include inaccuracies; some may be authentic\", pointing to a phony email saying that Stratfor's CEO George Friedman had resigned. They stated that the emails represented candid internal language that would probably be ripe for misinterpretation.One of the first items released was an email containing a glossary titled \"The Stratfor Glossary of Useful, Baffling and Strange Intelligence Terms\", which contained concise and sometimes humorously candid definitions, along with pointed assessments of U.S. intelligence and law enforcement. The glossary included items on how \"background checks\" can help \"run up clients\u2019 bill and makes it appear that you are busy\" and how \"briefs\" for customers need to \"make sh*t smell good\".\n\n\n*** Julian Assange ***\nJulian Assange was a frequent topic of discussion in emails from Stratfor staff in the period 2010\u20132012.  Emails from Fred Burton, who was Stratfor's Vice-President for Counterterrorism and Corporate Security and former Deputy Chief of the counterterrorism division of the Diplomatic Security Service, indicated that he knew in January 2011 about a United States Government secret indictment against Assange. Internal Stratfor emails gave a suggested strategy for dealing with Assange: \"Pile on. Move him from country to country to face various charges for the next 25 years\". Burton wrote that his strategy would be \"Bankrupt the arsehole first, ruin his life. Give him 7-12 yrs for conspiracy\". In one published email Burton allegedly wrote \"Assange is going to make a nice bride in prison. Screw the terrorist. He'll be eating cat food forever.\" In another leaked email, a Stratfor employee wanted Assange waterboarded.\n\n\n*** Governmental ***\nThe emails show Stratfor had contracts with Homeland Security. Mark LeVine, professor of history at the University of California, Irvine, described this as \"troubling\" because Homeland Security had coordinated police attacks on the Occupy movement.An email from a Stratfor analyst indicated that up to 12 officials in Pakistan's Inter-Services Intelligence (ISI) agency knew of Osama bin-Laden's safe house.Ynetnews reported that, according to internal emails between Stratfor employees, Israel and Russia were engaged in an exchange of information in 2008. Israel gave Russia \"data link codes\" for unmanned aerial vehicles (Elbit Hermes 450) that Israel sold to Georgia and in return Russia gave Israel \"the codes for Tor-M1 missile defense systems that Russia sold Iran\". Ynetnews also stated that, during the 2008 South Ossetia war, the leaked emails revealed  Georgia \"realized that their UAVs were compromised and were looking for a replacement for the Israeli made drones\".Business Insider reported that Israeli Prime Minister Benjamin Netanyahu was an intelligence source for Stratfor between 2007 and 2010. In emails, Fred Burton discussed his personal communications with Netanyahu. Burton stated by email that Netanyahu informed him of his success in consolidating power within the Likud party ahead of regaining the position of prime minister, shared thoughts regarding his distrust of US President Barack Obama, threatened assassination of Hezbollah leader Hasan Nasrallah, and declared intentions to unilaterally start a war against Iran.Al Akhbar, citing internal emails from the Stratfor hack, reported former Blackwater director James F. Smith had a relationship with Stratfor and was for a time considered one of their major sources.\nThe emails indicate that Stratfor was receiving information about Venezuelan president Hugo Chavez's medical condition from an Israeli intelligence source.\n\n\n*** Companies ***\nMultinational corporations use Statfor to obtain intelligence on their critics. Dow Chemical, Lockheed Martin, Northrop Grumman, Raytheon and Coca-Cola have used Stratfor's services.The Times of India reported that some emails indicate Stratfor was hired by Dow Chemical to spy on activists seeking compensation from Dow for the Bhopal disaster. Dow Chemical Company responded with a written statement that read: \"Major companies are often required to take appropriate action to protect their people and safeguard their facilities,\" and that it had not broken any laws.The released emails indicated that the Coca-Cola paid Stratfor to determine \"to what extent will US-based PETA supporters travel to Canada to support activism\" at the 2010 Olympics. The Coca-Cola Company responded to the emails with a statement saying that they \"consider it prudent to monitor for protest activities at any major event we sponsor\". Stratfor offered its services to Bank of America to investigate journalist Glenn Greenwald.\n\n\n*** Other ***\nStratfor received information from an informant at Occupy Austin, who was working as an undercover operative for the Texas Department of Public Safety.A memo from Friedman to his staff stated that Stratfor was partnering with Shea Morenz from Goldman Sachs, to create its own hedge fund. The memo said that the fund \"would allow us to utilize the intelligence we were gathering about the world in a new but related venue\u2014an investment fund. Where we had previously advised other hedge funds, we would now have our own, itself fully funded by Shea. Shea invested over $2 million in Stratfor\".\n\n== Responses ==\n\n\n*** Stratfor ***\nAround midnight on February 27, Stratfor released a statement saying that \"the release of its stolen emails was an attempt to silence and intimidate it.\" It also dismissed rumors of CEO and founder George Friedman's resignation.\n\n\n*** Others ***\nWikiLeaks founder Julian Assange told Reuters that his concerns with Stratfor stem from it being a private intelligence firm relying on informants from government agencies with dubious reputations and especially its monitoring of activist organizations. He also accused Stratfor of making investments based on the intelligence it obtained.Former NSA Director Bobby Inman stated that the leak would be damaging to Stratfor's business. He had previously stated that Stratfor was competent, delivering high-quality intelligence analyses.After the release was announced, analysts questioned the value of the firm's emails, since they mostly used reports from newspapers, think tanks and political science university departments. Max Fisher, the associate director of The Atlantic, argued that Stratfor has a poor reputation \"among foreign policy writers, analysts, and practitioners\" and that as a result Anonymous and Wikileaks have exaggerated the significance of the information they released. He also suggested that Assange may have targeted a relatively unimportant firm and over-hyped the results in order to \"regain some of his former glory\". Australian Broadcasting Corporation foreign correspondent and Stratfor subscriber Mark Corcoran also wrote that the e-mails showed Stratfor's methods used to gather information are similar to those employed by journalists, though he wrote that the quality of its reports are often inferior to news reports."
    }
  },
  {
    "instruction": "context: The Spamhaus versus nic.at dispute occurred when Spamhaus requested the national domain registry of Austria, nic.at, to suspend a number of domains registered anonymously by phishing gangs for illegal bank phishing purposes. The registry nic.at rejected the request, arguing that they would break Austrian law by suspending domains even though they were used for criminal purposes. Spamhaus then put the mail server of nic.at on their SBL spam blacklist, causing interference of mail traffic at nic.at. All of the phishing domains in question have been since deleted or suspended by their DNS providers.\n\nAsk a question about this context.",
    "context": "",
    "output": "What was the Spamhaus versus nic.at dispute and what was the outcome?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the Spamhaus versus nic.at dispute and what was the outcome?",
      "answer": "The Spamhaus versus nic.at dispute occurred when Spamhaus requested the national domain registry of Austria, nic.at, to suspend a number of domains registered anonymously by phishing gangs for illegal bank phishing purposes. The registry nic.at rejected the request, arguing that they would break Austrian law by suspending domains even though they were used for criminal purposes. Spamhaus then put the mail server of nic.at on their SBL spam blacklist, causing interference of mail traffic at nic.at. All of the phishing domains in question have been since deleted or suspended by their DNS providers."
    }
  },
  {
    "instruction": "Signal (software)\n\n==Introduction==\nSignal is an encrypted messaging service for instant messaging, voice, and video calls. The instant messaging function includes sending text, voice notes, images, videos, and other files. Communication may be one-to-one between users, or for group messaging.\nThe application uses a centralized computing architecture, and is cross-platform software. It is developed by the non-profit Signal Foundation and its subsidiary, Signal Messenger LLC. Signal's software is free and open-source. Its mobile clients, desktop client and server are all published under the AGPL-3.0-only license. The official Android app generally uses the proprietary Google Play Services, although it is designed to work without them. Signal is also distributed for iOS and desktop programs for Windows, macOS, and Linux. Registration for desktop use requires an iOS or Android device.Signal uses mobile telephone numbers as an identifier for users. It secures all communications with end-to-end encryption. The client software includes mechanisms by which users can independently verify the identity of their contacts and the integrity of the data channel.The non-profit Signal Foundation was launched in February 2018 with initial funding of $50 million from Brian Acton. As of January 2022, the platform had approximately 40 million monthly active users. As of May 2021, it was downloaded more than 105 million times.The Android version also optionally functions as an SMS app, but this functionality will be removed in 2023.\n\n== Features ==\nSignal allows users to make one-to-one and group voice and video calls with up to 40 people on iOS, Android, and desktop. All calls are made over a Wi-Fi or data connection and (with the exception of data fees) are free of charge, including long distance and international. Signal also allows users to send text messages, files, voice notes, pictures, GIFs, and video messages over a Wi-Fi or data connection to other Signal users on iOS, Android and a desktop program. The platform also supports group messaging.\nAll communications between Signal users are automatically end-to-end encrypted (the encryption keys are generated and stored on the phones, not on the servers). To verify that a correspondent is really the person that they claim to be, Signal users can compare key fingerprints (or scan QR codes) out-of-band. The platform employs a trust-on-first-use mechanism in order to notify the user if a correspondent's key changes.On Android, users can opt into making Signal the default SMS/MMS application, allowing them to send and receive unencrypted SMS messages in addition to the standard end-to-end encrypted Signal messages. Users can then use the same application to communicate with contacts who do not have Signal. As of October 2022, this feature has been deprecated  due to safety and security concerns, and will be removed in the near future.TextSecure allowed the user to set a passphrase that encrypted the local message database and the user's encryption keys. This did not encrypt the user's contact database or message timestamps. The Signal applications on Android and iOS can be locked with the phone's pin, passphrase, or biometric authentication. The user can define a \"screen lock timeout\" interval, providing an additional protection mechanism in case the phone is lost or stolen.Signal also allows users to set timers to messages. After a specified time interval, the messages will be deleted from both the sender's and the receivers' devices. The time interval can be between five seconds and one week long, and the timer begins for each recipient once they have read their copy of the message. The developers have stressed that this is meant to be \"a collaborative feature for conversations where all participants want to automate minimalist data hygiene, not for situations where your contact is your adversary\".Signal also has the ability to schedule sending messages. To help improve users security from curious people and provide more customisation, Signal allows the user to change the app icon with different colour themes as well as different names that mimic generic app names and icons, such as notes and weather. Upcoming features includes hiding spoilers as well adding other users via QR code.Signal excludes users' messages from non-encrypted cloud backups by default.Signal allows users to automatically blur faces of people in photos to protect their identities.Signal also includes a cryptocurrency wallet functionality that allows users to store, send and receive in-app payments. Apart from certain regions and countries, the feature was enabled globally in November 2021. As of January 2022, the only supported payment method is MobileCoin.\n\n== Limitations ==\nSignal requires that the user provides a phone number for verification, eliminating the need for user names or passwords and facilitating contact discovery (see below). The number does not have to be the same as on the device's SIM card; it can also be a VoIP number or a landline as long as the user can receive the verification code and have a separate device to set up the software. A number can only be registered on one mobile device at a time. Account registration requires an iOS or Android device.This mandatory connection to a phone number (a feature Signal shares with WhatsApp, KakaoTalk, and others) has been criticized as a \"major issue\" for privacy-conscious users who are not comfortable with giving out their private phone number. A workaround is to use a secondary phone number. The ability to choose a public, changeable username instead of sharing one's phone number is a widely-requested feature, and is currently in the works.Using phone numbers as identifiers may also create security risks that arise from the possibility of an attacker taking over a phone number. A similar vulnerability was used to attack at least one user in August 2022, though the attack was performed via the provider of Signal's SMS services, not any user's provider. The threat of this attack can be mitigated by enabling Signal's Registration Lock feature, a form of two-factor authentication that requires the user to enter a PIN to register the phone number on a new device.When linking Signal Desktop to a mobile device, the conversations history will not be synced; only the new messages will be shown on Signal Desktop.\n\n== Usability ==\nIn July 2016, the Internet Society published a user study that assessed the ability of Signal users to detect and deter man-in-the-middle attacks. The study concluded that 21 out of 28 participants failed to correctly compare public key fingerprints in order to verify the identity of other Signal users, and that most of these users believed they had succeeded, while they had actually failed. Four months later, Signal's user interface was updated to make verifying the identity of other Signal users simpler.\n\n== Architecture ==\n\n\n*** Encryption protocols ***\n\nSignal messages are encrypted with the Signal Protocol (formerly known as the TextSecure Protocol). The protocol combines the Double Ratchet Algorithm, prekeys, and an Extended Triple Diffie\u2013Hellman (X3DH) handshake. It uses Curve25519, AES-256, and HMAC-SHA256 as primitives. The protocol provides confidentiality, integrity, authentication, participant consistency, destination validation, forward secrecy, backward secrecy (a.k.a. future secrecy), causality preservation, message unlinkability, message repudiation, participation repudiation, and asynchronicity. It does not provide anonymity preservation, and requires servers for the relaying of messages and storing of public key material.The Signal Protocol also supports end-to-end encrypted group chats. The group chat protocol is a combination of a pairwise double ratchet and multicast encryption. In addition to the properties provided by the one-to-one protocol, the group chat protocol provides speaker consistency, out-of-order resilience, dropped message resilience, computational equality, trust equality, subgroup messaging, as well as contractible and expandable membership.In October 2014, researchers from Ruhr University Bochum published an analysis of the Signal Protocol. Among other findings, they presented an unknown key-share attack on the protocol, but in general, they found that it was secure. In October 2016, researchers from UK's University of Oxford, Queensland University of Technology in Australia, and Canada's McMaster University published a formal analysis of the protocol. They concluded that the protocol was cryptographically sound. In July 2017, researchers from Ruhr University Bochum found during another analysis of group messengers a purely theoretic attack against the group protocol of Signal: A user who knows the secret group ID of a group (due to having been a group member previously or stealing it from a member's device) can become a member of the group. Since the group ID cannot be guessed and such member changes are displayed to the remaining members, this attack is likely to be difficult to carry out without being detected.As of August 2018, the Signal Protocol has been implemented into WhatsApp, Facebook Messenger, Skype, and Google Allo, making it possible for the conversations of \"more than a billion people worldwide\" to be end-to-end encrypted. In Google Allo, Skype and Facebook Messenger, conversations are not encrypted with the Signal Protocol by default; they only offer end-to-end encryption in an optional mode.Up until March 2017, Signal's voice calls were encrypted with SRTP and the ZRTP key-agreement protocol, which was developed by Phil Zimmermann. In March 2017, Signal transitioned to a new WebRTC-based calling system that introduced the ability to make video calls. Signal's voice and video calling functionalities use the Signal Protocol channel for authentication instead of ZRTP.\n\n\n**** Authentication ****\nTo verify that a correspondent is really the person that they claim to be, Signal users can compare key fingerprints (or scan QR codes) out-of-band. The platform employs a trust on first use mechanism in order to notify the user if a correspondent's key changes.\n\n\n*** Local storage ***\nAfter receiving and decrypting messages, the application stored them locally on each device in a SQLite database that is encrypted with SQLCipher. The cryptographic key for this database is also stored locally and can be accessed if the device is unlocked. In December 2020, Cellebrite published a blog post announcing that one of their products could now access this key and use it to \"decrypt the Signal app\". Technology reporters later published articles about how Cellebrite had claimed to have the ability to \"break into the Signal app\" and \"crack Signal's encryption\". This latter interpretation was rejected by several experts, as well as representatives from Signal, who said the original post by Cellebrite had been about accessing data on \"an unlocked Android phone in their physical possession\" and that they \"could have just opened the app to look at the messages\". Similar extraction tools also exist for iOS devices and Signal Desktop.\n\n\n*** Servers ***\nSignal relies on centralized servers that are maintained by Signal Messenger. In addition to routing Signal's messages, the servers also facilitate the discovery of contacts who are also registered Signal users and the automatic exchange of users' public keys. By default, Signal's voice and video calls are peer-to-peer. If the caller is not in the receiver's address book, the call is routed through a server in order to hide the users' IP addresses.\n\n\n**** Contact discovery ****\nThe servers store registered users' phone numbers, public key material and push tokens which are necessary for setting up calls and transmitting messages. In order to determine which contacts are also Signal users, cryptographic hashes of the user's contact numbers are periodically transmitted to the server. The server then checks to see if those match any of the SHA256 hashes of registered users and tells the client if any matches are found. The hashed numbers are thereafter discarded from the server. In 2014, Moxie Marlinspike wrote that it is easy to calculate a map of all possible hash inputs to hash outputs and reverse the mapping because of the limited preimage space (the set of all possible hash inputs) of phone numbers, and that a \"practical privacy preserving contact discovery remains an unsolved problem.\" In September 2017, Signal's developers announced that they were working on a way for the Signal client applications to \"efficiently and scalably determine whether the contacts in their address book are Signal users without revealing the contacts in their address book to the Signal service.\"\n\n\n**** Metadata ****\nAll client-server communications are protected by TLS. Signal's developers have asserted that their servers do not keep logs about who called whom and when. In June 2016, Marlinspike told The Intercept that \"the closest piece of information to metadata that the Signal server stores is the last time each user connected to the server, and the precision of this information is reduced to the day, rather than the hour, minute, and second\".The group messaging mechanism is designed so that the servers do not have access to the membership list, group title, or group icon. Instead, the creation, updating, joining, and leaving of groups is done by the clients, which deliver pairwise messages to the participants in the same way that one-to-one messages are delivered.\n\n\n**** Federation ****\nSignal's server architecture was federated between December 2013 and February 2016. In December 2013, it was announced that the messaging protocol Signal uses had successfully been integrated into the Android-based open-source operating system CyanogenMod. Since CyanogenMod 11.0, the client logic was contained in a system app called WhisperPush. According to Signal's developers, the Cyanogen team ran their own Signal messaging server for WhisperPush clients, which federated with the main server, so that both clients could exchange messages with each other. The WhisperPush source code was available under the GPLv3 license. In February 2016, the CyanogenMod team discontinued WhisperPush and recommended that its users switch to Signal. In May 2016, Moxie Marlinspike wrote that federation with the CyanogenMod servers had degraded the user experience and held back development, and that their servers will probably not federate with other servers again.In May 2016, Moxie Marlinspike requested that a third-party client called LibreSignal not use the Signal service or the Signal name. As a result, on 24 May 2016 the LibreSignal project posted that the project was \"abandoned\". The functionality provided by LibreSignal was subsequently incorporated into Signal by Marlinspike.\n\n\n*** Licensing ***\nThe complete source code of the Signal clients for Android, iOS and desktop is available on GitHub under a free software license. This enables interested parties to examine the code and help the developers verify that everything is behaving as expected. It also allows advanced users to compile their own copies of the applications and compare them with the versions that are distributed by Signal Messenger. In March 2016, Moxie Marlinspike wrote that, apart from some shared libraries that are not compiled with the project build due to a lack of Gradle NDK support, Signal for Android is reproducible. Signal's servers are partially open source, but the server software's anti-spam component is proprietary and closed source due to security concerns.\n\n== Bibliography ==\nRead the text above and answer this question: How does Signal handle message storage and encryption on user devices?",
    "context": "",
    "output": "After receiving and decrypting messages, the application stores them locally on each device in an SQLite database that is encrypted with SQLCipher. The cryptographic key for this database is also stored locally and can be accessed if the device is unlocked. However, concerns have been raised about the ability of third-party tools like Cellebrite to access this key and potentially \"decrypt the Signal app\".",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Signal handle message storage and encryption on user devices?",
      "answer": "After receiving and decrypting messages, the application stores them locally on each device in an SQLite database that is encrypted with SQLCipher. The cryptographic key for this database is also stored locally and can be accessed if the device is unlocked. However, concerns have been raised about the ability of third-party tools like Cellebrite to access this key and potentially \"decrypt the Signal app\".",
      "context": "Signal (software)\n\n==Introduction==\nSignal is an encrypted messaging service for instant messaging, voice, and video calls. The instant messaging function includes sending text, voice notes, images, videos, and other files. Communication may be one-to-one between users, or for group messaging.\nThe application uses a centralized computing architecture, and is cross-platform software. It is developed by the non-profit Signal Foundation and its subsidiary, Signal Messenger LLC. Signal's software is free and open-source. Its mobile clients, desktop client and server are all published under the AGPL-3.0-only license. The official Android app generally uses the proprietary Google Play Services, although it is designed to work without them. Signal is also distributed for iOS and desktop programs for Windows, macOS, and Linux. Registration for desktop use requires an iOS or Android device.Signal uses mobile telephone numbers as an identifier for users. It secures all communications with end-to-end encryption. The client software includes mechanisms by which users can independently verify the identity of their contacts and the integrity of the data channel.The non-profit Signal Foundation was launched in February 2018 with initial funding of $50 million from Brian Acton. As of January 2022, the platform had approximately 40 million monthly active users. As of May 2021, it was downloaded more than 105 million times.The Android version also optionally functions as an SMS app, but this functionality will be removed in 2023.\n\n== Features ==\nSignal allows users to make one-to-one and group voice and video calls with up to 40 people on iOS, Android, and desktop. All calls are made over a Wi-Fi or data connection and (with the exception of data fees) are free of charge, including long distance and international. Signal also allows users to send text messages, files, voice notes, pictures, GIFs, and video messages over a Wi-Fi or data connection to other Signal users on iOS, Android and a desktop program. The platform also supports group messaging.\nAll communications between Signal users are automatically end-to-end encrypted (the encryption keys are generated and stored on the phones, not on the servers). To verify that a correspondent is really the person that they claim to be, Signal users can compare key fingerprints (or scan QR codes) out-of-band. The platform employs a trust-on-first-use mechanism in order to notify the user if a correspondent's key changes.On Android, users can opt into making Signal the default SMS/MMS application, allowing them to send and receive unencrypted SMS messages in addition to the standard end-to-end encrypted Signal messages. Users can then use the same application to communicate with contacts who do not have Signal. As of October 2022, this feature has been deprecated  due to safety and security concerns, and will be removed in the near future.TextSecure allowed the user to set a passphrase that encrypted the local message database and the user's encryption keys. This did not encrypt the user's contact database or message timestamps. The Signal applications on Android and iOS can be locked with the phone's pin, passphrase, or biometric authentication. The user can define a \"screen lock timeout\" interval, providing an additional protection mechanism in case the phone is lost or stolen.Signal also allows users to set timers to messages. After a specified time interval, the messages will be deleted from both the sender's and the receivers' devices. The time interval can be between five seconds and one week long, and the timer begins for each recipient once they have read their copy of the message. The developers have stressed that this is meant to be \"a collaborative feature for conversations where all participants want to automate minimalist data hygiene, not for situations where your contact is your adversary\".Signal also has the ability to schedule sending messages. To help improve users security from curious people and provide more customisation, Signal allows the user to change the app icon with different colour themes as well as different names that mimic generic app names and icons, such as notes and weather. Upcoming features includes hiding spoilers as well adding other users via QR code.Signal excludes users' messages from non-encrypted cloud backups by default.Signal allows users to automatically blur faces of people in photos to protect their identities.Signal also includes a cryptocurrency wallet functionality that allows users to store, send and receive in-app payments. Apart from certain regions and countries, the feature was enabled globally in November 2021. As of January 2022, the only supported payment method is MobileCoin.\n\n== Limitations ==\nSignal requires that the user provides a phone number for verification, eliminating the need for user names or passwords and facilitating contact discovery (see below). The number does not have to be the same as on the device's SIM card; it can also be a VoIP number or a landline as long as the user can receive the verification code and have a separate device to set up the software. A number can only be registered on one mobile device at a time. Account registration requires an iOS or Android device.This mandatory connection to a phone number (a feature Signal shares with WhatsApp, KakaoTalk, and others) has been criticized as a \"major issue\" for privacy-conscious users who are not comfortable with giving out their private phone number. A workaround is to use a secondary phone number. The ability to choose a public, changeable username instead of sharing one's phone number is a widely-requested feature, and is currently in the works.Using phone numbers as identifiers may also create security risks that arise from the possibility of an attacker taking over a phone number. A similar vulnerability was used to attack at least one user in August 2022, though the attack was performed via the provider of Signal's SMS services, not any user's provider. The threat of this attack can be mitigated by enabling Signal's Registration Lock feature, a form of two-factor authentication that requires the user to enter a PIN to register the phone number on a new device.When linking Signal Desktop to a mobile device, the conversations history will not be synced; only the new messages will be shown on Signal Desktop.\n\n== Usability ==\nIn July 2016, the Internet Society published a user study that assessed the ability of Signal users to detect and deter man-in-the-middle attacks. The study concluded that 21 out of 28 participants failed to correctly compare public key fingerprints in order to verify the identity of other Signal users, and that most of these users believed they had succeeded, while they had actually failed. Four months later, Signal's user interface was updated to make verifying the identity of other Signal users simpler.\n\n== Architecture ==\n\n\n*** Encryption protocols ***\n\nSignal messages are encrypted with the Signal Protocol (formerly known as the TextSecure Protocol). The protocol combines the Double Ratchet Algorithm, prekeys, and an Extended Triple Diffie\u2013Hellman (X3DH) handshake. It uses Curve25519, AES-256, and HMAC-SHA256 as primitives. The protocol provides confidentiality, integrity, authentication, participant consistency, destination validation, forward secrecy, backward secrecy (a.k.a. future secrecy), causality preservation, message unlinkability, message repudiation, participation repudiation, and asynchronicity. It does not provide anonymity preservation, and requires servers for the relaying of messages and storing of public key material.The Signal Protocol also supports end-to-end encrypted group chats. The group chat protocol is a combination of a pairwise double ratchet and multicast encryption. In addition to the properties provided by the one-to-one protocol, the group chat protocol provides speaker consistency, out-of-order resilience, dropped message resilience, computational equality, trust equality, subgroup messaging, as well as contractible and expandable membership.In October 2014, researchers from Ruhr University Bochum published an analysis of the Signal Protocol. Among other findings, they presented an unknown key-share attack on the protocol, but in general, they found that it was secure. In October 2016, researchers from UK's University of Oxford, Queensland University of Technology in Australia, and Canada's McMaster University published a formal analysis of the protocol. They concluded that the protocol was cryptographically sound. In July 2017, researchers from Ruhr University Bochum found during another analysis of group messengers a purely theoretic attack against the group protocol of Signal: A user who knows the secret group ID of a group (due to having been a group member previously or stealing it from a member's device) can become a member of the group. Since the group ID cannot be guessed and such member changes are displayed to the remaining members, this attack is likely to be difficult to carry out without being detected.As of August 2018, the Signal Protocol has been implemented into WhatsApp, Facebook Messenger, Skype, and Google Allo, making it possible for the conversations of \"more than a billion people worldwide\" to be end-to-end encrypted. In Google Allo, Skype and Facebook Messenger, conversations are not encrypted with the Signal Protocol by default; they only offer end-to-end encryption in an optional mode.Up until March 2017, Signal's voice calls were encrypted with SRTP and the ZRTP key-agreement protocol, which was developed by Phil Zimmermann. In March 2017, Signal transitioned to a new WebRTC-based calling system that introduced the ability to make video calls. Signal's voice and video calling functionalities use the Signal Protocol channel for authentication instead of ZRTP.\n\n\n**** Authentication ****\nTo verify that a correspondent is really the person that they claim to be, Signal users can compare key fingerprints (or scan QR codes) out-of-band. The platform employs a trust on first use mechanism in order to notify the user if a correspondent's key changes.\n\n\n*** Local storage ***\nAfter receiving and decrypting messages, the application stored them locally on each device in a SQLite database that is encrypted with SQLCipher. The cryptographic key for this database is also stored locally and can be accessed if the device is unlocked. In December 2020, Cellebrite published a blog post announcing that one of their products could now access this key and use it to \"decrypt the Signal app\". Technology reporters later published articles about how Cellebrite had claimed to have the ability to \"break into the Signal app\" and \"crack Signal's encryption\". This latter interpretation was rejected by several experts, as well as representatives from Signal, who said the original post by Cellebrite had been about accessing data on \"an unlocked Android phone in their physical possession\" and that they \"could have just opened the app to look at the messages\". Similar extraction tools also exist for iOS devices and Signal Desktop.\n\n\n*** Servers ***\nSignal relies on centralized servers that are maintained by Signal Messenger. In addition to routing Signal's messages, the servers also facilitate the discovery of contacts who are also registered Signal users and the automatic exchange of users' public keys. By default, Signal's voice and video calls are peer-to-peer. If the caller is not in the receiver's address book, the call is routed through a server in order to hide the users' IP addresses.\n\n\n**** Contact discovery ****\nThe servers store registered users' phone numbers, public key material and push tokens which are necessary for setting up calls and transmitting messages. In order to determine which contacts are also Signal users, cryptographic hashes of the user's contact numbers are periodically transmitted to the server. The server then checks to see if those match any of the SHA256 hashes of registered users and tells the client if any matches are found. The hashed numbers are thereafter discarded from the server. In 2014, Moxie Marlinspike wrote that it is easy to calculate a map of all possible hash inputs to hash outputs and reverse the mapping because of the limited preimage space (the set of all possible hash inputs) of phone numbers, and that a \"practical privacy preserving contact discovery remains an unsolved problem.\" In September 2017, Signal's developers announced that they were working on a way for the Signal client applications to \"efficiently and scalably determine whether the contacts in their address book are Signal users without revealing the contacts in their address book to the Signal service.\"\n\n\n**** Metadata ****\nAll client-server communications are protected by TLS. Signal's developers have asserted that their servers do not keep logs about who called whom and when. In June 2016, Marlinspike told The Intercept that \"the closest piece of information to metadata that the Signal server stores is the last time each user connected to the server, and the precision of this information is reduced to the day, rather than the hour, minute, and second\".The group messaging mechanism is designed so that the servers do not have access to the membership list, group title, or group icon. Instead, the creation, updating, joining, and leaving of groups is done by the clients, which deliver pairwise messages to the participants in the same way that one-to-one messages are delivered.\n\n\n**** Federation ****\nSignal's server architecture was federated between December 2013 and February 2016. In December 2013, it was announced that the messaging protocol Signal uses had successfully been integrated into the Android-based open-source operating system CyanogenMod. Since CyanogenMod 11.0, the client logic was contained in a system app called WhisperPush. According to Signal's developers, the Cyanogen team ran their own Signal messaging server for WhisperPush clients, which federated with the main server, so that both clients could exchange messages with each other. The WhisperPush source code was available under the GPLv3 license. In February 2016, the CyanogenMod team discontinued WhisperPush and recommended that its users switch to Signal. In May 2016, Moxie Marlinspike wrote that federation with the CyanogenMod servers had degraded the user experience and held back development, and that their servers will probably not federate with other servers again.In May 2016, Moxie Marlinspike requested that a third-party client called LibreSignal not use the Signal service or the Signal name. As a result, on 24 May 2016 the LibreSignal project posted that the project was \"abandoned\". The functionality provided by LibreSignal was subsequently incorporated into Signal by Marlinspike.\n\n\n*** Licensing ***\nThe complete source code of the Signal clients for Android, iOS and desktop is available on GitHub under a free software license. This enables interested parties to examine the code and help the developers verify that everything is behaving as expected. It also allows advanced users to compile their own copies of the applications and compare them with the versions that are distributed by Signal Messenger. In March 2016, Moxie Marlinspike wrote that, apart from some shared libraries that are not compiled with the project build due to a lack of Gradle NDK support, Signal for Android is reproducible. Signal's servers are partially open source, but the server software's anti-spam component is proprietary and closed source due to security concerns.\n\n== Bibliography =="
    }
  },
  {
    "instruction": "Write an answer to the following question: How do anti-virus software makers respond to the threat of Trojan:Win32/FakeSysdef?",
    "context": "",
    "output": "Anti-virus software makers respond to the threat of Trojan:Win32/FakeSysdef by adding checks for it in their products. However, simple removal of the software may not be enough to reverse the damage to configuration files that Trojan:Win32/FakeSysdef was known to edit.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do anti-virus software makers respond to the threat of Trojan:Win32/FakeSysdef?",
      "answer": "Anti-virus software makers respond to the threat of Trojan:Win32/FakeSysdef by adding checks for it in their products. However, simple removal of the software may not be enough to reverse the damage to configuration files that Trojan:Win32/FakeSysdef was known to edit."
    }
  },
  {
    "instruction": "Bug bounty program\n\n==Introduction==\nA bug bounty program is a deal offered by many websites, organizations and software developers by which individuals can receive recognition and compensation for reporting bugs, especially those pertaining to security exploits and vulnerabilities.These programs allow the developers to discover and resolve bugs before the general public is aware of them, preventing incidents of widespread abuse and data breaches. Bug bounty programs have been implemented by a large number of organizations, including Mozilla, Facebook, Yahoo!, Google, Reddit, Square, Microsoft, and the Internet bug bounty.Companies outside the technology industry, including traditionally conservative organizations like the United States Department of Defense, have started using bug bounty programs. The Pentagon's use of bug bounty programs is part of a posture shift that has seen several US Government Agencies reverse course from threatening white hat hackers with legal recourse to inviting them to participate as part of a comprehensive vulnerability disclosure framework or policy.\n\n== Vulnerability Disclosure Policy controversy ==\nIn August 2013, a Palestinian computer science student reported a vulnerability that allowed anyone to post a video on an arbitrary Facebook account. According to the email communication between the student and Facebook, he attempted to report the vulnerability using Facebook's bug bounty program but the student was misunderstood by Facebook's engineers. Later he exploited the vulnerability using the Facebook profile of Mark Zuckerberg, resulting into Facebook refusing to pay him a bounty.\n\nFacebook started paying researchers who find and report security bugs by issuing them custom branded \"White Hat\" debit cards that can be reloaded with funds each time the researchers discover new flaws. \"Researchers who find bugs and security improvements are rare, and we value them and have to find ways to reward them,\" Ryan McGeehan, former manager of Facebook's security response team, told CNET in an interview. \"Having this exclusive black card is another way to recognize them. They can show up at a conference and show this card and say 'I did special work for Facebook.'\" In 2014, Facebook stopped issuing debit cards to researchers.\nIn 2016, Uber experienced a security incident when an individual accessed the personal information of 57 million Uber users worldwide. The individual supposedly demanded a ransom of $100,000 in order to destroy rather than publish the data. In Congressional testimony, Uber CISO indicated that the company verified that the data had been destroyed before paying the $100,000. Mr. Flynn expressed regret that Uber did not disclose the incident in 2016. As part of their response to this incident, Uber worked with partner HackerOne to update their bug bounty program policies to, among other things, more thoroughly explain good faith vulnerability research and disclosure.Yahoo! was severely criticized for sending out Yahoo! T-shirts as reward to the Security Researchers for finding and reporting security vulnerabilities in Yahoo!, sparking what came to be called T-shirt-gate. High-Tech Bridge, a Geneva, Switzerland-based security testing company issued a press release saying Yahoo! offered $12.50 in credit per vulnerability, which could be used toward Yahoo-branded items such as T-shirts, cups and pens from its store. Ramses Martinez, director of Yahoo's security team claimed later in a blog post that he was behind the voucher reward program, and that he basically had been paying for them out of his own pocket. Eventually, Yahoo! launched its new bug bounty program on October 31 of the same year, that allows security researchers to submit bugs and receive rewards between $250 and $15,000, depending on the severity of the bug discovered.Similarly, when Ecava released the first known bug bounty program for ICS in 2013, they were criticized for offering store credits instead of cash which does not incentivize security researchers. Ecava explained that the program was intended to be initially restrictive and focused on the human safety perspective for the users of IntegraXor SCADA, their ICS software.Some bug bounties programs have been criticized as tools to prevent security researcher from publicly disclosing vulnerabilities, by conditioning the participation to bug bounty or even granting safe-harbor, to abusive non-disclosure agreements.\n\n== Geography ==\nThough submissions for bug bounties come from many countries, a handful of countries tend to submit more bugs and receive more bounties. The United States and India are the top countries from which researchers submit bugs. India, which has either the first or second largest number of bug hunters in the world, depending on which report one cites, topped the Facebook Bug Bounty Program with the largest number of valid bugs. \"India came out on top with the number of valid submissions in 2017, with the United States and Trinidad and Tobago in second and third place, respectively\", Facebook quoted in a post.\n\n== Notable programs ==\nIn October 2013, Google announced a major change to its Vulnerability Reward Program. Previously, it had been a bug bounty program covering many Google products. With the shift, however, the program was broadened to include a selection of high-risk free software applications and libraries, primarily those designed for networking or for low-level operating system functionality. Submissions that Google found adherent to the guidelines would be eligible for rewards ranging from $500 to $3,133.70. In 2017, Google expanded their program to cover vulnerabilities found in applications developed by third parties and made available through the Google Play Store. Google's Vulnerability Rewards Program now includes vulnerabilities found in Google, Google Cloud, Android, and Chrome products, and rewards up to $31,337.Microsoft and Facebook partnered in November 2013 to sponsor The Internet Bug Bounty, a program to offer rewards for reporting hacks and exploits for a broad range of Internet-related software. In 2017, GitHub and The Ford Foundation sponsored the initiative, which is managed by volunteers including from Uber, Microsoft, Adobe, HackerOne, GitHub, NCC Group, and Signal Sciences. The software covered by the IBB includes Adobe Flash, Python, Ruby, PHP, Django, Ruby on Rails, Perl, OpenSSL, Nginx, Apache HTTP Server, and Phabricator. In addition, the program offered rewards for broader exploits affecting widely used operating systems and web browsers, as well as the Internet as a whole.In March 2016, Peter Cook announced the US federal government's first bug bounty program, the \"Hack the Pentagon\" program. The program ran from April 18 to May 12 and over 1,400 people submitted 138 unique valid reports through HackerOne. In total, the US Department of Defense paid out $71,200.In 2019, The European Commission announced the EU-FOSSA 2 bug bounty initiative for popular open source projects, including Drupal, Apache Tomcat, VLC, 7-zip and KeePass. The project was co-facilitated by European bug bounty platform Intigriti and HackerOne and resulted in a total of 195 unique and valid vulnerabilities.Open Bug Bounty is a crowd security bug bounty program established in 2014 that allows individuals to post website and web application security vulnerabilities in the hope of a reward from affected website operators.Center for Analysis and Investigation of Cyber Attacks (TSARKA), a cybersecurity company of Kazakhstan, on December 8th, 2021, launched a National vulnerability reward program called BugBounty.kz. Among the private companies, governmental information systems and information resources have joined the program. Since the launch and up until October 28th, 2021, 1039 vulnerability reports were submitted. During the operation of the program several critical vulnerabilities were reported that could have led to the personal data leak from the critical infrastructure and possible manipulation of SCADA systems responsible for the city life support.\n\nQ: Why do companies issue custom branded debit cards as rewards for finding bugs?",
    "context": "",
    "output": "A: Companies issue custom branded debit cards as rewards to recognize and encourage researchers who find bugs and security improvements. This exclusive recognition allows researchers to showcase their work at conferences and receive rewards for their discoveries.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why do companies issue custom branded debit cards as rewards for finding bugs?",
      "answer": "Companies issue custom branded debit cards as rewards to recognize and encourage researchers who find bugs and security improvements. This exclusive recognition allows researchers to showcase their work at conferences and receive rewards for their discoveries.",
      "context": "Bug bounty program\n\n==Introduction==\nA bug bounty program is a deal offered by many websites, organizations and software developers by which individuals can receive recognition and compensation for reporting bugs, especially those pertaining to security exploits and vulnerabilities.These programs allow the developers to discover and resolve bugs before the general public is aware of them, preventing incidents of widespread abuse and data breaches. Bug bounty programs have been implemented by a large number of organizations, including Mozilla, Facebook, Yahoo!, Google, Reddit, Square, Microsoft, and the Internet bug bounty.Companies outside the technology industry, including traditionally conservative organizations like the United States Department of Defense, have started using bug bounty programs. The Pentagon's use of bug bounty programs is part of a posture shift that has seen several US Government Agencies reverse course from threatening white hat hackers with legal recourse to inviting them to participate as part of a comprehensive vulnerability disclosure framework or policy.\n\n== Vulnerability Disclosure Policy controversy ==\nIn August 2013, a Palestinian computer science student reported a vulnerability that allowed anyone to post a video on an arbitrary Facebook account. According to the email communication between the student and Facebook, he attempted to report the vulnerability using Facebook's bug bounty program but the student was misunderstood by Facebook's engineers. Later he exploited the vulnerability using the Facebook profile of Mark Zuckerberg, resulting into Facebook refusing to pay him a bounty.\n\nFacebook started paying researchers who find and report security bugs by issuing them custom branded \"White Hat\" debit cards that can be reloaded with funds each time the researchers discover new flaws. \"Researchers who find bugs and security improvements are rare, and we value them and have to find ways to reward them,\" Ryan McGeehan, former manager of Facebook's security response team, told CNET in an interview. \"Having this exclusive black card is another way to recognize them. They can show up at a conference and show this card and say 'I did special work for Facebook.'\" In 2014, Facebook stopped issuing debit cards to researchers.\nIn 2016, Uber experienced a security incident when an individual accessed the personal information of 57 million Uber users worldwide. The individual supposedly demanded a ransom of $100,000 in order to destroy rather than publish the data. In Congressional testimony, Uber CISO indicated that the company verified that the data had been destroyed before paying the $100,000. Mr. Flynn expressed regret that Uber did not disclose the incident in 2016. As part of their response to this incident, Uber worked with partner HackerOne to update their bug bounty program policies to, among other things, more thoroughly explain good faith vulnerability research and disclosure.Yahoo! was severely criticized for sending out Yahoo! T-shirts as reward to the Security Researchers for finding and reporting security vulnerabilities in Yahoo!, sparking what came to be called T-shirt-gate. High-Tech Bridge, a Geneva, Switzerland-based security testing company issued a press release saying Yahoo! offered $12.50 in credit per vulnerability, which could be used toward Yahoo-branded items such as T-shirts, cups and pens from its store. Ramses Martinez, director of Yahoo's security team claimed later in a blog post that he was behind the voucher reward program, and that he basically had been paying for them out of his own pocket. Eventually, Yahoo! launched its new bug bounty program on October 31 of the same year, that allows security researchers to submit bugs and receive rewards between $250 and $15,000, depending on the severity of the bug discovered.Similarly, when Ecava released the first known bug bounty program for ICS in 2013, they were criticized for offering store credits instead of cash which does not incentivize security researchers. Ecava explained that the program was intended to be initially restrictive and focused on the human safety perspective for the users of IntegraXor SCADA, their ICS software.Some bug bounties programs have been criticized as tools to prevent security researcher from publicly disclosing vulnerabilities, by conditioning the participation to bug bounty or even granting safe-harbor, to abusive non-disclosure agreements.\n\n== Geography ==\nThough submissions for bug bounties come from many countries, a handful of countries tend to submit more bugs and receive more bounties. The United States and India are the top countries from which researchers submit bugs. India, which has either the first or second largest number of bug hunters in the world, depending on which report one cites, topped the Facebook Bug Bounty Program with the largest number of valid bugs. \"India came out on top with the number of valid submissions in 2017, with the United States and Trinidad and Tobago in second and third place, respectively\", Facebook quoted in a post.\n\n== Notable programs ==\nIn October 2013, Google announced a major change to its Vulnerability Reward Program. Previously, it had been a bug bounty program covering many Google products. With the shift, however, the program was broadened to include a selection of high-risk free software applications and libraries, primarily those designed for networking or for low-level operating system functionality. Submissions that Google found adherent to the guidelines would be eligible for rewards ranging from $500 to $3,133.70. In 2017, Google expanded their program to cover vulnerabilities found in applications developed by third parties and made available through the Google Play Store. Google's Vulnerability Rewards Program now includes vulnerabilities found in Google, Google Cloud, Android, and Chrome products, and rewards up to $31,337.Microsoft and Facebook partnered in November 2013 to sponsor The Internet Bug Bounty, a program to offer rewards for reporting hacks and exploits for a broad range of Internet-related software. In 2017, GitHub and The Ford Foundation sponsored the initiative, which is managed by volunteers including from Uber, Microsoft, Adobe, HackerOne, GitHub, NCC Group, and Signal Sciences. The software covered by the IBB includes Adobe Flash, Python, Ruby, PHP, Django, Ruby on Rails, Perl, OpenSSL, Nginx, Apache HTTP Server, and Phabricator. In addition, the program offered rewards for broader exploits affecting widely used operating systems and web browsers, as well as the Internet as a whole.In March 2016, Peter Cook announced the US federal government's first bug bounty program, the \"Hack the Pentagon\" program. The program ran from April 18 to May 12 and over 1,400 people submitted 138 unique valid reports through HackerOne. In total, the US Department of Defense paid out $71,200.In 2019, The European Commission announced the EU-FOSSA 2 bug bounty initiative for popular open source projects, including Drupal, Apache Tomcat, VLC, 7-zip and KeePass. The project was co-facilitated by European bug bounty platform Intigriti and HackerOne and resulted in a total of 195 unique and valid vulnerabilities.Open Bug Bounty is a crowd security bug bounty program established in 2014 that allows individuals to post website and web application security vulnerabilities in the hope of a reward from affected website operators.Center for Analysis and Investigation of Cyber Attacks (TSARKA), a cybersecurity company of Kazakhstan, on December 8th, 2021, launched a National vulnerability reward program called BugBounty.kz. Among the private companies, governmental information systems and information resources have joined the program. Since the launch and up until October 28th, 2021, 1039 vulnerability reports were submitted. During the operation of the program several critical vulnerabilities were reported that could have led to the personal data leak from the critical infrastructure and possible manipulation of SCADA systems responsible for the city life support."
    }
  },
  {
    "instruction": "Write an answer to the following question: What steps did U.S. government agencies take in regards to Kaspersky software?",
    "context": "",
    "output": "From July 2017 to December 2017, U.S. government agencies phased out their use of Kaspersky software, and in July 2017, the General Services Administration (GSA) removed Kaspersky Lab from its list of vendors authorized to do business with the U.S. government.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What steps did U.S. government agencies take in regards to Kaspersky software?",
      "answer": "From July 2017 to December 2017, U.S. government agencies phased out their use of Kaspersky software, and in July 2017, the General Services Administration (GSA) removed Kaspersky Lab from its list of vendors authorized to do business with the U.S. government."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can a malicious cryptographer disrupt the DC-net protocol?",
    "context": "",
    "output": "A malicious cryptographer can disrupt the DC-net protocol by sending random bits instead of the correct result of the XOR. This problem occurs because the original protocol was designed without using any public key technology and lacks reliable mechanisms to check whether participants honestly follow the protocol.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a malicious cryptographer disrupt the DC-net protocol?",
      "answer": "A malicious cryptographer can disrupt the DC-net protocol by sending random bits instead of the correct result of the XOR. This problem occurs because the original protocol was designed without using any public key technology and lacks reliable mechanisms to check whether participants honestly follow the protocol."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Tor onion proxy software provide online anonymity and what are some benefits and drawbacks of this approach?",
    "context": "",
    "output": "The Tor onion proxy software provides online anonymity by routing Internet traffic through a worldwide volunteer network of servers for concealing a user's computer location or usage from someone conducting network surveillance or traffic analysis. This reduces the possibility of the original data being unscrambled or understood in transit and protects users' personal freedom and privacy. However, Tor may be slower than other proxy solutions due to the layered nature of the encryption service and the use of multiple servers to route traffic.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Tor onion proxy software provide online anonymity and what are some benefits and drawbacks of this approach?",
      "answer": "The Tor onion proxy software provides online anonymity by routing Internet traffic through a worldwide volunteer network of servers for concealing a user's computer location or usage from someone conducting network surveillance or traffic analysis. This reduces the possibility of the original data being unscrambled or understood in transit and protects users' personal freedom and privacy. However, Tor may be slower than other proxy solutions due to the layered nature of the encryption service and the use of multiple servers to route traffic."
    }
  },
  {
    "instruction": "Encrypted function\n\n==Introduction==\nAn encrypted function is an attempt to provide mobile code privacy without providing any tamper-resistant hardware. It is a method where in mobile code can carry out cryptographic primitives even though the code \n\nis executed in untrusted environments.\nshould run autonomously.Polynomial and rational functions are encrypted such that their transformation can again be implemented as programs consisting of cleartext instructions that a processor or interpreter understands. The processor would not understand the program's function. This field of study is gaining popularity as mobile cryptography.\n\n\n\n== Example ==\nScenario: \nHost A, has an algorithm which computes function f. A wants to send its mobile agent to B which holds input x, to compute f(x). But A doesn't want B to learn anything about f.\nScheme:\nFunction f is encrypted in a way that results in E(f). Host A then creates another program P(E(f)), which implements E(f), and sends it to B through its agent. B then runs the agent, which computes P(E(f))(x) and returns the result to A. A then decrypts this to get f(x).\nDrawbacks:\nFinding appropriate encryption schemes that can transform arbitrary functions is a challenge. The scheme doesn't prevent denial of service, replay, experimental extraction and others.\n\nQ: What is an encrypted function, and what is its purpose in the context of mobile code privacy?",
    "context": "",
    "output": "A: An encrypted function is a method used to provide mobile code privacy without the need for tamper-resistant hardware. It allows mobile code to perform cryptographic primitives even when executed in untrusted environments. The purpose is to enable the execution of encrypted functions on untrusted hosts, ensuring that the host cannot access or modify the original function.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is an encrypted function, and what is its purpose in the context of mobile code privacy?",
      "answer": "An encrypted function is a method used to provide mobile code privacy without the need for tamper-resistant hardware. It allows mobile code to perform cryptographic primitives even when executed in untrusted environments. The purpose is to enable the execution of encrypted functions on untrusted hosts, ensuring that the host cannot access or modify the original function.",
      "context": "Encrypted function\n\n==Introduction==\nAn encrypted function is an attempt to provide mobile code privacy without providing any tamper-resistant hardware. It is a method where in mobile code can carry out cryptographic primitives even though the code \n\nis executed in untrusted environments.\nshould run autonomously.Polynomial and rational functions are encrypted such that their transformation can again be implemented as programs consisting of cleartext instructions that a processor or interpreter understands. The processor would not understand the program's function. This field of study is gaining popularity as mobile cryptography.\n\n\n\n== Example ==\nScenario: \nHost A, has an algorithm which computes function f. A wants to send its mobile agent to B which holds input x, to compute f(x). But A doesn't want B to learn anything about f.\nScheme:\nFunction f is encrypted in a way that results in E(f). Host A then creates another program P(E(f)), which implements E(f), and sends it to B through its agent. B then runs the agent, which computes P(E(f))(x) and returns the result to A. A then decrypts this to get f(x).\nDrawbacks:\nFinding appropriate encryption schemes that can transform arbitrary functions is a challenge. The scheme doesn't prevent denial of service, replay, experimental extraction and others."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is the one-time pad used in quantum cryptography?",
    "context": "",
    "output": "The one-time pad is commonly used in association with quantum key distribution (QKD) to provide a way of distributing a long shared secret key securely and efficiently. This is because QKD algorithms are able to determine whether an adversarial party has been attempting to intercept key material, and allow for a shared secret key to be agreed upon with relatively few messages exchanged and relatively low computational overhead.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the one-time pad used in quantum cryptography?",
      "answer": "The one-time pad is commonly used in association with quantum key distribution (QKD) to provide a way of distributing a long shared secret key securely and efficiently. This is because QKD algorithms are able to determine whether an adversarial party has been attempting to intercept key material, and allow for a shared secret key to be agreed upon with relatively few messages exchanged and relatively low computational overhead."
    }
  },
  {
    "instruction": "context: Anonym.OS was created, designed, and distributed by kaos.theory/security.research.\n\nAsk a question about this context.",
    "context": "",
    "output": "Who was responsible for the creation, design, and distribution of Anonym.OS?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who was responsible for the creation, design, and distribution of Anonym.OS?",
      "answer": "Anonym.OS was created, designed, and distributed by kaos.theory/security.research."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is structured validation and what does it allow for?",
    "context": "",
    "output": "Structured validation allows for the combination of other kinds of validation, along with more complex processing. Such complex processing may include the testing of conditional constraints for an entire complex data object or set of process operations within a system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is structured validation and what does it allow for?",
      "answer": "Structured validation allows for the combination of other kinds of validation, along with more complex processing. Such complex processing may include the testing of conditional constraints for an entire complex data object or set of process operations within a system."
    }
  },
  {
    "instruction": "context: The commercial version of Immunet was discontinued as of June 10, 2014, but Cisco, having acquired SourceFire, continued to support the free version. The free version is still available and supported for personal use.\n\nAsk a question about this context.",
    "context": "",
    "output": "Why was the commercial version of Immunet discontinued, and which version is still supported?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why was the commercial version of Immunet discontinued, and which version is still supported?",
      "answer": "The commercial version of Immunet was discontinued as of June 10, 2014, but Cisco, having acquired SourceFire, continued to support the free version. The free version is still available and supported for personal use."
    }
  },
  {
    "instruction": "Context: MailChannels\n\n==Introduction==\nMailChannels  is a Canadian technology company specializing in email security and delivery solutions for businesses and internet service providers (ISPs). Founded in 2004 by Ken Simpson and headquartered in Vancouver, British Columbia. MailChannels has grown to become a trusted name in the email security and infrastructure market. The company offers a range of products and services aimed at protecting email systems from spam, phishing, and other malicious content, while also ensuring reliable email delivery for legitimate messages.\n\n== Products ==\nMailChannels' flagship product, MailChannels Outbound Filtering, is a cloud-based email filtering and delivery platform designed to help web hosting providers combat spam, phishing and other email threats. By leveraging advanced machine learning algorithms and a globally distributed network of servers, MailChannels Outbound Filtering offers a scalable and effective solution for ensuring email security deliverability. The platform helps prevent the delivery of spam and malware, as well as protects recipients from malicious emails.\nIn addition to its cloud-based email security and delivery service, MailChannels also offers an on-premise software solution, MailChannels Transparent Filtering, a high-performance email gateway designed for large enterprises and ISPs. MailChannels Transparent Filtering integrates with existing email infrastructure to provide advanced threat protection and improved email delivery performance.\nMailChannels' customers include large web hosting companies, internet service providers, mailbox providers and email service providers such as DreamHost, Hostinger, Namecheap, and HostPapa.\n\n== Company History ==\nThe company was founded in 2004 by former engineers of ActiveState (acquired by Sophos), who created one of the first commercial spam filters.\nThe company's first product was an SMTP proxy that provides tar-pitting and transparent SMTP proxy functionality for inbound email filtering. At the 2007 MIT Spam Conference, the company's founder, Ken Simpson, was awarded the Best Paper award.\nIn 2007, MailChannels joined M\u00b3AAWG and closed a series A round led by early Microsoft employees.\nIn 2010, the company launched an outbound email filtering software that claims to be capable of filtering up to 30 million messages per hour, transparently in the network. Outbound email filtering involves scanning email traffic as it exits the network, identifying compromised accounts, and reducing the risk of having IP addresses blocked by receiving networks.\nIn 2013, the company launched a cloud-based outbound email filtering service.\nIn 2018, the company launched a cloud-based inbound email filtering service.\nIn 2022, the company decided to stop supporting Plesk for outbound email filtering.\nAnswer this question: In what ways does MailChannels Transparent Filtering improve email delivery performance for large enterprises and ISPs?",
    "context": "",
    "output": "MailChannels Transparent Filtering enhances email delivery performance by integrating seamlessly with existing email infrastructure. This integration enables the high-performance email gateway to optimize email routing, minimize latency, and ensure efficient handling of large email volumes. Furthermore, its advanced threat protection features help maintain system uptime and availability by effectively filtering out spam, phishing, and malware, thereby reducing the risk of network congestion or downtime due to security incidents.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In what ways does MailChannels Transparent Filtering improve email delivery performance for large enterprises and ISPs?",
      "answer": "MailChannels Transparent Filtering enhances email delivery performance by integrating seamlessly with existing email infrastructure. This integration enables the high-performance email gateway to optimize email routing, minimize latency, and ensure efficient handling of large email volumes. Furthermore, its advanced threat protection features help maintain system uptime and availability by effectively filtering out spam, phishing, and malware, thereby reducing the risk of network congestion or downtime due to security incidents.",
      "context": "MailChannels\n\n==Introduction==\nMailChannels  is a Canadian technology company specializing in email security and delivery solutions for businesses and internet service providers (ISPs). Founded in 2004 by Ken Simpson and headquartered in Vancouver, British Columbia. MailChannels has grown to become a trusted name in the email security and infrastructure market. The company offers a range of products and services aimed at protecting email systems from spam, phishing, and other malicious content, while also ensuring reliable email delivery for legitimate messages.\n\n== Products ==\nMailChannels' flagship product, MailChannels Outbound Filtering, is a cloud-based email filtering and delivery platform designed to help web hosting providers combat spam, phishing and other email threats. By leveraging advanced machine learning algorithms and a globally distributed network of servers, MailChannels Outbound Filtering offers a scalable and effective solution for ensuring email security deliverability. The platform helps prevent the delivery of spam and malware, as well as protects recipients from malicious emails.\nIn addition to its cloud-based email security and delivery service, MailChannels also offers an on-premise software solution, MailChannels Transparent Filtering, a high-performance email gateway designed for large enterprises and ISPs. MailChannels Transparent Filtering integrates with existing email infrastructure to provide advanced threat protection and improved email delivery performance.\nMailChannels' customers include large web hosting companies, internet service providers, mailbox providers and email service providers such as DreamHost, Hostinger, Namecheap, and HostPapa.\n\n== Company History ==\nThe company was founded in 2004 by former engineers of ActiveState (acquired by Sophos), who created one of the first commercial spam filters.\nThe company's first product was an SMTP proxy that provides tar-pitting and transparent SMTP proxy functionality for inbound email filtering. At the 2007 MIT Spam Conference, the company's founder, Ken Simpson, was awarded the Best Paper award.\nIn 2007, MailChannels joined M\u00b3AAWG and closed a series A round led by early Microsoft employees.\nIn 2010, the company launched an outbound email filtering software that claims to be capable of filtering up to 30 million messages per hour, transparently in the network. Outbound email filtering involves scanning email traffic as it exits the network, identifying compromised accounts, and reducing the risk of having IP addresses blocked by receiving networks.\nIn 2013, the company launched a cloud-based outbound email filtering service.\nIn 2018, the company launched a cloud-based inbound email filtering service.\nIn 2022, the company decided to stop supporting Plesk for outbound email filtering."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did Phorm's Webwise service affect the use of HTTPS?",
    "context": "",
    "output": "Phorm's Webwise service could not prevent the UID from being sent to websites using HTTPS, which could allow websites to associate the UID to any details the website collects about the visitor.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Phorm's Webwise service affect the use of HTTPS?",
      "answer": "Phorm's Webwise service could not prevent the UID from being sent to websites using HTTPS, which could allow websites to associate the UID to any details the website collects about the visitor."
    }
  },
  {
    "instruction": "context: Cowrie is designed to log brute force attacks and shell interaction performed by an attacker, while also acting as an SSH and telnet proxy to monitor attacker behavior towards other systems. This dual functionality allows Cowrie to capture valuable information about attack attempts and techniques, while also enabling it to serve as a conduit for attackers to interact with other systems in a controlled environment.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does Cowrie, as a honeypot, balance the need for logging brute force attacks with functioning as a proxy for attackers?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Cowrie, as a honeypot, balance the need for logging brute force attacks with functioning as a proxy for attackers?",
      "answer": "Cowrie is designed to log brute force attacks and shell interaction performed by an attacker, while also acting as an SSH and telnet proxy to monitor attacker behavior towards other systems. This dual functionality allows Cowrie to capture valuable information about attack attempts and techniques, while also enabling it to serve as a conduit for attackers to interact with other systems in a controlled environment."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of data files in Nikto's functionality?",
    "context": "",
    "output": "The data files used by Nikto are not open source and are separate from the Nikto code itself. These data files drive the program by providing it with information about the potentially dangerous files/CGIs, outdated server software, and other problems that it looks for during a scan.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of data files in Nikto's functionality?",
      "answer": "The data files used by Nikto are not open source and are separate from the Nikto code itself. These data files drive the program by providing it with information about the potentially dangerous files/CGIs, outdated server software, and other problems that it looks for during a scan."
    }
  },
  {
    "instruction": "context: If an executable file is owned by 'root' and the SUID permission is set, the file will be executed as 'root', allowing it to modify specific files that the user would not normally be allowed to.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the SUID permission affect the behavior of an executable file owned by 'root' in Linux and Unix systems?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the SUID permission affect the behavior of an executable file owned by 'root' in Linux and Unix systems?",
      "answer": "If an executable file is owned by 'root' and the SUID permission is set, the file will be executed as 'root', allowing it to modify specific files that the user would not normally be allowed to."
    }
  },
  {
    "instruction": "Wildcard certificate\n\n==Introduction==\nIn computer networking, a wildcard certificate is a public key certificate which can be used with multiple sub-domains of a domain. The principal use is for securing web sites with HTTPS, but there are also applications in many other fields.  Compared with conventional certificates, a wildcard certificate can be cheaper and more convenient than a certificate for each sub-domain. Multi-domain wildcard certificates further simplify the complexity and reduce costs by securing multiple domains and their sub-domains.\n\n== Example ==\nA single wildcard certificate for https://*.example.com will secure all these subdomains on the https://*.example.com domain:\n\npayment.example.com\ncontact.example.com\nlogin-secure.example.com\nwww.example.comInstead of getting separate certificates for subdomains, you can use a single certificate for all main domains and subdomains and reduce cost.Because the wildcard only covers one level of subdomains (the asterisk doesn't match full stops), these domains would not be valid for the certificate:\n\ntest.login.example.comThe \"naked\" domain is valid when added separately as a Subject Alternative Name (SubjectAltName):\nexample.comNote possible exceptions by CAs, for example wildcard-plus cert by DigiCert contains an automatic \"Plus\" property for the naked domain example.com.\n\n== Type of wildcard certificates ==\nWildcard certificates are categorized on the basis of validation level, number of domain and number of servers it can be used with. Likewise they are named as domain validation wildcard certificate, organisation validation wildcard certificate and extended validation wildcard certificate when we categorize them according to validation level. The name Multi-domain wildcard certificates and Multi-server wildcard certificates are given according to number of domain and number of server. All types of wildcard certificates signed by popular CAs are categorized and listed internet. Therefore there are types of wildcard which can secure multiple domains, multiple servers and provide different levels of validation.\n\n== Limitations ==\nOnly a single level of subdomain matching is supported in accordance with RFC 2818.It is not possible to get a wildcard for an Extended Validation Certificate.  A workaround could be to add every virtual host name in the Subject Alternative Name (SAN) extension, the major problem being that the certificate needs to be reissued whenever a new virtual server is added. (See Transport Layer Security \u00a7 Support for name-based virtual servers for more information.)\nWildcards can be added as domains in multi-domain certificates or Unified Communications Certificates (UCC). In addition, wildcards themselves can have subjectAltName extensions, including other wildcards. For example, the wildcard certificate *.wikipedia.org has *.m.wikimedia.org as a Subject Alternative Name. Thus it secures www.wikipedia.org as well as the completely different website name meta.m.wikimedia.org.RFC 6125 argues against wildcard certificates on security grounds, in particular \"partial wildcards\".\n\n== Examples ==\nThe wildcard applies only to one level of the domain name.\n\nlabel.label.label.TLD*.domain.com is OK. It will match www.domain.com but not domain.com and not zzz.www.domain.comThe wildcard may appear anywhere inside a label as a \"partial wildcard\" according to early specifications\nf*.domain.com is OK. It will match frog.domain.com but not frog.super.domain.combaz*.example.net is OK and matches baz1.example.net\n*baz.example.net is OK and matches foobaz.example.net\nb*z.example.net is OK and matches buzz.example.netHowever, use of \"partial-wildcard\" certs is not recommended.  As of 2011, partial wildcard support is optional, and is explicitly disallowed in SubjectAltName headers that are required for multi-name certificates. All major browsers have deliberately removed support for partial-wildcard certificates; they will result in a \"SSL_ERROR_BAD_CERT_DOMAIN\" error. Similarly, it is typical for standard libraries in programming languages to not support \"partial-wildcard\" certificates. For example, any \"partial-wildcard\" certificate will not work with the latest versions of both Python and Go. Thus, \nDo not allow a label that consists entirely of just a wildcard unless it is the left-most label\n\nsub1.*.domain.com is not allowed.A cert with multiple wildcards in a name is not allowed.\n\n*.*.domain.comA cert with * plus a top-level domain is not allowed.\n\n*.comToo general and should not be allowed.\n\n*International domain names encoded in ASCII (A-label) are labels that are ASCII-encoded and begin with xn--.\nDo not allow wildcards in an international label.\n\nxn--caf-dma.com is caf\u00e9.com\nxn--caf-dma*.com is not allowed\nLw*.xn--caf-dma.com is allowed\n\n== Relevant RFCs ==\nNewman, C. (June 1999). \"RFC 2595 - Using TLS with IMAP, POP3 and ACAP\". Internet Engineering Task Force: 3. doi:10.17487/RFC2595. {{cite journal}}: Cite journal requires |journal\n\nWhat is the recommended approach for using wildcard certificates in domain names?",
    "context": "",
    "output": "A: It is recommended to use the wildcard only in the left-most label of the domain name, and not to use partial wildcards. This is because partial wildcard support is optional and has been disallowed in SubjectAltName headers for multi-name certificates.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the recommended approach for using wildcard certificates in domain names?",
      "answer": "It is recommended to use the wildcard only in the left-most label of the domain name, and not to use partial wildcards. This is because partial wildcard support is optional and has been disallowed in SubjectAltName headers for multi-name certificates.",
      "context": "Wildcard certificate\n\n==Introduction==\nIn computer networking, a wildcard certificate is a public key certificate which can be used with multiple sub-domains of a domain. The principal use is for securing web sites with HTTPS, but there are also applications in many other fields.  Compared with conventional certificates, a wildcard certificate can be cheaper and more convenient than a certificate for each sub-domain. Multi-domain wildcard certificates further simplify the complexity and reduce costs by securing multiple domains and their sub-domains.\n\n== Example ==\nA single wildcard certificate for https://*.example.com will secure all these subdomains on the https://*.example.com domain:\n\npayment.example.com\ncontact.example.com\nlogin-secure.example.com\nwww.example.comInstead of getting separate certificates for subdomains, you can use a single certificate for all main domains and subdomains and reduce cost.Because the wildcard only covers one level of subdomains (the asterisk doesn't match full stops), these domains would not be valid for the certificate:\n\ntest.login.example.comThe \"naked\" domain is valid when added separately as a Subject Alternative Name (SubjectAltName):\nexample.comNote possible exceptions by CAs, for example wildcard-plus cert by DigiCert contains an automatic \"Plus\" property for the naked domain example.com.\n\n== Type of wildcard certificates ==\nWildcard certificates are categorized on the basis of validation level, number of domain and number of servers it can be used with. Likewise they are named as domain validation wildcard certificate, organisation validation wildcard certificate and extended validation wildcard certificate when we categorize them according to validation level. The name Multi-domain wildcard certificates and Multi-server wildcard certificates are given according to number of domain and number of server. All types of wildcard certificates signed by popular CAs are categorized and listed internet. Therefore there are types of wildcard which can secure multiple domains, multiple servers and provide different levels of validation.\n\n== Limitations ==\nOnly a single level of subdomain matching is supported in accordance with RFC 2818.It is not possible to get a wildcard for an Extended Validation Certificate.  A workaround could be to add every virtual host name in the Subject Alternative Name (SAN) extension, the major problem being that the certificate needs to be reissued whenever a new virtual server is added. (See Transport Layer Security \u00a7 Support for name-based virtual servers for more information.)\nWildcards can be added as domains in multi-domain certificates or Unified Communications Certificates (UCC). In addition, wildcards themselves can have subjectAltName extensions, including other wildcards. For example, the wildcard certificate *.wikipedia.org has *.m.wikimedia.org as a Subject Alternative Name. Thus it secures www.wikipedia.org as well as the completely different website name meta.m.wikimedia.org.RFC 6125 argues against wildcard certificates on security grounds, in particular \"partial wildcards\".\n\n== Examples ==\nThe wildcard applies only to one level of the domain name.\n\nlabel.label.label.TLD*.domain.com is OK. It will match www.domain.com but not domain.com and not zzz.www.domain.comThe wildcard may appear anywhere inside a label as a \"partial wildcard\" according to early specifications\nf*.domain.com is OK. It will match frog.domain.com but not frog.super.domain.combaz*.example.net is OK and matches baz1.example.net\n*baz.example.net is OK and matches foobaz.example.net\nb*z.example.net is OK and matches buzz.example.netHowever, use of \"partial-wildcard\" certs is not recommended.  As of 2011, partial wildcard support is optional, and is explicitly disallowed in SubjectAltName headers that are required for multi-name certificates. All major browsers have deliberately removed support for partial-wildcard certificates; they will result in a \"SSL_ERROR_BAD_CERT_DOMAIN\" error. Similarly, it is typical for standard libraries in programming languages to not support \"partial-wildcard\" certificates. For example, any \"partial-wildcard\" certificate will not work with the latest versions of both Python and Go. Thus, \nDo not allow a label that consists entirely of just a wildcard unless it is the left-most label\n\nsub1.*.domain.com is not allowed.A cert with multiple wildcards in a name is not allowed.\n\n*.*.domain.comA cert with * plus a top-level domain is not allowed.\n\n*.comToo general and should not be allowed.\n\n*International domain names encoded in ASCII (A-label) are labels that are ASCII-encoded and begin with xn--.\nDo not allow wildcards in an international label.\n\nxn--caf-dma.com is caf\u00e9.com\nxn--caf-dma*.com is not allowed\nLw*.xn--caf-dma.com is allowed\n\n== Relevant RFCs ==\nNewman, C. (June 1999). \"RFC 2595 - Using TLS with IMAP, POP3 and ACAP\". Internet Engineering Task Force: 3. doi:10.17487/RFC2595. {{cite journal}}: Cite journal requires |journal"
    }
  },
  {
    "instruction": "Whale (computer virus)\n\n==Introduction==\nThe Whale virus is a computer virus discovered on July 1, 1990. The file size, at 9,216 bytes, was for its time the largest virus ever discovered. It is known for using several advanced \"stealth\" methods.\n\n\n\n== Description ==\nAfter the file becomes resident in the system memory below the 640k DOS boundary, the operator will experience total system slow down as a result of the virus' polymorphic code. Symptoms include video flicker to the screen writing very slowly.  Files may seem to \"hang\" even though they will eventually execute correctly.  This is just a product of the total system slow down within the system's memory.\nIt was reported that one infected program displayed the following message when run:\n\n             THE WHALE IN SEARCH OF THE 8 FISH\n             I AM '~knzyvo}' IN HAMBURG addr error D9EB,02\n\nShifting the letters of \"~knzyvo}\" left in the ASCII table by 10 characters turns the string into \"tadpoles\".\n\nAnswer this question based on the above context: What is the purpose of the message displayed by the infected program?",
    "context": "",
    "output": "The purpose of the message displayed by the infected program is not explicitly stated in the text, but it may be intended to signal the presence of the Whale virus or to provide information about the virus to the user.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the message displayed by the infected program?",
      "answer": "The purpose of the message displayed by the infected program is not explicitly stated in the text, but it may be intended to signal the presence of the Whale virus or to provide information about the virus to the user.",
      "context": "Whale (computer virus)\n\n==Introduction==\nThe Whale virus is a computer virus discovered on July 1, 1990. The file size, at 9,216 bytes, was for its time the largest virus ever discovered. It is known for using several advanced \"stealth\" methods.\n\n\n\n== Description ==\nAfter the file becomes resident in the system memory below the 640k DOS boundary, the operator will experience total system slow down as a result of the virus' polymorphic code. Symptoms include video flicker to the screen writing very slowly.  Files may seem to \"hang\" even though they will eventually execute correctly.  This is just a product of the total system slow down within the system's memory.\nIt was reported that one infected program displayed the following message when run:\n\n             THE WHALE IN SEARCH OF THE 8 FISH\n             I AM '~knzyvo}' IN HAMBURG addr error D9EB,02\n\nShifting the letters of \"~knzyvo}\" left in the ASCII table by 10 characters turns the string into \"tadpoles\"."
    }
  },
  {
    "instruction": "Write an answer to the following question: How are CTF exercises used in the Advanced Course in Engineering on Cyber Security?",
    "context": "",
    "output": "CTF exercises are used to teach cybersecurity concepts in the Advanced Course in Engineering on Cyber Security, an immersive summer program offered to ROTC cadets, active duty members, and undergraduates.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are CTF exercises used in the Advanced Course in Engineering on Cyber Security?",
      "answer": "CTF exercises are used to teach cybersecurity concepts in the Advanced Course in Engineering on Cyber Security, an immersive summer program offered to ROTC cadets, active duty members, and undergraduates."
    }
  },
  {
    "instruction": "context: A dual-homed host provides secure access between an untrusted network and a trusted network by having two network interfaces (NICs), with one interface connected to the untrusted network and the other connected to the trusted network. The dual-homed host acts as a proxy or gateway, providing secured applications or services directly to the untrusted network.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does a dual-homed host (or dual-homed gateway) provide secure access between an untrusted network and a trusted network?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a dual-homed host (or dual-homed gateway) provide secure access between an untrusted network and a trusted network?",
      "answer": "A dual-homed host provides secure access between an untrusted network and a trusted network by having two network interfaces (NICs), with one interface connected to the untrusted network and the other connected to the trusted network. The dual-homed host acts as a proxy or gateway, providing secured applications or services directly to the untrusted network."
    }
  },
  {
    "instruction": "context: The Pentium F00F bug is caused by the use of the lock prefix with an invalid operand in the cmpxchg8b instruction. The lock prefix is used to prevent two processors from interfering with the same memory location, but in this case, it leads to an erroneous use of locked bus cycles, resulting in the processor locking up.\n\nAsk a question about this context.",
    "context": "",
    "output": "What architectural issue is at the root of the Pentium F00F bug?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What architectural issue is at the root of the Pentium F00F bug?",
      "answer": "The Pentium F00F bug is caused by the use of the lock prefix with an invalid operand in the cmpxchg8b instruction. The lock prefix is used to prevent two processors from interfering with the same memory location, but in this case, it leads to an erroneous use of locked bus cycles, resulting in the processor locking up."
    }
  },
  {
    "instruction": "context: The RMF addresses outsourcing risks by focusing on the impact of third-party supplier meeting their requirements. This is achieved by categorizing risk at a high level into outsourcing risks and addressing these risks as part of the RMF process.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the RMF address outsourcing risks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the RMF address outsourcing risks?",
      "answer": "The RMF addresses outsourcing risks by focusing on the impact of third-party supplier meeting their requirements. This is achieved by categorizing risk at a high level into outsourcing risks and addressing these risks as part of the RMF process."
    }
  },
  {
    "instruction": "context: The Candiru spyware was used to infiltrate the personal computers of four victims in the CatalanGate scandal. The targets were sent emails containing malicious links and were enticed to click on them. Once they clicked on the link, their personal computers became infected with Candiru spyware. A total of seven such emails were identified, some of which appeared to be messages from a Spanish governmental institution with public health recommendations in connection to the 2019 coronavirus epidemic.\n\nAsk a question about this context.",
    "context": "",
    "output": "How was the Candiru spyware used in the CatalanGate scandal?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How was the Candiru spyware used in the CatalanGate scandal?",
      "answer": "The Candiru spyware was used to infiltrate the personal computers of four victims in the CatalanGate scandal. The targets were sent emails containing malicious links and were enticed to click on them. Once they clicked on the link, their personal computers became infected with Candiru spyware. A total of seven such emails were identified, some of which appeared to be messages from a Spanish governmental institution with public health recommendations in connection to the 2019 coronavirus epidemic."
    }
  },
  {
    "instruction": "Write an answer to the following question: Is VBA32 Antivirus used as one of the antivirus engines at other antivirus software platforms besides VirusTotal?",
    "context": "",
    "output": "The given text does not provide information on whether VBA32 Antivirus is used as an antivirus engine at other platforms.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is VBA32 Antivirus used as one of the antivirus engines at other antivirus software platforms besides VirusTotal?",
      "answer": "The given text does not provide information on whether VBA32 Antivirus is used as an antivirus engine at other platforms."
    }
  },
  {
    "instruction": "context: SSH tunneling allows users to forward all their traffic over an encrypted channel, which can hide both outgoing requests for blocked sites and the response from those sites from censors. This can make it more difficult for censors to detect and block the use of certain websites or services.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does SSH tunneling help to bypass Internet censorship?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SSH tunneling help to bypass Internet censorship?",
      "answer": "SSH tunneling allows users to forward all their traffic over an encrypted channel, which can hide both outgoing requests for blocked sites and the response from those sites from censors. This can make it more difficult for censors to detect and block the use of certain websites or services."
    }
  },
  {
    "instruction": "context: The Siemens & Halske T52 machine was used by Luftwaffe and German Navy units.\n\nAsk a question about this context.",
    "context": "",
    "output": "Which German units used the Siemens & Halske T52 machine?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which German units used the Siemens & Halske T52 machine?",
      "answer": "The Siemens & Halske T52 machine was used by Luftwaffe and German Navy units."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the Reference Identifier field in an NTP packet when a Stratum field is 0, and what was added in RFC 4330 in January 2006 to help with NTP server misuse and abuse?",
    "context": "",
    "output": "The Reference Identifier field in an NTP packet when a Stratum field is 0 was extended in semantics to provide a technical means of enforcing a server's access policy. In January 2006, RFC 4330 was published, updating details of the SNTP protocol, but also provisionally clarifying and extending the related NTP protocol in some areas. Sections 8 to 11 of RFC 4330 are of particular relevance to this topic (The Kiss-o'-Death Packet, On Being a Good Network Citizen, Best Practices, Security Considerations). Section 8 introduces Kiss-o'-Death packets, which got their name because an early use was to tell clients to stop sending packets that violate server access controls.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the Reference Identifier field in an NTP packet when a Stratum field is 0, and what was added in RFC 4330 in January 2006 to help with NTP server misuse and abuse?",
      "answer": "The Reference Identifier field in an NTP packet when a Stratum field is 0 was extended in semantics to provide a technical means of enforcing a server's access policy. In January 2006, RFC 4330 was published, updating details of the SNTP protocol, but also provisionally clarifying and extending the related NTP protocol in some areas. Sections 8 to 11 of RFC 4330 are of particular relevance to this topic (The Kiss-o'-Death Packet, On Being a Good Network Citizen, Best Practices, Security Considerations). Section 8 introduces Kiss-o'-Death packets, which got their name because an early use was to tell clients to stop sending packets that violate server access controls."
    }
  },
  {
    "instruction": "context: According to the claim, Iran holds the 4th rank among the world's cyber armies in terms of power.\n\nAsk a question about this context.",
    "context": "",
    "output": "According to a claim made by a general in the Islamic Revolutionary Guards and supported by the Israeli Institute for National Security Studies, what rank does Iran hold among the world's cyber armies in terms of power?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "According to a claim made by a general in the Islamic Revolutionary Guards and supported by the Israeli Institute for National Security Studies, what rank does Iran hold among the world's cyber armies in terms of power?",
      "answer": "According to the claim, Iran holds the 4th rank among the world's cyber armies in terms of power."
    }
  },
  {
    "instruction": "Answer based on context:\n\nGreat Cannon\n\n==Introduction==\nThe Great Cannon of China is an Internet attack tool that is used by the Chinese government to launch distributed denial-of-service attacks on websites by performing a man-in-the-middle attack on large amounts of web traffic and injecting code which causes the end-user's web browsers to  flood traffic to targeted websites. According to the researchers at the Citizen Lab, the International Computer Science Institute, and Princeton University's Center for Information Technology Policy, who coined the term, the Great Cannon hijacks foreign web traffic intended for Chinese websites and re-purposes them to flood targeted web servers with enormous amounts of traffic in an attempt to disrupt their operations. While it is co-located with the Great Firewall, the Great Cannon is \"a separate offensive system, with different capabilities and design.\"Besides launching denial-of-service attacks, the tool is also capable of monitoring web traffic and distributing malware in targeted attacks in ways that are similar to the Quantum Insert system used by the U.S. National Security Agency.\n\n\n\n== Mechanism ==\n\nThe Great Cannon hijacks insecure traffic inbound to servers within the Great Firewall, and injects JavaScript that redirects that traffic to the target. These attacks fail when websites have HTTPS encryption.\n\n== Known uses ==\n\nThe first known targets of the Great Cannon (in late March 2015) were websites hosting censorship-evading tools, including GitHub, a web-based code hosting service, and GreatFire, a service monitoring blocked websites in China.In 2017, the Great Cannon was used to attack the Mingjing News website.As of December 2019, the Great Cannon was being used to attempt to take down the Hong Kong-based LIHKG online forum, even though the Basic Law of Hong Kong clearly states that Hong Kong's internet is the affairs of Hong Kong and Hong Kong only.\n\n== Reaction ==\nQuartz reported that the 2015 GitHub attack caused \"severe\" political problems for China, including the United States Department of State viewing it as \"an attack against US infrastructure\".\n\nWhich websites were the first known targets of the Great Cannon of China in 2015?",
    "context": "",
    "output": "The first known targets of the Great Cannon were websites hosting censorship-evading tools, including GitHub, a web-based code hosting service, and GreatFire, a service monitoring blocked websites in China.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which websites were the first known targets of the Great Cannon of China in 2015?",
      "answer": "The first known targets of the Great Cannon were websites hosting censorship-evading tools, including GitHub, a web-based code hosting service, and GreatFire, a service monitoring blocked websites in China.",
      "context": "Great Cannon\n\n==Introduction==\nThe Great Cannon of China is an Internet attack tool that is used by the Chinese government to launch distributed denial-of-service attacks on websites by performing a man-in-the-middle attack on large amounts of web traffic and injecting code which causes the end-user's web browsers to  flood traffic to targeted websites. According to the researchers at the Citizen Lab, the International Computer Science Institute, and Princeton University's Center for Information Technology Policy, who coined the term, the Great Cannon hijacks foreign web traffic intended for Chinese websites and re-purposes them to flood targeted web servers with enormous amounts of traffic in an attempt to disrupt their operations. While it is co-located with the Great Firewall, the Great Cannon is \"a separate offensive system, with different capabilities and design.\"Besides launching denial-of-service attacks, the tool is also capable of monitoring web traffic and distributing malware in targeted attacks in ways that are similar to the Quantum Insert system used by the U.S. National Security Agency.\n\n\n\n== Mechanism ==\n\nThe Great Cannon hijacks insecure traffic inbound to servers within the Great Firewall, and injects JavaScript that redirects that traffic to the target. These attacks fail when websites have HTTPS encryption.\n\n== Known uses ==\n\nThe first known targets of the Great Cannon (in late March 2015) were websites hosting censorship-evading tools, including GitHub, a web-based code hosting service, and GreatFire, a service monitoring blocked websites in China.In 2017, the Great Cannon was used to attack the Mingjing News website.As of December 2019, the Great Cannon was being used to attempt to take down the Hong Kong-based LIHKG online forum, even though the Basic Law of Hong Kong clearly states that Hong Kong's internet is the affairs of Hong Kong and Hong Kong only.\n\n== Reaction ==\nQuartz reported that the 2015 GitHub attack caused \"severe\" political problems for China, including the United States Department of State viewing it as \"an attack against US infrastructure\"."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the advice given by the U.S. Department of Homeland Security to remediate Dorkbot infections in 2015?",
    "context": "",
    "output": "The U.S. Department of Homeland Security advised using and maintaining anti-virus software, changing passwords, keeping the operating system and application software up-to-date, using anti-malware tools, and disabling AutoRun to remediate Dorkbot infections.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the advice given by the U.S. Department of Homeland Security to remediate Dorkbot infections in 2015?",
      "answer": "The U.S. Department of Homeland Security advised using and maintaining anti-virus software, changing passwords, keeping the operating system and application software up-to-date, using anti-malware tools, and disabling AutoRun to remediate Dorkbot infections."
    }
  },
  {
    "instruction": "Health Insurance Portability and Accountability Act\n\n==Introduction==\nThe Health Insurance Portability and Accountability Act of 1996 (HIPAA or the Kennedy\u2013Kassebaum Act) is a United States Act of Congress enacted by the 104th United States Congress and signed into law by President Bill Clinton on August 21, 1996. It modernized the flow of healthcare information, stipulates how personally identifiable information maintained by the healthcare and healthcare insurance industries should be protected from fraud and theft, and addressed some limitations on healthcare insurance coverage. It generally prohibits healthcare providers and healthcare businesses, called covered entities, from disclosing protected information to anyone other than a patient and the patient's authorized representatives without their consent. With limited exceptions, it does not restrict patients from receiving information about themselves. It does not prohibit patients from voluntarily sharing their health information however they choose, nor does it require confidentiality where a patient discloses medical information to family members, friends, or other individuals not a part of a covered entity.\nThe act consists of five titles. Title I of HIPAA protects health insurance coverage for workers and their families when they change or lose their jobs. Title II of HIPAA, known as the Administrative Simplification (AS) provisions, requires the establishment of national standards for electronic health care transactions and national identifiers for providers, health insurance plans, and employers. Title III sets guidelines for pre-tax medical spending accounts, Title IV sets guidelines for group health plans, and Title V governs company-owned life insurance policies.\n\n== Titles ==\nThere are five sections to the act, known as titles.\n\n\n*** Title I: Health Care Access, Portability, and Renewability ***\nTitle I of HIPAA regulates the availability and breadth of group health plans and certain individual health insurance policies. It amended the Employee Retirement Income Security Act, the Public Health Service Act, and the Internal Revenue Code. Furthermore, Title I addresses the issue of \"job lock\" which is the inability for an employee to leave their job because they would lose their health coverage. To combat the job lock issue, the Title protects health insurance coverage for workers and their families if they lose or change their jobs.Title I requires the coverage of and also limits restrictions that a group health plan can place on benefits for preexisting conditions. Group health plans may refuse to provide benefits in relation to preexisting conditions for either 12 months following enrollment in the plan or 18 months in the case of late enrollment.  Title I allows individuals to reduce the exclusion period by the amount of time that they have had \"creditable coverage\" before enrolling in the plan and after any \"significant breaks\" in coverage. \"Creditable coverage\" is defined quite broadly and includes nearly all group and individual health plans, Medicare, and Medicaid. A \"significant break\" in coverage is defined as any 63-day period without any creditable coverage. Along with an exception, allowing employers to tie premiums or co-payments to tobacco use, or body mass index.\nTitle I also requires insurers to issue policies without exclusion to those leaving group health plans with creditable coverage (see above) exceeding 18 months, and renew individual policies for as long as they are offered or provide alternatives to discontinued plans for as long as the insurer stays in the market without exclusion regardless of health condition.\nSome health care plans are exempted from Title I requirements, such as long-term health plans and limited-scope plans like dental or vision plans offered separately from the general health plan. However, if such benefits are part of the general health plan, then HIPAA still applies to such benefits. For example, if the new plan offers dental benefits, then it must count creditable continuous coverage under the old health plan towards any of its exclusion periods for dental benefits.\nAn alternate method of calculating creditable continuous coverage is available to the health plan under Title I. That is, 5 categories of health coverage can be considered separately, including dental and vision coverage. Anything not under those 5 categories must use the general calculation (e.g., the beneficiary may be counted with 18 months of general coverage, but only 6 months of dental coverage, because the beneficiary did not have a general health plan that covered dental until 6 months prior to the application date). Since limited-coverage plans are exempt from HIPAA requirements, the odd case exists in which the applicant to a general group health plan cannot obtain certificates of creditable continuous coverage for independent limited-scope plans, such as dental to apply towards exclusion periods of the new plan that does include those coverages.\nHidden exclusion periods are not valid under Title I (e.g., \"The accident, to be covered, must have occurred while the beneficiary was covered under this exact same health insurance contract\"). Such clauses must not be acted upon by the health plan. Also, they must be re-written so they can comply with HIPAA.\n\n\n*** Title II: Preventing Health Care Fraud and Abuse; Administrative Simplification; Medical Liability Reform ***\nTitle II of HIPAA establishes policies and procedures for maintaining the privacy and the security of individually identifiable health information, outlines numerous offenses relating to health care, and establishes civil and criminal penalties for violations. It also creates several programs to control fraud and abuse within the health-care system. However, the most significant provisions of Title II are its Administrative Simplification rules. Title II requires the Department of Health and Human Services (HHS) to increase the efficiency of the health-care system by creating standards for the use and dissemination of health-care information.These rules apply to \"covered entities\", as defined by HIPAA and the HHS. Covered entities include health plans, health care clearinghouses (such as billing services and community health information systems), and health care providers that transmit health care data in a way regulated by HIPAA.Per the requirements of Title II, the HHS has promulgated five rules regarding Administrative Simplification: the Privacy Rule, the Transactions and Code Sets Rule, the Security Rule, the Unique Identifiers Rule, and the Enforcement Rule.\n\n\n**** Privacy Rule ****\nThe HIPAA Privacy Rule is composed of national regulations for the use and disclosure of Protected Health Information (PHI) in healthcare treatment, payment and operations by covered entities.\nThe effective compliance date of the Privacy Rule was April 14, 2003, with a one-year extension for certain \"small plans\". The HIPAA Privacy Rule regulates the use and disclosure of protected health information (PHI) held by \"covered entities\" (generally, health care clearinghouses, employer-sponsored health plans, health insurers, and medical service providers that engage in certain transactions). By regulation, the HHS extended the HIPAA privacy rule to independent contractors of covered entities who fit within the definition of \"business associates\". PHI is any information that is held by a covered entity regarding health status, provision of health care, or health care payment that can be linked to any individual. This is interpreted rather broadly and includes any part of an individual's medical record or payment history. Covered entities must disclose PHI to the individual within 30 days upon request. Also, they must disclose PHI when required to do so by law such as reporting suspected child abuse to state child welfare agencies.Covered entities may disclose protected health information to law enforcement officials for law enforcement purposes as required by law (including court orders, court-ordered warrants, subpoenas) and administrative requests; or to identify or locate a suspect, a fugitive, a material witness, or a missing person.A covered entity may disclose PHI to certain parties to facilitate treatment, payment, or health care operations without a patient's express written authorization. Any other disclosures of PHI require the covered entity to obtain written authorization from the individual for the disclosure. In any case, when a covered entity discloses any PHI, it must make a reasonable effort to disclose only the minimum necessary information required to achieve its purpose.The Privacy Rule gives individuals the right to request a covered entity to correct any inaccurate PHI. Also, it requires covered entities to take some reasonable steps on ensuring the confidentiality of communications with individuals. For example, an individual can ask to be called at their work number instead of home or cell phone numbers.\nThe Privacy Rule requires covered entities to notify individuals of uses of their PHI. Covered entities must also keep track of disclosures of PHI and document privacy policies and procedures. They must appoint a Privacy Official and a contact person responsible for receiving complaints and train all members of their workforce in procedures regarding PHI.An individual who believes that the Privacy Rule is not being upheld can file a complaint with the Department of Health and Human Services Office for Civil Rights (OCR). In 2006 the Wall Street Journal reported that the OCR had a long backlog and ignores most complaints. \"Complaints of privacy violations have been piling up at the Department of Health and Human Services. Between April of 2003 and November 2006, the agency fielded 23,886 complaints related to medical-privacy rules, but it has not yet taken any enforcement actions against hospitals, doctors, insurers or anyone else for rule violations. A spokesman for the agency says it has closed three-quarters of the complaints, typically because it found no violation or after it provided informal guidance to the parties involved.\" However, in July 2011, the University of California, Los Angeles agreed to pay $865,500 in a settlement regarding potential HIPAA violations. An HHS Office for Civil Rights investigation showed that from 2005 to 2008, unauthorized employees repeatedly and without legitimate cause looked at the electronic protected health information of numerous UCLAHS patients.It is a misconception that the Privacy Rule creates a right for any individual to refuse to disclose any health information (such as chronic conditions or immunization records) if requested by an employer or business. HIPAA Privacy Rule requirements merely place restrictions on disclosure by covered entities and their business associates without the consent of the individual whose records are being requested; they do not place any restrictions upon requesting health information directly from the subject of that information.\n\n\n***** 2013 Final Omnibus Rule update*****\nIn January 2013, HIPAA was updated via the Final Omnibus Rule. The updates included changes to the Security Rule and Breach Notification portions of the HITECH Act. The most significant changes related to the expansion of requirements to include business associates, where only covered entities had originally been held to uphold these sections of the law.In addition, the definition of \"significant harm\" to an individual in the analysis of a breach was updated to provide more scrutiny to covered entities with the intent of disclosing breaches that previously were unreported. Previously, an organization needed proof that harm had occurred whereas now organizations must prove that harm had not occurred.\nProtection of PHI was changed from indefinite to 50 years after death. More severe penalties for violation of PHI privacy requirements were also approved.The HIPAA Privacy rule may be waived during natural disaster. This was the case with Hurricane Harvey in 2017.\n\n\n****** HITECH Act: privacy requirements ******\nSee the Privacy section of the Health Information Technology for Economic and Clinical Health Act (HITECH Act).\n\n\n***** Right to access one's PHI*****\nThe Privacy Rule requires medical providers to give individuals access to their PHI.  After an individual requests information in writing (typically using the provider's form for this purpose), a provider has up to 30 days to provide a copy of the information to the individual.  An individual may request the information in electronic form or hard-copy, and the provider is obligated to attempt to conform to the requested format.  For providers using an electronic health record (EHR) system that is certified using CEHRT (Certified Electronic Health Record Technology) criteria, individuals must be allowed to obtain the PHI in electronic form.  Providers are encouraged to provide the information expediently, especially in the case of electronic record requests.\nIndividuals have the broad right to access their health-related information, including medical records, notes, images, lab results, and insurance and billing information.  Explicitly excluded are the private psychotherapy notes of a provider, and information gathered by a provider to defend against a lawsuit.Providers can charge a reasonable amount that relates to their cost of providing the copy, however, no charge is allowable when providing data electronically from a certified EHR using the \"view, download, and transfer\" feature which is required for certification.  When delivered to the individual in electronic form, the individual may authorize delivery using either encrypted or unencrypted email, delivery using media (USB drive, CD, etc., which may involve a charge), direct messaging (a secure email technology in common use in the healthcare industry), or possibly other methods.  When using un-encrypted email, the individual must understand and accept the risks to privacy using this technology (the information may be intercepted and examined by others).  Regardless of delivery technology, a provider must continue to fully secure the PHI while in their system and can deny the delivery method if it poses additional risk to PHI while in their system.An individual may also request (in writing) that their PHI is delivered to a designated third party such as a family care provider.\nAn individual may also request (in writing) that the provider send PHI to a designated service used to collect or manage their records, such as a Personal Health Record application.  For example, a patient can request in writing that her ob-gyn provider digitally transmit records of her latest pre-natal visit to a pregnancy self-care app that she has on her mobile phone.\n\n\n***** Disclosure to relatives*****\nAccording to their interpretations of HIPAA, hospitals will not reveal information over the phone to relatives of admitted patients. This has in some instances impeded the location of missing persons. After the Asiana Airlines Flight 214 San Francisco crash, some hospitals were reluctant to disclose the identities of passengers that they were treating, making it difficult for Asiana and the relatives to locate them. In one instance, a man in Washington state was unable to obtain information about his injured mother.Janlori Goldman, director of the advocacy group Health Privacy Project, said that some hospitals are being \"overcautious\" and misapplying the law, the Times reports. Suburban Hospital in Bethesda, Md., has interpreted a federal regulation that requires hospitals to allow patients to opt out of being included in the hospital directory as meaning that patients want to be kept out of the directory unless they specifically say otherwise. As a result, if a patient is unconscious or otherwise unable to choose to be included in the directory, relatives and friends might not be able to find them, Goldman said.\n\n\n**** Transactions and Code Sets Rule ****\nHIPAA was intended to make the health care system in the United States more efficient by standardizing health care transactions. HIPAA added a new Part C titled \"Administrative Simplification\" to Title XI of the Social Security Act. This is supposed to simplify healthcare transactions by requiring all health plans to engage in health care transactions in a standardized way.\nThe HIPAA/EDI (electronic data interchange) provision was scheduled to take effect from October 16, 2003, with a one-year extension for certain \"small plans\". However, due to widespread confusion and difficulty in implementing the rule, CMS granted a one-year extension to all parties. On January 1, 2012 newer versions, ASC X12 005010 and NCPDP D.0 become effective, replacing the previous ASC X12 004010 and NCPDP 5.1 mandate. The ASC X12 005010 version provides a mechanism allowing the use of ICD-10-CM as well as other improvements.\nAfter July 1, 2005 most medical providers that file electronically had to file their electronic claims using the HIPAA standards in order to be paid.Under HIPAA, HIPAA-covered health plans are now required to use standardized HIPAA electronic transactions. See, 42 USC \u00a7 1320d-2 and 45 CFR Part 162. Information about this can be found in the final rule for HIPAA electronic transaction standards (74 Fed. Reg. 3296, published in the Federal Register on January 16, 2009), and on the CMS website.Key EDI (X12) transactions used for HIPAA compliance are:EDI Health Care Claim Transaction set (837) is used to submit health care claim billing information, encounter information, or both, except for retail pharmacy claims (see EDI Retail Pharmacy Claim Transaction). It can be sent from providers of health care services to payers, either directly or via intermediary billers and claims clearinghouses. It can also be used to transmit health care claims and billing payment information between payers with different payment responsibilities where coordination of benefits is required or between payers and regulatory agencies to monitor the rendering, billing, and/or payment of health care services within a specific health care/insurance industry segment.\nFor example, a state mental health agency may mandate all healthcare claims, Providers and health plans who trade professional (medical) health care claims electronically must use the 837 Health Care Claim: Professional standard to send in claims. As there are many different business applications for the Health Care claim, there can be slight derivations to cover off claims involving unique claims such as for institutions, professionals, chiropractors, and dentists etc.\nEDI Retail Pharmacy Claim Transaction (NCPDP Telecommunications Standard version 5.1) is used to submit retail pharmacy claims to payers by health care professionals who dispense medications, either directly or via intermediary billers and claims clearinghouses. It can also be used to transmit claims for retail pharmacy services and billing payment information between payers with different payment responsibilities where coordination of benefits is required or between payers and regulatory agencies to monitor the rendering, billing, and/or payment of retail pharmacy services within the pharmacy health care/insurance industry segment.\nEDI Health Care Claim Payment/Advice Transaction Set (835) can be used to make a payment, send an Explanation of Benefits (EOB), send an Explanation of Payments (EOP) remittance advice, or make a payment and send an EOP remittance advice only from a health insurer to a health care provider either directly or via a financial institution.\nEDI Benefit Enrollment and Maintenance Set (834) can be used by employers, unions, government agencies, associations or insurance agencies to enroll members to a payer. The payer is a healthcare organization that pays claims, administers insurance or benefit or product. Examples of payers include an insurance company, healthcare professional (HMO), preferred provider organization (PPO), government agency (Medicaid, Medicare etc.) or any organization that may be contracted by one of these former groups.\nEDI Payroll Deducted and another group Premium Payment for Insurance Products (820) is a transaction set for making a premium payment for insurance products. It can be used to order a financial institution to make a payment to a payee.\nEDI Health Care Eligibility/Benefit Inquiry (270) is used to inquire about the health care benefits and eligibility associated with a subscriber or dependent.\nEDI Health Care Eligibility/Benefit Response (271) is used to respond to a request inquiry about the health care benefits and eligibility associated with a subscriber or dependent.\nEDI Health Care Claim Status Request (276) This transaction set can be used by a provider, recipient of health care products or services or their authorized agent to request the status of a health care claim.\nEDI Health Care Claim Status Notification (277) This transaction set can be used by a healthcare payer or authorized agent to notify a provider, recipient or authorized agent regarding the status of a health care claim or encounter, or to request additional information from the provider regarding a health care claim or encounter. This transaction set is not intended to replace the Health Care Claim Payment/Advice Transaction Set (835) and therefore, is not used for account payment posting. The notification is at a summary or service line detail level. The notification may be solicited or unsolicited.\nEDI Health Care Service Review Information (278) This transaction set can be used to transmit health care service information, such as subscriber, patient, demographic, diagnosis or treatment data for the purpose of the request for review, certification, notification or reporting the outcome of a health care services review.\nEDI Functional Acknowledgement Transaction Set (997) this transaction set can be used to define the control structures for a set of acknowledgments to indicate the results of the syntactical analysis of the electronically encoded documents. Although it is not specifically named in the HIPAA Legislation or Final Rule, it is necessary for X12 transaction set processing. The encoded documents are the transaction sets, which are grouped in functional groups, used in defining transactions for business data interchange. This standard does not cover the semantic meaning of the information encoded in the transaction sets.\n\n\n***** Brief 5010 Transactions and Code Sets Rules Update Summary*****\nTransaction Set (997) will be replaced by Transaction Set (999) \"acknowledgment report\".\nThe size of many fields {segment elements} will be expanded, causing a need for all IT providers to expand corresponding fields, element, files, GUI, paper media, and databases.\nSome segments have been removed from existing Transaction Sets.\nMany segments have been added to existing Transaction Sets allowing greater tracking and reporting of cost and patient encounters.\nCapacity to use both \"International Classification of Diseases\" versions 9 (ICD-9) and 10 (ICD-10-CM) has been added.\n\n\n**** Security Rule ****\nThe Final Rule on Security Standards was issued on February 20, 2003. It took effect on April 21, 2003, with a compliance date of April 21, 2005, for most covered entities and April 21, 2006, for \"small plans\".The Security Rule complements the Privacy Rule. While the Privacy Rule pertains to all Protected Health Information (PHI) including paper and electronic, the Security Rule deals specifically with Electronic Protected Health Information (EPHI). It lays out three types of security safeguards required for compliance: administrative, physical, and technical. For each of these types, the Rule identifies various security standards, and for each standard, it names both required and addressable implementation specifications. Required specifications must be adopted and administered as dictated by the Rule. Addressable specifications are more flexible. Individual covered entities can evaluate their own situation and determine the best way to implement addressable specifications. Some privacy advocates have argued that this \"flexibility\" may provide too much latitude to covered entities. Software tools have been developed to assist covered entities in the risk analysis and remediation tracking. The standards and specifications are as follows:\n\nAdministrative Safeguards \u2013 policies and procedures designed to clearly show how the entity will comply with the act\nCovered entities (entities that must comply with HIPAA requirements) must adopt a written set of privacy procedures and designate a privacy officer to be responsible for developing and implementing all required policies and procedures.\nThe policies and procedures must reference management oversight and organizational buy-in to compliance with the documented security controls.\nProcedures should clearly identify employees or classes of employees who have access to electronic protected health information (EPHI). Access to EPHI  must be restricted to only those employees who have a need for it to complete their job function.\nThe procedures must address access authorization, establishment, modification, and termination.\nEntities must show that an appropriate ongoing training program regarding the handling of PHI is provided to employees performing health plan administrative functions.\nCovered entities that out-source some of their business processes to a third party must ensure that their vendors also have a framework in place to comply with HIPAA requirements. Companies typically gain this assurance through clauses in the contracts stating that the vendor will meet the same data protection requirements that apply to the covered entity. Care must be taken to determine if the vendor further out-sources any data handling functions to other vendors and monitor whether appropriate contracts and controls are in place.\nA contingency plan should be in place for responding to emergencies. Covered entities are responsible for backing up their data and having disaster recovery procedures in place. The plan should document data priority and failure analysis, testing activities, and change control procedures.\nInternal audits play a key role in HIPAA compliance by reviewing operations with the goal of identifying potential security violations. Policies and procedures should specifically document the scope, frequency, and procedures of audits. Audits should be both routine and event-based.\nProcedures should document instructions for addressing and responding to security breaches that are identified either during the audit or the normal course of operations.\nPhysical Safeguards \u2013 controlling physical access to protect against inappropriate access to protected data\nControls must govern the introduction and removal of hardware and software from the network. (When equipment is retired it must be disposed of properly to ensure that PHI is not compromised.)\nAccess to equipment containing health information should be carefully controlled and monitored.\nAccess to hardware and software must be limited to properly authorized individuals.\nRequired access controls consist of facility security plans, maintenance records, and visitor sign-in and escorts.\nPolicies are required to address proper workstation use. Workstations should be removed from high traffic areas and monitor screens should not be in direct view of the public.\nIf the covered entities utilize contractors or agents, they too must be fully trained on their physical access responsibilities.\nTechnical Safeguards \u2013 controlling access to computer systems and enabling covered entities to protect communications containing PHI transmitted electronically over open networks from being intercepted by anyone other than the intended recipient.\nInformation systems housing PHI must be protected from intrusion. When information flows over open networks, some form of encryption must be utilized. If closed systems/networks are utilized, existing access controls are considered sufficient and encryption is optional.\nEach covered entity is responsible for ensuring that the data within its systems has not been changed or erased in an unauthorized manner.\nData corroboration, including the use of a checksum, double-keying, message authentication, and digital signature may be used to ensure data integrity.\nCovered entities must also authenticate entities with which they communicate. Authentication consists of corroborating that an entity is who it claims to be. Examples of corroboration include password systems, two or three-way handshakes, telephone callback, and token systems.\nCovered entities must make documentation of their HIPAA practices available to the government to determine compliance.\nIn addition to policies and procedures and access records, information technology documentation should also include a written record of all configuration settings on the components of the network because these components are complex, configurable, and always changing.\nDocumented risk analysis and risk management programs are required. Covered entities must carefully consider the risks of their operations as they implement systems to comply with the act. (The requirement of risk analysis and risk management implies that the act's security requirements are a minimum standard and places responsibility on covered entities to take all reasonable precautions necessary to prevent PHI from being used for non-health purposes.)\n\n\n**** Unique Identifiers Rule (National Provider Identifier) ****\nHIPAA covered entities such as providers completing electronic transactions, healthcare clearinghouses, and large health plans must use only the National Provider Identifier (NPI) to identify covered healthcare providers in standard transactions by May 23, 2007. Small health plans must use only the NPI by May 23, 2008.\nEffective from May 2006 (May 2007 for small health plans), all covered entities using electronic communications (e.g., physicians, hospitals, health insurance companies, and so forth) must use a single new NPI. The NPI replaces all other identifiers used by health plans, Medicare, Medicaid, and other government programs. However, the NPI does not replace a provider's DEA number, state license number, or tax identification number. The NPI is 10 digits (may be alphanumeric), with the last digit being a checksum. The NPI cannot contain any embedded intelligence; in other words, the NPI is simply a number that does not itself have any additional meaning. The NPI is unique and national, never re-used, and except for institutions, a provider usually can have only one. An institution may obtain multiple NPIs for different \"sub-parts\" such as a free-standing cancer center or rehab facility.\n\n\n**** Enforcement Rule ****\nOn February 16, 2006, HHS issued the Final Rule regarding HIPAA enforcement. It became effective on March 16, 2006. The Enforcement Rule sets civil money penalties for violating HIPAA rules and establishes procedures for investigations and hearings for HIPAA violations. For many years there were few prosecutions for violations.\nThis may have changed with the fining of $50,000 to the Hospice of North Idaho (HONI) as the first entity to be fined for a potential HIPAA Security Rule breach affecting fewer than 500 people. Rachel Seeger, a spokeswoman for HHS, stated, \"HONI did not conduct an accurate and thorough risk analysis to the confidentiality of ePHI [electronic Protected Health Information] as part of its security management process from 2005 through Jan. 17, 2012.\" This investigation was initiated with the theft from an employees vehicle of an unencrypted laptop containing 441 patient records.\n\nAs of March 2013, the U.S. Dept. of Health and Human Services (HHS) has investigated over 19,306 cases that have been resolved by requiring changes in privacy practice or by corrective action. If noncompliance is determined by HHS, entities must apply corrective measures. Complaints have been investigated against many different types of businesses such as national pharmacy chains, major health care centers, insurance groups, hospital chains and other small providers. There were 9,146 cases where the HHS investigation found that HIPAA was followed correctly. There were 44,118 cases that HHS did not find eligible cause for enforcement; for example, a violation that started before HIPAA started; cases withdrawn by the pursuer; or an activity that does not actually violate the Rules. According to the HHS website, the following lists the issues that have been reported according to frequency:\n\nMisuse and disclosures of PHI\nNo protection in place of health information\nPatient unable to access their health information\nUsing or disclosing more than the minimum necessary protected health information\nNo safeguards of electronic protected health information.The most common entities required to take corrective action to be in voluntary compliance according to HHS are listed by frequency:\nPrivate Practices\nHospitals\nOutpatient Facilities\nGroup plans such as insurance groups\nPharmacies\n\n\n*** Title III: Tax-related health provisions governing medical savings accounts ***\nTitle III standardizes the amount that may be saved per person in a pre-tax medical savings account. Beginning in 1997, a medical savings\naccount (\"MSA\") became available to employees covered under an employer-sponsored high deductible plan of a small employer and\nself-employed individuals.\n\n\n*** Title IV: Application and enforcement of group health insurance requirements ***\nTitle IV specifies conditions for group health plans regarding coverage of persons with pre-existing conditions, and modifies continuation of coverage requirements.  It also clarifies continuation coverage requirements and includes COBRA clarification.\n\n\n*** Title V: Revenue offset governing tax deductions for employers ***\nTitle V includes provisions related to company-owned life insurance for employers providing company-owned life insurance premiums, prohibiting the tax-deduction of interest on life insurance loans, company endowments, or contracts related to the company. It also repeals the financial institution rule to interest allocation rules. Finally, it amends provisions of law relating to people who give up United States citizenship or permanent residence, expanding the expatriation tax to be assessed against those deemed to be giving up their U.S. status for tax reasons, and making ex-citizens' names part of the public record through the creation of the Quarterly Publication of Individuals Who Have Chosen to Expatriate.\n\n== Effects on research and clinical care ==\nThe enactment of the Privacy and Security Rules has caused major changes in the way physicians and medical centers operate. The complex legalities and potentially stiff penalties associated with HIPAA, as well as the increase in paperwork and the cost of its implementation, were causes for concern among physicians and medical centers. An August 2006 article in the journal Annals of Internal Medicine detailed some such concerns over the implementation and effects of HIPAA.\n\n\n*** Effects on research ***\nHIPAA restrictions on researchers have affected their ability to perform retrospective, chart-based research as well as their ability to prospectively evaluate patients by contacting them for follow-up. A study from the University of Michigan demonstrated that implementation of the HIPAA Privacy rule resulted in a drop from 96% to 34% in the proportion of follow-up surveys completed by study patients being followed after a heart attack. Another study, detailing the effects of HIPAA on recruitment for a study on cancer prevention, demonstrated that HIPAA-mandated changes led to a 73% decrease in patient accrual, a tripling of time spent recruiting patients, and a tripling of mean recruitment costs.In addition, informed consent forms for research studies now are required to include extensive detail on how the participant's protected health information will be kept private. While such information is important, the addition of a lengthy, legalistic section on privacy may make these already complex documents even less user-friendly for patients who are asked to read and sign them.\nThese data suggest that the HIPAA privacy rule, as currently implemented, may be having negative impacts on the cost and quality of medical research. Dr. Kim Eagle, professor of internal medicine at the University of Michigan, was quoted in the Annals article as saying, \"Privacy is important, but research is also important for improving care. We hope that we will figure this out and do it right.\"\n\n\n*** Effects on clinical care ***\nThe complexity of HIPAA, combined with potentially stiff penalties for violators, can lead physicians and medical centers to withhold information from those who may have a right to it. A review of the implementation of the HIPAA Privacy Rule by the U.S. Government Accountability Office found that health care providers were \"uncertain about their legal privacy responsibilities and often responded with an overly guarded approach to disclosing information ... than necessary to ensure compliance with the Privacy rule\". Reports of this uncertainty continue.\n\n\n*** Costs of implementation ***\nIn the period immediately prior to the enactment of the HIPAA Privacy and Security Acts, medical centers and medical practices were charged with getting \"into compliance\". With an early emphasis on the potentially severe penalties associated with violation, many practices and centers turned to private, for-profit \"HIPAA consultants\" who were intimately familiar with the details of the legislation and offered their services to ensure that physicians and medical centers were fully \"in compliance\". In addition to the costs of developing and revamping systems and practices, the increase in paperwork and staff time necessary to meet the legal requirements of HIPAA may impact the finances of medical centers and practices at a time when insurance companies' and Medicare reimbursement is also declining.\n\n\n*** Education and training ***\nEducation and training of healthcare providers is a requirement for correct implementation of both the HIPAA Privacy Rule and Security Rule.\n\n== HIPAA acronym ==\nAlthough the acronym HIPAA matches the title of the 1996 Public Law 104-191, Health Insurance Portability and Accountability Act, HIPAA is sometimes incorrectly referred to as \"Health Information Privacy and Portability Act (HIPPA).\"\n\n== Violations ==\n\nAccording to the US Department of Health and Human Services Office for Civil Rights, between April 2003 and January 2013, it received 91,000 complaints of HIPAA violations, in which 22,000 led to enforcement actions of varying kinds (from settlements to fines) and 521 led to referrals to the US Department of Justice as criminal actions. Examples of significant breaches of protected information and other HIPAA violations include:\n\nThe largest loss of data that affected 4.9 million people by Tricare Management of Virginia in 2011\nThe largest fines of $5.5 million levied against Memorial Healthcare Systems in 2017 for accessing confidential information of 115,143 patients and of $4.3 million levied against Cignet Health of Maryland in 2010 for ignoring patients' requests to obtain copies of their own records and repeated ignoring of federal officials' inquiries\nThe first criminal indictment was lodged in 2011 against a Virginia physician who shared information with a patient's employer \"under the false pretenses that the patient was a serious and imminent threat to the safety of the public, when in fact he knew that the patient was not such a threat.\"According to Koczkodaj et al., 2018, the total number of individuals affected since October 2009 is 173,398,820.\nThe differences between civil and criminal penalties are summarized in the following table:\n\n== Legislative information ==\nIn 1994, President Clinton had ambitions to renovate the state of the nation's health care. Despite his efforts to revamp the system, he did not receive the support he needed at the time. The Congressional Quarterly Almanac of 1996 explains how two senators, Nancy Kassebaum (R-KS) and Edward Kennedy (D-MA) came together and created a bill called the Health Insurance Reform Act of 1995 or more commonly known as the Kassebaum-Kennedy Bill. This bill was stalled despite making it out of the Senate. Undeterred by this, Clinton pushed harder for his ambitions and eventually in 1996 after the State of the Union address, there was some headway as it resulted in bipartisan cooperation. After much debate and negotiation, there was a shift in momentum once a \u201ccompromise between Kennedy and Ways and Means Committee Chairman Bill Archer\u201d was accepted after alterations were made of the original Kassebaum-Kennedy Bill. Soon after this, the bill was signed into law by President Clinton and was named the Health Insurance Portability and Accountability Act of 1996 (HIPAA).\n\nPub. L. 104\u2013191 (text) (PDF), 110 Stat. 1936H.R. 3103; H. Rept. 104-469, part 1; H. Rept. 104-736\nS. 1028; S. 1698; S. Rept. 104-156\nHHS Security Standards, 45 CFR 160, 45 CFR 162, and 45 CFR 164\nHHS Standards for Privacy of Individually Identifiable Health Information, 45 CFR 160 and 45 CFR 164\n\nHow does the HIPAA/EDI provision affect healthcare transactions?",
    "context": "",
    "output": "A: The HIPAA/EDI provision was intended to make the health care system in the United States more efficient by standardizing health care transactions. It requires all health plans to engage in health care transactions in a standardized way.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the HIPAA/EDI provision affect healthcare transactions?",
      "answer": "The HIPAA/EDI provision was intended to make the health care system in the United States more efficient by standardizing health care transactions. It requires all health plans to engage in health care transactions in a standardized way.",
      "context": "Health Insurance Portability and Accountability Act\n\n==Introduction==\nThe Health Insurance Portability and Accountability Act of 1996 (HIPAA or the Kennedy\u2013Kassebaum Act) is a United States Act of Congress enacted by the 104th United States Congress and signed into law by President Bill Clinton on August 21, 1996. It modernized the flow of healthcare information, stipulates how personally identifiable information maintained by the healthcare and healthcare insurance industries should be protected from fraud and theft, and addressed some limitations on healthcare insurance coverage. It generally prohibits healthcare providers and healthcare businesses, called covered entities, from disclosing protected information to anyone other than a patient and the patient's authorized representatives without their consent. With limited exceptions, it does not restrict patients from receiving information about themselves. It does not prohibit patients from voluntarily sharing their health information however they choose, nor does it require confidentiality where a patient discloses medical information to family members, friends, or other individuals not a part of a covered entity.\nThe act consists of five titles. Title I of HIPAA protects health insurance coverage for workers and their families when they change or lose their jobs. Title II of HIPAA, known as the Administrative Simplification (AS) provisions, requires the establishment of national standards for electronic health care transactions and national identifiers for providers, health insurance plans, and employers. Title III sets guidelines for pre-tax medical spending accounts, Title IV sets guidelines for group health plans, and Title V governs company-owned life insurance policies.\n\n== Titles ==\nThere are five sections to the act, known as titles.\n\n\n*** Title I: Health Care Access, Portability, and Renewability ***\nTitle I of HIPAA regulates the availability and breadth of group health plans and certain individual health insurance policies. It amended the Employee Retirement Income Security Act, the Public Health Service Act, and the Internal Revenue Code. Furthermore, Title I addresses the issue of \"job lock\" which is the inability for an employee to leave their job because they would lose their health coverage. To combat the job lock issue, the Title protects health insurance coverage for workers and their families if they lose or change their jobs.Title I requires the coverage of and also limits restrictions that a group health plan can place on benefits for preexisting conditions. Group health plans may refuse to provide benefits in relation to preexisting conditions for either 12 months following enrollment in the plan or 18 months in the case of late enrollment.  Title I allows individuals to reduce the exclusion period by the amount of time that they have had \"creditable coverage\" before enrolling in the plan and after any \"significant breaks\" in coverage. \"Creditable coverage\" is defined quite broadly and includes nearly all group and individual health plans, Medicare, and Medicaid. A \"significant break\" in coverage is defined as any 63-day period without any creditable coverage. Along with an exception, allowing employers to tie premiums or co-payments to tobacco use, or body mass index.\nTitle I also requires insurers to issue policies without exclusion to those leaving group health plans with creditable coverage (see above) exceeding 18 months, and renew individual policies for as long as they are offered or provide alternatives to discontinued plans for as long as the insurer stays in the market without exclusion regardless of health condition.\nSome health care plans are exempted from Title I requirements, such as long-term health plans and limited-scope plans like dental or vision plans offered separately from the general health plan. However, if such benefits are part of the general health plan, then HIPAA still applies to such benefits. For example, if the new plan offers dental benefits, then it must count creditable continuous coverage under the old health plan towards any of its exclusion periods for dental benefits.\nAn alternate method of calculating creditable continuous coverage is available to the health plan under Title I. That is, 5 categories of health coverage can be considered separately, including dental and vision coverage. Anything not under those 5 categories must use the general calculation (e.g., the beneficiary may be counted with 18 months of general coverage, but only 6 months of dental coverage, because the beneficiary did not have a general health plan that covered dental until 6 months prior to the application date). Since limited-coverage plans are exempt from HIPAA requirements, the odd case exists in which the applicant to a general group health plan cannot obtain certificates of creditable continuous coverage for independent limited-scope plans, such as dental to apply towards exclusion periods of the new plan that does include those coverages.\nHidden exclusion periods are not valid under Title I (e.g., \"The accident, to be covered, must have occurred while the beneficiary was covered under this exact same health insurance contract\"). Such clauses must not be acted upon by the health plan. Also, they must be re-written so they can comply with HIPAA.\n\n\n*** Title II: Preventing Health Care Fraud and Abuse; Administrative Simplification; Medical Liability Reform ***\nTitle II of HIPAA establishes policies and procedures for maintaining the privacy and the security of individually identifiable health information, outlines numerous offenses relating to health care, and establishes civil and criminal penalties for violations. It also creates several programs to control fraud and abuse within the health-care system. However, the most significant provisions of Title II are its Administrative Simplification rules. Title II requires the Department of Health and Human Services (HHS) to increase the efficiency of the health-care system by creating standards for the use and dissemination of health-care information.These rules apply to \"covered entities\", as defined by HIPAA and the HHS. Covered entities include health plans, health care clearinghouses (such as billing services and community health information systems), and health care providers that transmit health care data in a way regulated by HIPAA.Per the requirements of Title II, the HHS has promulgated five rules regarding Administrative Simplification: the Privacy Rule, the Transactions and Code Sets Rule, the Security Rule, the Unique Identifiers Rule, and the Enforcement Rule.\n\n\n**** Privacy Rule ****\nThe HIPAA Privacy Rule is composed of national regulations for the use and disclosure of Protected Health Information (PHI) in healthcare treatment, payment and operations by covered entities.\nThe effective compliance date of the Privacy Rule was April 14, 2003, with a one-year extension for certain \"small plans\". The HIPAA Privacy Rule regulates the use and disclosure of protected health information (PHI) held by \"covered entities\" (generally, health care clearinghouses, employer-sponsored health plans, health insurers, and medical service providers that engage in certain transactions). By regulation, the HHS extended the HIPAA privacy rule to independent contractors of covered entities who fit within the definition of \"business associates\". PHI is any information that is held by a covered entity regarding health status, provision of health care, or health care payment that can be linked to any individual. This is interpreted rather broadly and includes any part of an individual's medical record or payment history. Covered entities must disclose PHI to the individual within 30 days upon request. Also, they must disclose PHI when required to do so by law such as reporting suspected child abuse to state child welfare agencies.Covered entities may disclose protected health information to law enforcement officials for law enforcement purposes as required by law (including court orders, court-ordered warrants, subpoenas) and administrative requests; or to identify or locate a suspect, a fugitive, a material witness, or a missing person.A covered entity may disclose PHI to certain parties to facilitate treatment, payment, or health care operations without a patient's express written authorization. Any other disclosures of PHI require the covered entity to obtain written authorization from the individual for the disclosure. In any case, when a covered entity discloses any PHI, it must make a reasonable effort to disclose only the minimum necessary information required to achieve its purpose.The Privacy Rule gives individuals the right to request a covered entity to correct any inaccurate PHI. Also, it requires covered entities to take some reasonable steps on ensuring the confidentiality of communications with individuals. For example, an individual can ask to be called at their work number instead of home or cell phone numbers.\nThe Privacy Rule requires covered entities to notify individuals of uses of their PHI. Covered entities must also keep track of disclosures of PHI and document privacy policies and procedures. They must appoint a Privacy Official and a contact person responsible for receiving complaints and train all members of their workforce in procedures regarding PHI.An individual who believes that the Privacy Rule is not being upheld can file a complaint with the Department of Health and Human Services Office for Civil Rights (OCR). In 2006 the Wall Street Journal reported that the OCR had a long backlog and ignores most complaints. \"Complaints of privacy violations have been piling up at the Department of Health and Human Services. Between April of 2003 and November 2006, the agency fielded 23,886 complaints related to medical-privacy rules, but it has not yet taken any enforcement actions against hospitals, doctors, insurers or anyone else for rule violations. A spokesman for the agency says it has closed three-quarters of the complaints, typically because it found no violation or after it provided informal guidance to the parties involved.\" However, in July 2011, the University of California, Los Angeles agreed to pay $865,500 in a settlement regarding potential HIPAA violations. An HHS Office for Civil Rights investigation showed that from 2005 to 2008, unauthorized employees repeatedly and without legitimate cause looked at the electronic protected health information of numerous UCLAHS patients.It is a misconception that the Privacy Rule creates a right for any individual to refuse to disclose any health information (such as chronic conditions or immunization records) if requested by an employer or business. HIPAA Privacy Rule requirements merely place restrictions on disclosure by covered entities and their business associates without the consent of the individual whose records are being requested; they do not place any restrictions upon requesting health information directly from the subject of that information.\n\n\n***** 2013 Final Omnibus Rule update*****\nIn January 2013, HIPAA was updated via the Final Omnibus Rule. The updates included changes to the Security Rule and Breach Notification portions of the HITECH Act. The most significant changes related to the expansion of requirements to include business associates, where only covered entities had originally been held to uphold these sections of the law.In addition, the definition of \"significant harm\" to an individual in the analysis of a breach was updated to provide more scrutiny to covered entities with the intent of disclosing breaches that previously were unreported. Previously, an organization needed proof that harm had occurred whereas now organizations must prove that harm had not occurred.\nProtection of PHI was changed from indefinite to 50 years after death. More severe penalties for violation of PHI privacy requirements were also approved.The HIPAA Privacy rule may be waived during natural disaster. This was the case with Hurricane Harvey in 2017.\n\n\n****** HITECH Act: privacy requirements ******\nSee the Privacy section of the Health Information Technology for Economic and Clinical Health Act (HITECH Act).\n\n\n***** Right to access one's PHI*****\nThe Privacy Rule requires medical providers to give individuals access to their PHI.  After an individual requests information in writing (typically using the provider's form for this purpose), a provider has up to 30 days to provide a copy of the information to the individual.  An individual may request the information in electronic form or hard-copy, and the provider is obligated to attempt to conform to the requested format.  For providers using an electronic health record (EHR) system that is certified using CEHRT (Certified Electronic Health Record Technology) criteria, individuals must be allowed to obtain the PHI in electronic form.  Providers are encouraged to provide the information expediently, especially in the case of electronic record requests.\nIndividuals have the broad right to access their health-related information, including medical records, notes, images, lab results, and insurance and billing information.  Explicitly excluded are the private psychotherapy notes of a provider, and information gathered by a provider to defend against a lawsuit.Providers can charge a reasonable amount that relates to their cost of providing the copy, however, no charge is allowable when providing data electronically from a certified EHR using the \"view, download, and transfer\" feature which is required for certification.  When delivered to the individual in electronic form, the individual may authorize delivery using either encrypted or unencrypted email, delivery using media (USB drive, CD, etc., which may involve a charge), direct messaging (a secure email technology in common use in the healthcare industry), or possibly other methods.  When using un-encrypted email, the individual must understand and accept the risks to privacy using this technology (the information may be intercepted and examined by others).  Regardless of delivery technology, a provider must continue to fully secure the PHI while in their system and can deny the delivery method if it poses additional risk to PHI while in their system.An individual may also request (in writing) that their PHI is delivered to a designated third party such as a family care provider.\nAn individual may also request (in writing) that the provider send PHI to a designated service used to collect or manage their records, such as a Personal Health Record application.  For example, a patient can request in writing that her ob-gyn provider digitally transmit records of her latest pre-natal visit to a pregnancy self-care app that she has on her mobile phone.\n\n\n***** Disclosure to relatives*****\nAccording to their interpretations of HIPAA, hospitals will not reveal information over the phone to relatives of admitted patients. This has in some instances impeded the location of missing persons. After the Asiana Airlines Flight 214 San Francisco crash, some hospitals were reluctant to disclose the identities of passengers that they were treating, making it difficult for Asiana and the relatives to locate them. In one instance, a man in Washington state was unable to obtain information about his injured mother.Janlori Goldman, director of the advocacy group Health Privacy Project, said that some hospitals are being \"overcautious\" and misapplying the law, the Times reports. Suburban Hospital in Bethesda, Md., has interpreted a federal regulation that requires hospitals to allow patients to opt out of being included in the hospital directory as meaning that patients want to be kept out of the directory unless they specifically say otherwise. As a result, if a patient is unconscious or otherwise unable to choose to be included in the directory, relatives and friends might not be able to find them, Goldman said.\n\n\n**** Transactions and Code Sets Rule ****\nHIPAA was intended to make the health care system in the United States more efficient by standardizing health care transactions. HIPAA added a new Part C titled \"Administrative Simplification\" to Title XI of the Social Security Act. This is supposed to simplify healthcare transactions by requiring all health plans to engage in health care transactions in a standardized way.\nThe HIPAA/EDI (electronic data interchange) provision was scheduled to take effect from October 16, 2003, with a one-year extension for certain \"small plans\". However, due to widespread confusion and difficulty in implementing the rule, CMS granted a one-year extension to all parties. On January 1, 2012 newer versions, ASC X12 005010 and NCPDP D.0 become effective, replacing the previous ASC X12 004010 and NCPDP 5.1 mandate. The ASC X12 005010 version provides a mechanism allowing the use of ICD-10-CM as well as other improvements.\nAfter July 1, 2005 most medical providers that file electronically had to file their electronic claims using the HIPAA standards in order to be paid.Under HIPAA, HIPAA-covered health plans are now required to use standardized HIPAA electronic transactions. See, 42 USC \u00a7 1320d-2 and 45 CFR Part 162. Information about this can be found in the final rule for HIPAA electronic transaction standards (74 Fed. Reg. 3296, published in the Federal Register on January 16, 2009), and on the CMS website.Key EDI (X12) transactions used for HIPAA compliance are:EDI Health Care Claim Transaction set (837) is used to submit health care claim billing information, encounter information, or both, except for retail pharmacy claims (see EDI Retail Pharmacy Claim Transaction). It can be sent from providers of health care services to payers, either directly or via intermediary billers and claims clearinghouses. It can also be used to transmit health care claims and billing payment information between payers with different payment responsibilities where coordination of benefits is required or between payers and regulatory agencies to monitor the rendering, billing, and/or payment of health care services within a specific health care/insurance industry segment.\nFor example, a state mental health agency may mandate all healthcare claims, Providers and health plans who trade professional (medical) health care claims electronically must use the 837 Health Care Claim: Professional standard to send in claims. As there are many different business applications for the Health Care claim, there can be slight derivations to cover off claims involving unique claims such as for institutions, professionals, chiropractors, and dentists etc.\nEDI Retail Pharmacy Claim Transaction (NCPDP Telecommunications Standard version 5.1) is used to submit retail pharmacy claims to payers by health care professionals who dispense medications, either directly or via intermediary billers and claims clearinghouses. It can also be used to transmit claims for retail pharmacy services and billing payment information between payers with different payment responsibilities where coordination of benefits is required or between payers and regulatory agencies to monitor the rendering, billing, and/or payment of retail pharmacy services within the pharmacy health care/insurance industry segment.\nEDI Health Care Claim Payment/Advice Transaction Set (835) can be used to make a payment, send an Explanation of Benefits (EOB), send an Explanation of Payments (EOP) remittance advice, or make a payment and send an EOP remittance advice only from a health insurer to a health care provider either directly or via a financial institution.\nEDI Benefit Enrollment and Maintenance Set (834) can be used by employers, unions, government agencies, associations or insurance agencies to enroll members to a payer. The payer is a healthcare organization that pays claims, administers insurance or benefit or product. Examples of payers include an insurance company, healthcare professional (HMO), preferred provider organization (PPO), government agency (Medicaid, Medicare etc.) or any organization that may be contracted by one of these former groups.\nEDI Payroll Deducted and another group Premium Payment for Insurance Products (820) is a transaction set for making a premium payment for insurance products. It can be used to order a financial institution to make a payment to a payee.\nEDI Health Care Eligibility/Benefit Inquiry (270) is used to inquire about the health care benefits and eligibility associated with a subscriber or dependent.\nEDI Health Care Eligibility/Benefit Response (271) is used to respond to a request inquiry about the health care benefits and eligibility associated with a subscriber or dependent.\nEDI Health Care Claim Status Request (276) This transaction set can be used by a provider, recipient of health care products or services or their authorized agent to request the status of a health care claim.\nEDI Health Care Claim Status Notification (277) This transaction set can be used by a healthcare payer or authorized agent to notify a provider, recipient or authorized agent regarding the status of a health care claim or encounter, or to request additional information from the provider regarding a health care claim or encounter. This transaction set is not intended to replace the Health Care Claim Payment/Advice Transaction Set (835) and therefore, is not used for account payment posting. The notification is at a summary or service line detail level. The notification may be solicited or unsolicited.\nEDI Health Care Service Review Information (278) This transaction set can be used to transmit health care service information, such as subscriber, patient, demographic, diagnosis or treatment data for the purpose of the request for review, certification, notification or reporting the outcome of a health care services review.\nEDI Functional Acknowledgement Transaction Set (997) this transaction set can be used to define the control structures for a set of acknowledgments to indicate the results of the syntactical analysis of the electronically encoded documents. Although it is not specifically named in the HIPAA Legislation or Final Rule, it is necessary for X12 transaction set processing. The encoded documents are the transaction sets, which are grouped in functional groups, used in defining transactions for business data interchange. This standard does not cover the semantic meaning of the information encoded in the transaction sets.\n\n\n***** Brief 5010 Transactions and Code Sets Rules Update Summary*****\nTransaction Set (997) will be replaced by Transaction Set (999) \"acknowledgment report\".\nThe size of many fields {segment elements} will be expanded, causing a need for all IT providers to expand corresponding fields, element, files, GUI, paper media, and databases.\nSome segments have been removed from existing Transaction Sets.\nMany segments have been added to existing Transaction Sets allowing greater tracking and reporting of cost and patient encounters.\nCapacity to use both \"International Classification of Diseases\" versions 9 (ICD-9) and 10 (ICD-10-CM) has been added.\n\n\n**** Security Rule ****\nThe Final Rule on Security Standards was issued on February 20, 2003. It took effect on April 21, 2003, with a compliance date of April 21, 2005, for most covered entities and April 21, 2006, for \"small plans\".The Security Rule complements the Privacy Rule. While the Privacy Rule pertains to all Protected Health Information (PHI) including paper and electronic, the Security Rule deals specifically with Electronic Protected Health Information (EPHI). It lays out three types of security safeguards required for compliance: administrative, physical, and technical. For each of these types, the Rule identifies various security standards, and for each standard, it names both required and addressable implementation specifications. Required specifications must be adopted and administered as dictated by the Rule. Addressable specifications are more flexible. Individual covered entities can evaluate their own situation and determine the best way to implement addressable specifications. Some privacy advocates have argued that this \"flexibility\" may provide too much latitude to covered entities. Software tools have been developed to assist covered entities in the risk analysis and remediation tracking. The standards and specifications are as follows:\n\nAdministrative Safeguards \u2013 policies and procedures designed to clearly show how the entity will comply with the act\nCovered entities (entities that must comply with HIPAA requirements) must adopt a written set of privacy procedures and designate a privacy officer to be responsible for developing and implementing all required policies and procedures.\nThe policies and procedures must reference management oversight and organizational buy-in to compliance with the documented security controls.\nProcedures should clearly identify employees or classes of employees who have access to electronic protected health information (EPHI). Access to EPHI  must be restricted to only those employees who have a need for it to complete their job function.\nThe procedures must address access authorization, establishment, modification, and termination.\nEntities must show that an appropriate ongoing training program regarding the handling of PHI is provided to employees performing health plan administrative functions.\nCovered entities that out-source some of their business processes to a third party must ensure that their vendors also have a framework in place to comply with HIPAA requirements. Companies typically gain this assurance through clauses in the contracts stating that the vendor will meet the same data protection requirements that apply to the covered entity. Care must be taken to determine if the vendor further out-sources any data handling functions to other vendors and monitor whether appropriate contracts and controls are in place.\nA contingency plan should be in place for responding to emergencies. Covered entities are responsible for backing up their data and having disaster recovery procedures in place. The plan should document data priority and failure analysis, testing activities, and change control procedures.\nInternal audits play a key role in HIPAA compliance by reviewing operations with the goal of identifying potential security violations. Policies and procedures should specifically document the scope, frequency, and procedures of audits. Audits should be both routine and event-based.\nProcedures should document instructions for addressing and responding to security breaches that are identified either during the audit or the normal course of operations.\nPhysical Safeguards \u2013 controlling physical access to protect against inappropriate access to protected data\nControls must govern the introduction and removal of hardware and software from the network. (When equipment is retired it must be disposed of properly to ensure that PHI is not compromised.)\nAccess to equipment containing health information should be carefully controlled and monitored.\nAccess to hardware and software must be limited to properly authorized individuals.\nRequired access controls consist of facility security plans, maintenance records, and visitor sign-in and escorts.\nPolicies are required to address proper workstation use. Workstations should be removed from high traffic areas and monitor screens should not be in direct view of the public.\nIf the covered entities utilize contractors or agents, they too must be fully trained on their physical access responsibilities.\nTechnical Safeguards \u2013 controlling access to computer systems and enabling covered entities to protect communications containing PHI transmitted electronically over open networks from being intercepted by anyone other than the intended recipient.\nInformation systems housing PHI must be protected from intrusion. When information flows over open networks, some form of encryption must be utilized. If closed systems/networks are utilized, existing access controls are considered sufficient and encryption is optional.\nEach covered entity is responsible for ensuring that the data within its systems has not been changed or erased in an unauthorized manner.\nData corroboration, including the use of a checksum, double-keying, message authentication, and digital signature may be used to ensure data integrity.\nCovered entities must also authenticate entities with which they communicate. Authentication consists of corroborating that an entity is who it claims to be. Examples of corroboration include password systems, two or three-way handshakes, telephone callback, and token systems.\nCovered entities must make documentation of their HIPAA practices available to the government to determine compliance.\nIn addition to policies and procedures and access records, information technology documentation should also include a written record of all configuration settings on the components of the network because these components are complex, configurable, and always changing.\nDocumented risk analysis and risk management programs are required. Covered entities must carefully consider the risks of their operations as they implement systems to comply with the act. (The requirement of risk analysis and risk management implies that the act's security requirements are a minimum standard and places responsibility on covered entities to take all reasonable precautions necessary to prevent PHI from being used for non-health purposes.)\n\n\n**** Unique Identifiers Rule (National Provider Identifier) ****\nHIPAA covered entities such as providers completing electronic transactions, healthcare clearinghouses, and large health plans must use only the National Provider Identifier (NPI) to identify covered healthcare providers in standard transactions by May 23, 2007. Small health plans must use only the NPI by May 23, 2008.\nEffective from May 2006 (May 2007 for small health plans), all covered entities using electronic communications (e.g., physicians, hospitals, health insurance companies, and so forth) must use a single new NPI. The NPI replaces all other identifiers used by health plans, Medicare, Medicaid, and other government programs. However, the NPI does not replace a provider's DEA number, state license number, or tax identification number. The NPI is 10 digits (may be alphanumeric), with the last digit being a checksum. The NPI cannot contain any embedded intelligence; in other words, the NPI is simply a number that does not itself have any additional meaning. The NPI is unique and national, never re-used, and except for institutions, a provider usually can have only one. An institution may obtain multiple NPIs for different \"sub-parts\" such as a free-standing cancer center or rehab facility.\n\n\n**** Enforcement Rule ****\nOn February 16, 2006, HHS issued the Final Rule regarding HIPAA enforcement. It became effective on March 16, 2006. The Enforcement Rule sets civil money penalties for violating HIPAA rules and establishes procedures for investigations and hearings for HIPAA violations. For many years there were few prosecutions for violations.\nThis may have changed with the fining of $50,000 to the Hospice of North Idaho (HONI) as the first entity to be fined for a potential HIPAA Security Rule breach affecting fewer than 500 people. Rachel Seeger, a spokeswoman for HHS, stated, \"HONI did not conduct an accurate and thorough risk analysis to the confidentiality of ePHI [electronic Protected Health Information] as part of its security management process from 2005 through Jan. 17, 2012.\" This investigation was initiated with the theft from an employees vehicle of an unencrypted laptop containing 441 patient records.\n\nAs of March 2013, the U.S. Dept. of Health and Human Services (HHS) has investigated over 19,306 cases that have been resolved by requiring changes in privacy practice or by corrective action. If noncompliance is determined by HHS, entities must apply corrective measures. Complaints have been investigated against many different types of businesses such as national pharmacy chains, major health care centers, insurance groups, hospital chains and other small providers. There were 9,146 cases where the HHS investigation found that HIPAA was followed correctly. There were 44,118 cases that HHS did not find eligible cause for enforcement; for example, a violation that started before HIPAA started; cases withdrawn by the pursuer; or an activity that does not actually violate the Rules. According to the HHS website, the following lists the issues that have been reported according to frequency:\n\nMisuse and disclosures of PHI\nNo protection in place of health information\nPatient unable to access their health information\nUsing or disclosing more than the minimum necessary protected health information\nNo safeguards of electronic protected health information.The most common entities required to take corrective action to be in voluntary compliance according to HHS are listed by frequency:\nPrivate Practices\nHospitals\nOutpatient Facilities\nGroup plans such as insurance groups\nPharmacies\n\n\n*** Title III: Tax-related health provisions governing medical savings accounts ***\nTitle III standardizes the amount that may be saved per person in a pre-tax medical savings account. Beginning in 1997, a medical savings\naccount (\"MSA\") became available to employees covered under an employer-sponsored high deductible plan of a small employer and\nself-employed individuals.\n\n\n*** Title IV: Application and enforcement of group health insurance requirements ***\nTitle IV specifies conditions for group health plans regarding coverage of persons with pre-existing conditions, and modifies continuation of coverage requirements.  It also clarifies continuation coverage requirements and includes COBRA clarification.\n\n\n*** Title V: Revenue offset governing tax deductions for employers ***\nTitle V includes provisions related to company-owned life insurance for employers providing company-owned life insurance premiums, prohibiting the tax-deduction of interest on life insurance loans, company endowments, or contracts related to the company. It also repeals the financial institution rule to interest allocation rules. Finally, it amends provisions of law relating to people who give up United States citizenship or permanent residence, expanding the expatriation tax to be assessed against those deemed to be giving up their U.S. status for tax reasons, and making ex-citizens' names part of the public record through the creation of the Quarterly Publication of Individuals Who Have Chosen to Expatriate.\n\n== Effects on research and clinical care ==\nThe enactment of the Privacy and Security Rules has caused major changes in the way physicians and medical centers operate. The complex legalities and potentially stiff penalties associated with HIPAA, as well as the increase in paperwork and the cost of its implementation, were causes for concern among physicians and medical centers. An August 2006 article in the journal Annals of Internal Medicine detailed some such concerns over the implementation and effects of HIPAA.\n\n\n*** Effects on research ***\nHIPAA restrictions on researchers have affected their ability to perform retrospective, chart-based research as well as their ability to prospectively evaluate patients by contacting them for follow-up. A study from the University of Michigan demonstrated that implementation of the HIPAA Privacy rule resulted in a drop from 96% to 34% in the proportion of follow-up surveys completed by study patients being followed after a heart attack. Another study, detailing the effects of HIPAA on recruitment for a study on cancer prevention, demonstrated that HIPAA-mandated changes led to a 73% decrease in patient accrual, a tripling of time spent recruiting patients, and a tripling of mean recruitment costs.In addition, informed consent forms for research studies now are required to include extensive detail on how the participant's protected health information will be kept private. While such information is important, the addition of a lengthy, legalistic section on privacy may make these already complex documents even less user-friendly for patients who are asked to read and sign them.\nThese data suggest that the HIPAA privacy rule, as currently implemented, may be having negative impacts on the cost and quality of medical research. Dr. Kim Eagle, professor of internal medicine at the University of Michigan, was quoted in the Annals article as saying, \"Privacy is important, but research is also important for improving care. We hope that we will figure this out and do it right.\"\n\n\n*** Effects on clinical care ***\nThe complexity of HIPAA, combined with potentially stiff penalties for violators, can lead physicians and medical centers to withhold information from those who may have a right to it. A review of the implementation of the HIPAA Privacy Rule by the U.S. Government Accountability Office found that health care providers were \"uncertain about their legal privacy responsibilities and often responded with an overly guarded approach to disclosing information ... than necessary to ensure compliance with the Privacy rule\". Reports of this uncertainty continue.\n\n\n*** Costs of implementation ***\nIn the period immediately prior to the enactment of the HIPAA Privacy and Security Acts, medical centers and medical practices were charged with getting \"into compliance\". With an early emphasis on the potentially severe penalties associated with violation, many practices and centers turned to private, for-profit \"HIPAA consultants\" who were intimately familiar with the details of the legislation and offered their services to ensure that physicians and medical centers were fully \"in compliance\". In addition to the costs of developing and revamping systems and practices, the increase in paperwork and staff time necessary to meet the legal requirements of HIPAA may impact the finances of medical centers and practices at a time when insurance companies' and Medicare reimbursement is also declining.\n\n\n*** Education and training ***\nEducation and training of healthcare providers is a requirement for correct implementation of both the HIPAA Privacy Rule and Security Rule.\n\n== HIPAA acronym ==\nAlthough the acronym HIPAA matches the title of the 1996 Public Law 104-191, Health Insurance Portability and Accountability Act, HIPAA is sometimes incorrectly referred to as \"Health Information Privacy and Portability Act (HIPPA).\"\n\n== Violations ==\n\nAccording to the US Department of Health and Human Services Office for Civil Rights, between April 2003 and January 2013, it received 91,000 complaints of HIPAA violations, in which 22,000 led to enforcement actions of varying kinds (from settlements to fines) and 521 led to referrals to the US Department of Justice as criminal actions. Examples of significant breaches of protected information and other HIPAA violations include:\n\nThe largest loss of data that affected 4.9 million people by Tricare Management of Virginia in 2011\nThe largest fines of $5.5 million levied against Memorial Healthcare Systems in 2017 for accessing confidential information of 115,143 patients and of $4.3 million levied against Cignet Health of Maryland in 2010 for ignoring patients' requests to obtain copies of their own records and repeated ignoring of federal officials' inquiries\nThe first criminal indictment was lodged in 2011 against a Virginia physician who shared information with a patient's employer \"under the false pretenses that the patient was a serious and imminent threat to the safety of the public, when in fact he knew that the patient was not such a threat.\"According to Koczkodaj et al., 2018, the total number of individuals affected since October 2009 is 173,398,820.\nThe differences between civil and criminal penalties are summarized in the following table:\n\n== Legislative information ==\nIn 1994, President Clinton had ambitions to renovate the state of the nation's health care. Despite his efforts to revamp the system, he did not receive the support he needed at the time. The Congressional Quarterly Almanac of 1996 explains how two senators, Nancy Kassebaum (R-KS) and Edward Kennedy (D-MA) came together and created a bill called the Health Insurance Reform Act of 1995 or more commonly known as the Kassebaum-Kennedy Bill. This bill was stalled despite making it out of the Senate. Undeterred by this, Clinton pushed harder for his ambitions and eventually in 1996 after the State of the Union address, there was some headway as it resulted in bipartisan cooperation. After much debate and negotiation, there was a shift in momentum once a \u201ccompromise between Kennedy and Ways and Means Committee Chairman Bill Archer\u201d was accepted after alterations were made of the original Kassebaum-Kennedy Bill. Soon after this, the bill was signed into law by President Clinton and was named the Health Insurance Portability and Accountability Act of 1996 (HIPAA).\n\nPub. L. 104\u2013191 (text) (PDF), 110 Stat. 1936H.R. 3103; H. Rept. 104-469, part 1; H. Rept. 104-736\nS. 1028; S. 1698; S. Rept. 104-156\nHHS Security Standards, 45 CFR 160, 45 CFR 162, and 45 CFR 164\nHHS Standards for Privacy of Individually Identifiable Health Information, 45 CFR 160 and 45 CFR 164"
    }
  },
  {
    "instruction": "Context: Netcat\n\n==Introduction==\nnetcat (often abbreviated to nc) is a computer networking utility for reading from and writing to network connections using TCP or UDP. The command is designed to be a dependable back-end that can be used directly or easily driven by other programs and scripts. At the same time, it is a feature-rich network debugging and investigation tool, since it can produce almost any kind of connection its user could need and has a number of built-in capabilities.\nIts list of features includes port scanning, transferring files, and port listening: as with any server, it can be used as a backdoor.\n\n== Features ==\nThe original netcat's features include:\nOutbound or inbound connections, TCP or UDP, to or from any ports\nFull DNS forward/reverse checking, with appropriate warnings\nAbility to use any local source port\nAbility to use any locally configured network source address\nBuilt-in port-scanning capabilities, with randomization\nBuilt-in loose source-routing capability\nCan read command line arguments from standard input\nSlow-send mode, one line every N seconds\nHex dump of transmitted and received data\nOptional ability to let another program service establish connections\nOptional telnet-options responderRewrites like GNU's and OpenBSD's support additional features. For example, OpenBSD's nc supports TLS, and GNU netcat natively supports a tunneling mode supporting UDP and TCP (optionally allowing one to be tunneled over the other) in a single command, where other versions may require piping data from one netcat instance to another.\n\n== Examples ==\n\n\n*** Opening a raw connection to port 25 ***\nnc mail.server.net 25\n\n\n*** Performing an HTTP request ***\n\nThe full response (including HTTP headers) will be dumped to standard output.\n\n\n*** Setting up a one-shot webserver on port 8080 to present the content of a file ***\n\nThe file can then be accessed via a web browser under http://servername:8080/. Netcat only serves the file once to the first client that connects and then exits; it also provides the content length for browsers that expect it. (This should work fine in a LAN, but may potentially fail with any kind of firewall between.) In some versions of netcat like netcat-traditional in Debian 8.6, you need to specify -p before the port number.\n\n\n*** Checking whether UDP ports (-u) 80\u201390 are open on 192.168.0.1 using zero mode I/O (-z) ***\nnc -vzu 192.168.0.1 80-90\n\nUDP tests will always show as \"open\".\n\n\n*** Test whether UDP port is open: simple UDP server and client ***\nThis test is useful, if you have shell access to the server that should be tested, but you do not know whether there is a firewall blocking a specific UDP port on the server.\nOn the listening host, i.e. on the server whose port needs to be checked, do the following:\n\nnc -l -u -p 4172\n\nOn the sending host, do the following \u2013 servname is the hostname of the listening host:\n\nnc -u servname 4172\n\nIf text typed on the sending host (type something and hit enter) is displayed also on the listening host, then the UDP port 4172 is open. If it is not open, you will get an error such as \"Connection refused\".\nThere is a caveat. On some machines, IPv6 may be the default IP version to use by netcat. Thus, the host specified by the hostname is contacted using IPv6, and the user might not know about this. Ports may appear closed in the test, even though they would be open when using IPv4. This can be difficult to notice and may cause the false impression that the port is blocked, while it is actually open. You can force the use of IPv4 by adding -4 to the options of the nc commands.\n\n\n*** Pipe via UDP (-u) with a wait time (-w) of 1 second to \"loggerhost\" on port 514 ***\necho '<0>message' | nc -w 1 -u loggerhost 514\n\n\n*** Port scanning ***\nAn uncommon use of netcat is port scanning. Netcat is not considered the best tool for this job, but it can be sufficient (a more advanced tool is nmap)\n\nnc -v -n -z -w 1 192.168.1.2 1-1000\n\nThe -n parameter here prevents DNS lookup, -z makes nc not receive any data from the server, and -w 1 makes the connection timeout after 1 second of inactivity.\n\n\n*** Proxying ***\nAnother useful behaviour is using netcat as a proxy. Both ports and hosts can be redirected. Look at this example:\n\nnc -l 12345 | nc www.google.com 80\n\nPort 12345 represents the request.\nThis starts a nc server on port 12345 and all the connections get redirected to google.com:80. If a web browser makes a request to nc, the request will be sent to google but the response will not be sent to the web browser. That is because pipes are unidirectional. This can be worked around with a named pipe to redirect the input and output.\n\nThe -c option may also be used with the ncat implementation:\n\nUsing a named pipe is a more reliable method because using -c option provides only a one-shot proxy.\nAnother useful feature is to proxy SSL connections. This way, the traffic can not be viewed in wire sniffing applications such as wireshark. This can be accomplished on UNIXes by utilizing mkfifo, netcat, and openssl.\n\n\n*** Making any process a server ***\nnetcat can be used to make any process a network server. It can listen on a port and pipe the input it receives to that process.\nThe -e option spawns the executable with its input and output redirected via network socket.\nFor example, it is possible to expose a bourne shell process to remote computers.\nTo do so, on a computer A with IP address 192.168.1.2, run this command:\n\nThen, from any other computer on the same network, one could run this nc command:\n\nIn this way, the -e option can be used to create a rudimentary backdoor. Some administrators perceive this as a risk and thus do not allow netcat on a computer. The version of netcat developed by OpenBSD that is often installed by default on distributions such as Debian and Ubuntu lacks this option due to this potential as a security risk.\n\n== ncat ==\nNcat is a similar tool to netcat provided by Nmap suite. \"While Ncat isn't built on any code from the \u201ctraditional\u201d Netcat (or any other implementation), Ncat is most definitely based on Netcat in spirit and functionality.\"Ncat features includes: ability to chain Ncats together, redirect both TCP and UDP ports to other sites, SSL support, and proxy connections via SOCKS4 or HTTP (CONNECT method) proxies (with optional proxy authentication as well).\nConnect to example.org on TCP port 8080. :  ncat example.org 8080\nListen for connections on TCP port 8080. : ncat -l 8080\nRedirect TCP port 8080 on the local machine to host on port 80. : $ ncat --sh-exec \"ncat example.org 80\" -l 8080 --keep-open\nBind to TCP port 8081 and attach /bin/bash for the world to access freely. : $ ncat --exec \"/bin/bash\" -l 8081 --keep-open\nBind a shell to TCP port 8081, limit access to hosts on a local network, and limit the maximum number of simultaneous connections to 3:\n$ ncat --exec \"/bin/bash\" --max-conns 3 --allow 192.168.0.0/24 -l 8081 --keep-open\nConnect to smtphost:25 through a SOCKS4 server on port 1080: ncat --proxy socks4host --proxy-type socks4 --proxy-auth user smtphost 25\nCreate an HTTP proxy server on localhost port 8888. : ncat -l --proxy-type http localhost 8888\nSend a file over TCP port 9899 from host2 (client) to host1 (server).\nTransfer in the other direction, turning Ncat into a \u201cone file\u201d server.\n\n\n*** Encrypted file transfer ***\nSuppose you have an SSH tunnel, and you want to copy a file to the remote machine. You could just scp it directly, but that opens up another connection. The goal is to re-use the existing connection. You can use ncat to do this:\nWhen you SSH in, add in -L 31000:127.0.0.1:31000 (this is port forwarding, sending everything from port 31000 on the remote machine to the same port on the local machine)\n\nOn the remote: ncat -lvnp 31000 127.0.0.1 > file\nOn the local: ncat -v -w 2 127.0.0.1 31000 < fileNo extra overhead. TCP takes care of error correction. SSH has already encrypted the pipe.\n\n== Ports and reimplementations ==\nThe original version of netcat was a Unix program. The last version (1.10) was released in March 1996.There are several implementations on POSIX systems, including rewrites from scratch like GNU netcat or OpenBSD netcat,\nthe latter of which supports IPv6 and TLS. The OpenBSD version has been ported to the FreeBSD base,\nWindows/Cygwin,\nand Linux.Mac OS X comes with netcat installed as of OSX 10.13 or users can use MacPorts to install a variant.A DOS version of netcat called NTOOL is included in the FreeDOS Package group Networking. It is based on the WatTCP stack and licensed under the European Union Public Licence Version 1.1.Known ports for embedded systems includes versions for Windows CE (named \"Netcat 4 wince\") or for the iPhone.BusyBox includes by default a lightweight version of netcat.\nSolaris 11 includes netcat implementation based on OpenBSD netcat.\nSocat is a more complex variant of netcat. It is larger and more flexible and has more options that must be configured for a given task.  On February 1, 2016, Santiago Zanella-Beguelin and Microsoft Vulnerability Research issued a security advisory regarding a composite Diffie-Hellman parameter which had been hard-coded into the OpenSSL implementation of socat. The implausibility that a composite might have been unintentionally introduced where a prime number is required has led to the suspicion of sabotage to introduce a backdoor software vulnerability. This socat bug affected version 1.7.3.0 and 2.0.0-b8 it was corrected in following releases from 1.7.3.1 and 2.0.0-b9.Cryptcat is a version of netcat with integrated transport encryption capabilities.\nIn the middle of 2005, Nmap announced another netcat incarnation called Ncat. It features new possibilities such as \"Connection Brokering\", TCP/UDP Redirection, SOCKS4 client and server support, ability to \"Chain\" Ncat processes, HTTP CONNECT proxying (and proxy chaining), SSL connect/listen support and IP address/connection filtering. Like Nmap, Ncat is cross-platform.\nOn some systems, modified versions or similar netcat utilities go by the command name(s) nc, ncat, pnetcat, socat, sock, socket, sbd.\nAnswer this question: Can netcat be used for scanning ports, and how does it compare to other tools for this purpose?",
    "context": "",
    "output": "Yes, netcat can be used for scanning ports, but it is not considered the best tool for this job. It lacks some advanced features present in specialized port scanning tools like nmap. However, it can still be sufficient for basic port scanning tasks and may be useful in specific situations where more advanced tools are not available.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can netcat be used for scanning ports, and how does it compare to other tools for this purpose?",
      "answer": "Yes, netcat can be used for scanning ports, but it is not considered the best tool for this job. It lacks some advanced features present in specialized port scanning tools like nmap. However, it can still be sufficient for basic port scanning tasks and may be useful in specific situations where more advanced tools are not available.",
      "context": "Netcat\n\n==Introduction==\nnetcat (often abbreviated to nc) is a computer networking utility for reading from and writing to network connections using TCP or UDP. The command is designed to be a dependable back-end that can be used directly or easily driven by other programs and scripts. At the same time, it is a feature-rich network debugging and investigation tool, since it can produce almost any kind of connection its user could need and has a number of built-in capabilities.\nIts list of features includes port scanning, transferring files, and port listening: as with any server, it can be used as a backdoor.\n\n== Features ==\nThe original netcat's features include:\nOutbound or inbound connections, TCP or UDP, to or from any ports\nFull DNS forward/reverse checking, with appropriate warnings\nAbility to use any local source port\nAbility to use any locally configured network source address\nBuilt-in port-scanning capabilities, with randomization\nBuilt-in loose source-routing capability\nCan read command line arguments from standard input\nSlow-send mode, one line every N seconds\nHex dump of transmitted and received data\nOptional ability to let another program service establish connections\nOptional telnet-options responderRewrites like GNU's and OpenBSD's support additional features. For example, OpenBSD's nc supports TLS, and GNU netcat natively supports a tunneling mode supporting UDP and TCP (optionally allowing one to be tunneled over the other) in a single command, where other versions may require piping data from one netcat instance to another.\n\n== Examples ==\n\n\n*** Opening a raw connection to port 25 ***\nnc mail.server.net 25\n\n\n*** Performing an HTTP request ***\n\nThe full response (including HTTP headers) will be dumped to standard output.\n\n\n*** Setting up a one-shot webserver on port 8080 to present the content of a file ***\n\nThe file can then be accessed via a web browser under http://servername:8080/. Netcat only serves the file once to the first client that connects and then exits; it also provides the content length for browsers that expect it. (This should work fine in a LAN, but may potentially fail with any kind of firewall between.) In some versions of netcat like netcat-traditional in Debian 8.6, you need to specify -p before the port number.\n\n\n*** Checking whether UDP ports (-u) 80\u201390 are open on 192.168.0.1 using zero mode I/O (-z) ***\nnc -vzu 192.168.0.1 80-90\n\nUDP tests will always show as \"open\".\n\n\n*** Test whether UDP port is open: simple UDP server and client ***\nThis test is useful, if you have shell access to the server that should be tested, but you do not know whether there is a firewall blocking a specific UDP port on the server.\nOn the listening host, i.e. on the server whose port needs to be checked, do the following:\n\nnc -l -u -p 4172\n\nOn the sending host, do the following \u2013 servname is the hostname of the listening host:\n\nnc -u servname 4172\n\nIf text typed on the sending host (type something and hit enter) is displayed also on the listening host, then the UDP port 4172 is open. If it is not open, you will get an error such as \"Connection refused\".\nThere is a caveat. On some machines, IPv6 may be the default IP version to use by netcat. Thus, the host specified by the hostname is contacted using IPv6, and the user might not know about this. Ports may appear closed in the test, even though they would be open when using IPv4. This can be difficult to notice and may cause the false impression that the port is blocked, while it is actually open. You can force the use of IPv4 by adding -4 to the options of the nc commands.\n\n\n*** Pipe via UDP (-u) with a wait time (-w) of 1 second to \"loggerhost\" on port 514 ***\necho '<0>message' | nc -w 1 -u loggerhost 514\n\n\n*** Port scanning ***\nAn uncommon use of netcat is port scanning. Netcat is not considered the best tool for this job, but it can be sufficient (a more advanced tool is nmap)\n\nnc -v -n -z -w 1 192.168.1.2 1-1000\n\nThe -n parameter here prevents DNS lookup, -z makes nc not receive any data from the server, and -w 1 makes the connection timeout after 1 second of inactivity.\n\n\n*** Proxying ***\nAnother useful behaviour is using netcat as a proxy. Both ports and hosts can be redirected. Look at this example:\n\nnc -l 12345 | nc www.google.com 80\n\nPort 12345 represents the request.\nThis starts a nc server on port 12345 and all the connections get redirected to google.com:80. If a web browser makes a request to nc, the request will be sent to google but the response will not be sent to the web browser. That is because pipes are unidirectional. This can be worked around with a named pipe to redirect the input and output.\n\nThe -c option may also be used with the ncat implementation:\n\nUsing a named pipe is a more reliable method because using -c option provides only a one-shot proxy.\nAnother useful feature is to proxy SSL connections. This way, the traffic can not be viewed in wire sniffing applications such as wireshark. This can be accomplished on UNIXes by utilizing mkfifo, netcat, and openssl.\n\n\n*** Making any process a server ***\nnetcat can be used to make any process a network server. It can listen on a port and pipe the input it receives to that process.\nThe -e option spawns the executable with its input and output redirected via network socket.\nFor example, it is possible to expose a bourne shell process to remote computers.\nTo do so, on a computer A with IP address 192.168.1.2, run this command:\n\nThen, from any other computer on the same network, one could run this nc command:\n\nIn this way, the -e option can be used to create a rudimentary backdoor. Some administrators perceive this as a risk and thus do not allow netcat on a computer. The version of netcat developed by OpenBSD that is often installed by default on distributions such as Debian and Ubuntu lacks this option due to this potential as a security risk.\n\n== ncat ==\nNcat is a similar tool to netcat provided by Nmap suite. \"While Ncat isn't built on any code from the \u201ctraditional\u201d Netcat (or any other implementation), Ncat is most definitely based on Netcat in spirit and functionality.\"Ncat features includes: ability to chain Ncats together, redirect both TCP and UDP ports to other sites, SSL support, and proxy connections via SOCKS4 or HTTP (CONNECT method) proxies (with optional proxy authentication as well).\nConnect to example.org on TCP port 8080. :  ncat example.org 8080\nListen for connections on TCP port 8080. : ncat -l 8080\nRedirect TCP port 8080 on the local machine to host on port 80. : $ ncat --sh-exec \"ncat example.org 80\" -l 8080 --keep-open\nBind to TCP port 8081 and attach /bin/bash for the world to access freely. : $ ncat --exec \"/bin/bash\" -l 8081 --keep-open\nBind a shell to TCP port 8081, limit access to hosts on a local network, and limit the maximum number of simultaneous connections to 3:\n$ ncat --exec \"/bin/bash\" --max-conns 3 --allow 192.168.0.0/24 -l 8081 --keep-open\nConnect to smtphost:25 through a SOCKS4 server on port 1080: ncat --proxy socks4host --proxy-type socks4 --proxy-auth user smtphost 25\nCreate an HTTP proxy server on localhost port 8888. : ncat -l --proxy-type http localhost 8888\nSend a file over TCP port 9899 from host2 (client) to host1 (server).\nTransfer in the other direction, turning Ncat into a \u201cone file\u201d server.\n\n\n*** Encrypted file transfer ***\nSuppose you have an SSH tunnel, and you want to copy a file to the remote machine. You could just scp it directly, but that opens up another connection. The goal is to re-use the existing connection. You can use ncat to do this:\nWhen you SSH in, add in -L 31000:127.0.0.1:31000 (this is port forwarding, sending everything from port 31000 on the remote machine to the same port on the local machine)\n\nOn the remote: ncat -lvnp 31000 127.0.0.1 > file\nOn the local: ncat -v -w 2 127.0.0.1 31000 < fileNo extra overhead. TCP takes care of error correction. SSH has already encrypted the pipe.\n\n== Ports and reimplementations ==\nThe original version of netcat was a Unix program. The last version (1.10) was released in March 1996.There are several implementations on POSIX systems, including rewrites from scratch like GNU netcat or OpenBSD netcat,\nthe latter of which supports IPv6 and TLS. The OpenBSD version has been ported to the FreeBSD base,\nWindows/Cygwin,\nand Linux.Mac OS X comes with netcat installed as of OSX 10.13 or users can use MacPorts to install a variant.A DOS version of netcat called NTOOL is included in the FreeDOS Package group Networking. It is based on the WatTCP stack and licensed under the European Union Public Licence Version 1.1.Known ports for embedded systems includes versions for Windows CE (named \"Netcat 4 wince\") or for the iPhone.BusyBox includes by default a lightweight version of netcat.\nSolaris 11 includes netcat implementation based on OpenBSD netcat.\nSocat is a more complex variant of netcat. It is larger and more flexible and has more options that must be configured for a given task.  On February 1, 2016, Santiago Zanella-Beguelin and Microsoft Vulnerability Research issued a security advisory regarding a composite Diffie-Hellman parameter which had been hard-coded into the OpenSSL implementation of socat. The implausibility that a composite might have been unintentionally introduced where a prime number is required has led to the suspicion of sabotage to introduce a backdoor software vulnerability. This socat bug affected version 1.7.3.0 and 2.0.0-b8 it was corrected in following releases from 1.7.3.1 and 2.0.0-b9.Cryptcat is a version of netcat with integrated transport encryption capabilities.\nIn the middle of 2005, Nmap announced another netcat incarnation called Ncat. It features new possibilities such as \"Connection Brokering\", TCP/UDP Redirection, SOCKS4 client and server support, ability to \"Chain\" Ncat processes, HTTP CONNECT proxying (and proxy chaining), SSL connect/listen support and IP address/connection filtering. Like Nmap, Ncat is cross-platform.\nOn some systems, modified versions or similar netcat utilities go by the command name(s) nc, ncat, pnetcat, socat, sock, socket, sbd."
    }
  },
  {
    "instruction": "context: The Education and Awareness Special Function Component is responsible for developing and implementing a comprehensive education and awareness strategy for a successful DoD CIP program.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the role of the Education and Awareness Special Function Component in DoD critical infrastructure protection?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Education and Awareness Special Function Component in DoD critical infrastructure protection?",
      "answer": "The Education and Awareness Special Function Component is responsible for developing and implementing a comprehensive education and awareness strategy for a successful DoD CIP program."
    }
  },
  {
    "instruction": "context: Norton AntiVirus 2007 will not install alongside ZoneAlarm. Symantec recommends removing ZoneAlarm, then reinstalling it with its Internet Worm Protection feature disabled.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does Norton AntiVirus handle incompatibilities with ZoneAlarm?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Norton AntiVirus handle incompatibilities with ZoneAlarm?",
      "answer": "Norton AntiVirus 2007 will not install alongside ZoneAlarm. Symantec recommends removing ZoneAlarm, then reinstalling it with its Internet Worm Protection feature disabled."
    }
  },
  {
    "instruction": "context: The SYNPROXY target is used to handle large SYN floods without the large performance penalties imposed by connection tracking in such cases. It redirects initial SYN requests to the SYNPROXY target, freeing up connection tracking from accounting large numbers of potentially invalid connections.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the SYNPROXY target in Netfilter?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the SYNPROXY target in Netfilter?",
      "answer": "The SYNPROXY target is used to handle large SYN floods without the large performance penalties imposed by connection tracking in such cases. It redirects initial SYN requests to the SYNPROXY target, freeing up connection tracking from accounting large numbers of potentially invalid connections."
    }
  },
  {
    "instruction": "context: The way sessions are instantiated in Windows Vista and Windows Server 2008 creates backward compatibility issues as some software was designed with the assumption that the service is running in the same session as the logged-in user.\n\nAsk a question about this context.",
    "context": "",
    "output": "What issues arise from the way sessions are instantiated in Windows Vista and Windows Server 2008?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What issues arise from the way sessions are instantiated in Windows Vista and Windows Server 2008?",
      "answer": "The way sessions are instantiated in Windows Vista and Windows Server 2008 creates backward compatibility issues as some software was designed with the assumption that the service is running in the same session as the logged-in user."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Agent.BTZ worm open backdoors on infected computers?",
    "context": "",
    "output": "The Agent.BTZ worm opens backdoors on infected computers by exploiting vulnerabilities and creating hidden entry points that can be used by the attacker to access the system remotely.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Agent.BTZ worm open backdoors on infected computers?",
      "answer": "The Agent.BTZ worm opens backdoors on infected computers by exploiting vulnerabilities and creating hidden entry points that can be used by the attacker to access the system remotely."
    }
  },
  {
    "instruction": "context: To determine if a device is affected, users should check for firmware updates from the manufacturer's website and follow installation instructions. Some vendors may provide tools or guides to help users identify vulnerable devices.\n\nAsk a question about this context.",
    "context": "",
    "output": "How would an individual or business determine if their device is affected by the Misfortune Cookie vulnerability?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How would an individual or business determine if their device is affected by the Misfortune Cookie vulnerability?",
      "answer": "To determine if a device is affected, users should check for firmware updates from the manufacturer's website and follow installation instructions. Some vendors may provide tools or guides to help users identify vulnerable devices."
    }
  },
  {
    "instruction": "Global kOS\n\n==Introduction==\nGlobal kOS \n('kos' pronounced as chaos) were a grey hat (leaning black hat) computer hacker group active from 1996 through 2000, considered a highly influential group who were involved in multiple high-profile security breaches and defacements as well as a releasing notable network security and intrusion tools. Global kOS were involved with the media heavily and were interviewed and profiled by journalist Jon Newton in his blog titled \"On The Road in Cyberspace\" (OTRiCS). The group were reported multiple times to the FBI by Carolyn Meinel who attempted to bring the group to justice while members of Global kOS openly mocked her. The FBI had a San Antonio based informant within the group and individually raided several members after contact with the informant.\n\n\n\n== Overview ==\nGlobal kOS were a loose collective of members of other hacking groups active in 1996 who released network and security tools for Windows and Linux. The group did not release exploit code as other groups did, each member maintained their own webpage and often acted individually or with their original group. Global kOS continually reiterated that their goal was entirely about rampaging across the internet and creating as much chaos as they could by releasing automated denial of service tools. The group was humorous and irreverent in interviews and press releases, they and affiliates openly taunted webmasters through website defacements. The group's members hacked and defaced a large number of websites in the nightly hacking contests over IRC on EFNet.\n\n== Members ==\nMembership between Global kOS and other hacking groups of the time is difficult to determine as most members were involved in multiple groups, crossover appears between Global kOS, Technophoria, SiN and GlobalHell (gH).\n\nAcidAngel - Author of the denial of service tools 'Up Yours!' and 'Panther modern'.\nMaterva\nGlitch\nThe Assassin\nNaCHoMaN - cracker\nThe Raven - author of 'kOS Crack'\nShadow Hunter\nSilicon Toad\nSpidey\nThat Guy\nZaven\nDigital Kid\n\n\n*** Affiliated members ***\nModify\nBroncBuster\nBanshee - author of bitchslap\nThe Messiah\nDeprave\nCyan Ide\nKiss\ndvdman\nThe boss\nRevelation\nQuestion: Who were Global kOS, and what were their goals and values?",
    "context": "",
    "output": "Answer: Global kOS were a grey hat (leaning black hat) hacker group that was active from 1996 to 2000. The group was involved in multiple high-profile security breaches and defacements, and they released network security and intrusion tools for Windows and Linux. Global kOS members did not release exploit code, but instead, they focused on creating chaos on the internet by releasing automated denial of service tools. The group was known for its humorous and irreverent interviews and press releases, and its members often taunted webmasters through website defacements.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who were Global kOS, and what were their goals and values?",
      "answer": "Global kOS were a grey hat (leaning black hat) hacker group that was active from 1996 to 2000. The group was involved in multiple high-profile security breaches and defacements, and they released network security and intrusion tools for Windows and Linux. Global kOS members did not release exploit code, but instead, they focused on creating chaos on the internet by releasing automated denial of service tools. The group was known for its humorous and irreverent interviews and press releases, and its members often taunted webmasters through website defacements.",
      "context": "Global kOS\n\n==Introduction==\nGlobal kOS \n('kos' pronounced as chaos) were a grey hat (leaning black hat) computer hacker group active from 1996 through 2000, considered a highly influential group who were involved in multiple high-profile security breaches and defacements as well as a releasing notable network security and intrusion tools. Global kOS were involved with the media heavily and were interviewed and profiled by journalist Jon Newton in his blog titled \"On The Road in Cyberspace\" (OTRiCS). The group were reported multiple times to the FBI by Carolyn Meinel who attempted to bring the group to justice while members of Global kOS openly mocked her. The FBI had a San Antonio based informant within the group and individually raided several members after contact with the informant.\n\n\n\n== Overview ==\nGlobal kOS were a loose collective of members of other hacking groups active in 1996 who released network and security tools for Windows and Linux. The group did not release exploit code as other groups did, each member maintained their own webpage and often acted individually or with their original group. Global kOS continually reiterated that their goal was entirely about rampaging across the internet and creating as much chaos as they could by releasing automated denial of service tools. The group was humorous and irreverent in interviews and press releases, they and affiliates openly taunted webmasters through website defacements. The group's members hacked and defaced a large number of websites in the nightly hacking contests over IRC on EFNet.\n\n== Members ==\nMembership between Global kOS and other hacking groups of the time is difficult to determine as most members were involved in multiple groups, crossover appears between Global kOS, Technophoria, SiN and GlobalHell (gH).\n\nAcidAngel - Author of the denial of service tools 'Up Yours!' and 'Panther modern'.\nMaterva\nGlitch\nThe Assassin\nNaCHoMaN - cracker\nThe Raven - author of 'kOS Crack'\nShadow Hunter\nSilicon Toad\nSpidey\nThat Guy\nZaven\nDigital Kid\n\n\n*** Affiliated members ***\nModify\nBroncBuster\nBanshee - author of bitchslap\nThe Messiah\nDeprave\nCyan Ide\nKiss\ndvdman\nThe boss\nRevelation"
    }
  },
  {
    "instruction": "Write an answer to the following question: Is segmentation only applied to the Enforcement Layer in SDP?",
    "context": "",
    "output": "No, segmentation is incorporated into the entire SDP architecture, not just the Enforcement Layer. The segmentation principle is used to divide a network into compartments with different security characteristics, and security controls are established for threat containment and recovery.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is segmentation only applied to the Enforcement Layer in SDP?",
      "answer": "No, segmentation is incorporated into the entire SDP architecture, not just the Enforcement Layer. The segmentation principle is used to divide a network into compartments with different security characteristics, and security controls are established for threat containment and recovery."
    }
  },
  {
    "instruction": "context: In 2012, Forcepoint released a cloud-based suite of IT security products for smartphones, tablets, laptops, USB drives, and other mobile devices. This is an important aspect of cybersecurity and network security, as mobile devices can be vulnerable to malware and other cyber threats.\n\nAsk a question about this context.",
    "context": "",
    "output": "How has Forcepoint's software been used to protect mobile devices from security threats, and what are the implications of this for cybersecurity and network security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has Forcepoint's software been used to protect mobile devices from security threats, and what are the implications of this for cybersecurity and network security?",
      "answer": "In 2012, Forcepoint released a cloud-based suite of IT security products for smartphones, tablets, laptops, USB drives, and other mobile devices. This is an important aspect of cybersecurity and network security, as mobile devices can be vulnerable to malware and other cyber threats."
    }
  },
  {
    "instruction": "Context: Commitment scheme\n\n==Introduction==\nA commitment scheme is a cryptographic primitive that allows one to commit to a chosen value (or chosen statement) while keeping it hidden to others, with the ability to reveal the committed value later. Commitment schemes are designed so that a party cannot change the value or statement after they have committed to it: that is, commitment schemes are binding. Commitment schemes have important applications in a number of cryptographic protocols including secure coin flipping, zero-knowledge proofs, and secure computation.\nA way to visualize a commitment scheme is to think of a sender as putting a message in a locked box, and giving the box to a receiver. The message in the box is hidden from the receiver, who cannot open the lock themselves. Since the receiver has the box, the message inside cannot be changed\u2014merely revealed if the sender chooses to give them the key at some later time.\nInteractions in a commitment scheme take place in two phases:\n\nthe commit phase during which a value is chosen and committed to\nthe reveal phase during which the value is revealed by the sender, then the receiver verifies its authenticityIn the above metaphor, the commit phase is the sender putting the message in the box, and locking it. The reveal phase is the sender giving the key to the receiver, who uses it to open the box and verify its contents. The locked box is the commitment, and the key is the proof.\nIn simple protocols, the commit phase consists of a single message from the sender to the receiver. This message is called the commitment. It is essential that the specific value chosen cannot be known by the receiver at that time (this is called the hiding property). A simple reveal phase would consist of a single message, the opening, from the sender to the receiver, followed by a check performed by the receiver. The value chosen during the commit phase must be the only one that the sender can compute and that validates during the reveal phase (this is called the binding property).\nThe concept of commitment schemes was perhaps first formalized by Gilles Brassard, David Chaum, and Claude Cr\u00e9peau in 1988, as part of various zero-knowledge protocols for NP, based on various types of commitment schemes. But the concept was used prior to that without being treated formally. The notion of commitments appeared earliest in works by Manuel Blum, Shimon Even, and Adi Shamir et al. The terminology seems to have been originated by Blum, although commitment schemes can be interchangeably called bit commitment schemes\u2014sometimes reserved for the special case where the committed value is a bit. Earlier to that, commitment via one-way hash functions was considered, e.g., as part of, say, Lamport signature, the original one-time one-bit signature scheme.\n\n== Applications ==\n\n\n*** Coin flipping ***\nSuppose Alice and Bob want to resolve some dispute via coin flipping. If they are physically in the same place, a typical procedure might be:\n\nAlice \"calls\" the coin flip\nBob flips the coin\nIf Alice's call is correct, she wins, otherwise Bob winsIf Alice and Bob are not in the same place a problem arises. Once Alice has \"called\" the coin flip, Bob can stipulate the flip \"results\" to be whatever is most desirable for him. Similarly, if Alice doesn't announce her \"call\" to Bob, after Bob flips the coin and announces the result, Alice can report that she called whatever result is most desirable for her. Alice and Bob can use commitments in a procedure that will allow both to trust the outcome:\n\nAlice \"calls\" the coin flip but only tells Bob a commitment to her call,\nBob flips the coin and reports the result,\nAlice reveals what she committed to,\nBob verifies that Alice's call matches her commitment,\nIf Alice's revelation matches the coin result Bob reported, Alice winsFor Bob to be able to skew the results to his favor, he must be able to understand the call hidden in Alice's commitment. If the commitment scheme is a good one, Bob cannot skew the results.  Similarly, Alice cannot affect the result if she cannot change the value she commits to.\nA real-life application of this problem exists, when people (often in media) commit to a decision or give an answer in a \"sealed envelope\", which is then opened later. \"Let's find out if that's what the candidate answered\", for example on a game show, can serve as a model of this system.\n\n\n*** Zero-knowledge proofs ***\nOne particular motivating example is the use of commitment schemes in zero-knowledge proofs. Commitments are used in zero-knowledge proofs for two main purposes: first, to allow the prover to participate in \"cut and choose\" proofs where the verifier will be presented with a choice of what to learn, and the prover will reveal only what corresponds to the verifier's choice. Commitment schemes allow the prover to specify all the information in advance, and only reveal what should be revealed later in the proof. \nSecond, commitments are also used in zero-knowledge proofs by the verifier, who will often specify their choices ahead of time in a commitment. This allows zero-knowledge proofs to be composed in parallel without revealing additional information to the prover.\n\n\n*** Signature schemes ***\nThe Lamport signature scheme is a digital signature system that relies on maintaining two sets of secret data packets, publishing verifiable hashes of the data packets, and then selectively revealing partial secret data packets in a manner that conforms specifically to the data to be signed. In this way, the prior public commitment to the secret values becomes a critical part of the functioning of the system.\nBecause the Lamport signature system cannot be used more than once, a system to combine many Lamport key-sets under a single public value that can be tied to a person and verified by others was developed. This system uses trees of hashes to compress many published Lamport-key-commitment sets into a single hash value that can be associated with the prospective author of later-verified data.\n\n\n*** Verifiable secret sharing ***\nAnother important application of commitments is in verifiable secret sharing, a critical building block of secure multiparty computation. In a secret sharing scheme, each of several parties receive \"shares\" of a value that is meant to be hidden from everyone. If enough parties get together, their shares can be used to reconstruct the secret, but even a malicious cabal of insufficient size should learn nothing. Secret sharing is at the root of many protocols for secure computation: in order to securely compute a function of some shared input, the secret shares are manipulated instead. However, if shares are to be generated by malicious parties, it may be important that those shares can be checked for correctness. In a verifiable secret sharing scheme, the distribution of a secret is accompanied by commitments to the individual shares. The commitments reveal nothing that can help a dishonest cabal, but the shares allow each individual party to check to see if their shares are correct.\n\n== Defining the security ==\nFormal definitions of commitment schemes vary strongly in notation and in flavour. The first such flavour is whether the commitment scheme provides perfect or computational security with respect to the hiding or binding properties.  Another such flavour is whether the commitment is interactive, i.e. whether both the commit phase and the reveal phase can be seen as being executed by a cryptographic protocol or whether they are non-interactive, consisting of two algorithms Commit and CheckReveal. In the latter case CheckReveal can often be seen as a derandomised version of Commit, with the randomness used by Commit constituting the opening information.\nIf the commitment C to a value x is computed as C:\n\n== Construction ==\nA commitment scheme can either be perfectly binding (it is impossible for Alice to alter her commitment after she has made it, even if she has unbounded computational resources); or perfectly concealing (it is impossible for Bob to find out the commitment without Alice revealing it, even if he has unbounded computational resources); or formulated as an instance-dependent commitment scheme, which is either hiding or binding depending on the solution to another problem. A commitment scheme can not be both perfectly hiding and perfectly binding at the same time.\n\n\n*** Bit-commitment in the random oracle model ***\nBit-commitment schemes are trivial to construct in the random oracle model. Given a hash function H with a 3k bit output, to commit the k-bit message m, Alice generates a random k bit string R and sends Bob H(R||m). The probability that any R\u2032, m\u2032 exist where m\u2032 \u2260 m such that H(R\u2032||m\u2032)\n\n== Partial reveal ==\nSome commitment schemes permit a proof to be given of only a portion of the committed value. In these schemes, the secret value \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n   is a vector of many individually separable values.\n\n  \n    \n      \n        X\n\n== Quantum bit commitment ==\nIt is an interesting question in quantum cryptography if unconditionally secure bit commitment protocols exist on the quantum level, that is, protocols which are (at least asymptotically) binding and concealing even if there are no restrictions on the computational resources. One could hope that there might be a way to exploit the intrinsic properties of quantum mechanics, as in the protocols for unconditionally secure key distribution.\nHowever, this is impossible, as Dominic Mayers showed in 1996 (see for the original proof). Any such protocol can be reduced to a protocol where the system is in one of two pure states after the commitment phase, depending on the bit Alice wants to commit. If the protocol is unconditionally concealing, then Alice can unitarily transform these states into each other using the properties of the Schmidt decomposition, effectively defeating the binding property.\nOne subtle assumption of the proof is that the commit phase must be finished at some point in time. This leaves room for protocols that require a continuing information flow until the bit is unveiled or the protocol is cancelled, in which case it is not binding anymore. More generally,  Mayers' proof applies only to protocols that exploit quantum physics but not special relativity. Kent has shown that there exist unconditionally secure protocols for bit commitment that exploit the principle of special relativity stating that information cannot travel faster than light.\n\n== Commitments based on physical unclonable functions ==\nPhysical unclonable functions (PUFs) rely on the use of a physical key with internal randomness, which is hard to clone or to emulate. Electronic, optical and other types of PUFs have been discussed extensively in the literature, in connection with their potential cryptographic applications including commitment schemes.\n\nQuestion: How are bit-commitment schemes constructed in the random oracle model?\n\nAnswer:",
    "context": "",
    "output": "In the random oracle model, bit-commitment schemes can be constructed by having the sender generate a random string and send the hash of the string concatenated with the message to the receiver.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are bit-commitment schemes constructed in the random oracle model?",
      "answer": "In the random oracle model, bit-commitment schemes can be constructed by having the sender generate a random string and send the hash of the string concatenated with the message to the receiver.",
      "context": "Commitment scheme\n\n==Introduction==\nA commitment scheme is a cryptographic primitive that allows one to commit to a chosen value (or chosen statement) while keeping it hidden to others, with the ability to reveal the committed value later. Commitment schemes are designed so that a party cannot change the value or statement after they have committed to it: that is, commitment schemes are binding. Commitment schemes have important applications in a number of cryptographic protocols including secure coin flipping, zero-knowledge proofs, and secure computation.\nA way to visualize a commitment scheme is to think of a sender as putting a message in a locked box, and giving the box to a receiver. The message in the box is hidden from the receiver, who cannot open the lock themselves. Since the receiver has the box, the message inside cannot be changed\u2014merely revealed if the sender chooses to give them the key at some later time.\nInteractions in a commitment scheme take place in two phases:\n\nthe commit phase during which a value is chosen and committed to\nthe reveal phase during which the value is revealed by the sender, then the receiver verifies its authenticityIn the above metaphor, the commit phase is the sender putting the message in the box, and locking it. The reveal phase is the sender giving the key to the receiver, who uses it to open the box and verify its contents. The locked box is the commitment, and the key is the proof.\nIn simple protocols, the commit phase consists of a single message from the sender to the receiver. This message is called the commitment. It is essential that the specific value chosen cannot be known by the receiver at that time (this is called the hiding property). A simple reveal phase would consist of a single message, the opening, from the sender to the receiver, followed by a check performed by the receiver. The value chosen during the commit phase must be the only one that the sender can compute and that validates during the reveal phase (this is called the binding property).\nThe concept of commitment schemes was perhaps first formalized by Gilles Brassard, David Chaum, and Claude Cr\u00e9peau in 1988, as part of various zero-knowledge protocols for NP, based on various types of commitment schemes. But the concept was used prior to that without being treated formally. The notion of commitments appeared earliest in works by Manuel Blum, Shimon Even, and Adi Shamir et al. The terminology seems to have been originated by Blum, although commitment schemes can be interchangeably called bit commitment schemes\u2014sometimes reserved for the special case where the committed value is a bit. Earlier to that, commitment via one-way hash functions was considered, e.g., as part of, say, Lamport signature, the original one-time one-bit signature scheme.\n\n== Applications ==\n\n\n*** Coin flipping ***\nSuppose Alice and Bob want to resolve some dispute via coin flipping. If they are physically in the same place, a typical procedure might be:\n\nAlice \"calls\" the coin flip\nBob flips the coin\nIf Alice's call is correct, she wins, otherwise Bob winsIf Alice and Bob are not in the same place a problem arises. Once Alice has \"called\" the coin flip, Bob can stipulate the flip \"results\" to be whatever is most desirable for him. Similarly, if Alice doesn't announce her \"call\" to Bob, after Bob flips the coin and announces the result, Alice can report that she called whatever result is most desirable for her. Alice and Bob can use commitments in a procedure that will allow both to trust the outcome:\n\nAlice \"calls\" the coin flip but only tells Bob a commitment to her call,\nBob flips the coin and reports the result,\nAlice reveals what she committed to,\nBob verifies that Alice's call matches her commitment,\nIf Alice's revelation matches the coin result Bob reported, Alice winsFor Bob to be able to skew the results to his favor, he must be able to understand the call hidden in Alice's commitment. If the commitment scheme is a good one, Bob cannot skew the results.  Similarly, Alice cannot affect the result if she cannot change the value she commits to.\nA real-life application of this problem exists, when people (often in media) commit to a decision or give an answer in a \"sealed envelope\", which is then opened later. \"Let's find out if that's what the candidate answered\", for example on a game show, can serve as a model of this system.\n\n\n*** Zero-knowledge proofs ***\nOne particular motivating example is the use of commitment schemes in zero-knowledge proofs. Commitments are used in zero-knowledge proofs for two main purposes: first, to allow the prover to participate in \"cut and choose\" proofs where the verifier will be presented with a choice of what to learn, and the prover will reveal only what corresponds to the verifier's choice. Commitment schemes allow the prover to specify all the information in advance, and only reveal what should be revealed later in the proof. \nSecond, commitments are also used in zero-knowledge proofs by the verifier, who will often specify their choices ahead of time in a commitment. This allows zero-knowledge proofs to be composed in parallel without revealing additional information to the prover.\n\n\n*** Signature schemes ***\nThe Lamport signature scheme is a digital signature system that relies on maintaining two sets of secret data packets, publishing verifiable hashes of the data packets, and then selectively revealing partial secret data packets in a manner that conforms specifically to the data to be signed. In this way, the prior public commitment to the secret values becomes a critical part of the functioning of the system.\nBecause the Lamport signature system cannot be used more than once, a system to combine many Lamport key-sets under a single public value that can be tied to a person and verified by others was developed. This system uses trees of hashes to compress many published Lamport-key-commitment sets into a single hash value that can be associated with the prospective author of later-verified data.\n\n\n*** Verifiable secret sharing ***\nAnother important application of commitments is in verifiable secret sharing, a critical building block of secure multiparty computation. In a secret sharing scheme, each of several parties receive \"shares\" of a value that is meant to be hidden from everyone. If enough parties get together, their shares can be used to reconstruct the secret, but even a malicious cabal of insufficient size should learn nothing. Secret sharing is at the root of many protocols for secure computation: in order to securely compute a function of some shared input, the secret shares are manipulated instead. However, if shares are to be generated by malicious parties, it may be important that those shares can be checked for correctness. In a verifiable secret sharing scheme, the distribution of a secret is accompanied by commitments to the individual shares. The commitments reveal nothing that can help a dishonest cabal, but the shares allow each individual party to check to see if their shares are correct.\n\n== Defining the security ==\nFormal definitions of commitment schemes vary strongly in notation and in flavour. The first such flavour is whether the commitment scheme provides perfect or computational security with respect to the hiding or binding properties.  Another such flavour is whether the commitment is interactive, i.e. whether both the commit phase and the reveal phase can be seen as being executed by a cryptographic protocol or whether they are non-interactive, consisting of two algorithms Commit and CheckReveal. In the latter case CheckReveal can often be seen as a derandomised version of Commit, with the randomness used by Commit constituting the opening information.\nIf the commitment C to a value x is computed as C:\n\n== Construction ==\nA commitment scheme can either be perfectly binding (it is impossible for Alice to alter her commitment after she has made it, even if she has unbounded computational resources); or perfectly concealing (it is impossible for Bob to find out the commitment without Alice revealing it, even if he has unbounded computational resources); or formulated as an instance-dependent commitment scheme, which is either hiding or binding depending on the solution to another problem. A commitment scheme can not be both perfectly hiding and perfectly binding at the same time.\n\n\n*** Bit-commitment in the random oracle model ***\nBit-commitment schemes are trivial to construct in the random oracle model. Given a hash function H with a 3k bit output, to commit the k-bit message m, Alice generates a random k bit string R and sends Bob H(R||m). The probability that any R\u2032, m\u2032 exist where m\u2032 \u2260 m such that H(R\u2032||m\u2032)\n\n== Partial reveal ==\nSome commitment schemes permit a proof to be given of only a portion of the committed value. In these schemes, the secret value \n  \n    \n      \n        X\n      \n    \n    {\\displaystyle X}\n   is a vector of many individually separable values.\n\n  \n    \n      \n        X\n\n== Quantum bit commitment ==\nIt is an interesting question in quantum cryptography if unconditionally secure bit commitment protocols exist on the quantum level, that is, protocols which are (at least asymptotically) binding and concealing even if there are no restrictions on the computational resources. One could hope that there might be a way to exploit the intrinsic properties of quantum mechanics, as in the protocols for unconditionally secure key distribution.\nHowever, this is impossible, as Dominic Mayers showed in 1996 (see for the original proof). Any such protocol can be reduced to a protocol where the system is in one of two pure states after the commitment phase, depending on the bit Alice wants to commit. If the protocol is unconditionally concealing, then Alice can unitarily transform these states into each other using the properties of the Schmidt decomposition, effectively defeating the binding property.\nOne subtle assumption of the proof is that the commit phase must be finished at some point in time. This leaves room for protocols that require a continuing information flow until the bit is unveiled or the protocol is cancelled, in which case it is not binding anymore. More generally,  Mayers' proof applies only to protocols that exploit quantum physics but not special relativity. Kent has shown that there exist unconditionally secure protocols for bit commitment that exploit the principle of special relativity stating that information cannot travel faster than light.\n\n== Commitments based on physical unclonable functions ==\nPhysical unclonable functions (PUFs) rely on the use of a physical key with internal randomness, which is hard to clone or to emulate. Electronic, optical and other types of PUFs have been discussed extensively in the literature, in connection with their potential cryptographic applications including commitment schemes."
    }
  },
  {
    "instruction": "context: The Oakley protocol has been implemented in Cisco Systems' ISAKMP (Internet Security Association and Key Management Protocol) daemon, which is used to establish and manage security associations between network devices. This allows for the secure exchange of keying material and the establishment of encrypted connections between devices.\n\nAsk a question about this context.",
    "context": "",
    "output": "In what context has the Oakley protocol been implemented?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In what context has the Oakley protocol been implemented?",
      "answer": "The Oakley protocol has been implemented in Cisco Systems' ISAKMP (Internet Security Association and Key Management Protocol) daemon, which is used to establish and manage security associations between network devices. This allows for the secure exchange of keying material and the establishment of encrypted connections between devices."
    }
  },
  {
    "instruction": "context: Yes, the Common Criteria is supported by a Mutual Recognition Agreement (MRA), which means that products tested in one country will normally be accepted in other markets, at least at the lower EAL numbers.\n\nAsk a question about this context.",
    "context": "",
    "output": "Does the Common Criteria have a Mutual Recognition Agreement (MRA)?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Does the Common Criteria have a Mutual Recognition Agreement (MRA)?",
      "answer": "Yes, the Common Criteria is supported by a Mutual Recognition Agreement (MRA), which means that products tested in one country will normally be accepted in other markets, at least at the lower EAL numbers."
    }
  },
  {
    "instruction": "context: Paul Le Roux, the original author of Encryption for the Masses (E4M), began working on commercial encryption software in 2000.\n\nAsk a question about this context.",
    "context": "",
    "output": "Who began working on commercial encryption software in 2000?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who began working on commercial encryption software in 2000?",
      "answer": "Paul Le Roux, the original author of Encryption for the Masses (E4M), began working on commercial encryption software in 2000."
    }
  },
  {
    "instruction": "context: The need to know affects user access in mandatory access control (MAC) systems by determining which data a user can access. Users in system high, compartmented security, and multilevel security modes can only access data that is within their need to know.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the need to know affect user access in mandatory access control systems?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the need to know affect user access in mandatory access control systems?",
      "answer": "The need to know affects user access in mandatory access control (MAC) systems by determining which data a user can access. Users in system high, compartmented security, and multilevel security modes can only access data that is within their need to know."
    }
  },
  {
    "instruction": "Protocol for Carrying Authentication for Network Access\n\n==Introduction==\nPANA (Protocol for Carrying Authentication for Network Access) is an IP-based protocol that allows a device to authenticate itself with a network to be granted access. PANA will not define any new authentication protocol, key distribution, key agreement or key derivation protocols. For these purposes, the Extensible Authentication Protocol (EAP) will be used, and PANA will carry the EAP payload. PANA allows dynamic service provider selection, supports various authentication methods, is suitable for roaming users, and is independent from the link layer mechanisms.\nPANA is an Internet Engineering Task Force (IETF) protocol and described in RFC 5191.\n\n== Architecture's elements ==\nPaC (PANA Client)\nThe PaC is the client part of the protocol. This element is located in the node that wants to reach the access network.\nPAA (PANA Authentication Agent)\nThis entity represents the server part of the PANA protocol. Its main task is the message exchange with the PaC for authenticating and authorizing it for network access. In addition, in some scenarios, the PAA entity has to do other message exchange with the AAA server in order to offer the PaC credentials to it. In this case, EAP is configured as pass-through and the AAA server is placed physically in a different place than the PAA.\nAS (Authentication Server)\nThis element contains the information needed to check the PaC's credentials. To this end this node receives the PaC's credentials from the PAA, performs a credential check, and sends a packet with the result of the credential check. If the credential check was successful, that packet contains access parameters, such as allowed bandwidth or IP configuration. At this point, a session between PAA and PaC has been established. This session has a session lifetime. When the session expires, a re-authentication process is required for the PaC to regain network access.\nEP (Enforcement Point) It works as a filter of the packets which source is an authenticated PaC. Basically, an EP is a network node which drops packets according to some parameters provided as results of the authentication processes. Typically, this function is applied by a communication device as an access point or a router. When an authentication process is done successfully, a key is installed in EP and PaC, establishing a session between EP and PaC. While this session is active (hasn't expired), the PaC can access network services for which it has been authorised. When the session expires, the PaC will have to indicate this situation to the PAA in order to perform re-authentication.\n\nBased on the above text, answer a question. How is the AAA server involved in PANA's message exchange?",
    "context": "",
    "output": "In some scenarios, the PAA entity communicates with the AAA server to offer the PaC credentials. This happens when EAP is configured as pass-through and the AAA server is placed in a different physical location than the PAA.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the AAA server involved in PANA's message exchange?",
      "answer": "In some scenarios, the PAA entity communicates with the AAA server to offer the PaC credentials. This happens when EAP is configured as pass-through and the AAA server is placed in a different physical location than the PAA.",
      "context": "Protocol for Carrying Authentication for Network Access\n\n==Introduction==\nPANA (Protocol for Carrying Authentication for Network Access) is an IP-based protocol that allows a device to authenticate itself with a network to be granted access. PANA will not define any new authentication protocol, key distribution, key agreement or key derivation protocols. For these purposes, the Extensible Authentication Protocol (EAP) will be used, and PANA will carry the EAP payload. PANA allows dynamic service provider selection, supports various authentication methods, is suitable for roaming users, and is independent from the link layer mechanisms.\nPANA is an Internet Engineering Task Force (IETF) protocol and described in RFC 5191.\n\n== Architecture's elements ==\nPaC (PANA Client)\nThe PaC is the client part of the protocol. This element is located in the node that wants to reach the access network.\nPAA (PANA Authentication Agent)\nThis entity represents the server part of the PANA protocol. Its main task is the message exchange with the PaC for authenticating and authorizing it for network access. In addition, in some scenarios, the PAA entity has to do other message exchange with the AAA server in order to offer the PaC credentials to it. In this case, EAP is configured as pass-through and the AAA server is placed physically in a different place than the PAA.\nAS (Authentication Server)\nThis element contains the information needed to check the PaC's credentials. To this end this node receives the PaC's credentials from the PAA, performs a credential check, and sends a packet with the result of the credential check. If the credential check was successful, that packet contains access parameters, such as allowed bandwidth or IP configuration. At this point, a session between PAA and PaC has been established. This session has a session lifetime. When the session expires, a re-authentication process is required for the PaC to regain network access.\nEP (Enforcement Point) It works as a filter of the packets which source is an authenticated PaC. Basically, an EP is a network node which drops packets according to some parameters provided as results of the authentication processes. Typically, this function is applied by a communication device as an access point or a router. When an authentication process is done successfully, a key is installed in EP and PaC, establishing a session between EP and PaC. While this session is active (hasn't expired), the PaC can access network services for which it has been authorised. When the session expires, the PaC will have to indicate this situation to the PAA in order to perform re-authentication."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of US-CERT in the handling and response center for EINSTEIN?",
    "context": "",
    "output": "US-CERT data is provided only to those authorized users who \"need to know such data for business and security purposes\" including security analysts, system administrators and certain DHS contractors. Incident data and contact information are never shared outside of US-CERT and contact information is not analyzed.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of US-CERT in the handling and response center for EINSTEIN?",
      "answer": "US-CERT data is provided only to those authorized users who \"need to know such data for business and security purposes\" including security analysts, system administrators and certain DHS contractors. Incident data and contact information are never shared outside of US-CERT and contact information is not analyzed."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why are Android devices not susceptible to the DirtyTooth exploit?",
    "context": "",
    "output": "Android devices are not affected by the DirtyTooth exploit because they typically ask the user to accept profile changes, unlike iOS devices that change automatically.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why are Android devices not susceptible to the DirtyTooth exploit?",
      "answer": "Android devices are not affected by the DirtyTooth exploit because they typically ask the user to accept profile changes, unlike iOS devices that change automatically."
    }
  },
  {
    "instruction": "context: With the growth of complexity in ERP systems, the possibility of errors and segregation of duties conflicts increases, leading to potential security vulnerabilities.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is one way complexity in ERP systems can lead to vulnerabilities?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is one way complexity in ERP systems can lead to vulnerabilities?",
      "answer": "With the growth of complexity in ERP systems, the possibility of errors and segregation of duties conflicts increases, leading to potential security vulnerabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the potential impact of the Misfortune Cookie vulnerability on an exposed network?",
    "context": "",
    "output": "An attacker exploiting the Misfortune Cookie vulnerability could hijack any device connected to an exposed network, monitor the Internet connection, steal credentials, personal or business data, or even attempt to infect the target machines with malware.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the potential impact of the Misfortune Cookie vulnerability on an exposed network?",
      "answer": "An attacker exploiting the Misfortune Cookie vulnerability could hijack any device connected to an exposed network, monitor the Internet connection, steal credentials, personal or business data, or even attempt to infect the target machines with malware."
    }
  },
  {
    "instruction": "context: The Ctrl-Alt-Del sequence in Microsoft Windows acts as a secure attention key to escape any third-party programs and invoke the system login prompt. This helps mitigate login spoofing, as any fake login prompts will not be able to intercept the user's password when the Ctrl-Alt-Del sequence is used.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the Ctrl-Alt-Del sequence help mitigate login spoofing in Microsoft Windows?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Ctrl-Alt-Del sequence help mitigate login spoofing in Microsoft Windows?",
      "answer": "The Ctrl-Alt-Del sequence in Microsoft Windows acts as a secure attention key to escape any third-party programs and invoke the system login prompt. This helps mitigate login spoofing, as any fake login prompts will not be able to intercept the user's password when the Ctrl-Alt-Del sequence is used."
    }
  },
  {
    "instruction": "context: The uniform ensemble is used in cryptography to generate random keys or other cryptographic primitives. By generating random variables that are uniformly distributed over strings of a certain length, the uniform ensemble ensures that each possible value of the key is equally likely, making it difficult for an attacker to guess or predict the key. This property is crucial for the security of many cryptographic algorithms.\n\nAsk a question about this context.",
    "context": "",
    "output": "How is the uniform ensemble used in cryptography?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is the uniform ensemble used in cryptography?",
      "answer": "The uniform ensemble is used in cryptography to generate random keys or other cryptographic primitives. By generating random variables that are uniformly distributed over strings of a certain length, the uniform ensemble ensures that each possible value of the key is equally likely, making it difficult for an attacker to guess or predict the key. This property is crucial for the security of many cryptographic algorithms."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is cryptanalysis in the context of SSE schemes?",
    "context": "",
    "output": "Cryptanalysis in the context of SSE schemes is the process of understanding whether the leakage described by a leakage profile can be exploited or not, by analyzing the real-world security of the leakage profile using various attacks, assumptions, and adversarial models.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is cryptanalysis in the context of SSE schemes?",
      "answer": "Cryptanalysis in the context of SSE schemes is the process of understanding whether the leakage described by a leakage profile can be exploited or not, by analyzing the real-world security of the leakage profile using various attacks, assumptions, and adversarial models."
    }
  },
  {
    "instruction": "context: The use of password managers can significantly enhance the security of online accounts, as users can generate and use strong, unique passwords for each of their accounts. To further enhance this security, users can enable multi-factor authentication on their password manager account, as well as on any online accounts that offer this feature.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the use of password managers impact the security of online accounts, and what measures can be taken to further enhance this security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the use of password managers impact the security of online accounts, and what measures can be taken to further enhance this security?",
      "answer": "The use of password managers can significantly enhance the security of online accounts, as users can generate and use strong, unique passwords for each of their accounts. To further enhance this security, users can enable multi-factor authentication on their password manager account, as well as on any online accounts that offer this feature."
    }
  },
  {
    "instruction": "Answer based on context:\n\nSoftware Engineering Institute\n\n==Introduction==\nSoftware Engineering Institute (SEI) is a federally funded research and development center in Pittsburgh, Pennsylvania, United States. Founded in 1984, the institute is now sponsored by the United States Department of Defense and the Office of the Under Secretary of Defense for Research and Engineering, and administrated by Carnegie Mellon University. The activities of the institute cover cybersecurity, software assurance, software engineering and acquisition, and component capabilities critical to the United States Department of Defense.\n\n== Authority ==\nThe Carnegie Mellon Software Engineering Institute is a federally funded research and development center headquartered on the campus of Carnegie Mellon University in Pittsburgh, Pennsylvania,  United States. The SEI also has offices in  Washington, DC; Arlington County, Virginia; and Los Angeles, California. The SEI operates with major funding from the U.S. Department of Defense. The SEI also works with industry and academia through research collaborations.On November 14, 1984, the U.S. Department of Defense elected Carnegie Mellon University as the host site of the Software Engineering Institute. The institute was founded with an initial allocation of $6 million, with another $97 million to be allocated in the subsequent five years. The SEI's contract with the Department of Defense is subject to review and renewal every five years.\nThe SEI program of work is conducted in several principal areas: cybersecurity, software assurance, software engineering and acquisition, DevOps, and component capabilities critical to the Department of Defense.\n\n== Areas of work ==\nThe SEI defines specific initiatives aimed at improving organizations' software engineering capabilities.\n\n\n*** Management practices ***\nOrganizations need to effectively manage the acquisition, development, and evolution (ADE) of software-intensive systems. Success in software engineering management practices helps organizations predict and control quality, schedule, cost, cycle time, and productivity. The best-known example of SEI  in management practices is the SEI's Capability Maturity Model (CMM) for Software (now Capability Maturity Model Integration (CMMI)). The CMMI approach consists of models, appraisal methods, and training courses that have been proven to improve process performance. In 2006, Version 1.2 of the CMMI Product Suite included the release of CMMI for Development. CMMI for Development was the first of three constellations defined in Version 1.2: the others include CMMI for Acquisition and CMMI for Services. The CMMI for Services constellation was released in February 2009. Another management practice developed by CERT, which is part of the SEI, is the Resilience Management Model (CERT-RMM). The CERT-RMM is a capability model for operational resilience management. Version 1.0 of the Resilience Management Model was released in May 2010.\n\n\n*** Engineering practices ***\nSEI work in engineering practices increases the ability of software engineers to analyze, predict, and control selected\nfunctional and non-functional properties of software systems. Key SEI tools and methods include the SEI Architecture Tradeoff Analysis Method (ATAM) method, the SEI Framework for Software Product Line Practice, and the SEI Service Migration and Reuse Technique (SMART).\n\n\n*** Security ***\nThe SEI is also the home of the CERT/CC (CERT Coordination Center), a federally funded computer security organization. The SEI CERT Program's primary goals are to ensure that appropriate technology and systems-management practices are used to resist attacks on networked systems and to limit damage and ensure continuity of critical services in spite of successful attacks, accidents, or failures. The SEI CERT program is working with US-CERT to produce the Build Security In (BSI) website, which provides guidelines for building security into every phase of the software development lifecycle. The SEI has also conducted research on insider threats and computer forensics. Results of this research and other information now populate the CERT Virtual Training Environment.\n\n== Special programs ==\n\n\n*** SEI Partner Network ***\nThe SEI Partner Network helps the SEI disseminate software engineering best practices. Organizations and individuals in the SEI Partner Network are selected, trained, and licensed by the SEI to deliver authentic SEI services, which include courses, consulting methods, and management processes.  The network currently consists of nearly 250 partner organizations worldwide.\n\n\n*** Conferences ***\nThe SEI sponsors national and international conferences, workshops, and user-group meetings. Other events cover subjects including acquisition of software-intensive systems, commercial off-the-shelf (COTS)-based systems, network security and survivability, software process research, software product lines, CMMI, and the SEI Team Software Process.\n\n\n*** Education and training ***\n\nSEI courses are currently offered at the SEI's locations in the United States and Europe. In addition, using licensed course materials, SEI Partners train individuals.\n\n\n*** Membership program ***\nThe SEI Membership Program helps the software engineering community to network. SEI Members include small business owners, software and systems programmers, CEOs, directors, and managers from both Fortune 500 companies and government organizations\n\n\n*** Affiliate program ***\nThrough the SEI Affiliate Program, organizations place technical experts with the SEI for periods ranging from 12 months to four years. Affiliates currently are working on projects with the SEI to identify, develop, and demonstrate improved software engineering practices.\n\n\n*** Software Process Achievement award program ***\nIn order to recognize outstanding achievement in improving an organization's ability to create and evolve software-dependent systems, the SEI and IEEE Computer Society created the Software Process Achievement Award program. In addition to rewarding excellence, the purpose of this award is to foster continuous advancement in the practice of software engineering and to disseminate insights, experiences, and proven practices throughout the relevant research and practitioner communities.\n\n== Research and publications ==\nThe SEI publishes reports that offer new technical information about software engineering topics, whether theoretical or applied. The SEI also publishes books on software engineering for industry, government and military applications and practices.\nIn addition, the SEI offers public courses, workshops, and conferences in process improvement, software architecture and product lines, and security.\n\n== Controversies ==\n\nOn November 11, 2015, the head of the Tor Project accused the Software Engineering Institute of aiding Federal Bureau of Investigation in uncovering the identities of users of the Tor network.  Later prosecution showed the hack was paid for by the Department of Defense and subpoena by the FBI.\n\n== Focus of progressive protests ==\nSEI has been an occasional site of anti-war movement and peace movement protests, many of which have been organized by Pittsburgh's Thomas Merton Center.\n\n== References in popular culture ==\n\nSEI served as the Blackgate Prison in the 2012 film The Dark Knight Rises.\n\nHow does the SEI enhance the ability of software engineers to analyze, predict, and control software system properties?",
    "context": "",
    "output": "The SEI works on enhancing the ability of software engineers to analyze, predict, and control selected functional and non-functional properties of software systems through its engineering practices. Key SEI tools and methods include the Architecture Tradeoff Analysis Method (ATAM), the Framework for Software Product Line Practice, and the Service Migration and Reuse Technique (SMART). These tools enable software engineers to make more informed decisions and create better-performing software systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the SEI enhance the ability of software engineers to analyze, predict, and control software system properties?",
      "answer": "The SEI works on enhancing the ability of software engineers to analyze, predict, and control selected functional and non-functional properties of software systems through its engineering practices. Key SEI tools and methods include the Architecture Tradeoff Analysis Method (ATAM), the Framework for Software Product Line Practice, and the Service Migration and Reuse Technique (SMART). These tools enable software engineers to make more informed decisions and create better-performing software systems.",
      "context": "Software Engineering Institute\n\n==Introduction==\nSoftware Engineering Institute (SEI) is a federally funded research and development center in Pittsburgh, Pennsylvania, United States. Founded in 1984, the institute is now sponsored by the United States Department of Defense and the Office of the Under Secretary of Defense for Research and Engineering, and administrated by Carnegie Mellon University. The activities of the institute cover cybersecurity, software assurance, software engineering and acquisition, and component capabilities critical to the United States Department of Defense.\n\n== Authority ==\nThe Carnegie Mellon Software Engineering Institute is a federally funded research and development center headquartered on the campus of Carnegie Mellon University in Pittsburgh, Pennsylvania,  United States. The SEI also has offices in  Washington, DC; Arlington County, Virginia; and Los Angeles, California. The SEI operates with major funding from the U.S. Department of Defense. The SEI also works with industry and academia through research collaborations.On November 14, 1984, the U.S. Department of Defense elected Carnegie Mellon University as the host site of the Software Engineering Institute. The institute was founded with an initial allocation of $6 million, with another $97 million to be allocated in the subsequent five years. The SEI's contract with the Department of Defense is subject to review and renewal every five years.\nThe SEI program of work is conducted in several principal areas: cybersecurity, software assurance, software engineering and acquisition, DevOps, and component capabilities critical to the Department of Defense.\n\n== Areas of work ==\nThe SEI defines specific initiatives aimed at improving organizations' software engineering capabilities.\n\n\n*** Management practices ***\nOrganizations need to effectively manage the acquisition, development, and evolution (ADE) of software-intensive systems. Success in software engineering management practices helps organizations predict and control quality, schedule, cost, cycle time, and productivity. The best-known example of SEI  in management practices is the SEI's Capability Maturity Model (CMM) for Software (now Capability Maturity Model Integration (CMMI)). The CMMI approach consists of models, appraisal methods, and training courses that have been proven to improve process performance. In 2006, Version 1.2 of the CMMI Product Suite included the release of CMMI for Development. CMMI for Development was the first of three constellations defined in Version 1.2: the others include CMMI for Acquisition and CMMI for Services. The CMMI for Services constellation was released in February 2009. Another management practice developed by CERT, which is part of the SEI, is the Resilience Management Model (CERT-RMM). The CERT-RMM is a capability model for operational resilience management. Version 1.0 of the Resilience Management Model was released in May 2010.\n\n\n*** Engineering practices ***\nSEI work in engineering practices increases the ability of software engineers to analyze, predict, and control selected\nfunctional and non-functional properties of software systems. Key SEI tools and methods include the SEI Architecture Tradeoff Analysis Method (ATAM) method, the SEI Framework for Software Product Line Practice, and the SEI Service Migration and Reuse Technique (SMART).\n\n\n*** Security ***\nThe SEI is also the home of the CERT/CC (CERT Coordination Center), a federally funded computer security organization. The SEI CERT Program's primary goals are to ensure that appropriate technology and systems-management practices are used to resist attacks on networked systems and to limit damage and ensure continuity of critical services in spite of successful attacks, accidents, or failures. The SEI CERT program is working with US-CERT to produce the Build Security In (BSI) website, which provides guidelines for building security into every phase of the software development lifecycle. The SEI has also conducted research on insider threats and computer forensics. Results of this research and other information now populate the CERT Virtual Training Environment.\n\n== Special programs ==\n\n\n*** SEI Partner Network ***\nThe SEI Partner Network helps the SEI disseminate software engineering best practices. Organizations and individuals in the SEI Partner Network are selected, trained, and licensed by the SEI to deliver authentic SEI services, which include courses, consulting methods, and management processes.  The network currently consists of nearly 250 partner organizations worldwide.\n\n\n*** Conferences ***\nThe SEI sponsors national and international conferences, workshops, and user-group meetings. Other events cover subjects including acquisition of software-intensive systems, commercial off-the-shelf (COTS)-based systems, network security and survivability, software process research, software product lines, CMMI, and the SEI Team Software Process.\n\n\n*** Education and training ***\n\nSEI courses are currently offered at the SEI's locations in the United States and Europe. In addition, using licensed course materials, SEI Partners train individuals.\n\n\n*** Membership program ***\nThe SEI Membership Program helps the software engineering community to network. SEI Members include small business owners, software and systems programmers, CEOs, directors, and managers from both Fortune 500 companies and government organizations\n\n\n*** Affiliate program ***\nThrough the SEI Affiliate Program, organizations place technical experts with the SEI for periods ranging from 12 months to four years. Affiliates currently are working on projects with the SEI to identify, develop, and demonstrate improved software engineering practices.\n\n\n*** Software Process Achievement award program ***\nIn order to recognize outstanding achievement in improving an organization's ability to create and evolve software-dependent systems, the SEI and IEEE Computer Society created the Software Process Achievement Award program. In addition to rewarding excellence, the purpose of this award is to foster continuous advancement in the practice of software engineering and to disseminate insights, experiences, and proven practices throughout the relevant research and practitioner communities.\n\n== Research and publications ==\nThe SEI publishes reports that offer new technical information about software engineering topics, whether theoretical or applied. The SEI also publishes books on software engineering for industry, government and military applications and practices.\nIn addition, the SEI offers public courses, workshops, and conferences in process improvement, software architecture and product lines, and security.\n\n== Controversies ==\n\nOn November 11, 2015, the head of the Tor Project accused the Software Engineering Institute of aiding Federal Bureau of Investigation in uncovering the identities of users of the Tor network.  Later prosecution showed the hack was paid for by the Department of Defense and subpoena by the FBI.\n\n== Focus of progressive protests ==\nSEI has been an occasional site of anti-war movement and peace movement protests, many of which have been organized by Pittsburgh's Thomas Merton Center.\n\n== References in popular culture ==\n\nSEI served as the Blackgate Prison in the 2012 film The Dark Knight Rises."
    }
  },
  {
    "instruction": "context: Users may choose to use fake answers to security questions due to concerns about the security and privacy of their personal information, as they fear it could be easily discovered by hackers through social media platforms.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the primary reason why users may choose to use fake answers to security questions?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the primary reason why users may choose to use fake answers to security questions?",
      "answer": "Users may choose to use fake answers to security questions due to concerns about the security and privacy of their personal information, as they fear it could be easily discovered by hackers through social media platforms."
    }
  },
  {
    "instruction": "context: Yes, data exhaust can be used for malicious purposes such as identity theft, cyberstalking, and other forms of online harassment. It can also be used to manipulate or influence users in various ways.\n\nAsk a question about this context.",
    "context": "",
    "output": "Can data exhaust be used for malicious purposes?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can data exhaust be used for malicious purposes?",
      "answer": "Yes, data exhaust can be used for malicious purposes such as identity theft, cyberstalking, and other forms of online harassment. It can also be used to manipulate or influence users in various ways."
    }
  },
  {
    "instruction": "Answer based on context:\n\nDamn Vulnerable Web Application\n\n==Introduction==\nThe Damn Vulnerable Web Application is a software project that intentionally includes security vulnerabilities and is intended for educational purposes.\n\n\n\n== Examples ==\nCross site scripting\nSQL injection\n\nCan the Damn Vulnerable Web Application be used to train individuals in web application security?",
    "context": "",
    "output": "Yes, the Damn Vulnerable Web Application can be used as a training tool for individuals to learn about web application security and its potential vulnerabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can the Damn Vulnerable Web Application be used to train individuals in web application security?",
      "answer": "Yes, the Damn Vulnerable Web Application can be used as a training tool for individuals to learn about web application security and its potential vulnerabilities.",
      "context": "Damn Vulnerable Web Application\n\n==Introduction==\nThe Damn Vulnerable Web Application is a software project that intentionally includes security vulnerabilities and is intended for educational purposes.\n\n\n\n== Examples ==\nCross site scripting\nSQL injection"
    }
  },
  {
    "instruction": "Write an answer to the following question: How can speculative execution vulnerabilities be mitigated?",
    "context": "",
    "output": "Speculative execution vulnerabilities can be mitigated through various measures, such as disabling certain features, applying security patches, and implementing additional security measures.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can speculative execution vulnerabilities be mitigated?",
      "answer": "Speculative execution vulnerabilities can be mitigated through various measures, such as disabling certain features, applying security patches, and implementing additional security measures."
    }
  },
  {
    "instruction": "Write an answer to the following question: How many versions of Silver Sparrow have been detected?",
    "context": "",
    "output": "Two versions of Silver Sparrow have been detected, one compiled for Intel x86-64 and the other containing code that runs natively on Apple's M1 processor.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many versions of Silver Sparrow have been detected?",
      "answer": "Two versions of Silver Sparrow have been detected, one compiled for Intel x86-64 and the other containing code that runs natively on Apple's M1 processor."
    }
  },
  {
    "instruction": "context: Some common defects of software artifacts that can be identified using testing or fuzzing include memory leaks, buffer overflows, and other programming errors that can lead to security vulnerabilities.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are some common defects of software artifacts that can be identified using testing or fuzzing?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some common defects of software artifacts that can be identified using testing or fuzzing?",
      "answer": "Some common defects of software artifacts that can be identified using testing or fuzzing include memory leaks, buffer overflows, and other programming errors that can lead to security vulnerabilities."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do signature-based systems attempt to detect patterns in request packets?",
    "context": "",
    "output": "Signature-based systems attempt to detect patterns in the request packet by analyzing the characteristics of the request and comparing it to known patterns of malicious activity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do signature-based systems attempt to detect patterns in request packets?",
      "answer": "Signature-based systems attempt to detect patterns in the request packet by analyzing the characteristics of the request and comparing it to known patterns of malicious activity."
    }
  },
  {
    "instruction": "context: A hypervisor rootkit runs in Ring -1 and hosts the target operating system as a virtual machine, enabling the rootkit to intercept hardware calls made by the original operating system. This type of rootkit does not have to make any modifications to the kernel of the target to subvert it.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does a hypervisor rootkit work?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a hypervisor rootkit work?",
      "answer": "A hypervisor rootkit runs in Ring -1 and hosts the target operating system as a virtual machine, enabling the rootkit to intercept hardware calls made by the original operating system. This type of rootkit does not have to make any modifications to the kernel of the target to subvert it."
    }
  },
  {
    "instruction": "context: Chosen-ciphertext attacks can be adaptive or non-adaptive. In an adaptive chosen-ciphertext attack, the attacker can use the results from prior decryptions to inform their choices of which ciphertexts to have decrypted. In a non-adaptive attack, the attacker chooses the ciphertexts to have decrypted without seeing any of the resulting plaintexts.\n\nAsk a question about this context.",
    "context": "",
    "output": "How are chosen-ciphertext attacks classified?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are chosen-ciphertext attacks classified?",
      "answer": "Chosen-ciphertext attacks can be adaptive or non-adaptive. In an adaptive chosen-ciphertext attack, the attacker can use the results from prior decryptions to inform their choices of which ciphertexts to have decrypted. In a non-adaptive attack, the attacker chooses the ciphertexts to have decrypted without seeing any of the resulting plaintexts."
    }
  },
  {
    "instruction": "Write an answer to the following question: What programming language is Fail2ban written in and what type of attacks does it prevent?",
    "context": "",
    "output": "Fail2ban is written in the Python programming language and it is designed to prevent against brute-force attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What programming language is Fail2ban written in and what type of attacks does it prevent?",
      "answer": "Fail2ban is written in the Python programming language and it is designed to prevent against brute-force attacks."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can online predators exploit users' vulnerabilities, and what measures can be taken to protect oneself from them?",
    "context": "",
    "output": "Online predators exploit users' vulnerabilities, often for sexual or financial purposes, by grooming them and gaining their trust through compliments and positive statements. To protect oneself, it is essential to verify a person's identity using means beyond style and photographs, as these can be easily forged. Long-term Internet relationships may also be challenging to understand in terms of someone's true identity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can online predators exploit users' vulnerabilities, and what measures can be taken to protect oneself from them?",
      "answer": "Online predators exploit users' vulnerabilities, often for sexual or financial purposes, by grooming them and gaining their trust through compliments and positive statements. To protect oneself, it is essential to verify a person's identity using means beyond style and photographs, as these can be easily forged. Long-term Internet relationships may also be challenging to understand in terms of someone's true identity."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the main goal of World Backup Day?",
    "context": "",
    "output": "The main goal of World Backup Day is to raise awareness about the importance of data backup, promote the adoption of backup solutions, emphasize the importance of testing backups, and foster a culture of data protection.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the main goal of World Backup Day?",
      "answer": "The main goal of World Backup Day is to raise awareness about the importance of data backup, promote the adoption of backup solutions, emphasize the importance of testing backups, and foster a culture of data protection."
    }
  },
  {
    "instruction": "context: FIPS 140 is a standard issued by the National Institute of Standards and Technology (NIST) to coordinate the requirements and standards for cryptographic modules used by departments and agencies of the United States federal government. The standard is not meant to guarantee the security of a module or system, but it outlines specific requirements for the modules, their documentation, and source code. The use of FIPS 140 validated cryptographic modules is required by the United States Government for all unclassified uses of cryptography, and the Government of Canada also recommends their use in unclassified applications.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the purpose of FIPS 140 and what federal agencies require its use?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of FIPS 140 and what federal agencies require its use?",
      "answer": "FIPS 140 is a standard issued by the National Institute of Standards and Technology (NIST) to coordinate the requirements and standards for cryptographic modules used by departments and agencies of the United States federal government. The standard is not meant to guarantee the security of a module or system, but it outlines specific requirements for the modules, their documentation, and source code. The use of FIPS 140 validated cryptographic modules is required by the United States Government for all unclassified uses of cryptography, and the Government of Canada also recommends their use in unclassified applications."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the complexity of the DC-net protocol in terms of shared secret keys?",
    "context": "",
    "output": "The complexity of the DC-net protocol is that it requires pairwise shared secret keys between the participants. This may be problematic if there are many participants, as it would require a large number of shared secrets.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the complexity of the DC-net protocol in terms of shared secret keys?",
      "answer": "The complexity of the DC-net protocol is that it requires pairwise shared secret keys between the participants. This may be problematic if there are many participants, as it would require a large number of shared secrets."
    }
  },
  {
    "instruction": "Context: Utimaco Atalla\n\n==Introduction==\nUtimaco Atalla, founded as Atalla Technovation and formerly known as Atalla Corporation or HP Atalla, is a security vendor, active in the market segments of data security and cryptography. Atalla provides government-grade end-to-end products in network security, and hardware security modules (HSMs) used in automated teller machines (ATMs) and Internet security. The company was founded by Egyptian engineer Mohamed M. Atalla in 1972. Atalla HSMs are the payment card industry's de facto standard, protecting 250 million card transactions daily (more than 90 billion transactions annually) as of 2013, and securing the majority of the world's ATM transactions as of 2014.\n\n\n\n== Company history ==\n\n\n*** 1970s ***\nThe company was originally founded in 1972, initially as Atalla Technovation, before it was later called Atalla Corporation. The company was founded by Dr. Mohamed M. Atalla, the inventor of the MOSFET (metal\u2013oxide\u2013semiconductor field-effect transistor). In 1972, Atalla filed U.S. Patent 3,938,091 for a remote PIN verification system, which utilized encryption techniques to assure telephone link security while entering personal ID information, which would be transmitted as encrypted data over telecommunications networks to a remote location for verification.He invented the first hardware security module (HSM), dubbed the \"Atalla Box\", a security system which encrypted PIN and ATM messages, and protected offline devices with an un-guessable PIN-generating key. He commercially released the \"Atalla Box\" in 1973. The product was released as the Identikey. It was a card reader and customer identification system, providing a terminal with plastic card and PIN capabilities. The system was designed to let banks and thrift institutions switch to a plastic card environment from a passbook program. The Identikey system consisted of a card reader console, two customer PIN pads, intelligent controller and built-in electronic interface package. The device consisted of two keypads, one for the customer and one for the teller. It allowed the customer to type in a secret code, which is transformed by the device, using a microprocessor, into another code for the teller. The Identikey system connected directly into the ATM without hardware or software changes, and was designed for easy operation by the teller and customer. During a transaction, the customer's account number was read by the card reader. This process replaced manual entry and avoided possible key stroke errors. It allowed users to replace traditional customer verification methods such as signature verification and test questions with a secure PIN system.A key innovation of the Atalla Box was the key block, which is required to securely interchange symmetric keys or PINs with other actors of the banking industry. This secure interchange is performed using the Atalla Key Block (AKB) format, which lies at the root of all cryptographic block formats used within the Payment Card Industry Data Security Standard (PCI DSS) and American National Standards Institute (ANSI) standards.Fearful that Atalla would dominate the market, banks and credit card companies began working on an international standard. The work of Atalla led to the use of high security modules. Its PIN verification process was similar to the later IBM 3624 system. Atalla was an early competitor to IBM in the banking market, and was cited as an influence by IBM employees who worked on the Data Encryption Standard (DES).At the National Association of Mutual Savings Banks (NAMSB) conference in January 1976, Atalla announced an upgrade to its Identikey system, called the Interchange Identikey. It added the capabilities of processing online transactions and dealing with network security. Designed with the focus of taking bank transactions online, the Identikey system was extended to shared-facility operations. It was consistent and compatible with various switching networks, and was capable of resetting itself electronically to any one of 64,000 irreversible nonlinear algorithms as directed by card data information. The Interchange Identikey device was released in March 1976. It was one of the first products designed to deal with online transactions, along with Bunker Ramo Corporation products unveiled at the same NAMSB conference. In 1979, Atalla introduced the first network security processor (NSP). In recognition of his work on the PIN system of information security management, Atalla has been referred to as the \"Father of the PIN\" and as a father of information security technology.\n\n\n*** 1980s\u2013present ***\nIt merged in 1987 with Tandem Computers, who were then acquired by Compaq in 1997. The Atalla Box protected over 90% of all ATM networks in operation as of 1998, and secured 85% of all ATM transactions worldwide as of 2006. In 2001, HP acquired Compaq. In 2015, HP was divided into two companies, and the Atalla products were assigned to the newly formed Hewlett Packard Enterprise (HPE). \nOn September 7, 2016, HPE CEO Meg Whitman announced that the software assets of Hewlett Packard Enterprise, including Atalla, would be spun out and then merged with Micro Focus to create an independent company of which HP Enterprise shareholders would retain majority ownership. Micro Focus CEO Kevin Loosemore called the transaction \"entirely consistent with our established acquisition strategy and our focus on efficient management of mature infrastructure products\" and indicated that Micro Focus intended to \"bring the core earnings margin for the mature assets in the deal - about 80 percent of the total - from 21 percent today to Micro Focus's existing 46 percent level within three years.\" The merger concluded on September 1, 2017.\nOn 18 May 2018, Utimaco, a German producer of hardware security modules, announced its intent to acquire the Atalla HSM and ESKM (Enterprise Secure Key Manager) business lines from Micro Focus. The venture received United States regulatory clearance in October 2018.In February 2020, Ultimaco acquired GEOBRIDGE Corporation. GEOBRIDGE Corporation is a woman-owned technology company providing compliance services integration systems, development of key management programs, consultancy in the payments industry and architecture and implementation of cryptographic solutions. This acquisition will expand Utimaco 's key financial sector management portfolio.\n\n== Product overview ==\nAtalla is a multi-chip embedded cryptographic module, which consists of a hardware platform, a firmware secure loader, and firmware. The purpose of the module is to load Approved application programs, also referred to as personalities, securely. The firmware monitors the physical security of the cryptographic module. Verification that the module is approved can be observed.The Atalla security policy addresses the hardware and the firmware secure loader. This approach creates a security platform able to load secure code. Once control passes from the loader, the module is no longer operating in FIPS mode. Note: that no personality will have access to the module's secret keys. The cryptographic boundary of the ACS for the FIPS 140-2 Level 3  validation is the outer perimeter of the secure metal enclosure that encompasses all critical security components.\n\nQuestion: How did the introduction of the network security processor (NSP) by Atalla in 1979 impact the banking and financial industries?\n\nAnswer:",
    "context": "",
    "output": "The introduction of the network security processor (NSP) by Atalla in 1979 significantly improved the security of banking and financial networks, protecting transactions and sensitive data from unauthorized access or tampering. This innovation further solidified Atalla's position as a leader in information security technology.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the introduction of the network security processor (NSP) by Atalla in 1979 impact the banking and financial industries?",
      "answer": "The introduction of the network security processor (NSP) by Atalla in 1979 significantly improved the security of banking and financial networks, protecting transactions and sensitive data from unauthorized access or tampering. This innovation further solidified Atalla's position as a leader in information security technology.",
      "context": "Utimaco Atalla\n\n==Introduction==\nUtimaco Atalla, founded as Atalla Technovation and formerly known as Atalla Corporation or HP Atalla, is a security vendor, active in the market segments of data security and cryptography. Atalla provides government-grade end-to-end products in network security, and hardware security modules (HSMs) used in automated teller machines (ATMs) and Internet security. The company was founded by Egyptian engineer Mohamed M. Atalla in 1972. Atalla HSMs are the payment card industry's de facto standard, protecting 250 million card transactions daily (more than 90 billion transactions annually) as of 2013, and securing the majority of the world's ATM transactions as of 2014.\n\n\n\n== Company history ==\n\n\n*** 1970s ***\nThe company was originally founded in 1972, initially as Atalla Technovation, before it was later called Atalla Corporation. The company was founded by Dr. Mohamed M. Atalla, the inventor of the MOSFET (metal\u2013oxide\u2013semiconductor field-effect transistor). In 1972, Atalla filed U.S. Patent 3,938,091 for a remote PIN verification system, which utilized encryption techniques to assure telephone link security while entering personal ID information, which would be transmitted as encrypted data over telecommunications networks to a remote location for verification.He invented the first hardware security module (HSM), dubbed the \"Atalla Box\", a security system which encrypted PIN and ATM messages, and protected offline devices with an un-guessable PIN-generating key. He commercially released the \"Atalla Box\" in 1973. The product was released as the Identikey. It was a card reader and customer identification system, providing a terminal with plastic card and PIN capabilities. The system was designed to let banks and thrift institutions switch to a plastic card environment from a passbook program. The Identikey system consisted of a card reader console, two customer PIN pads, intelligent controller and built-in electronic interface package. The device consisted of two keypads, one for the customer and one for the teller. It allowed the customer to type in a secret code, which is transformed by the device, using a microprocessor, into another code for the teller. The Identikey system connected directly into the ATM without hardware or software changes, and was designed for easy operation by the teller and customer. During a transaction, the customer's account number was read by the card reader. This process replaced manual entry and avoided possible key stroke errors. It allowed users to replace traditional customer verification methods such as signature verification and test questions with a secure PIN system.A key innovation of the Atalla Box was the key block, which is required to securely interchange symmetric keys or PINs with other actors of the banking industry. This secure interchange is performed using the Atalla Key Block (AKB) format, which lies at the root of all cryptographic block formats used within the Payment Card Industry Data Security Standard (PCI DSS) and American National Standards Institute (ANSI) standards.Fearful that Atalla would dominate the market, banks and credit card companies began working on an international standard. The work of Atalla led to the use of high security modules. Its PIN verification process was similar to the later IBM 3624 system. Atalla was an early competitor to IBM in the banking market, and was cited as an influence by IBM employees who worked on the Data Encryption Standard (DES).At the National Association of Mutual Savings Banks (NAMSB) conference in January 1976, Atalla announced an upgrade to its Identikey system, called the Interchange Identikey. It added the capabilities of processing online transactions and dealing with network security. Designed with the focus of taking bank transactions online, the Identikey system was extended to shared-facility operations. It was consistent and compatible with various switching networks, and was capable of resetting itself electronically to any one of 64,000 irreversible nonlinear algorithms as directed by card data information. The Interchange Identikey device was released in March 1976. It was one of the first products designed to deal with online transactions, along with Bunker Ramo Corporation products unveiled at the same NAMSB conference. In 1979, Atalla introduced the first network security processor (NSP). In recognition of his work on the PIN system of information security management, Atalla has been referred to as the \"Father of the PIN\" and as a father of information security technology.\n\n\n*** 1980s\u2013present ***\nIt merged in 1987 with Tandem Computers, who were then acquired by Compaq in 1997. The Atalla Box protected over 90% of all ATM networks in operation as of 1998, and secured 85% of all ATM transactions worldwide as of 2006. In 2001, HP acquired Compaq. In 2015, HP was divided into two companies, and the Atalla products were assigned to the newly formed Hewlett Packard Enterprise (HPE). \nOn September 7, 2016, HPE CEO Meg Whitman announced that the software assets of Hewlett Packard Enterprise, including Atalla, would be spun out and then merged with Micro Focus to create an independent company of which HP Enterprise shareholders would retain majority ownership. Micro Focus CEO Kevin Loosemore called the transaction \"entirely consistent with our established acquisition strategy and our focus on efficient management of mature infrastructure products\" and indicated that Micro Focus intended to \"bring the core earnings margin for the mature assets in the deal - about 80 percent of the total - from 21 percent today to Micro Focus's existing 46 percent level within three years.\" The merger concluded on September 1, 2017.\nOn 18 May 2018, Utimaco, a German producer of hardware security modules, announced its intent to acquire the Atalla HSM and ESKM (Enterprise Secure Key Manager) business lines from Micro Focus. The venture received United States regulatory clearance in October 2018.In February 2020, Ultimaco acquired GEOBRIDGE Corporation. GEOBRIDGE Corporation is a woman-owned technology company providing compliance services integration systems, development of key management programs, consultancy in the payments industry and architecture and implementation of cryptographic solutions. This acquisition will expand Utimaco 's key financial sector management portfolio.\n\n== Product overview ==\nAtalla is a multi-chip embedded cryptographic module, which consists of a hardware platform, a firmware secure loader, and firmware. The purpose of the module is to load Approved application programs, also referred to as personalities, securely. The firmware monitors the physical security of the cryptographic module. Verification that the module is approved can be observed.The Atalla security policy addresses the hardware and the firmware secure loader. This approach creates a security platform able to load secure code. Once control passes from the loader, the module is no longer operating in FIPS mode. Note: that no personality will have access to the module's secret keys. The cryptographic boundary of the ACS for the FIPS 140-2 Level 3  validation is the outer perimeter of the secure metal enclosure that encompasses all critical security components."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of a workflow engine in a user provisioning system?",
    "context": "",
    "output": "A workflow engine is used primarily to invite users to review and either approve or reject changes, ensuring that updates to user objects follow a consistent and controlled process.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of a workflow engine in a user provisioning system?",
      "answer": "A workflow engine is used primarily to invite users to review and either approve or reject changes, ensuring that updates to user objects follow a consistent and controlled process."
    }
  },
  {
    "instruction": "context: Tools used for monitoring employee computer usage include screen monitoring software, data monitoring software, keystroke monitoring software, idle time monitoring software, printer monitoring software, and video/audio monitoring software.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are some examples of tools used for monitoring employee computer usage?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some examples of tools used for monitoring employee computer usage?",
      "answer": "Tools used for monitoring employee computer usage include screen monitoring software, data monitoring software, keystroke monitoring software, idle time monitoring software, printer monitoring software, and video/audio monitoring software."
    }
  },
  {
    "instruction": "context: Virtual memory and virtual address space work together to provide memory space isolation in process isolation by creating a virtual address space for each process, which isolates the memory space of one process from another.\n\nAsk a question about this context.",
    "context": "",
    "output": "How do virtual memory and virtual address space work together to provide memory space isolation in process isolation?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do virtual memory and virtual address space work together to provide memory space isolation in process isolation?",
      "answer": "Virtual memory and virtual address space work together to provide memory space isolation in process isolation by creating a virtual address space for each process, which isolates the memory space of one process from another."
    }
  },
  {
    "instruction": "Stratfor email leak\n\n==Introduction==\nEmails by strategic intelligence company Stratfor, referred to by WikiLeaks as the Global Intelligence Files, began appearing on WikiLeaks on February 27, 2012, with 5,543,061 emails published as of July 18, 2014.Stratfor is a security group based in Austin, Texas. On December 24, 2011, hackers took control of Stratfor's website and released a list of names, credit card numbers, passwords, and home and email addresses. Those listed were affiliated with organizations such as Bank of America, the United States Department of Defense, M\u00e9decins Sans Fronti\u00e8res, Lockheed Martin, Los Alamos National Laboratory, and the United Nations. The hackers included Jeremy Hammond, who worked with Anonymous to release Stratfor's emails to WikiLeaks. The emails revealed Stratfor's surveillance of groups such as Occupy Wall Street and protestors of the Bhopal disaster.The e-mails are alleged to include client information, notes between Stratfor employees and internal procedural documentation on securing intelligence data. These communications date from July 2004 through to December 2011. \nStratfor said the emails appeared to be those that were stolen by hackers in December 2011. In an initial announcement, WikiLeaks stated that they opened up a database of the emails to two dozen media organizations operating in several countries, including the McClatchy Company, l'Espresso, la Repubblica, ARD, the Russia Reporter, and Rolling Stone, along with a \"sneak preview\" to the Yes Men.In June 2012, Stratfor settled a class action lawsuit regarding the hack.\n\n== Content ==\nStratfor stated that some of the leaked emails \"may be forged or altered to include inaccuracies; some may be authentic\", pointing to a phony email saying that Stratfor's CEO George Friedman had resigned. They stated that the emails represented candid internal language that would probably be ripe for misinterpretation.One of the first items released was an email containing a glossary titled \"The Stratfor Glossary of Useful, Baffling and Strange Intelligence Terms\", which contained concise and sometimes humorously candid definitions, along with pointed assessments of U.S. intelligence and law enforcement. The glossary included items on how \"background checks\" can help \"run up clients\u2019 bill and makes it appear that you are busy\" and how \"briefs\" for customers need to \"make sh*t smell good\".\n\n\n*** Julian Assange ***\nJulian Assange was a frequent topic of discussion in emails from Stratfor staff in the period 2010\u20132012.  Emails from Fred Burton, who was Stratfor's Vice-President for Counterterrorism and Corporate Security and former Deputy Chief of the counterterrorism division of the Diplomatic Security Service, indicated that he knew in January 2011 about a United States Government secret indictment against Assange. Internal Stratfor emails gave a suggested strategy for dealing with Assange: \"Pile on. Move him from country to country to face various charges for the next 25 years\". Burton wrote that his strategy would be \"Bankrupt the arsehole first, ruin his life. Give him 7-12 yrs for conspiracy\". In one published email Burton allegedly wrote \"Assange is going to make a nice bride in prison. Screw the terrorist. He'll be eating cat food forever.\" In another leaked email, a Stratfor employee wanted Assange waterboarded.\n\n\n*** Governmental ***\nThe emails show Stratfor had contracts with Homeland Security. Mark LeVine, professor of history at the University of California, Irvine, described this as \"troubling\" because Homeland Security had coordinated police attacks on the Occupy movement.An email from a Stratfor analyst indicated that up to 12 officials in Pakistan's Inter-Services Intelligence (ISI) agency knew of Osama bin-Laden's safe house.Ynetnews reported that, according to internal emails between Stratfor employees, Israel and Russia were engaged in an exchange of information in 2008. Israel gave Russia \"data link codes\" for unmanned aerial vehicles (Elbit Hermes 450) that Israel sold to Georgia and in return Russia gave Israel \"the codes for Tor-M1 missile defense systems that Russia sold Iran\". Ynetnews also stated that, during the 2008 South Ossetia war, the leaked emails revealed  Georgia \"realized that their UAVs were compromised and were looking for a replacement for the Israeli made drones\".Business Insider reported that Israeli Prime Minister Benjamin Netanyahu was an intelligence source for Stratfor between 2007 and 2010. In emails, Fred Burton discussed his personal communications with Netanyahu. Burton stated by email that Netanyahu informed him of his success in consolidating power within the Likud party ahead of regaining the position of prime minister, shared thoughts regarding his distrust of US President Barack Obama, threatened assassination of Hezbollah leader Hasan Nasrallah, and declared intentions to unilaterally start a war against Iran.Al Akhbar, citing internal emails from the Stratfor hack, reported former Blackwater director James F. Smith had a relationship with Stratfor and was for a time considered one of their major sources.\nThe emails indicate that Stratfor was receiving information about Venezuelan president Hugo Chavez's medical condition from an Israeli intelligence source.\n\n\n*** Companies ***\nMultinational corporations use Statfor to obtain intelligence on their critics. Dow Chemical, Lockheed Martin, Northrop Grumman, Raytheon and Coca-Cola have used Stratfor's services.The Times of India reported that some emails indicate Stratfor was hired by Dow Chemical to spy on activists seeking compensation from Dow for the Bhopal disaster. Dow Chemical Company responded with a written statement that read: \"Major companies are often required to take appropriate action to protect their people and safeguard their facilities,\" and that it had not broken any laws.The released emails indicated that the Coca-Cola paid Stratfor to determine \"to what extent will US-based PETA supporters travel to Canada to support activism\" at the 2010 Olympics. The Coca-Cola Company responded to the emails with a statement saying that they \"consider it prudent to monitor for protest activities at any major event we sponsor\". Stratfor offered its services to Bank of America to investigate journalist Glenn Greenwald.\n\n\n*** Other ***\nStratfor received information from an informant at Occupy Austin, who was working as an undercover operative for the Texas Department of Public Safety.A memo from Friedman to his staff stated that Stratfor was partnering with Shea Morenz from Goldman Sachs, to create its own hedge fund. The memo said that the fund \"would allow us to utilize the intelligence we were gathering about the world in a new but related venue\u2014an investment fund. Where we had previously advised other hedge funds, we would now have our own, itself fully funded by Shea. Shea invested over $2 million in Stratfor\".\n\n== Responses ==\n\n\n*** Stratfor ***\nAround midnight on February 27, Stratfor released a statement saying that \"the release of its stolen emails was an attempt to silence and intimidate it.\" It also dismissed rumors of CEO and founder George Friedman's resignation.\n\n\n*** Others ***\nWikiLeaks founder Julian Assange told Reuters that his concerns with Stratfor stem from it being a private intelligence firm relying on informants from government agencies with dubious reputations and especially its monitoring of activist organizations. He also accused Stratfor of making investments based on the intelligence it obtained.Former NSA Director Bobby Inman stated that the leak would be damaging to Stratfor's business. He had previously stated that Stratfor was competent, delivering high-quality intelligence analyses.After the release was announced, analysts questioned the value of the firm's emails, since they mostly used reports from newspapers, think tanks and political science university departments. Max Fisher, the associate director of The Atlantic, argued that Stratfor has a poor reputation \"among foreign policy writers, analysts, and practitioners\" and that as a result Anonymous and Wikileaks have exaggerated the significance of the information they released. He also suggested that Assange may have targeted a relatively unimportant firm and over-hyped the results in order to \"regain some of his former glory\". Australian Broadcasting Corporation foreign correspondent and Stratfor subscriber Mark Corcoran also wrote that the e-mails showed Stratfor's methods used to gather information are similar to those employed by journalists, though he wrote that the quality of its reports are often inferior to news reports.\n\nWhat contracts did Stratfor have with Homeland Security and how did professor Mark LeVine describe it?",
    "context": "",
    "output": "A: Stratfor had contracts with Homeland Security, which professor Mark LeVine of the University of California, Irvine, described as troubling due to Homeland Security's coordination of police attacks on the Occupy movement.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What contracts did Stratfor have with Homeland Security and how did professor Mark LeVine describe it?",
      "answer": "Stratfor had contracts with Homeland Security, which professor Mark LeVine of the University of California, Irvine, described as troubling due to Homeland Security's coordination of police attacks on the Occupy movement.",
      "context": "Stratfor email leak\n\n==Introduction==\nEmails by strategic intelligence company Stratfor, referred to by WikiLeaks as the Global Intelligence Files, began appearing on WikiLeaks on February 27, 2012, with 5,543,061 emails published as of July 18, 2014.Stratfor is a security group based in Austin, Texas. On December 24, 2011, hackers took control of Stratfor's website and released a list of names, credit card numbers, passwords, and home and email addresses. Those listed were affiliated with organizations such as Bank of America, the United States Department of Defense, M\u00e9decins Sans Fronti\u00e8res, Lockheed Martin, Los Alamos National Laboratory, and the United Nations. The hackers included Jeremy Hammond, who worked with Anonymous to release Stratfor's emails to WikiLeaks. The emails revealed Stratfor's surveillance of groups such as Occupy Wall Street and protestors of the Bhopal disaster.The e-mails are alleged to include client information, notes between Stratfor employees and internal procedural documentation on securing intelligence data. These communications date from July 2004 through to December 2011. \nStratfor said the emails appeared to be those that were stolen by hackers in December 2011. In an initial announcement, WikiLeaks stated that they opened up a database of the emails to two dozen media organizations operating in several countries, including the McClatchy Company, l'Espresso, la Repubblica, ARD, the Russia Reporter, and Rolling Stone, along with a \"sneak preview\" to the Yes Men.In June 2012, Stratfor settled a class action lawsuit regarding the hack.\n\n== Content ==\nStratfor stated that some of the leaked emails \"may be forged or altered to include inaccuracies; some may be authentic\", pointing to a phony email saying that Stratfor's CEO George Friedman had resigned. They stated that the emails represented candid internal language that would probably be ripe for misinterpretation.One of the first items released was an email containing a glossary titled \"The Stratfor Glossary of Useful, Baffling and Strange Intelligence Terms\", which contained concise and sometimes humorously candid definitions, along with pointed assessments of U.S. intelligence and law enforcement. The glossary included items on how \"background checks\" can help \"run up clients\u2019 bill and makes it appear that you are busy\" and how \"briefs\" for customers need to \"make sh*t smell good\".\n\n\n*** Julian Assange ***\nJulian Assange was a frequent topic of discussion in emails from Stratfor staff in the period 2010\u20132012.  Emails from Fred Burton, who was Stratfor's Vice-President for Counterterrorism and Corporate Security and former Deputy Chief of the counterterrorism division of the Diplomatic Security Service, indicated that he knew in January 2011 about a United States Government secret indictment against Assange. Internal Stratfor emails gave a suggested strategy for dealing with Assange: \"Pile on. Move him from country to country to face various charges for the next 25 years\". Burton wrote that his strategy would be \"Bankrupt the arsehole first, ruin his life. Give him 7-12 yrs for conspiracy\". In one published email Burton allegedly wrote \"Assange is going to make a nice bride in prison. Screw the terrorist. He'll be eating cat food forever.\" In another leaked email, a Stratfor employee wanted Assange waterboarded.\n\n\n*** Governmental ***\nThe emails show Stratfor had contracts with Homeland Security. Mark LeVine, professor of history at the University of California, Irvine, described this as \"troubling\" because Homeland Security had coordinated police attacks on the Occupy movement.An email from a Stratfor analyst indicated that up to 12 officials in Pakistan's Inter-Services Intelligence (ISI) agency knew of Osama bin-Laden's safe house.Ynetnews reported that, according to internal emails between Stratfor employees, Israel and Russia were engaged in an exchange of information in 2008. Israel gave Russia \"data link codes\" for unmanned aerial vehicles (Elbit Hermes 450) that Israel sold to Georgia and in return Russia gave Israel \"the codes for Tor-M1 missile defense systems that Russia sold Iran\". Ynetnews also stated that, during the 2008 South Ossetia war, the leaked emails revealed  Georgia \"realized that their UAVs were compromised and were looking for a replacement for the Israeli made drones\".Business Insider reported that Israeli Prime Minister Benjamin Netanyahu was an intelligence source for Stratfor between 2007 and 2010. In emails, Fred Burton discussed his personal communications with Netanyahu. Burton stated by email that Netanyahu informed him of his success in consolidating power within the Likud party ahead of regaining the position of prime minister, shared thoughts regarding his distrust of US President Barack Obama, threatened assassination of Hezbollah leader Hasan Nasrallah, and declared intentions to unilaterally start a war against Iran.Al Akhbar, citing internal emails from the Stratfor hack, reported former Blackwater director James F. Smith had a relationship with Stratfor and was for a time considered one of their major sources.\nThe emails indicate that Stratfor was receiving information about Venezuelan president Hugo Chavez's medical condition from an Israeli intelligence source.\n\n\n*** Companies ***\nMultinational corporations use Statfor to obtain intelligence on their critics. Dow Chemical, Lockheed Martin, Northrop Grumman, Raytheon and Coca-Cola have used Stratfor's services.The Times of India reported that some emails indicate Stratfor was hired by Dow Chemical to spy on activists seeking compensation from Dow for the Bhopal disaster. Dow Chemical Company responded with a written statement that read: \"Major companies are often required to take appropriate action to protect their people and safeguard their facilities,\" and that it had not broken any laws.The released emails indicated that the Coca-Cola paid Stratfor to determine \"to what extent will US-based PETA supporters travel to Canada to support activism\" at the 2010 Olympics. The Coca-Cola Company responded to the emails with a statement saying that they \"consider it prudent to monitor for protest activities at any major event we sponsor\". Stratfor offered its services to Bank of America to investigate journalist Glenn Greenwald.\n\n\n*** Other ***\nStratfor received information from an informant at Occupy Austin, who was working as an undercover operative for the Texas Department of Public Safety.A memo from Friedman to his staff stated that Stratfor was partnering with Shea Morenz from Goldman Sachs, to create its own hedge fund. The memo said that the fund \"would allow us to utilize the intelligence we were gathering about the world in a new but related venue\u2014an investment fund. Where we had previously advised other hedge funds, we would now have our own, itself fully funded by Shea. Shea invested over $2 million in Stratfor\".\n\n== Responses ==\n\n\n*** Stratfor ***\nAround midnight on February 27, Stratfor released a statement saying that \"the release of its stolen emails was an attempt to silence and intimidate it.\" It also dismissed rumors of CEO and founder George Friedman's resignation.\n\n\n*** Others ***\nWikiLeaks founder Julian Assange told Reuters that his concerns with Stratfor stem from it being a private intelligence firm relying on informants from government agencies with dubious reputations and especially its monitoring of activist organizations. He also accused Stratfor of making investments based on the intelligence it obtained.Former NSA Director Bobby Inman stated that the leak would be damaging to Stratfor's business. He had previously stated that Stratfor was competent, delivering high-quality intelligence analyses.After the release was announced, analysts questioned the value of the firm's emails, since they mostly used reports from newspapers, think tanks and political science university departments. Max Fisher, the associate director of The Atlantic, argued that Stratfor has a poor reputation \"among foreign policy writers, analysts, and practitioners\" and that as a result Anonymous and Wikileaks have exaggerated the significance of the information they released. He also suggested that Assange may have targeted a relatively unimportant firm and over-hyped the results in order to \"regain some of his former glory\". Australian Broadcasting Corporation foreign correspondent and Stratfor subscriber Mark Corcoran also wrote that the e-mails showed Stratfor's methods used to gather information are similar to those employed by journalists, though he wrote that the quality of its reports are often inferior to news reports."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is MPA implemented in a network infrastructure or computerized control system?",
    "context": "",
    "output": "MPA can be implemented in a network infrastructure or computerized control system to protect any type of sensitive data in electronic form or any activity, providing proactive protection from undesirable acts by the inexperienced technician or malicious insider.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is MPA implemented in a network infrastructure or computerized control system?",
      "answer": "MPA can be implemented in a network infrastructure or computerized control system to protect any type of sensitive data in electronic form or any activity, providing proactive protection from undesirable acts by the inexperienced technician or malicious insider."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the role of Jennifer Granick in this incident?",
    "context": "",
    "output": "Jennifer Granick was the lawyer who represented Michael Lynn during his legal battle with Cisco and ISS. She asserted Lynn's rights under the Fifth and Sixth amendment, and negotiated the settlement with the plaintiff's lawyers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the role of Jennifer Granick in this incident?",
      "answer": "Jennifer Granick was the lawyer who represented Michael Lynn during his legal battle with Cisco and ISS. She asserted Lynn's rights under the Fifth and Sixth amendment, and negotiated the settlement with the plaintiff's lawyers."
    }
  },
  {
    "instruction": "Write an answer to the following question: What were some of the notable tools released by Global kOS?",
    "context": "",
    "output": "Global kOS released network and security tools for Windows and Linux. However, the group did not release exploit code. Instead, they focused on creating automated denial of service tools.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What were some of the notable tools released by Global kOS?",
      "answer": "Global kOS released network and security tools for Windows and Linux. However, the group did not release exploit code. Instead, they focused on creating automated denial of service tools."
    }
  },
  {
    "instruction": "Antivirus software\n\n==Introduction==\nAntivirus software (abbreviated to AV software), also known as anti-malware, is a computer program used to prevent, detect, and remove malware.\nAntivirus software was originally developed to detect and remove computer viruses, hence the name. However, with the proliferation of other malware, antivirus software started to protect against other computer threats. Some products also include protection from malicious URLs, spam, and phishing.\n\n\n\n== Identification methods ==\nOne of the few solid theoretical results in the study of computer viruses is Frederick B. Cohen's 1987 demonstration that there is no algorithm that can perfectly detect all possible viruses. However, using different layers of defense, a good detection rate may be achieved.\nThere are several methods which antivirus engines can use to identify malware:\n\nSandbox detection: a particular behavioural-based detection technique that, instead of detecting the behavioural fingerprint at run time, it executes the programs in a virtual environment, logging what actions the program performs. Depending on the actions logged, the antivirus engine can determine if the program is malicious or not. If not, then, the program is executed in the real environment. Albeit this technique has shown to be quite effective, given its heaviness and slowness, it is rarely used in end-user antivirus solutions.\nData mining techniques: one of the latest approaches applied in malware detection. Data mining and machine learning algorithms are used to try to classify the behaviour of a file (as either malicious or benign) given a series of file features, that are extracted from the file itself.\n\n\n*** Signature-based detection ***\nTraditional antivirus software relies heavily upon signatures to identify malware.Substantially, when a malware sample arrives in the hands of an antivirus firm, it is analysed by malware researchers or by dynamic analysis systems. Then, once it is determined to be a malware, a proper signature of the file is extracted and added to the signatures database of the antivirus software.Although the signature-based approach can effectively contain malware outbreaks, malware authors have tried to stay a step ahead of such software by writing \"oligomorphic\", \"polymorphic\" and, more recently, \"metamorphic\" viruses, which encrypt parts of themselves or otherwise modify themselves as a method of disguise, so as to not match virus signatures in the dictionary.\n\n\n*** Heuristics ***\nMany viruses start as a single infection and through either mutation or refinements by other attackers, can grow into dozens of slightly different strains, called variants. Generic detection refers to the detection and removal of multiple threats using a single virus definition.For example, the Vundo trojan has several family members, depending on the antivirus vendor's classification. Symantec classifies members of the Vundo family into two distinct categories, Trojan.Vundo and Trojan.Vundo.B.While it may be advantageous to identify a specific virus, it can be quicker to detect a virus family through a generic signature or through an inexact match to an existing signature. Virus researchers find common areas that all viruses in a family share uniquely and can thus create a single generic signature. These signatures often contain non-contiguous code, using wildcard characters where differences lie. These wildcards allow the scanner to detect viruses even if they are padded with extra, meaningless code. A detection that uses this method is said to be \"heuristic detection.\"\n\n\n*** Rootkit detection ***\n\nAnti-virus software can attempt to scan for rootkits. A rootkit is a type of malware designed to gain administrative-level control over a computer system without being detected. Rootkits can change how the operating system functions and in some cases can tamper with the anti-virus program and render it ineffective. Rootkits are also difficult to remove, in some cases requiring a complete re-installation of the operating system.\n\n\n*** Real-time protection ***\nReal-time protection, on-access scanning, background guard, resident shield, autoprotect, and other synonyms refer to the automatic protection provided by most antivirus, anti-spyware, and other anti-malware programs. This monitors computer systems for suspicious activity such as computer viruses, spyware, adware, and other malicious objects. Real-time protection detects threats in opened files and scans apps in real-time as they are installed on the device. When inserting a CD, opening an email, or browsing the web, or when a file already on the computer is opened or executed.\n\n== Issues of concern ==\n\n\n*** Unexpected renewal costs ***\nSome commercial antivirus software end-user license agreements include a clause that the subscription will be automatically renewed, and the purchaser's credit card automatically billed, at the renewal time without explicit approval. For example, McAfee requires users to unsubscribe at least 60 days before the expiration of the present subscription while BitDefender sends notifications to unsubscribe 30 days before the renewal. Norton AntiVirus also renews subscriptions automatically by default.\n\n\n*** Rogue security applications ***\n\nSome apparent antivirus programs are actually malware masquerading as legitimate software, such as WinFixer, MS Antivirus, and Mac Defender.\n\n\n*** Problems caused by false positives ***\nA \"false positive\" or \"false alarm\" is when antivirus software identifies a non-malicious file as malware. When this happens, it can cause serious problems. For example, if an antivirus program is configured to immediately delete or quarantine infected files, as is common on Microsoft Windows antivirus applications, a false positive in an essential file can render the Windows operating system or some applications unusable. Recovering from such damage to critical software infrastructure incurs technical support costs and businesses can be forced to close whilst remedial action is undertaken.Examples of serious false-positives:\n\nMay 2007: a faulty virus signature issued by Symantec mistakenly removed essential operating system files, leaving thousands of PCs unable to boot.\nMay 2007: the executable file required by Pegasus Mail on Windows was falsely detected by Norton AntiVirus as being a Trojan and it was automatically removed, preventing Pegasus Mail from running. Norton AntiVirus had falsely identified three releases of Pegasus Mail as malware, and would delete the Pegasus Mail installer file when that happened. In response to this Pegasus Mail stated:On the basis that Norton/Symantec has done this for every one of the last three releases of Pegasus Mail, we can only condemn this product as too flawed to use, and recommend in the strongest terms that our users cease using it in favour of alternative, less buggy anti-virus packages.April 2010: McAfee VirusScan detected svchost.exe, a normal Windows binary, as a virus on machines running Windows XP with Service Pack 3, causing a reboot loop and loss of all network access.\nDecember 2010: a faulty update on the AVG anti-virus suite damaged 64-bit versions of Windows 7, rendering it unable to boot, due to an endless boot loop created.\nOctober 2011: Microsoft Security Essentials (MSE) removed the Google Chrome web browser, rival to Microsoft's own Internet Explorer. MSE flagged Chrome as a Zbot banking trojan.\nSeptember 2012: Sophos' anti-virus suite identified various update-mechanisms, including its own, as malware. If it was configured to automatically delete detected files, Sophos Antivirus could render itself unable to update, required manual intervention to fix the problem.\nSeptember 2017: the Google Play Protect anti-virus started identifying Motorola's Moto G4 Bluetooth application as malware, causing Bluetooth functionality to become disabled.\nSeptember 2022: Microsoft Defender flagged all Chromium based web browsers and Electron based apps like Whatsapp, Discord, Spotify as a severe threat.\n\n\n*** System and interoperability related issues ***\nRunning (the real-time protection of) multiple antivirus programs concurrently can degrade performance and create conflicts. However, using a concept called multiscanning, several companies (including G Data Software and Microsoft) have created applications which can run multiple engines concurrently.\nIt is sometimes necessary to temporarily disable virus protection when installing major updates such as Windows Service Packs or updating graphics card drivers. Active antivirus protection may partially or completely prevent the installation of a major update. Anti-virus software can cause problems during the installation of an operating system upgrade, e.g. when upgrading to a newer version of Windows \"in place\"\u2014without erasing the previous version of Windows. Microsoft recommends that anti-virus software be disabled to avoid conflicts with the upgrade installation process. Active anti-virus software can also interfere with a firmware update process.The functionality of a few computer programs can be hampered by active anti-virus software. For example, TrueCrypt, a disk encryption program, states on its troubleshooting page that anti-virus programs can conflict with TrueCrypt and cause it to malfunction or operate very slowly. Anti-virus software can impair the performance and stability of games running in the Steam platform.Support issues also exist around antivirus application interoperability with common solutions like SSL VPN remote access and network access control products. These technology solutions often have policy assessment applications that require an up-to-date antivirus to be installed and running. If the antivirus application is not recognized by the policy assessment, whether because the antivirus application has been updated or because it is not part of the policy assessment library, the user will be unable to connect.\n\n\n*** Effectiveness ***\nStudies in December 2007 showed that the effectiveness of antivirus software had decreased in the previous year, particularly against unknown or zero day attacks. The computer magazine c't found that detection rates for these threats had dropped from 40-50% in 2006 to 20\u201330% in 2007. At that time, the only exception was the NOD32 antivirus, which managed a detection rate of 68%. According to the ZeuS tracker website the average detection rate for all variants of the well-known ZeuS trojan is as low as 40%.The problem is magnified by the changing intent of virus authors. Some years ago it was obvious when a virus infection was present. At the time, viruses were written by amateurs and exhibited destructive behavior or pop-ups. Modern viruses are often written by professionals, financed by criminal organizations.In 2008, Eva Chen, CEO of Trend Micro, stated that the anti-virus industry has over-hyped how effective its products are\u2014and so has been misleading customers\u2014for years.Independent testing on all the major virus scanners consistently shows that none provides 100% virus detection. The best ones provided as high as 99.9% detection for simulated real-world situations, while the lowest provided 91.1% in tests conducted in August 2013. Many virus scanners produce false positive results as well, identifying benign files as malware.Although methods may differ, some notable independent quality testing agencies include AV-Comparatives, ICSA Labs, West Coast Labs, Virus Bulletin, AV-TEST and other members of the Anti-Malware Testing Standards Organization.\n\n\n*** New viruses ***\nAnti-virus programs are not always effective against new viruses, even those that use non-signature-based methods that should detect new viruses. The reason for this is that the virus designers test their new viruses on the major anti-virus applications to make sure that they are not detected before releasing them into the wild.Some new viruses, particularly ransomware, use polymorphic code to avoid detection by virus scanners. Jerome Segura, a security analyst with ParetoLogic, explained:\nIt's something that they miss a lot of the time because this type of [ransomware virus] comes from sites that use a polymorphism, which means they basically randomize the file they send you and it gets by well-known antivirus products very easily. I've seen people firsthand getting infected, having all the pop-ups and yet they have antivirus software running and it's not detecting anything. It actually can be pretty hard to get rid of, as well, and you're never really sure if it's really gone. When we see something like that usually we advise to reinstall the operating system or reinstall backups.\nA proof of concept virus has used the Graphics Processing Unit (GPU) to avoid detection from anti-virus software. The potential success of this involves bypassing the CPU in order to make it much harder for security researchers to analyse the inner workings of such malware.\n\n\n*** Rootkits ***\nDetecting rootkits is a major challenge for anti-virus programs. Rootkits have full administrative access to the computer and are invisible to users and hidden from the list of running processes in the task manager. Rootkits can modify the inner workings of the operating system and tamper with antivirus programs.\n\n\n*** Damaged files ***\nIf a file has been infected by a computer virus, anti-virus software will attempt to remove the virus code from the file during disinfection, but it is not always able to restore the file to its undamaged state. In such circumstances, damaged files can only be restored from existing backups or shadow copies (this is also true for ransomware); installed software that is damaged requires re-installation (however, see System File Checker).\n\n\n*** Firmware infections ***\nAny writeable firmware in the computer can be infected by malicious code. This is a major concern, as an infected BIOS could require the actual BIOS chip to be replaced to ensure the malicious code is completely removed. Anti-virus software is not effective at protecting firmware and the motherboard BIOS from infection. In 2014, security researchers discovered that USB devices contain writeable firmware which can be modified with malicious code (dubbed \"BadUSB\"), which anti-virus software cannot detect or prevent. The malicious code can run undetected on the computer and could even infect the operating system prior to it booting up.\n\n== Performance and other drawbacks ==\nAntivirus software has some drawbacks, first of which that it can impact a computer's performance.Furthermore, inexperienced users can be lulled into a false sense of security when using the computer, considering their computers to be invulnerable, and may have problems understanding the prompts and decisions that antivirus software presents them with. An incorrect decision may lead to a security breach. If the antivirus software employs heuristic detection, it must be fine-tuned to minimize misidentifying harmless software as malicious (false positive).Antivirus software itself usually runs at the highly trusted kernel level of the operating system to allow it access to all the potential malicious process and files, creating a potential avenue of attack. The US National Security Agency (NSA) and the UK Government Communications Headquarters (GCHQ) intelligence agencies, \nrespectively, have been exploiting anti-virus software to spy on users. Anti-virus software has highly privileged and trusted access to the underlying operating system, which makes it a much more appealing target for remote attacks. Additionally anti-virus software is \"years behind security-conscious client-side applications like browsers or document readers. It means that Acrobat Reader, Microsoft Word or Google Chrome are harder to exploit than 90 percent of the anti-virus products out there\", according to Joxean Koret, a researcher with Coseinc, a Singapore-based information security consultancy.\n\n== Alternative solutions ==\n\nAntivirus software running on individual computers is the most common method employed of guarding against malware, but it is not the only solution. Other solutions can also be employed by users, including Unified Threat Management (UTM), hardware and network firewalls, Cloud-based antivirus and online scanners.\n\n\n*** Hardware and network firewall ***\nNetwork firewalls prevent unknown programs and processes from accessing the system. However, they are not antivirus systems and make no attempt to identify or remove anything. They may protect against infection from outside the protected computer or network, and limit the activity of any malicious software which is present by blocking incoming or outgoing requests on certain TCP/IP ports. A firewall is designed to deal with broader system threats that come from network connections into the system and is not an alternative to a virus protection system.\n\n\n*** Cloud antivirus ***\nCloud antivirus is a technology that uses lightweight agent software on the protected computer, while offloading the majority of data analysis to the provider's infrastructure.One approach to implementing cloud antivirus involves scanning suspicious files using multiple antivirus engines. This approach was proposed by an early implementation of the cloud antivirus concept called CloudAV. CloudAV was designed to send programs or documents to a network cloud where multiple antivirus and behavioral detection programs are used simultaneously in order to improve detection rates. Parallel scanning of files using potentially incompatible antivirus scanners is achieved by spawning a virtual machine per detection engine and therefore eliminating any possible issues. CloudAV can also perform \"retrospective detection,\" whereby the cloud detection engine rescans all files in its file access history when a new threat is identified thus improving new threat detection speed. Finally, CloudAV is a solution for effective virus scanning on devices that lack the computing power to perform the scans themselves.Some examples of cloud anti-virus products are Panda Cloud Antivirus and Immunet. Comodo Group has also produced cloud-based anti-virus.\n\n\n*** Online scanning ***\nSome antivirus vendors maintain websites with free online scanning capability of the entire computer, critical areas only, local disks, folders or files. Periodic online scanning is a good idea for those that run antivirus applications on their computers because those applications are frequently slow to catch threats. One of the first things that malicious software does in an attack is disable any existing antivirus software and sometimes the only way to know of an attack is by turning to an online resource that is not installed on the infected computer.\n\n\n*** Specialized tools ***\n\nVirus removal tools are available to help remove stubborn infections or a certain type of infection. Examples include Windows Malicious Software Removal Tool, Sophos Scan & Clean, and Kaspersky Virus Removal Tool. It is also worth noting that sometimes antivirus software can produce a false-positive result, indicating an infection where there is none.A rescue disk that is bootable, such as a CD or USB storage device, can be used to run antivirus software outside of the installed operating system in order to remove infections while they are dormant. A bootable antivirus disk can be useful when, for example, the installed operating system is no longer bootable or has malware that is resisting all attempts to be removed by the installed antivirus software. Examples of some of these bootable disks include the Trend Micro Rescue Disk, Kaspersky Rescue Disk, and Comodo Rescue Disk. Most of the rescue disk software can also be installed onto a USB storage device that is bootable on newer computers.\n\n== Usage and risks ==\nAccording to an FBI survey, major businesses lose $12 million annually dealing with virus incidents. A survey by Symantec in 2009 found that a third of small to medium-sized business did not use antivirus protection at that time, whereas more than 80% of home users had some kind of antivirus installed. According to a sociological survey conducted by G Data Software in 2010 49% of women did not use any antivirus program at all.\n\n== Citations ==\n\n== General bibliography ==\n\nQ: How do new viruses pose a challenge for antivirus programs?",
    "context": "",
    "output": "A: New viruses, particularly ransomware, can use polymorphic code to avoid detection by virus scanners, making it difficult for antivirus programs to detect and remove them.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do new viruses pose a challenge for antivirus programs?",
      "answer": "New viruses, particularly ransomware, can use polymorphic code to avoid detection by virus scanners, making it difficult for antivirus programs to detect and remove them.",
      "context": "Antivirus software\n\n==Introduction==\nAntivirus software (abbreviated to AV software), also known as anti-malware, is a computer program used to prevent, detect, and remove malware.\nAntivirus software was originally developed to detect and remove computer viruses, hence the name. However, with the proliferation of other malware, antivirus software started to protect against other computer threats. Some products also include protection from malicious URLs, spam, and phishing.\n\n\n\n== Identification methods ==\nOne of the few solid theoretical results in the study of computer viruses is Frederick B. Cohen's 1987 demonstration that there is no algorithm that can perfectly detect all possible viruses. However, using different layers of defense, a good detection rate may be achieved.\nThere are several methods which antivirus engines can use to identify malware:\n\nSandbox detection: a particular behavioural-based detection technique that, instead of detecting the behavioural fingerprint at run time, it executes the programs in a virtual environment, logging what actions the program performs. Depending on the actions logged, the antivirus engine can determine if the program is malicious or not. If not, then, the program is executed in the real environment. Albeit this technique has shown to be quite effective, given its heaviness and slowness, it is rarely used in end-user antivirus solutions.\nData mining techniques: one of the latest approaches applied in malware detection. Data mining and machine learning algorithms are used to try to classify the behaviour of a file (as either malicious or benign) given a series of file features, that are extracted from the file itself.\n\n\n*** Signature-based detection ***\nTraditional antivirus software relies heavily upon signatures to identify malware.Substantially, when a malware sample arrives in the hands of an antivirus firm, it is analysed by malware researchers or by dynamic analysis systems. Then, once it is determined to be a malware, a proper signature of the file is extracted and added to the signatures database of the antivirus software.Although the signature-based approach can effectively contain malware outbreaks, malware authors have tried to stay a step ahead of such software by writing \"oligomorphic\", \"polymorphic\" and, more recently, \"metamorphic\" viruses, which encrypt parts of themselves or otherwise modify themselves as a method of disguise, so as to not match virus signatures in the dictionary.\n\n\n*** Heuristics ***\nMany viruses start as a single infection and through either mutation or refinements by other attackers, can grow into dozens of slightly different strains, called variants. Generic detection refers to the detection and removal of multiple threats using a single virus definition.For example, the Vundo trojan has several family members, depending on the antivirus vendor's classification. Symantec classifies members of the Vundo family into two distinct categories, Trojan.Vundo and Trojan.Vundo.B.While it may be advantageous to identify a specific virus, it can be quicker to detect a virus family through a generic signature or through an inexact match to an existing signature. Virus researchers find common areas that all viruses in a family share uniquely and can thus create a single generic signature. These signatures often contain non-contiguous code, using wildcard characters where differences lie. These wildcards allow the scanner to detect viruses even if they are padded with extra, meaningless code. A detection that uses this method is said to be \"heuristic detection.\"\n\n\n*** Rootkit detection ***\n\nAnti-virus software can attempt to scan for rootkits. A rootkit is a type of malware designed to gain administrative-level control over a computer system without being detected. Rootkits can change how the operating system functions and in some cases can tamper with the anti-virus program and render it ineffective. Rootkits are also difficult to remove, in some cases requiring a complete re-installation of the operating system.\n\n\n*** Real-time protection ***\nReal-time protection, on-access scanning, background guard, resident shield, autoprotect, and other synonyms refer to the automatic protection provided by most antivirus, anti-spyware, and other anti-malware programs. This monitors computer systems for suspicious activity such as computer viruses, spyware, adware, and other malicious objects. Real-time protection detects threats in opened files and scans apps in real-time as they are installed on the device. When inserting a CD, opening an email, or browsing the web, or when a file already on the computer is opened or executed.\n\n== Issues of concern ==\n\n\n*** Unexpected renewal costs ***\nSome commercial antivirus software end-user license agreements include a clause that the subscription will be automatically renewed, and the purchaser's credit card automatically billed, at the renewal time without explicit approval. For example, McAfee requires users to unsubscribe at least 60 days before the expiration of the present subscription while BitDefender sends notifications to unsubscribe 30 days before the renewal. Norton AntiVirus also renews subscriptions automatically by default.\n\n\n*** Rogue security applications ***\n\nSome apparent antivirus programs are actually malware masquerading as legitimate software, such as WinFixer, MS Antivirus, and Mac Defender.\n\n\n*** Problems caused by false positives ***\nA \"false positive\" or \"false alarm\" is when antivirus software identifies a non-malicious file as malware. When this happens, it can cause serious problems. For example, if an antivirus program is configured to immediately delete or quarantine infected files, as is common on Microsoft Windows antivirus applications, a false positive in an essential file can render the Windows operating system or some applications unusable. Recovering from such damage to critical software infrastructure incurs technical support costs and businesses can be forced to close whilst remedial action is undertaken.Examples of serious false-positives:\n\nMay 2007: a faulty virus signature issued by Symantec mistakenly removed essential operating system files, leaving thousands of PCs unable to boot.\nMay 2007: the executable file required by Pegasus Mail on Windows was falsely detected by Norton AntiVirus as being a Trojan and it was automatically removed, preventing Pegasus Mail from running. Norton AntiVirus had falsely identified three releases of Pegasus Mail as malware, and would delete the Pegasus Mail installer file when that happened. In response to this Pegasus Mail stated:On the basis that Norton/Symantec has done this for every one of the last three releases of Pegasus Mail, we can only condemn this product as too flawed to use, and recommend in the strongest terms that our users cease using it in favour of alternative, less buggy anti-virus packages.April 2010: McAfee VirusScan detected svchost.exe, a normal Windows binary, as a virus on machines running Windows XP with Service Pack 3, causing a reboot loop and loss of all network access.\nDecember 2010: a faulty update on the AVG anti-virus suite damaged 64-bit versions of Windows 7, rendering it unable to boot, due to an endless boot loop created.\nOctober 2011: Microsoft Security Essentials (MSE) removed the Google Chrome web browser, rival to Microsoft's own Internet Explorer. MSE flagged Chrome as a Zbot banking trojan.\nSeptember 2012: Sophos' anti-virus suite identified various update-mechanisms, including its own, as malware. If it was configured to automatically delete detected files, Sophos Antivirus could render itself unable to update, required manual intervention to fix the problem.\nSeptember 2017: the Google Play Protect anti-virus started identifying Motorola's Moto G4 Bluetooth application as malware, causing Bluetooth functionality to become disabled.\nSeptember 2022: Microsoft Defender flagged all Chromium based web browsers and Electron based apps like Whatsapp, Discord, Spotify as a severe threat.\n\n\n*** System and interoperability related issues ***\nRunning (the real-time protection of) multiple antivirus programs concurrently can degrade performance and create conflicts. However, using a concept called multiscanning, several companies (including G Data Software and Microsoft) have created applications which can run multiple engines concurrently.\nIt is sometimes necessary to temporarily disable virus protection when installing major updates such as Windows Service Packs or updating graphics card drivers. Active antivirus protection may partially or completely prevent the installation of a major update. Anti-virus software can cause problems during the installation of an operating system upgrade, e.g. when upgrading to a newer version of Windows \"in place\"\u2014without erasing the previous version of Windows. Microsoft recommends that anti-virus software be disabled to avoid conflicts with the upgrade installation process. Active anti-virus software can also interfere with a firmware update process.The functionality of a few computer programs can be hampered by active anti-virus software. For example, TrueCrypt, a disk encryption program, states on its troubleshooting page that anti-virus programs can conflict with TrueCrypt and cause it to malfunction or operate very slowly. Anti-virus software can impair the performance and stability of games running in the Steam platform.Support issues also exist around antivirus application interoperability with common solutions like SSL VPN remote access and network access control products. These technology solutions often have policy assessment applications that require an up-to-date antivirus to be installed and running. If the antivirus application is not recognized by the policy assessment, whether because the antivirus application has been updated or because it is not part of the policy assessment library, the user will be unable to connect.\n\n\n*** Effectiveness ***\nStudies in December 2007 showed that the effectiveness of antivirus software had decreased in the previous year, particularly against unknown or zero day attacks. The computer magazine c't found that detection rates for these threats had dropped from 40-50% in 2006 to 20\u201330% in 2007. At that time, the only exception was the NOD32 antivirus, which managed a detection rate of 68%. According to the ZeuS tracker website the average detection rate for all variants of the well-known ZeuS trojan is as low as 40%.The problem is magnified by the changing intent of virus authors. Some years ago it was obvious when a virus infection was present. At the time, viruses were written by amateurs and exhibited destructive behavior or pop-ups. Modern viruses are often written by professionals, financed by criminal organizations.In 2008, Eva Chen, CEO of Trend Micro, stated that the anti-virus industry has over-hyped how effective its products are\u2014and so has been misleading customers\u2014for years.Independent testing on all the major virus scanners consistently shows that none provides 100% virus detection. The best ones provided as high as 99.9% detection for simulated real-world situations, while the lowest provided 91.1% in tests conducted in August 2013. Many virus scanners produce false positive results as well, identifying benign files as malware.Although methods may differ, some notable independent quality testing agencies include AV-Comparatives, ICSA Labs, West Coast Labs, Virus Bulletin, AV-TEST and other members of the Anti-Malware Testing Standards Organization.\n\n\n*** New viruses ***\nAnti-virus programs are not always effective against new viruses, even those that use non-signature-based methods that should detect new viruses. The reason for this is that the virus designers test their new viruses on the major anti-virus applications to make sure that they are not detected before releasing them into the wild.Some new viruses, particularly ransomware, use polymorphic code to avoid detection by virus scanners. Jerome Segura, a security analyst with ParetoLogic, explained:\nIt's something that they miss a lot of the time because this type of [ransomware virus] comes from sites that use a polymorphism, which means they basically randomize the file they send you and it gets by well-known antivirus products very easily. I've seen people firsthand getting infected, having all the pop-ups and yet they have antivirus software running and it's not detecting anything. It actually can be pretty hard to get rid of, as well, and you're never really sure if it's really gone. When we see something like that usually we advise to reinstall the operating system or reinstall backups.\nA proof of concept virus has used the Graphics Processing Unit (GPU) to avoid detection from anti-virus software. The potential success of this involves bypassing the CPU in order to make it much harder for security researchers to analyse the inner workings of such malware.\n\n\n*** Rootkits ***\nDetecting rootkits is a major challenge for anti-virus programs. Rootkits have full administrative access to the computer and are invisible to users and hidden from the list of running processes in the task manager. Rootkits can modify the inner workings of the operating system and tamper with antivirus programs.\n\n\n*** Damaged files ***\nIf a file has been infected by a computer virus, anti-virus software will attempt to remove the virus code from the file during disinfection, but it is not always able to restore the file to its undamaged state. In such circumstances, damaged files can only be restored from existing backups or shadow copies (this is also true for ransomware); installed software that is damaged requires re-installation (however, see System File Checker).\n\n\n*** Firmware infections ***\nAny writeable firmware in the computer can be infected by malicious code. This is a major concern, as an infected BIOS could require the actual BIOS chip to be replaced to ensure the malicious code is completely removed. Anti-virus software is not effective at protecting firmware and the motherboard BIOS from infection. In 2014, security researchers discovered that USB devices contain writeable firmware which can be modified with malicious code (dubbed \"BadUSB\"), which anti-virus software cannot detect or prevent. The malicious code can run undetected on the computer and could even infect the operating system prior to it booting up.\n\n== Performance and other drawbacks ==\nAntivirus software has some drawbacks, first of which that it can impact a computer's performance.Furthermore, inexperienced users can be lulled into a false sense of security when using the computer, considering their computers to be invulnerable, and may have problems understanding the prompts and decisions that antivirus software presents them with. An incorrect decision may lead to a security breach. If the antivirus software employs heuristic detection, it must be fine-tuned to minimize misidentifying harmless software as malicious (false positive).Antivirus software itself usually runs at the highly trusted kernel level of the operating system to allow it access to all the potential malicious process and files, creating a potential avenue of attack. The US National Security Agency (NSA) and the UK Government Communications Headquarters (GCHQ) intelligence agencies, \nrespectively, have been exploiting anti-virus software to spy on users. Anti-virus software has highly privileged and trusted access to the underlying operating system, which makes it a much more appealing target for remote attacks. Additionally anti-virus software is \"years behind security-conscious client-side applications like browsers or document readers. It means that Acrobat Reader, Microsoft Word or Google Chrome are harder to exploit than 90 percent of the anti-virus products out there\", according to Joxean Koret, a researcher with Coseinc, a Singapore-based information security consultancy.\n\n== Alternative solutions ==\n\nAntivirus software running on individual computers is the most common method employed of guarding against malware, but it is not the only solution. Other solutions can also be employed by users, including Unified Threat Management (UTM), hardware and network firewalls, Cloud-based antivirus and online scanners.\n\n\n*** Hardware and network firewall ***\nNetwork firewalls prevent unknown programs and processes from accessing the system. However, they are not antivirus systems and make no attempt to identify or remove anything. They may protect against infection from outside the protected computer or network, and limit the activity of any malicious software which is present by blocking incoming or outgoing requests on certain TCP/IP ports. A firewall is designed to deal with broader system threats that come from network connections into the system and is not an alternative to a virus protection system.\n\n\n*** Cloud antivirus ***\nCloud antivirus is a technology that uses lightweight agent software on the protected computer, while offloading the majority of data analysis to the provider's infrastructure.One approach to implementing cloud antivirus involves scanning suspicious files using multiple antivirus engines. This approach was proposed by an early implementation of the cloud antivirus concept called CloudAV. CloudAV was designed to send programs or documents to a network cloud where multiple antivirus and behavioral detection programs are used simultaneously in order to improve detection rates. Parallel scanning of files using potentially incompatible antivirus scanners is achieved by spawning a virtual machine per detection engine and therefore eliminating any possible issues. CloudAV can also perform \"retrospective detection,\" whereby the cloud detection engine rescans all files in its file access history when a new threat is identified thus improving new threat detection speed. Finally, CloudAV is a solution for effective virus scanning on devices that lack the computing power to perform the scans themselves.Some examples of cloud anti-virus products are Panda Cloud Antivirus and Immunet. Comodo Group has also produced cloud-based anti-virus.\n\n\n*** Online scanning ***\nSome antivirus vendors maintain websites with free online scanning capability of the entire computer, critical areas only, local disks, folders or files. Periodic online scanning is a good idea for those that run antivirus applications on their computers because those applications are frequently slow to catch threats. One of the first things that malicious software does in an attack is disable any existing antivirus software and sometimes the only way to know of an attack is by turning to an online resource that is not installed on the infected computer.\n\n\n*** Specialized tools ***\n\nVirus removal tools are available to help remove stubborn infections or a certain type of infection. Examples include Windows Malicious Software Removal Tool, Sophos Scan & Clean, and Kaspersky Virus Removal Tool. It is also worth noting that sometimes antivirus software can produce a false-positive result, indicating an infection where there is none.A rescue disk that is bootable, such as a CD or USB storage device, can be used to run antivirus software outside of the installed operating system in order to remove infections while they are dormant. A bootable antivirus disk can be useful when, for example, the installed operating system is no longer bootable or has malware that is resisting all attempts to be removed by the installed antivirus software. Examples of some of these bootable disks include the Trend Micro Rescue Disk, Kaspersky Rescue Disk, and Comodo Rescue Disk. Most of the rescue disk software can also be installed onto a USB storage device that is bootable on newer computers.\n\n== Usage and risks ==\nAccording to an FBI survey, major businesses lose $12 million annually dealing with virus incidents. A survey by Symantec in 2009 found that a third of small to medium-sized business did not use antivirus protection at that time, whereas more than 80% of home users had some kind of antivirus installed. According to a sociological survey conducted by G Data Software in 2010 49% of women did not use any antivirus program at all.\n\n== Citations ==\n\n== General bibliography =="
    }
  },
  {
    "instruction": "AV-TEST\n\n==Introduction==\nAV-TEST is an independent organization which evaluates and rates antivirus and security suite software for Microsoft Windows, MacOS and Android operating systems, according to a variety of criteria. The organisation is based in Magdeburg, Germany.Every other month, the researchers publish the results of their testing, where they list which products they awarded their certification. They regularly test antivirus, anti-spyware and firewall software for the software publishers and for magazines. In the field of product certification they work together with Tekit Consult Bonn GmbH (T\u00dcV Saarland group).\nThe tests are performed on desktop computers and servers running Windows 98, ME, NT 4, 2000, XP, 2003; Novell NetWare, Linux, Solaris, FreeBSD, OpenBSD, Lotus Domino/Notes and Microsoft Exchange.\n\n\n\n== Criticism ==\nIn 2013, the security specialist and CEO of IT security company Kaspersky Lab, Eugene Kaspersky, criticized AV-TEST for changing their certification process.\nQ: How does AV-TEST's testing process help to protect the privacy of users?",
    "context": "",
    "output": "AV-TEST's testing process can help protect the privacy of users by evaluating the software's ability to detect and remove malware that may compromise user privacy and by evaluating the software's usability, which can help ensure that users can effectively use the software to protect their privacy.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does AV-TEST's testing process help to protect the privacy of users?",
      "answer": "AV-TEST's testing process can help protect the privacy of users by evaluating the software's ability to detect and remove malware that may compromise user privacy and by evaluating the software's usability, which can help ensure that users can effectively use the software to protect their privacy.",
      "context": "AV-TEST\n\n==Introduction==\nAV-TEST is an independent organization which evaluates and rates antivirus and security suite software for Microsoft Windows, MacOS and Android operating systems, according to a variety of criteria. The organisation is based in Magdeburg, Germany.Every other month, the researchers publish the results of their testing, where they list which products they awarded their certification. They regularly test antivirus, anti-spyware and firewall software for the software publishers and for magazines. In the field of product certification they work together with Tekit Consult Bonn GmbH (T\u00dcV Saarland group).\nThe tests are performed on desktop computers and servers running Windows 98, ME, NT 4, 2000, XP, 2003; Novell NetWare, Linux, Solaris, FreeBSD, OpenBSD, Lotus Domino/Notes and Microsoft Exchange.\n\n\n\n== Criticism ==\nIn 2013, the security specialist and CEO of IT security company Kaspersky Lab, Eugene Kaspersky, criticized AV-TEST for changing their certification process."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the topological quantum computer and how does it address the stability-decoherence problem?",
    "context": "",
    "output": "The topological quantum computer is a proposed approach to the stability-decoherence problem that relies on the use of anyons, quasi-particles used as threads, and braid theory to form stable logic gates.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the topological quantum computer and how does it address the stability-decoherence problem?",
      "answer": "The topological quantum computer is a proposed approach to the stability-decoherence problem that relies on the use of anyons, quasi-particles used as threads, and braid theory to form stable logic gates."
    }
  },
  {
    "instruction": "Write an answer to the following question: What security measures did Dream Market have in place for its users' accounts?",
    "context": "",
    "output": "Dream Market operated on a hidden service of the Tor network, allowing users to browse anonymously and securely. The marketplace also provided an escrow service for secure transactions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What security measures did Dream Market have in place for its users' accounts?",
      "answer": "Dream Market operated on a hidden service of the Tor network, allowing users to browse anonymously and securely. The marketplace also provided an escrow service for secure transactions."
    }
  },
  {
    "instruction": "Context: Trusted Network Connect\n\n==Introduction==\nTrusted Network Connect (TNC) is an open architecture for Network Access Control, promulgated by the Trusted Network Connect Work Group (TNC-WG) of the Trusted Computing Group (TCG).\n\n== Specifications ==\nSpecifications introduced by the TNC Work Group:\nTNC Architecture for Interoperability\nIF-IMC - Integrity Measurement Collector Interface\nIF-IMV - Integrity Measurement Verifier Interface\nIF-TNCCS - Trusted Network Connect Client-Server Interface\nIF-M - Vendor-Specific IMC/IMV Messages Interface\nIF-T - Network Authorization Transport Interface\nIF-PEP - Policy Enforcement Point Interface\nIF-MAP - Metadata Access Point Interface\nCESP - Clientless Endpoint Support Profile\nFederated TNC\n\n== TNC Vendor Adoption ==\nA partial list of vendors who have adopted TNC Standards:\n\nAlso, networking by \n\nCisco\nHP\nSymantec\nTrapeze Networks\nTofino\n\n== TNC Customer Adoption ==\nThe U.S. Army has planned to use this technology to enhance the security of its computer networks.The South Carolina Department of Probation, Parole, and Pardon Services has tested a TNC-SCAP integration combination in a pilot program.\nAnswer this question: What is the Network Authorization Transport Interface (IF-T) and what is its role in Trusted Network Connect?",
    "context": "",
    "output": "The Network Authorization Transport Interface (IF-T) is a specification introduced by the TNC Work Group that defines how Trusted Network Connect handles network authorization and communication between different Trusted Network Connect components.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Network Authorization Transport Interface (IF-T) and what is its role in Trusted Network Connect?",
      "answer": "The Network Authorization Transport Interface (IF-T) is a specification introduced by the TNC Work Group that defines how Trusted Network Connect handles network authorization and communication between different Trusted Network Connect components.",
      "context": "Trusted Network Connect\n\n==Introduction==\nTrusted Network Connect (TNC) is an open architecture for Network Access Control, promulgated by the Trusted Network Connect Work Group (TNC-WG) of the Trusted Computing Group (TCG).\n\n== Specifications ==\nSpecifications introduced by the TNC Work Group:\nTNC Architecture for Interoperability\nIF-IMC - Integrity Measurement Collector Interface\nIF-IMV - Integrity Measurement Verifier Interface\nIF-TNCCS - Trusted Network Connect Client-Server Interface\nIF-M - Vendor-Specific IMC/IMV Messages Interface\nIF-T - Network Authorization Transport Interface\nIF-PEP - Policy Enforcement Point Interface\nIF-MAP - Metadata Access Point Interface\nCESP - Clientless Endpoint Support Profile\nFederated TNC\n\n== TNC Vendor Adoption ==\nA partial list of vendors who have adopted TNC Standards:\n\nAlso, networking by \n\nCisco\nHP\nSymantec\nTrapeze Networks\nTofino\n\n== TNC Customer Adoption ==\nThe U.S. Army has planned to use this technology to enhance the security of its computer networks.The South Carolina Department of Probation, Parole, and Pardon Services has tested a TNC-SCAP integration combination in a pilot program."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which Linux distributions ship firewalld by default, and is it enabled by default in these distributions?",
    "context": "",
    "output": "firewalld ships by default on the following Linux distributions: CentOS 7 and newer, Fedora 18 and newer, OpenSUSE Leap 15 and newer, Red Hat Enterprise Linux 7 and newer, SUSE Linux Enterprise 15 and newer, and EndeavourOS Apollo and newer. firewalld is enabled by default in all of these distributions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which Linux distributions ship firewalld by default, and is it enabled by default in these distributions?",
      "answer": "firewalld ships by default on the following Linux distributions: CentOS 7 and newer, Fedora 18 and newer, OpenSUSE Leap 15 and newer, Red Hat Enterprise Linux 7 and newer, SUSE Linux Enterprise 15 and newer, and EndeavourOS Apollo and newer. firewalld is enabled by default in all of these distributions."
    }
  },
  {
    "instruction": "context: Cryptocat ensures the security of messages in transit by using TLS (Transport Layer Security) to encrypt the communication between the client and the server, making it difficult for an attacker to intercept and read the messages.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does Cryptocat ensure the security of messages in transit?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Cryptocat ensure the security of messages in transit?",
      "answer": "Cryptocat ensures the security of messages in transit by using TLS (Transport Layer Security) to encrypt the communication between the client and the server, making it difficult for an attacker to intercept and read the messages."
    }
  },
  {
    "instruction": "context: Predictable serial numbers were used as a part of the counterfeit MD5 certificate attack by exploiting the weaknesses in the MD5 hash function. The attackers were able to generate a collision, where two different sets of data produced the same hash value. This allowed them to create counterfeit digital certificates that appeared to be legitimate, but were actually fraudulent.\n\nAsk a question about this context.",
    "context": "",
    "output": "How were predictable serial numbers used in the counterfeit MD5 certificate attack?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How were predictable serial numbers used in the counterfeit MD5 certificate attack?",
      "answer": "Predictable serial numbers were used as a part of the counterfeit MD5 certificate attack by exploiting the weaknesses in the MD5 hash function. The attackers were able to generate a collision, where two different sets of data produced the same hash value. This allowed them to create counterfeit digital certificates that appeared to be legitimate, but were actually fraudulent."
    }
  },
  {
    "instruction": "Group-based cryptography\n\n==Introduction==\nGroup-based cryptography is a use of groups to construct cryptographic primitives.  A group is a very general algebraic object and most cryptographic schemes use groups in some way. In particular Diffie\u2013Hellman key exchange uses finite cyclic groups.  So the term group-based cryptography refers mostly to cryptographic protocols that use infinite nonabelian groups such as a braid group.\n\n== Examples ==\nShpilrain\u2013Zapata public-key protocols\nMagyarik\u2013Wagner public key protocol\nAnshel\u2013Anshel\u2013Goldfeld key exchange\nKo\u2013Lee et al. key exchange protocol\nQ: What is the purpose of using groups in cryptographic schemes?",
    "context": "",
    "output": "Groups are used in cryptographic schemes as a way to provide mathematical structure and security. They allow for the creation of complex mathematical problems that are difficult to solve, which is essential for the security of many cryptographic protocols.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of using groups in cryptographic schemes?",
      "answer": "Groups are used in cryptographic schemes as a way to provide mathematical structure and security. They allow for the creation of complex mathematical problems that are difficult to solve, which is essential for the security of many cryptographic protocols.",
      "context": "Group-based cryptography\n\n==Introduction==\nGroup-based cryptography is a use of groups to construct cryptographic primitives.  A group is a very general algebraic object and most cryptographic schemes use groups in some way. In particular Diffie\u2013Hellman key exchange uses finite cyclic groups.  So the term group-based cryptography refers mostly to cryptographic protocols that use infinite nonabelian groups such as a braid group.\n\n== Examples ==\nShpilrain\u2013Zapata public-key protocols\nMagyarik\u2013Wagner public key protocol\nAnshel\u2013Anshel\u2013Goldfeld key exchange\nKo\u2013Lee et al. key exchange protocol"
    }
  },
  {
    "instruction": "context: The TE access matrix in SELinux contains rules about clearance granted to a given security context, which is used to determine access to objects.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the TE access matrix determine clearance in SELinux?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the TE access matrix determine clearance in SELinux?",
      "answer": "The TE access matrix in SELinux contains rules about clearance granted to a given security context, which is used to determine access to objects."
    }
  },
  {
    "instruction": "context: The two types of failure for facial recognition tests are false positives, where the database matches the image with a data set but not the data set of the actual user's image, and false negatives, where the database fails to recognize the face of the correct user.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are the two types of failure for facial recognition tests?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the two types of failure for facial recognition tests?",
      "answer": "The two types of failure for facial recognition tests are false positives, where the database matches the image with a data set but not the data set of the actual user's image, and false negatives, where the database fails to recognize the face of the correct user."
    }
  },
  {
    "instruction": "context: Wireshark is a free and open-source packet analyzer used for network troubleshooting, analysis, software and communications protocol development, and education. It can be used to capture, parse, and display the fields of different networking protocols, and can be run on various platforms including Linux, macOS, BSD, Solaris, and Microsoft Windows.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is Wireshark and what is it used for?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is Wireshark and what is it used for?",
      "answer": "Wireshark is a free and open-source packet analyzer used for network troubleshooting, analysis, software and communications protocol development, and education. It can be used to capture, parse, and display the fields of different networking protocols, and can be run on various platforms including Linux, macOS, BSD, Solaris, and Microsoft Windows."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Evil Twin attack use manipulation?",
    "context": "",
    "output": "The Evil Twin attack uses manipulation by forcing users to use the snarf \"splash page\" in order to access the internet. This increases the likelihood that users will enter their credentials, which can then be captured by the attacker.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Evil Twin attack use manipulation?",
      "answer": "The Evil Twin attack uses manipulation by forcing users to use the snarf \"splash page\" in order to access the internet. This increases the likelihood that users will enter their credentials, which can then be captured by the attacker."
    }
  },
  {
    "instruction": "context: Automated tools are discouraged for analyzing HijackThis logs as they are not accurate or reliable enough to substitute for consulting with a trained human analyst, and can be dangerous for inexperienced users.\n\nAsk a question about this context.",
    "context": "",
    "output": "Why are automated tools discouraged for analyzing HijackThis logs?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why are automated tools discouraged for analyzing HijackThis logs?",
      "answer": "Automated tools are discouraged for analyzing HijackThis logs as they are not accurate or reliable enough to substitute for consulting with a trained human analyst, and can be dangerous for inexperienced users."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which American companies were targeted by NoName057(16) and what was the impact of their attack on the ITT company?",
    "context": "",
    "output": "NoName057(16) carried out attacks on the websites of American companies from various fields of activity. As a result of one of these attacks, the website of the ITT company ceased to be available to users for a long time.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which American companies were targeted by NoName057(16) and what was the impact of their attack on the ITT company?",
      "answer": "NoName057(16) carried out attacks on the websites of American companies from various fields of activity. As a result of one of these attacks, the website of the ITT company ceased to be available to users for a long time."
    }
  },
  {
    "instruction": "Capsicum (Unix)\n\n==Introduction==\nCapsicum is an implementation of capability-based security for UNIX and similar systems. Presented at USENIX 2010, the system is part of FreeBSD since its 9.0 release. It has also been adapted to DragonflyBSD in the form of kernel patches.The system works by chunking the normal permissions up into very small pieces. When a process enters capsicum mode, it loses all permissions normally associated with its controlling user, with the exception of \"capabilities\" it already has in the form of file descriptors. A process can also receive capabilities via Unix sockets. These file descriptors not only control access to the file system, but also to other devices like the network sockets. Flags are also used to control more fine-grained access like reads and writes.\n\n\n\n== CloudABI ==\nCloudABI is an application binary interface based on capsicum. It keeps the overall capsicum permission model, but uses it to redesign a simplified environment for processes (system calls, C library, etc.) to run on, so that programs become portable to any platform supporting the ABI on the same instruction set architecture. The interface it offers is roughly POSIX minus parts that do not work with capability-based security. As of March 2020, CloudABI is natively a part of FreeBSD, and it can be run on other systems either via a Capsicum-based patch or using a non-secure system call emulator.As of October 2020, CloudABI has been deprecated in favor of WebAssembly System Interface for lack of interest.\n\nBased on the above text, answer a question. How does Capsicum enhance the security of file system access?",
    "context": "",
    "output": "In Capsicum, when a process enters capsicum mode, it loses all permissions normally associated with its controlling user, with the exception of \"capabilities\" it already has in the form of file descriptors. These file descriptors control access to the file system, enhancing the security of file system access.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Capsicum enhance the security of file system access?",
      "answer": "In Capsicum, when a process enters capsicum mode, it loses all permissions normally associated with its controlling user, with the exception of \"capabilities\" it already has in the form of file descriptors. These file descriptors control access to the file system, enhancing the security of file system access.",
      "context": "Capsicum (Unix)\n\n==Introduction==\nCapsicum is an implementation of capability-based security for UNIX and similar systems. Presented at USENIX 2010, the system is part of FreeBSD since its 9.0 release. It has also been adapted to DragonflyBSD in the form of kernel patches.The system works by chunking the normal permissions up into very small pieces. When a process enters capsicum mode, it loses all permissions normally associated with its controlling user, with the exception of \"capabilities\" it already has in the form of file descriptors. A process can also receive capabilities via Unix sockets. These file descriptors not only control access to the file system, but also to other devices like the network sockets. Flags are also used to control more fine-grained access like reads and writes.\n\n\n\n== CloudABI ==\nCloudABI is an application binary interface based on capsicum. It keeps the overall capsicum permission model, but uses it to redesign a simplified environment for processes (system calls, C library, etc.) to run on, so that programs become portable to any platform supporting the ABI on the same instruction set architecture. The interface it offers is roughly POSIX minus parts that do not work with capability-based security. As of March 2020, CloudABI is natively a part of FreeBSD, and it can be run on other systems either via a Capsicum-based patch or using a non-secure system call emulator.As of October 2020, CloudABI has been deprecated in favor of WebAssembly System Interface for lack of interest."
    }
  },
  {
    "instruction": "Write an answer to the following question: What security features does Safetica provide for external devices?",
    "context": "",
    "output": "Safetica provides external device management, which controls and manages the usage of various external devices, such as USBs, CD/DVDs, and FireWire. This ensures that sensitive data cannot be transferred or copied to these devices without proper authorization, thereby preventing potential data leaks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What security features does Safetica provide for external devices?",
      "answer": "Safetica provides external device management, which controls and manages the usage of various external devices, such as USBs, CD/DVDs, and FireWire. This ensures that sensitive data cannot be transferred or copied to these devices without proper authorization, thereby preventing potential data leaks."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the challenges of protecting sensitive information in the digital age?",
    "context": "",
    "output": "The digital age has brought about a number of challenges to protecting sensitive information. The increasing amounts of sensitive information being stored and transmitted through digital means has made it more vulnerable to attack. Additionally, the cultural shifts in perception towards political and government secrecy have added an additional layer of complexity to protecting classified information. The ever-evolving arms race between those who exploit existing vulnerabilities in security systems and those who must then engineer new mechanisms of security is a significant challenge.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the challenges of protecting sensitive information in the digital age?",
      "answer": "The digital age has brought about a number of challenges to protecting sensitive information. The increasing amounts of sensitive information being stored and transmitted through digital means has made it more vulnerable to attack. Additionally, the cultural shifts in perception towards political and government secrecy have added an additional layer of complexity to protecting classified information. The ever-evolving arms race between those who exploit existing vulnerabilities in security systems and those who must then engineer new mechanisms of security is a significant challenge."
    }
  },
  {
    "instruction": "Answer based on context:\n\nRicochet (software)\n\n==Introduction==\nRicochet or Ricochet IM is a free software, multi-platform, instant messaging software project originally developed by John Brooks and later adopted as the official instant messaging client project of the Invisible.im group. A goal of the Invisible.im group is to help people maintain privacy by developing a \"metadata free\" instant messaging client.\n\n== Technology ==\nRicochet is a decentralized instant messenger, meaning there is no server to connect to and share metadata with. Further, using Tor, Ricochet starts a Tor hidden service locally on a person's computer and can communicate only with other Ricochet users who are also running their own Ricochet-created Tor hidden services. This way, Ricochet communication never leaves the Tor network. A user screen name (example: ricochet:hslmfsg47dmcqctb) is auto-generated upon first starting Ricochet; the first half of the screen name is the word \"ricochet\", with the second half being the address of the Tor hidden service. Before two Ricochet users can talk, at least one of them must privately or publicly share their unique screen name in some way.\n\n== Privacy benefits ==\nRicochet does not reveal user IP addresses or physical locations because it uses Tor.\nMessage content is cryptographically authenticated and private.\nThere is no need to register anywhere in order to use Ricochet, particularly with a fixed server.\nContact list information is stored locally, and it would be very difficult for passive surveillance techniques to determine whom the user is chatting with.\nRicochet does not save chat history. When the user closes a conversation, the chat log is not recoverable.\nThe use of Tor hidden services prevents network traffic from ever leaving the Tor network, thereby preserving anonymity and complicating passive network surveillance.\nRicochet is a portable application, users do not need to install any software to use Ricochet. Ricochet connects to the Tor network automatically.\n\nWhat measures does Ricochet take to protect user metadata?",
    "context": "",
    "output": "Ricochet uses a decentralized infrastructure, Tor hidden services, and local contact list storage to ensure user metadata, such as IP addresses and physical locations, remains private.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What measures does Ricochet take to protect user metadata?",
      "answer": "Ricochet uses a decentralized infrastructure, Tor hidden services, and local contact list storage to ensure user metadata, such as IP addresses and physical locations, remains private.",
      "context": "Ricochet (software)\n\n==Introduction==\nRicochet or Ricochet IM is a free software, multi-platform, instant messaging software project originally developed by John Brooks and later adopted as the official instant messaging client project of the Invisible.im group. A goal of the Invisible.im group is to help people maintain privacy by developing a \"metadata free\" instant messaging client.\n\n== Technology ==\nRicochet is a decentralized instant messenger, meaning there is no server to connect to and share metadata with. Further, using Tor, Ricochet starts a Tor hidden service locally on a person's computer and can communicate only with other Ricochet users who are also running their own Ricochet-created Tor hidden services. This way, Ricochet communication never leaves the Tor network. A user screen name (example: ricochet:hslmfsg47dmcqctb) is auto-generated upon first starting Ricochet; the first half of the screen name is the word \"ricochet\", with the second half being the address of the Tor hidden service. Before two Ricochet users can talk, at least one of them must privately or publicly share their unique screen name in some way.\n\n== Privacy benefits ==\nRicochet does not reveal user IP addresses or physical locations because it uses Tor.\nMessage content is cryptographically authenticated and private.\nThere is no need to register anywhere in order to use Ricochet, particularly with a fixed server.\nContact list information is stored locally, and it would be very difficult for passive surveillance techniques to determine whom the user is chatting with.\nRicochet does not save chat history. When the user closes a conversation, the chat log is not recoverable.\nThe use of Tor hidden services prevents network traffic from ever leaving the Tor network, thereby preserving anonymity and complicating passive network surveillance.\nRicochet is a portable application, users do not need to install any software to use Ricochet. Ricochet connects to the Tor network automatically."
    }
  },
  {
    "instruction": "Network Security Services\n\n==Introduction==\nNetwork Security Services (NSS) is a collection of cryptographic computer libraries designed to support cross-platform development of security-enabled client and server applications with optional support for hardware TLS/SSL acceleration on the server side and hardware smart cards on the client side. NSS provides a complete open-source implementation of cryptographic libraries supporting Transport Layer Security (TLS) / Secure Sockets Layer (SSL) and S/MIME. NSS releases prior to version 3.14 are tri-licensed under the Mozilla Public License 1.1, the GNU General Public License, and the GNU Lesser General Public License. Since release 3.14, NSS releases are licensed under GPL-compatible Mozilla Public License 2.0.\n\n\n\n== Applications that use NSS ==\nAOL, Red Hat, Sun Microsystems/Oracle Corporation, Google and other companies and individual contributors have co-developed NSS. Mozilla provides the source code repository, bug tracking system, and infrastructure for mailing lists and discussion groups. They and others named below use NSS in a variety of products, including the following:\n\nMozilla client products, including Firefox, Thunderbird, SeaMonkey, and Firefox for mobile.\nAOL Communicator and AOL Instant Messenger (AIM)\nOpen source client applications such as Evolution, Pidgin, and OpenOffice.org 2.0 onward (and its descendants).\nServer products from Red Hat: Red Hat Directory Server, Red Hat Certificate System, and the mod nss SSL module for the Apache web server.\nSun server products from the Sun Java Enterprise System, including Sun Java System Web Server, Sun Java System Directory Server, Sun Java System Portal Server, Sun Java System Messaging Server, and Sun Java System Application Server, open source version of Directory Server OpenDS.\nLibreswan IKE/IPsec requires NSS. It is a fork of Openswan which could optionally use NSS.\n\n== Architecture ==\nNSS includes a framework to which developers and OEMs can contribute patches, such as assembly code, to optimize performance on their platforms. Mozilla has certified NSS 3.x on 18 platforms. NSS makes use of Netscape Portable Runtime (NSPR), a platform-neutral open-source API for system functions designed to facilitate cross-platform development. Like NSS, NSPR has been used heavily in multiple products.\n\n\n*** Software development kit ***\nIn addition to libraries and APIs, NSS provides security tools required for debugging, diagnostics, certificate and key management, cryptography-module management, and other development tasks. NSS comes with an extensive and growing set of documentation, including introductory material, API references, man pages for command-line tools, and sample code.\nProgrammers can utilize NSS as source and as shared (dynamic) libraries. Every NSS release is backward-compatible with previous releases, allowing NSS users to upgrade to new NSS shared libraries without recompiling or relinking their applications.\n\n\n*** Interoperability and open standards ***\nNSS supports a range of security standards, including the following:\nTLS 1.0 (RFC 2246), 1.1 (RFC 4346), 1.2 (RFC 5246), and 1.3 (RFC 8446). The Transport Layer Security (TLS) protocol from the IETF supersedes SSL v3.0 while remaining backward-compatible with SSL v3 implementations.\nSSL 3.0. The Secure Sockets Layer (SSL) protocol allows mutual authentication between a client and server and the establishment of an authenticated and encrypted connection.\nDTLS 1.0 (RFC 4347) and 1.2 (RFC 6347).\nDTLS-SRTP (RFC 5764).\nThe following PKCS standards:\nPKCS #1. RSA standard that governs implementation of public-key cryptography based on the RSA algorithm.\nPKCS #3. RSA standard that governs implementation of Diffie\u2013Hellman key agreement.\nPKCS #5. RSA standard that governs password-based cryptography, for example to encrypt private keys for storage.\nPKCS #7. RSA standard that governs the application of cryptography to data, for example digital signatures and digital envelopes.\nPKCS #8. RSA standard that governs the storage and encryption of private keys.\nPKCS #9. RSA standard that governs selected attribute types, including those used with PKCS #7, PKCS #8, and PKCS #10.\nPKCS #10. RSA standard that governs the syntax for certificate requests.\nPKCS #11. RSA standard that governs communication with cryptographic tokens (such as hardware accelerators and smart cards) and permits application independence from specific algorithms and implementations.\nPKCS #12. RSA standard that governs the format used to store or transport private keys, certificates, and other secret material.\nCryptographic Message Syntax, used in S/MIME (RFC 2311 and RFC 2633). IETF message specification (based on the popular Internet MIME standard) that provides a consistent way to send and receive signed and encrypted MIME data.\nX.509 v3. ITU standard that governs the format of certificates used for authentication in public-key cryptography.\nOCSP (RFC 2560). The Online Certificate Status Protocol (OCSP) governs real-time confirmation of certificate validity.\nPKIX Certificate and CRL Profile (RFC 3280). The first part of the four-part standard under development by the Public-Key Infrastructure (X.509) working group of the IETF (known as PKIX) for a public-key infrastructure for the Internet.\nRSA, DSA, ECDSA, Diffie\u2013Hellman, EC Diffie\u2013Hellman, AES, Triple DES, Camellia, IDEA, SEED, DES, RC2, RC4, SHA-1, SHA-256, SHA-384, SHA-512, MD2, MD5, HMAC: Common cryptographic algorithms used in public-key and symmetric-key cryptography.\nFIPS 186-2 pseudorandom number generator.\n\n\n*** Hardware support ***\nNSS supports the PKCS #11 interface for access to  cryptographic hardware like TLS/SSL accelerators, hardware security modules and smart cards. Since most hardware vendors such as SafeNet, AEP and Thales also support this interface, NSS-enabled applications can work with high-speed crypto hardware and use private keys residing on various smart cards, if vendors provide the necessary middleware. NSS version 3.13 and above support the Advanced Encryption Standard New Instructions (AES-NI).\n\n\n*** Java support ***\nNetwork Security Services for Java (JSS) consists of a Java interface to NSS. It supports most of the security standards and encryption technologies supported by NSS. JSS also provides a pure Java interface for ASN.1 types and BER/DER encoding.\nQ: What is the role of NSPR in NSS?",
    "context": "",
    "output": "NSPR, or Netscape Portable Runtime, is a platform-neutral open-source API for system functions that NSS uses to facilitate cross-platform development.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of NSPR in NSS?",
      "answer": "NSPR, or Netscape Portable Runtime, is a platform-neutral open-source API for system functions that NSS uses to facilitate cross-platform development.",
      "context": "Network Security Services\n\n==Introduction==\nNetwork Security Services (NSS) is a collection of cryptographic computer libraries designed to support cross-platform development of security-enabled client and server applications with optional support for hardware TLS/SSL acceleration on the server side and hardware smart cards on the client side. NSS provides a complete open-source implementation of cryptographic libraries supporting Transport Layer Security (TLS) / Secure Sockets Layer (SSL) and S/MIME. NSS releases prior to version 3.14 are tri-licensed under the Mozilla Public License 1.1, the GNU General Public License, and the GNU Lesser General Public License. Since release 3.14, NSS releases are licensed under GPL-compatible Mozilla Public License 2.0.\n\n\n\n== Applications that use NSS ==\nAOL, Red Hat, Sun Microsystems/Oracle Corporation, Google and other companies and individual contributors have co-developed NSS. Mozilla provides the source code repository, bug tracking system, and infrastructure for mailing lists and discussion groups. They and others named below use NSS in a variety of products, including the following:\n\nMozilla client products, including Firefox, Thunderbird, SeaMonkey, and Firefox for mobile.\nAOL Communicator and AOL Instant Messenger (AIM)\nOpen source client applications such as Evolution, Pidgin, and OpenOffice.org 2.0 onward (and its descendants).\nServer products from Red Hat: Red Hat Directory Server, Red Hat Certificate System, and the mod nss SSL module for the Apache web server.\nSun server products from the Sun Java Enterprise System, including Sun Java System Web Server, Sun Java System Directory Server, Sun Java System Portal Server, Sun Java System Messaging Server, and Sun Java System Application Server, open source version of Directory Server OpenDS.\nLibreswan IKE/IPsec requires NSS. It is a fork of Openswan which could optionally use NSS.\n\n== Architecture ==\nNSS includes a framework to which developers and OEMs can contribute patches, such as assembly code, to optimize performance on their platforms. Mozilla has certified NSS 3.x on 18 platforms. NSS makes use of Netscape Portable Runtime (NSPR), a platform-neutral open-source API for system functions designed to facilitate cross-platform development. Like NSS, NSPR has been used heavily in multiple products.\n\n\n*** Software development kit ***\nIn addition to libraries and APIs, NSS provides security tools required for debugging, diagnostics, certificate and key management, cryptography-module management, and other development tasks. NSS comes with an extensive and growing set of documentation, including introductory material, API references, man pages for command-line tools, and sample code.\nProgrammers can utilize NSS as source and as shared (dynamic) libraries. Every NSS release is backward-compatible with previous releases, allowing NSS users to upgrade to new NSS shared libraries without recompiling or relinking their applications.\n\n\n*** Interoperability and open standards ***\nNSS supports a range of security standards, including the following:\nTLS 1.0 (RFC 2246), 1.1 (RFC 4346), 1.2 (RFC 5246), and 1.3 (RFC 8446). The Transport Layer Security (TLS) protocol from the IETF supersedes SSL v3.0 while remaining backward-compatible with SSL v3 implementations.\nSSL 3.0. The Secure Sockets Layer (SSL) protocol allows mutual authentication between a client and server and the establishment of an authenticated and encrypted connection.\nDTLS 1.0 (RFC 4347) and 1.2 (RFC 6347).\nDTLS-SRTP (RFC 5764).\nThe following PKCS standards:\nPKCS #1. RSA standard that governs implementation of public-key cryptography based on the RSA algorithm.\nPKCS #3. RSA standard that governs implementation of Diffie\u2013Hellman key agreement.\nPKCS #5. RSA standard that governs password-based cryptography, for example to encrypt private keys for storage.\nPKCS #7. RSA standard that governs the application of cryptography to data, for example digital signatures and digital envelopes.\nPKCS #8. RSA standard that governs the storage and encryption of private keys.\nPKCS #9. RSA standard that governs selected attribute types, including those used with PKCS #7, PKCS #8, and PKCS #10.\nPKCS #10. RSA standard that governs the syntax for certificate requests.\nPKCS #11. RSA standard that governs communication with cryptographic tokens (such as hardware accelerators and smart cards) and permits application independence from specific algorithms and implementations.\nPKCS #12. RSA standard that governs the format used to store or transport private keys, certificates, and other secret material.\nCryptographic Message Syntax, used in S/MIME (RFC 2311 and RFC 2633). IETF message specification (based on the popular Internet MIME standard) that provides a consistent way to send and receive signed and encrypted MIME data.\nX.509 v3. ITU standard that governs the format of certificates used for authentication in public-key cryptography.\nOCSP (RFC 2560). The Online Certificate Status Protocol (OCSP) governs real-time confirmation of certificate validity.\nPKIX Certificate and CRL Profile (RFC 3280). The first part of the four-part standard under development by the Public-Key Infrastructure (X.509) working group of the IETF (known as PKIX) for a public-key infrastructure for the Internet.\nRSA, DSA, ECDSA, Diffie\u2013Hellman, EC Diffie\u2013Hellman, AES, Triple DES, Camellia, IDEA, SEED, DES, RC2, RC4, SHA-1, SHA-256, SHA-384, SHA-512, MD2, MD5, HMAC: Common cryptographic algorithms used in public-key and symmetric-key cryptography.\nFIPS 186-2 pseudorandom number generator.\n\n\n*** Hardware support ***\nNSS supports the PKCS #11 interface for access to  cryptographic hardware like TLS/SSL accelerators, hardware security modules and smart cards. Since most hardware vendors such as SafeNet, AEP and Thales also support this interface, NSS-enabled applications can work with high-speed crypto hardware and use private keys residing on various smart cards, if vendors provide the necessary middleware. NSS version 3.13 and above support the Advanced Encryption Standard New Instructions (AES-NI).\n\n\n*** Java support ***\nNetwork Security Services for Java (JSS) consists of a Java interface to NSS. It supports most of the security standards and encryption technologies supported by NSS. JSS also provides a pure Java interface for ASN.1 types and BER/DER encoding."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the \"gettens\" commercially hosted web site differ from the official Department of Defense web site?",
    "context": "",
    "output": "The \"gettens\" web site was originally established to provide instructions on how to configure a web browser to work with the official Department of Defense web site. However, in 2023, the \"gettens\" web site was repurposed to actually host Encryption Wizard, while the official web site was shut down.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the \"gettens\" commercially hosted web site differ from the official Department of Defense web site?",
      "answer": "The \"gettens\" web site was originally established to provide instructions on how to configure a web browser to work with the official Department of Defense web site. However, in 2023, the \"gettens\" web site was repurposed to actually host Encryption Wizard, while the official web site was shut down."
    }
  },
  {
    "instruction": "context: Intel and AMD are not planning to release microcode patches for the Hertzbleed vulnerability, instead advising to harden cryptography libraries against the vulnerability.\n\nAsk a question about this context.",
    "context": "",
    "output": "Is there a plan to release microcode patches for the Hertzbleed vulnerability?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is there a plan to release microcode patches for the Hertzbleed vulnerability?",
      "answer": "Intel and AMD are not planning to release microcode patches for the Hertzbleed vulnerability, instead advising to harden cryptography libraries against the vulnerability."
    }
  },
  {
    "instruction": "Context: BGP hijacking\n\n==Introduction==\nBGP hijacking (sometimes referred to as prefix hijacking, route hijacking or IP hijacking) is the illegitimate takeover of groups of IP addresses by corrupting Internet routing tables maintained using the Border Gateway Protocol (BGP).\n\n== Background ==\nThe Internet is a global network in enabling any connected host, identified by its unique IP address, to talk to any other, anywhere in the world.  This is achieved by passing data from one router to another, repeatedly moving each packet closer to its destination, until it is hopefully delivered.  To do this, each router must be regularly supplied with up-to-date routing tables.  At the global level, individual IP addresses are grouped together into prefixes.  These prefixes will be originated, or owned, by an autonomous system (AS) and the routing tables between ASes are maintained using the Border Gateway Protocol (BGP).\nA group of networks that operates under a single external routing policy is known as an autonomous system.  For example, Sprint, Verizon, and AT&T each are an AS.  Each AS has its own unique AS identifier number. BGP is the standard routing protocol used to exchange information about IP routing between autonomous systems.\nEach AS uses BGP to advertise prefixes that it can deliver traffic to.  For example, if the network prefix 192.0.2.0/24 is inside AS 64496, then that AS will advertise to its provider(s) and/or peer(s) that it can deliver any traffic destined for 192.0.2.0/24.\nAlthough security extensions are available for BGP, and third-party route DB resources exist for validating routes, by default the BGP protocol is designed to trust all route announcements sent by peers, and few ISPs rigorously enforce checks on BGP sessions.\n\n== Mechanism ==\nIP hijacking can occur deliberately or by accident in one of several ways:\n\nAn AS announces that it originates a prefix that it does not actually originate.\nAn AS announces a more specific prefix than what may be announced by the true originating AS.\nAn AS announces that it can route traffic to the hijacked AS through a shorter route than is already available, regardless of whether or not the route actually exists.Common to these ways is their disruption of the normal routing of the network: packets end up being forwarded towards the wrong part of the network and then either enter an endless loop (and are discarded), or are found at the mercy of the offending AS.\nTypically ISPs filter BGP traffic, allowing BGP advertisements from their downstream networks to contain only valid IP space.  However, a history of hijacking incidents shows this is not always the case.\nThe Resource Public Key Infrastructure (RPKI) is designed to authenticate route origins via cryptographic certificate chains demonstrating address block range ownership, but is not widely deployed yet.  Once deployed, IP hijacking through errant issues at the origin (via both accident or intent) should be detectable and filterable.\nIP hijacking is sometimes used by malicious users to obtain IP addresses for use in spamming or a distributed denial-of-service (DDoS) attack.\nWhen a router promulgates flawed BGP routing information, whether that action is intentional or accidental, it is defined by the Internet Engineering Task Force (IETF) in RFC 7908 as a \"route leak\". Such leaks are described as \"the propagation of routing announcement(s) beyond their intended scope. That is, an announcement from an Autonomous System (AS) of a learned BGP route to another AS is in violation of the intended policies of the receiver, the sender, and/or one of the ASes along the preceding AS path.\" Such leaks are possible because of a long-standing \"\u2026systemic vulnerability of the Border Gateway Protocol routing system\u2026\"\n\n== BGP hijacking and transit-AS problems ==\nLike the TCP reset attack, session hijacking involves intrusion into an ongoing BGP session, i.e., the attacker successfully masquerades as one of the peers in a BGP session, and requires the same information needed to accomplish the reset attack. The difference is that a session hijacking attack may be designed to achieve more than simply bringing down a session between BGP peers. For example, the objective may be to change routes used by the peer, in order to facilitate eavesdropping, black holing, or traffic analysis.\nBy default EBGP peers will attempt to add all routes received by another peer into the device's routing table and will then attempt to advertise nearly all of these routes to other EBGP peers.  This can be a problem as multi-homed organizations can inadvertently advertise prefixes learned from one AS to another, causing the end customer to become the new, best-path to the prefixes in question.  For example, a customer with a Cisco router peering with say AT&T and Verizon and using no filtering will automatically attempt to link the two major carriers, which could cause the providers to prefer sending some or all traffic through the customer (on perhaps a T1), instead of using high-speed dedicated links.  This problem can further affect others that peer with these two providers and also cause those ASs to prefer the misconfigured link.  In reality, this problem hardly ever occurs with large ISPs, as these ISPs tend to restrict what an end customer can advertise.  However,  any ISP not filtering customer advertisements can allow errant information to be advertised into the global routing table where it can affect even the large Tier-1 providers.\nThe concept of BGP hijacking revolves around locating an ISP that is not filtering advertisements (intentionally or otherwise) or locating an ISP whose internal or ISP-to-ISP BGP session is susceptible to a man-in-the-middle attack.  Once located, an attacker can potentially advertise any prefix they want, causing some or all traffic to be diverted from the real source towards the attacker.  This can be done either to overload the ISP the attacker has infiltrated, or to perform a DoS or impersonation attack on the entity whose prefix is being advertised.  It is not uncommon for an attacker to cause serious outages, up to and including a complete loss of connectivity.  In early 2008, at least eight US Universities had their traffic diverted to Indonesia for about 90 minutes one morning in an attack kept mostly quiet by those involved.  Also, in February 2008, a large portion of YouTube's address space was redirected to Pakistan when the PTA decided to block access to the site from inside the country, but accidentally blackholed the route in the global BGP table.\nWhile filtering and MD5/TTL protection is already available for most BGP implementations (thus preventing the source of most attacks), the problem stems from the concept that ISPs rarely ever filter advertisements from other ISPs, as there is no common or efficient way to determine the list of permissible prefixes each AS can originate.  The penalty for allowing errant information to be advertised can range from simple filtering by other/larger ISPs to a complete shutdown of the BGP session by the neighboring ISP (causing the two ISPs to cease peering), and repeated problems often end in permanent termination of all peering agreements.  It is also noteworthy that even causing a major provider to block or shutdown a smaller, problematic provider, the global BGP table will often reconfigure and reroute the traffic through other available routes until all peers take action, or until the errant ISP fixes the problem at the source.\nOne useful offshoot of this concept is called BGP anycasting and is frequently used by root DNS servers to allow multiple servers to use the same IP address, providing redundancy and a layer of protection against DoS attacks without publishing hundreds of server IP addresses.  The difference in this situation is that each point advertising a prefix actually has access to the real data (DNS in this case) and responds correctly to end user requests.\n\n== Public incidents ==\nApril 1997:  The \"AS 7007 incident\"\nDecember 24, 2004: TTNet in Turkey hijacks the Internet\nMay 7, 2005: Google's May 2005 Outage\nJanuary 22, 2006: Con Edison Communications hijacks big chunk of the Internet\nFebruary 24, 2008: Pakistan's attempt to block YouTube access within their country takes down YouTube entirely.\nNovember 11, 2008: The Brazilian ISP CTBC - Companhia de Telecomunica\u00e7\u00f5es do Brasil Central leaked their internal table into the global BGP table. It lasted over 5 minutes. Although, it was detected by a RIPE route server and then it was not propagated, affecting practically only their own ISP customers and few others.\nApril 8, 2010: Chinese ISP hijacks the Internet\nJuly 2013: The Hacking Team aided Raggruppamento Operativo Speciale (ROS - Special Operations Group of the Italian National Military police) in regaining access to Remote Access Tool (RAT) clients after they abruptly lost access to one of their control servers when the Santrex IPv4 prefix 46.166.163.0/24 became permanently unreachable. ROS and the Hacking Team worked with the Italian network operator Aruba S.p.A. (AS31034) to get the prefix announced in BGP in order to regain access to the control server.\nFebruary, 2014: Canadian ISP used to redirect data from ISPs. - In 22 incidents between February and May a hacker redirected traffic for roughly 30 seconds each session. Bitcoin and other crypto-currency mining operations were targeted and currency was stolen.\nJanuary 2017: Iranian pornography censorship.\nApril 2017: Russian telecommunication company Rostelecom (AS12389) originated 37 prefixes for numerous other Autonomous Systems. The hijacked prefixes belonged to financial institutions (most notably MasterCard and Visa), other telecom companies, and a variety of other organizations. Even though the possible hijacking lasted no more than 7 minutes it is still not clear if the traffic got intercepted or modified.\nDecember 2017: Eighty high-traffic prefixes normally announced by Google, Apple, Facebook, Microsoft, Twitch, NTT Communications, Riot Games, and others, were announced by a Russian AS, DV-LINK-AS (AS39523).\nApril 2018: Roughly 1300 IP addresses within Amazon Web Services space, dedicated to Amazon Route 53, were hijacked by eNet (or a customer thereof), an ISP in Columbus, Ohio.  Several peering partners, such as Hurricane Electric, blindly propagated the announcements.\nJuly 2018: Iran Telecommunication Company (AS58224) originated 10 prefixes of Telegram Messenger.\nNovember 2018: US-based China Telecom site originated Google addresses.\nMay 2019: Traffic to a public DNS run by Taiwan Network Information Center (TWNIC) was rerouted to an entity in Brazil (AS268869).\nJune 2019: Large European mobile traffic was rerouted through China Telecom (AS4134) \"This route leak began when [Swiss] SafeHost (AS21217) announced more than forty-thousand IPv4 routes that had been learned from other peers and providers to its provider China Telecom (AS 4134). \u2026In turn, China Telecom accepted these routes and propagated them\u2026\"\nFebruary 2021: Initially reported that Cablevision Mexico (AS28548) leaked 282 prefixes creating conflicts for 763 ASNs in 80 countries, with the main impact in Mexico. Data from the Isolario MRT dump suggested that 7,200 IPv4 prefixes were announced and leaked to AS1874 impacting more than 1290 ASNs from over 100 countries.\nApril 2021: Large BGP routing leak out of India: over 30,000 BGP prefixes hijacked via Vodafone Idea Ltd (AS55410) causing 13X spike in inbound traffic. Prefixes were from around the globe but mostly US including Google, Microsoft, Akamai, and Cloudflare.\nFebruary 2022: Attackers hijacked BGP prefixes that belonged to a South Korean cryptocurrency platform, and then issued a certificate on the domain via ZeroSSL to serve a malicious JavaScript file, stealing $1.9 million worth of cryptocurrency.\nMarch 2022: RTComm hijacked a prefix used by Twitter.\n\nQuestion: What is the impact of IP hijacking on the global BGP table?\n\nAnswer:",
    "context": "",
    "output": "IP hijacking can affect even the large Tier-1 providers by allowing errant information to be advertised into the global BGP table, where it can affect the routing of traffic and cause outages.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the impact of IP hijacking on the global BGP table?",
      "answer": "IP hijacking can affect even the large Tier-1 providers by allowing errant information to be advertised into the global BGP table, where it can affect the routing of traffic and cause outages.",
      "context": "BGP hijacking\n\n==Introduction==\nBGP hijacking (sometimes referred to as prefix hijacking, route hijacking or IP hijacking) is the illegitimate takeover of groups of IP addresses by corrupting Internet routing tables maintained using the Border Gateway Protocol (BGP).\n\n== Background ==\nThe Internet is a global network in enabling any connected host, identified by its unique IP address, to talk to any other, anywhere in the world.  This is achieved by passing data from one router to another, repeatedly moving each packet closer to its destination, until it is hopefully delivered.  To do this, each router must be regularly supplied with up-to-date routing tables.  At the global level, individual IP addresses are grouped together into prefixes.  These prefixes will be originated, or owned, by an autonomous system (AS) and the routing tables between ASes are maintained using the Border Gateway Protocol (BGP).\nA group of networks that operates under a single external routing policy is known as an autonomous system.  For example, Sprint, Verizon, and AT&T each are an AS.  Each AS has its own unique AS identifier number. BGP is the standard routing protocol used to exchange information about IP routing between autonomous systems.\nEach AS uses BGP to advertise prefixes that it can deliver traffic to.  For example, if the network prefix 192.0.2.0/24 is inside AS 64496, then that AS will advertise to its provider(s) and/or peer(s) that it can deliver any traffic destined for 192.0.2.0/24.\nAlthough security extensions are available for BGP, and third-party route DB resources exist for validating routes, by default the BGP protocol is designed to trust all route announcements sent by peers, and few ISPs rigorously enforce checks on BGP sessions.\n\n== Mechanism ==\nIP hijacking can occur deliberately or by accident in one of several ways:\n\nAn AS announces that it originates a prefix that it does not actually originate.\nAn AS announces a more specific prefix than what may be announced by the true originating AS.\nAn AS announces that it can route traffic to the hijacked AS through a shorter route than is already available, regardless of whether or not the route actually exists.Common to these ways is their disruption of the normal routing of the network: packets end up being forwarded towards the wrong part of the network and then either enter an endless loop (and are discarded), or are found at the mercy of the offending AS.\nTypically ISPs filter BGP traffic, allowing BGP advertisements from their downstream networks to contain only valid IP space.  However, a history of hijacking incidents shows this is not always the case.\nThe Resource Public Key Infrastructure (RPKI) is designed to authenticate route origins via cryptographic certificate chains demonstrating address block range ownership, but is not widely deployed yet.  Once deployed, IP hijacking through errant issues at the origin (via both accident or intent) should be detectable and filterable.\nIP hijacking is sometimes used by malicious users to obtain IP addresses for use in spamming or a distributed denial-of-service (DDoS) attack.\nWhen a router promulgates flawed BGP routing information, whether that action is intentional or accidental, it is defined by the Internet Engineering Task Force (IETF) in RFC 7908 as a \"route leak\". Such leaks are described as \"the propagation of routing announcement(s) beyond their intended scope. That is, an announcement from an Autonomous System (AS) of a learned BGP route to another AS is in violation of the intended policies of the receiver, the sender, and/or one of the ASes along the preceding AS path.\" Such leaks are possible because of a long-standing \"\u2026systemic vulnerability of the Border Gateway Protocol routing system\u2026\"\n\n== BGP hijacking and transit-AS problems ==\nLike the TCP reset attack, session hijacking involves intrusion into an ongoing BGP session, i.e., the attacker successfully masquerades as one of the peers in a BGP session, and requires the same information needed to accomplish the reset attack. The difference is that a session hijacking attack may be designed to achieve more than simply bringing down a session between BGP peers. For example, the objective may be to change routes used by the peer, in order to facilitate eavesdropping, black holing, or traffic analysis.\nBy default EBGP peers will attempt to add all routes received by another peer into the device's routing table and will then attempt to advertise nearly all of these routes to other EBGP peers.  This can be a problem as multi-homed organizations can inadvertently advertise prefixes learned from one AS to another, causing the end customer to become the new, best-path to the prefixes in question.  For example, a customer with a Cisco router peering with say AT&T and Verizon and using no filtering will automatically attempt to link the two major carriers, which could cause the providers to prefer sending some or all traffic through the customer (on perhaps a T1), instead of using high-speed dedicated links.  This problem can further affect others that peer with these two providers and also cause those ASs to prefer the misconfigured link.  In reality, this problem hardly ever occurs with large ISPs, as these ISPs tend to restrict what an end customer can advertise.  However,  any ISP not filtering customer advertisements can allow errant information to be advertised into the global routing table where it can affect even the large Tier-1 providers.\nThe concept of BGP hijacking revolves around locating an ISP that is not filtering advertisements (intentionally or otherwise) or locating an ISP whose internal or ISP-to-ISP BGP session is susceptible to a man-in-the-middle attack.  Once located, an attacker can potentially advertise any prefix they want, causing some or all traffic to be diverted from the real source towards the attacker.  This can be done either to overload the ISP the attacker has infiltrated, or to perform a DoS or impersonation attack on the entity whose prefix is being advertised.  It is not uncommon for an attacker to cause serious outages, up to and including a complete loss of connectivity.  In early 2008, at least eight US Universities had their traffic diverted to Indonesia for about 90 minutes one morning in an attack kept mostly quiet by those involved.  Also, in February 2008, a large portion of YouTube's address space was redirected to Pakistan when the PTA decided to block access to the site from inside the country, but accidentally blackholed the route in the global BGP table.\nWhile filtering and MD5/TTL protection is already available for most BGP implementations (thus preventing the source of most attacks), the problem stems from the concept that ISPs rarely ever filter advertisements from other ISPs, as there is no common or efficient way to determine the list of permissible prefixes each AS can originate.  The penalty for allowing errant information to be advertised can range from simple filtering by other/larger ISPs to a complete shutdown of the BGP session by the neighboring ISP (causing the two ISPs to cease peering), and repeated problems often end in permanent termination of all peering agreements.  It is also noteworthy that even causing a major provider to block or shutdown a smaller, problematic provider, the global BGP table will often reconfigure and reroute the traffic through other available routes until all peers take action, or until the errant ISP fixes the problem at the source.\nOne useful offshoot of this concept is called BGP anycasting and is frequently used by root DNS servers to allow multiple servers to use the same IP address, providing redundancy and a layer of protection against DoS attacks without publishing hundreds of server IP addresses.  The difference in this situation is that each point advertising a prefix actually has access to the real data (DNS in this case) and responds correctly to end user requests.\n\n== Public incidents ==\nApril 1997:  The \"AS 7007 incident\"\nDecember 24, 2004: TTNet in Turkey hijacks the Internet\nMay 7, 2005: Google's May 2005 Outage\nJanuary 22, 2006: Con Edison Communications hijacks big chunk of the Internet\nFebruary 24, 2008: Pakistan's attempt to block YouTube access within their country takes down YouTube entirely.\nNovember 11, 2008: The Brazilian ISP CTBC - Companhia de Telecomunica\u00e7\u00f5es do Brasil Central leaked their internal table into the global BGP table. It lasted over 5 minutes. Although, it was detected by a RIPE route server and then it was not propagated, affecting practically only their own ISP customers and few others.\nApril 8, 2010: Chinese ISP hijacks the Internet\nJuly 2013: The Hacking Team aided Raggruppamento Operativo Speciale (ROS - Special Operations Group of the Italian National Military police) in regaining access to Remote Access Tool (RAT) clients after they abruptly lost access to one of their control servers when the Santrex IPv4 prefix 46.166.163.0/24 became permanently unreachable. ROS and the Hacking Team worked with the Italian network operator Aruba S.p.A. (AS31034) to get the prefix announced in BGP in order to regain access to the control server.\nFebruary, 2014: Canadian ISP used to redirect data from ISPs. - In 22 incidents between February and May a hacker redirected traffic for roughly 30 seconds each session. Bitcoin and other crypto-currency mining operations were targeted and currency was stolen.\nJanuary 2017: Iranian pornography censorship.\nApril 2017: Russian telecommunication company Rostelecom (AS12389) originated 37 prefixes for numerous other Autonomous Systems. The hijacked prefixes belonged to financial institutions (most notably MasterCard and Visa), other telecom companies, and a variety of other organizations. Even though the possible hijacking lasted no more than 7 minutes it is still not clear if the traffic got intercepted or modified.\nDecember 2017: Eighty high-traffic prefixes normally announced by Google, Apple, Facebook, Microsoft, Twitch, NTT Communications, Riot Games, and others, were announced by a Russian AS, DV-LINK-AS (AS39523).\nApril 2018: Roughly 1300 IP addresses within Amazon Web Services space, dedicated to Amazon Route 53, were hijacked by eNet (or a customer thereof), an ISP in Columbus, Ohio.  Several peering partners, such as Hurricane Electric, blindly propagated the announcements.\nJuly 2018: Iran Telecommunication Company (AS58224) originated 10 prefixes of Telegram Messenger.\nNovember 2018: US-based China Telecom site originated Google addresses.\nMay 2019: Traffic to a public DNS run by Taiwan Network Information Center (TWNIC) was rerouted to an entity in Brazil (AS268869).\nJune 2019: Large European mobile traffic was rerouted through China Telecom (AS4134) \"This route leak began when [Swiss] SafeHost (AS21217) announced more than forty-thousand IPv4 routes that had been learned from other peers and providers to its provider China Telecom (AS 4134). \u2026In turn, China Telecom accepted these routes and propagated them\u2026\"\nFebruary 2021: Initially reported that Cablevision Mexico (AS28548) leaked 282 prefixes creating conflicts for 763 ASNs in 80 countries, with the main impact in Mexico. Data from the Isolario MRT dump suggested that 7,200 IPv4 prefixes were announced and leaked to AS1874 impacting more than 1290 ASNs from over 100 countries.\nApril 2021: Large BGP routing leak out of India: over 30,000 BGP prefixes hijacked via Vodafone Idea Ltd (AS55410) causing 13X spike in inbound traffic. Prefixes were from around the globe but mostly US including Google, Microsoft, Akamai, and Cloudflare.\nFebruary 2022: Attackers hijacked BGP prefixes that belonged to a South Korean cryptocurrency platform, and then issued a certificate on the domain via ZeroSSL to serve a malicious JavaScript file, stealing $1.9 million worth of cryptocurrency.\nMarch 2022: RTComm hijacked a prefix used by Twitter."
    }
  },
  {
    "instruction": "Write an answer to the following question: How are red teams used in the Marine Corps?",
    "context": "",
    "output": "The Marine Corps red team concept commenced in 2010, and all Marines designated to fill red team positions complete six-week or nine-week red team training courses provided by the University of Foreign Military and Cultural Studies.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are red teams used in the Marine Corps?",
      "answer": "The Marine Corps red team concept commenced in 2010, and all Marines designated to fill red team positions complete six-week or nine-week red team training courses provided by the University of Foreign Military and Cultural Studies."
    }
  },
  {
    "instruction": "Write an answer to the following question: In what year and in what category did The Wall Street Journal name CloudPassage a runner up in its Technology Innovation Awards?",
    "context": "",
    "output": "The Wall Street Journal named CloudPassage a runner up in the Information Security category of its Technology Innovation Awards in 2012.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In what year and in what category did The Wall Street Journal name CloudPassage a runner up in its Technology Innovation Awards?",
      "answer": "The Wall Street Journal named CloudPassage a runner up in the Information Security category of its Technology Innovation Awards in 2012."
    }
  },
  {
    "instruction": "context: Stalkerware is used for cyberstalking because of its powerful surveillance functions, ability to work in stealth mode, and the fact that it can be installed from resources other than official app stores.\n\nAsk a question about this context.",
    "context": "",
    "output": "Why is stalkerware used for cyberstalking?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why is stalkerware used for cyberstalking?",
      "answer": "Stalkerware is used for cyberstalking because of its powerful surveillance functions, ability to work in stealth mode, and the fact that it can be installed from resources other than official app stores."
    }
  },
  {
    "instruction": "Public-key cryptography\n\n==Introduction==\nPublic-key cryptography, or asymmetric cryptography, is the field of cryptographic systems that use pairs of related keys. Each key pair consists of a public key and a corresponding private key. Key pairs are generated with cryptographic algorithms based on mathematical problems termed one-way functions. Security of public-key cryptography depends on keeping the private key secret; the public key can be openly distributed without compromising security.In a public-key encryption system, anyone with a public key can encrypt a message, yielding a ciphertext, but only those who know the corresponding private key can decrypt the ciphertext to obtain the original message.For example, a journalist can publish the public key of an encryption key pair on a web site so that sources can send secret messages to the news organization in ciphertext.\nOnly the journalist who knows the corresponding private key can decrypt the ciphertexts to obtain the sources' messages\u2014an eavesdropper reading email on its way to the journalist cannot decrypt the ciphertexts.\nHowever, public-key encryption does not conceal metadata like what computer a source used to send a message, when they sent it, or how long it is.\nPublic-key encryption on its own also does not tell the recipient anything about who sent a message\u2014it just conceals the content of a message in a ciphertext that can only be decrypted with the private key.\nIn a digital signature system, a sender can use a private key together with a message to create a signature.\nAnyone with the corresponding public key can verify whether the signature matches the message, but a forger who does not know the private key cannot find any message/signature pair that will pass verification with the public key.For example, a software publisher can create a signature key pair and include the public key in software installed on computers.\nLater, the publisher can distribute an update to the software signed using the private key, and any computer receiving an update can confirm it is genuine by verifying the signature using the public key.\nAs long as the software publisher keeps the private key secret, even if a forger can distribute malicious updates to computers, they cannot convince the computers that any malicious updates are genuine.\nPublic key algorithms are fundamental security primitives in modern cryptosystems, including applications and protocols which offer assurance of the confidentiality, authenticity and non-repudiability of electronic communications and data storage. They underpin numerous Internet standards, such as Transport Layer Security (TLS), SSH, S/MIME and PGP. Some public key algorithms provide key distribution and secrecy (e.g., Diffie\u2013Hellman key exchange), some provide digital signatures (e.g., Digital Signature Algorithm), and some provide both (e.g., RSA). Compared to symmetric encryption, asymmetric encryption is rather slower than good symmetric encryption, too slow for many purposes. Today's cryptosystems (such as TLS, Secure Shell) use both symmetric encryption and asymmetric encryption, often by using asymmetric encryption to securely exchange a secret key which is then used for symmetric encryption.\n\n\n\n== Description ==\nBefore the mid-1970s, all cipher systems used symmetric key algorithms, in which the same cryptographic key is used with the underlying algorithm by both the sender and the recipient, who must both keep it secret. Of necessity, the key in every such system had to be exchanged between the communicating parties in some secure way prior to any use of the system \u2013 for instance, via a secure channel. This requirement is never trivial and very rapidly becomes unmanageable as the number of participants increases, or when secure channels are not available, or when, (as is sensible cryptographic practice), keys are frequently changed. In particular, if messages are meant to be secure from other users, a separate key is required for each possible pair of users.\nBy contrast, in a public key system, the public keys can be disseminated widely and openly, and only the corresponding private keys need be kept secret by its owner.\nTwo of the best-known uses of public key cryptography are:\n\nPublic key encryption, in which a message is encrypted with the intended recipient's public key. For properly chosen and used algorithms, messages cannot in practice be decrypted by anyone who does not possess the matching private key, who is thus presumed to be the owner of that key and so the person associated with the public key. This can be used to ensure confidentiality of a message.\nDigital signatures, in which a message is signed with the sender's private key and can be verified by anyone who has access to the sender's public key. This verification proves that the sender had access to the private key, and therefore is very likely to be the person associated with the public key. It also proves that the signature was prepared for that exact message, since verification will fail for any other message one could devise without using the private key.One important issue is confidence/proof that a particular public key is authentic, i.e. that it is correct and belongs to the person or entity claimed, and has not been tampered with or replaced by some (perhaps malicious) third party. There are several possible approaches, including:\nA public key infrastructure (PKI), in which one or more third parties \u2013 known as certificate authorities \u2013 certify ownership of key pairs. TLS relies upon this. This implies that the PKI system (software, hardware, and management) is trust-able by all involved.\nA \"web of trust\" which decentralizes authentication by using individual endorsements of links between a user and the public key belonging to that user. PGP uses this approach, in addition to lookup in the domain name system (DNS). The DKIM system for digitally signing emails also uses this approach.\n\n== Applications ==\nThe most obvious application of a public key encryption system is for encrypting communication to provide confidentiality \u2013 a message that a sender encrypts using the recipient's public key which can be decrypted only by the recipient's paired private key.\nAnother application in public key cryptography is the digital signature. Digital signature schemes can be used for sender authentication.\nNon-repudiation systems use digital signatures to ensure that one party cannot successfully dispute its authorship of a document or communication.\nFurther applications built on this foundation include: digital cash, password-authenticated key agreement, time-stamping services and non-repudiation protocols.\n\n\n*** Hybrid cryptosystems ***\nBecause asymmetric key algorithms are nearly always much more computationally intensive than symmetric ones, it is common to use a public/private asymmetric key-exchange algorithm to encrypt and exchange a symmetric key, which is then used by  symmetric-key cryptography to transmit data using the now-shared symmetric key for a symmetric key encryption algorithm. PGP, SSH, and the SSL/TLS family of schemes use this procedure;  they are thus called hybrid cryptosystems. The initial asymmetric cryptography-based key exchange to share a server-generated symmetric key from the server to client has the advantage of not requiring that a symmetric key be pre-shared manually, such as on printed paper or discs transported by a courier, while providing the higher data throughput of symmetric key cryptography over asymmetric key cryptography for the remainder of the shared connection.\n\n== Weaknesses ==\nAs with all security-related systems, it is important to identify potential weaknesses.  Aside from poor choice of an asymmetric key algorithm (there are few which are widely regarded as satisfactory) or too short a key length, the chief security risk is that the private key of a pair becomes known.  All security of messages, authentication, etc., will then be lost.\n\n\n*** Algorithms ***\nAll public key schemes are in theory susceptible to a \"brute-force key search attack\". However, such an attack is impractical if the amount of computation needed to succeed \u2013 termed the \"work factor\" by Claude Shannon \u2013 is out of reach of all potential attackers. In many cases, the work factor can be increased by simply choosing a longer key. But other algorithms may inherently have much lower work factors, making resistance to a brute-force attack (e.g., from longer keys) irrelevant. Some special and specific algorithms have been developed to aid in attacking some public key encryption algorithms; both RSA and ElGamal encryption have known attacks that are much faster than the brute-force approach. None of these are sufficiently improved to be actually practical, however.\nMajor weaknesses have been found for several formerly promising asymmetric key algorithms. The \"knapsack packing\" algorithm was found to be insecure after the development of a new attack. As with all cryptographic functions, public-key implementations may be vulnerable to side-channel attacks that exploit information leakage to simplify the search for a secret key. These are often independent of the algorithm being used. Research is underway to both discover, and to protect against, new attacks.\n\n\n*** Alteration of public keys ***\nAnother potential security vulnerability in using asymmetric keys is the possibility of a \"man-in-the-middle\" attack, in which the communication of public keys is intercepted by a third party (the \"man in the middle\") and then modified to provide different public keys instead. Encrypted messages and responses must, in all instances, be intercepted, decrypted, and re-encrypted by the attacker using the correct public keys for the different communication segments so as to avoid suspicion.\nA communication is said to be insecure where data is transmitted in a manner that allows for interception (also called \"sniffing\"). These terms refer to reading the sender's private data in its entirety. A communication is particularly unsafe when interceptions can't be prevented or monitored by the sender.A man-in-the-middle attack can be difficult to implement due to the complexities of modern security protocols. However, the task becomes simpler when a sender is using insecure media such as public networks, the Internet, or wireless communication. In these cases an attacker can compromise the communications infrastructure rather than the data itself. A hypothetical malicious staff member at an Internet Service Provider (ISP) might find a man-in-the-middle attack relatively straightforward. Capturing the public key would only require searching for the key as it gets sent through the ISP's communications hardware;  in properly implemented asymmetric key schemes, this is not a significant risk.\nIn some advanced man-in-the-middle attacks, one side of the communication will see the original data while the other will receive a malicious variant. Asymmetric man-in-the-middle attacks can prevent users from realizing their connection is compromised. This remains so even when one user's data is known to be compromised because the data appears fine to the other user. This can lead to confusing disagreements between users such as \"it must be on your end!\" when neither user is at fault. Hence, man-in-the-middle attacks are only fully preventable when the communications infrastructure is physically controlled by one or both parties; such as via a wired route inside the sender's own building. In summation, public keys are easier to alter when the communications hardware used by a sender is controlled by an attacker.\n\n\n*** Public key infrastructure ***\nOne approach to prevent such attacks involves the use of a public key infrastructure (PKI); a set of roles, policies, and procedures needed to create, manage, distribute, use, store and revoke digital certificates and manage public-key encryption. However, this has potential weaknesses.\nFor example, the certificate authority issuing the certificate must be trusted by all participating parties to have properly checked the identity of the key-holder, to have ensured the correctness of the public key when it issues a certificate, to be secure from computer piracy, and to have made arrangements with all participants to check all their certificates before protected communications can begin. Web browsers, for instance, are supplied with a long list of \"self-signed identity certificates\" from PKI providers \u2013 these are used to check the bona fides of the certificate authority and then, in a second step, the certificates of potential communicators. An attacker who could subvert one of those certificate authorities into issuing a certificate for a bogus public key could then mount a \"man-in-the-middle\" attack as easily as if the certificate scheme were not used at all. In an alternative scenario rarely discussed, an attacker who penetrates an authority's servers and obtains its store of certificates and keys (public and private) would be able to spoof, masquerade, decrypt, and forge transactions without limit.\nDespite its theoretical and potential problems, this approach is widely used. Examples include TLS and its predecessor SSL, which are commonly used to provide security for web browser transactions (for example, to securely send credit card details to an online store).\nAside from the resistance to attack of a particular key pair, the security of the certification hierarchy must be considered when deploying public key systems. Some certificate authority \u2013 usually a purpose-built program running on a server computer \u2013 vouches for the identities assigned to specific private keys by producing a digital certificate. Public key digital certificates are typically valid for several years at a time, so the associated private keys must be held securely over that time. When a private key used for certificate creation higher in the PKI server hierarchy is compromised, or accidentally disclosed, then a \"man-in-the-middle attack\" is possible, making any subordinate certificate wholly insecure.\n\n== Examples ==\nExamples of well-regarded asymmetric key techniques for varied purposes include:\n\nDiffie\u2013Hellman key exchange protocol\nDSS (Digital Signature Standard), which incorporates the Digital Signature Algorithm\nElGamal\nElliptic-curve cryptography\nElliptic Curve Digital Signature Algorithm (ECDSA)\nElliptic-curve Diffie\u2013Hellman (ECDH)\nEd25519 and Ed448 (EdDSA)\nX25519 and X448 (ECDH/EdDH)\nVarious password-authenticated key agreement techniques\nPaillier cryptosystem\nRSA encryption algorithm (PKCS#1)\nCramer\u2013Shoup cryptosystem\nYAK authenticated key agreement protocolExamples of asymmetric key algorithms not yet widely adopted include:\n\nNTRUEncrypt cryptosystem\nKyber\nMcEliece cryptosystemExamples of notable \u2013 yet insecure \u2013 asymmetric key algorithms include:\n\nMerkle\u2013Hellman knapsack cryptosystemExamples of protocols using asymmetric key algorithms include:\n\nS/MIME\nGPG, an implementation of OpenPGP, and an Internet Standard\nEMV, EMV Certificate Authority\nIPsec\nPGP\nZRTP, a secure VoIP protocol\nTransport Layer Security standardized by IETF and its predecessor Secure Socket Layer\nSILC\nSSH\nBitcoin\nOff-the-Record Messaging\n\nHow can the security of a public key system be affected by the dissemination of public keys?",
    "context": "",
    "output": "A: In a public key system, the public keys can be disseminated widely and openly, but only the corresponding private keys need to be kept secret by their owner. If public keys are not properly authenticated, there is a risk that they may be altered by a man-in-the-middle attacker, which can lead to the compromise of the security of the system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can the security of a public key system be affected by the dissemination of public keys?",
      "answer": "In a public key system, the public keys can be disseminated widely and openly, but only the corresponding private keys need to be kept secret by their owner. If public keys are not properly authenticated, there is a risk that they may be altered by a man-in-the-middle attacker, which can lead to the compromise of the security of the system.",
      "context": "Public-key cryptography\n\n==Introduction==\nPublic-key cryptography, or asymmetric cryptography, is the field of cryptographic systems that use pairs of related keys. Each key pair consists of a public key and a corresponding private key. Key pairs are generated with cryptographic algorithms based on mathematical problems termed one-way functions. Security of public-key cryptography depends on keeping the private key secret; the public key can be openly distributed without compromising security.In a public-key encryption system, anyone with a public key can encrypt a message, yielding a ciphertext, but only those who know the corresponding private key can decrypt the ciphertext to obtain the original message.For example, a journalist can publish the public key of an encryption key pair on a web site so that sources can send secret messages to the news organization in ciphertext.\nOnly the journalist who knows the corresponding private key can decrypt the ciphertexts to obtain the sources' messages\u2014an eavesdropper reading email on its way to the journalist cannot decrypt the ciphertexts.\nHowever, public-key encryption does not conceal metadata like what computer a source used to send a message, when they sent it, or how long it is.\nPublic-key encryption on its own also does not tell the recipient anything about who sent a message\u2014it just conceals the content of a message in a ciphertext that can only be decrypted with the private key.\nIn a digital signature system, a sender can use a private key together with a message to create a signature.\nAnyone with the corresponding public key can verify whether the signature matches the message, but a forger who does not know the private key cannot find any message/signature pair that will pass verification with the public key.For example, a software publisher can create a signature key pair and include the public key in software installed on computers.\nLater, the publisher can distribute an update to the software signed using the private key, and any computer receiving an update can confirm it is genuine by verifying the signature using the public key.\nAs long as the software publisher keeps the private key secret, even if a forger can distribute malicious updates to computers, they cannot convince the computers that any malicious updates are genuine.\nPublic key algorithms are fundamental security primitives in modern cryptosystems, including applications and protocols which offer assurance of the confidentiality, authenticity and non-repudiability of electronic communications and data storage. They underpin numerous Internet standards, such as Transport Layer Security (TLS), SSH, S/MIME and PGP. Some public key algorithms provide key distribution and secrecy (e.g., Diffie\u2013Hellman key exchange), some provide digital signatures (e.g., Digital Signature Algorithm), and some provide both (e.g., RSA). Compared to symmetric encryption, asymmetric encryption is rather slower than good symmetric encryption, too slow for many purposes. Today's cryptosystems (such as TLS, Secure Shell) use both symmetric encryption and asymmetric encryption, often by using asymmetric encryption to securely exchange a secret key which is then used for symmetric encryption.\n\n\n\n== Description ==\nBefore the mid-1970s, all cipher systems used symmetric key algorithms, in which the same cryptographic key is used with the underlying algorithm by both the sender and the recipient, who must both keep it secret. Of necessity, the key in every such system had to be exchanged between the communicating parties in some secure way prior to any use of the system \u2013 for instance, via a secure channel. This requirement is never trivial and very rapidly becomes unmanageable as the number of participants increases, or when secure channels are not available, or when, (as is sensible cryptographic practice), keys are frequently changed. In particular, if messages are meant to be secure from other users, a separate key is required for each possible pair of users.\nBy contrast, in a public key system, the public keys can be disseminated widely and openly, and only the corresponding private keys need be kept secret by its owner.\nTwo of the best-known uses of public key cryptography are:\n\nPublic key encryption, in which a message is encrypted with the intended recipient's public key. For properly chosen and used algorithms, messages cannot in practice be decrypted by anyone who does not possess the matching private key, who is thus presumed to be the owner of that key and so the person associated with the public key. This can be used to ensure confidentiality of a message.\nDigital signatures, in which a message is signed with the sender's private key and can be verified by anyone who has access to the sender's public key. This verification proves that the sender had access to the private key, and therefore is very likely to be the person associated with the public key. It also proves that the signature was prepared for that exact message, since verification will fail for any other message one could devise without using the private key.One important issue is confidence/proof that a particular public key is authentic, i.e. that it is correct and belongs to the person or entity claimed, and has not been tampered with or replaced by some (perhaps malicious) third party. There are several possible approaches, including:\nA public key infrastructure (PKI), in which one or more third parties \u2013 known as certificate authorities \u2013 certify ownership of key pairs. TLS relies upon this. This implies that the PKI system (software, hardware, and management) is trust-able by all involved.\nA \"web of trust\" which decentralizes authentication by using individual endorsements of links between a user and the public key belonging to that user. PGP uses this approach, in addition to lookup in the domain name system (DNS). The DKIM system for digitally signing emails also uses this approach.\n\n== Applications ==\nThe most obvious application of a public key encryption system is for encrypting communication to provide confidentiality \u2013 a message that a sender encrypts using the recipient's public key which can be decrypted only by the recipient's paired private key.\nAnother application in public key cryptography is the digital signature. Digital signature schemes can be used for sender authentication.\nNon-repudiation systems use digital signatures to ensure that one party cannot successfully dispute its authorship of a document or communication.\nFurther applications built on this foundation include: digital cash, password-authenticated key agreement, time-stamping services and non-repudiation protocols.\n\n\n*** Hybrid cryptosystems ***\nBecause asymmetric key algorithms are nearly always much more computationally intensive than symmetric ones, it is common to use a public/private asymmetric key-exchange algorithm to encrypt and exchange a symmetric key, which is then used by  symmetric-key cryptography to transmit data using the now-shared symmetric key for a symmetric key encryption algorithm. PGP, SSH, and the SSL/TLS family of schemes use this procedure;  they are thus called hybrid cryptosystems. The initial asymmetric cryptography-based key exchange to share a server-generated symmetric key from the server to client has the advantage of not requiring that a symmetric key be pre-shared manually, such as on printed paper or discs transported by a courier, while providing the higher data throughput of symmetric key cryptography over asymmetric key cryptography for the remainder of the shared connection.\n\n== Weaknesses ==\nAs with all security-related systems, it is important to identify potential weaknesses.  Aside from poor choice of an asymmetric key algorithm (there are few which are widely regarded as satisfactory) or too short a key length, the chief security risk is that the private key of a pair becomes known.  All security of messages, authentication, etc., will then be lost.\n\n\n*** Algorithms ***\nAll public key schemes are in theory susceptible to a \"brute-force key search attack\". However, such an attack is impractical if the amount of computation needed to succeed \u2013 termed the \"work factor\" by Claude Shannon \u2013 is out of reach of all potential attackers. In many cases, the work factor can be increased by simply choosing a longer key. But other algorithms may inherently have much lower work factors, making resistance to a brute-force attack (e.g., from longer keys) irrelevant. Some special and specific algorithms have been developed to aid in attacking some public key encryption algorithms; both RSA and ElGamal encryption have known attacks that are much faster than the brute-force approach. None of these are sufficiently improved to be actually practical, however.\nMajor weaknesses have been found for several formerly promising asymmetric key algorithms. The \"knapsack packing\" algorithm was found to be insecure after the development of a new attack. As with all cryptographic functions, public-key implementations may be vulnerable to side-channel attacks that exploit information leakage to simplify the search for a secret key. These are often independent of the algorithm being used. Research is underway to both discover, and to protect against, new attacks.\n\n\n*** Alteration of public keys ***\nAnother potential security vulnerability in using asymmetric keys is the possibility of a \"man-in-the-middle\" attack, in which the communication of public keys is intercepted by a third party (the \"man in the middle\") and then modified to provide different public keys instead. Encrypted messages and responses must, in all instances, be intercepted, decrypted, and re-encrypted by the attacker using the correct public keys for the different communication segments so as to avoid suspicion.\nA communication is said to be insecure where data is transmitted in a manner that allows for interception (also called \"sniffing\"). These terms refer to reading the sender's private data in its entirety. A communication is particularly unsafe when interceptions can't be prevented or monitored by the sender.A man-in-the-middle attack can be difficult to implement due to the complexities of modern security protocols. However, the task becomes simpler when a sender is using insecure media such as public networks, the Internet, or wireless communication. In these cases an attacker can compromise the communications infrastructure rather than the data itself. A hypothetical malicious staff member at an Internet Service Provider (ISP) might find a man-in-the-middle attack relatively straightforward. Capturing the public key would only require searching for the key as it gets sent through the ISP's communications hardware;  in properly implemented asymmetric key schemes, this is not a significant risk.\nIn some advanced man-in-the-middle attacks, one side of the communication will see the original data while the other will receive a malicious variant. Asymmetric man-in-the-middle attacks can prevent users from realizing their connection is compromised. This remains so even when one user's data is known to be compromised because the data appears fine to the other user. This can lead to confusing disagreements between users such as \"it must be on your end!\" when neither user is at fault. Hence, man-in-the-middle attacks are only fully preventable when the communications infrastructure is physically controlled by one or both parties; such as via a wired route inside the sender's own building. In summation, public keys are easier to alter when the communications hardware used by a sender is controlled by an attacker.\n\n\n*** Public key infrastructure ***\nOne approach to prevent such attacks involves the use of a public key infrastructure (PKI); a set of roles, policies, and procedures needed to create, manage, distribute, use, store and revoke digital certificates and manage public-key encryption. However, this has potential weaknesses.\nFor example, the certificate authority issuing the certificate must be trusted by all participating parties to have properly checked the identity of the key-holder, to have ensured the correctness of the public key when it issues a certificate, to be secure from computer piracy, and to have made arrangements with all participants to check all their certificates before protected communications can begin. Web browsers, for instance, are supplied with a long list of \"self-signed identity certificates\" from PKI providers \u2013 these are used to check the bona fides of the certificate authority and then, in a second step, the certificates of potential communicators. An attacker who could subvert one of those certificate authorities into issuing a certificate for a bogus public key could then mount a \"man-in-the-middle\" attack as easily as if the certificate scheme were not used at all. In an alternative scenario rarely discussed, an attacker who penetrates an authority's servers and obtains its store of certificates and keys (public and private) would be able to spoof, masquerade, decrypt, and forge transactions without limit.\nDespite its theoretical and potential problems, this approach is widely used. Examples include TLS and its predecessor SSL, which are commonly used to provide security for web browser transactions (for example, to securely send credit card details to an online store).\nAside from the resistance to attack of a particular key pair, the security of the certification hierarchy must be considered when deploying public key systems. Some certificate authority \u2013 usually a purpose-built program running on a server computer \u2013 vouches for the identities assigned to specific private keys by producing a digital certificate. Public key digital certificates are typically valid for several years at a time, so the associated private keys must be held securely over that time. When a private key used for certificate creation higher in the PKI server hierarchy is compromised, or accidentally disclosed, then a \"man-in-the-middle attack\" is possible, making any subordinate certificate wholly insecure.\n\n== Examples ==\nExamples of well-regarded asymmetric key techniques for varied purposes include:\n\nDiffie\u2013Hellman key exchange protocol\nDSS (Digital Signature Standard), which incorporates the Digital Signature Algorithm\nElGamal\nElliptic-curve cryptography\nElliptic Curve Digital Signature Algorithm (ECDSA)\nElliptic-curve Diffie\u2013Hellman (ECDH)\nEd25519 and Ed448 (EdDSA)\nX25519 and X448 (ECDH/EdDH)\nVarious password-authenticated key agreement techniques\nPaillier cryptosystem\nRSA encryption algorithm (PKCS#1)\nCramer\u2013Shoup cryptosystem\nYAK authenticated key agreement protocolExamples of asymmetric key algorithms not yet widely adopted include:\n\nNTRUEncrypt cryptosystem\nKyber\nMcEliece cryptosystemExamples of notable \u2013 yet insecure \u2013 asymmetric key algorithms include:\n\nMerkle\u2013Hellman knapsack cryptosystemExamples of protocols using asymmetric key algorithms include:\n\nS/MIME\nGPG, an implementation of OpenPGP, and an Internet Standard\nEMV, EMV Certificate Authority\nIPsec\nPGP\nZRTP, a secure VoIP protocol\nTransport Layer Security standardized by IETF and its predecessor Secure Socket Layer\nSILC\nSSH\nBitcoin\nOff-the-Record Messaging"
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a proof-of-space and what are its main requirements?",
    "context": "",
    "output": "A proof-of-space is a piece of data that a prover sends to a verifier to prove that the prover has reserved a certain amount of space. The main requirements for PoS are that the verification process needs to be efficient, namely, consume a small amount of space and time, and it should be hard for the prover to pass the verification if it does not actually reserve the claimed amount of space.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a proof-of-space and what are its main requirements?",
      "answer": "A proof-of-space is a piece of data that a prover sends to a verifier to prove that the prover has reserved a certain amount of space. The main requirements for PoS are that the verification process needs to be efficient, namely, consume a small amount of space and time, and it should be hard for the prover to pass the verification if it does not actually reserve the claimed amount of space."
    }
  },
  {
    "instruction": "context: The \"learn the remaining information attack\" is a type of attack where an attacker can extract sensitive information from a slightly modified public document. For example, if a defender encrypts a bank form with a ten-digit bank account number, an attacker can produce bank forms for all possible bank account numbers, encrypt them, and then compare those encryptions with the defender's encrypted file to deduce the bank account number.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the \"learn the remaining information attack\" in convergent encryption, and how does it work?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the \"learn the remaining information attack\" in convergent encryption, and how does it work?",
      "answer": "The \"learn the remaining information attack\" is a type of attack where an attacker can extract sensitive information from a slightly modified public document. For example, if a defender encrypts a bank form with a ten-digit bank account number, an attacker can produce bank forms for all possible bank account numbers, encrypt them, and then compare those encryptions with the defender's encrypted file to deduce the bank account number."
    }
  },
  {
    "instruction": "Answer based on context:\n\nPrivateCore\n\n==Introduction==\nPrivateCore is a venture-backed startup located in Palo Alto, California that develops software to secure server data through server attestation and memory encryption. The company's attestation and memory encryption technology fills a gap that exists between \u201cdata in motion\u201d encryption (TLS, email encryption) and \u201cdata at rest\u201d encryption (disk encryption, tape encryption) by protecting \u201cdata in use\u201d (random access memory).  PrivateCore memory encryption technology protects against threats to servers such as cold boot attacks, hardware advanced persistent threats, rootkits/bootkits, computer hardware supply chain attacks, and physical threats to servers from insiders. PrivateCore was acquired by Facebook (now Meta Platforms) on 7 August 2014.\n\n\n\n== Technology ==\nPrivateCore's focus is securing data-in-use on x86 servers.  The company has taken advantage of recent microprocessor innovations including larger microprocessor caches and hardware cryptographic acceleration technology that enable more effective methods of encrypting memory while maintaining acceptable application performance.  The technology approach goes beyond previous academic research efforts such as TRESOR.\nPrivateCore assumes that the only element that needs to be trusted in a system is the Central Processing Unit (CPU).   The firm uses Trusted Platform Module (TPM) chips and Intel Trusted Execution Technology (Intel TXT) to provide remote server attestation.  PrivateCore also supports the cryptographic hardware acceleration provided by Intel AES-NI technology.\nPrivateCore technology is positioned as being most applicable to outsourced or hosted environments where the enterprise cannot have trust in the computing infrastructure.\n\n== Products ==\nThe PrivateCore vCage product portfolio comprises vCage Manager and vCage Host.  vCage Manager validates the integrity of x86 servers running Linux as well as the vCage Host. vCage Host installs on bare-metal  servers and provides a hardened hypervisor based on KVM that can secure server random access memory (RAM) with AES encryption.   vCage Host does this by loading a secure hypervisor into the CPU cache and acting as a gateway to encrypt memory paging in and out between the CPU cache and RAM.  vCage memory encryption leverages the KVM hypervisor but also has the potential to support other hypervisors.  vCage Host supports existing KVM management tools.\nvCage supports a number of use cases including creating OpenStack trusted computing pools as well as protecting x86 servers in co-location and bare-metal cloud environments.\nvCage Manager and vCage Host became generally available on 11 February 2014.\n\nHow does PrivateCore use Trusted Platform Module (TPM) chips and Intel Trusted Execution Technology (Intel TXT) in their technology approach?",
    "context": "",
    "output": "PrivateCore uses TPM chips and Intel TXT to provide remote server attestation, which is the process of verifying the integrity of a remote system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does PrivateCore use Trusted Platform Module (TPM) chips and Intel Trusted Execution Technology (Intel TXT) in their technology approach?",
      "answer": "PrivateCore uses TPM chips and Intel TXT to provide remote server attestation, which is the process of verifying the integrity of a remote system.",
      "context": "PrivateCore\n\n==Introduction==\nPrivateCore is a venture-backed startup located in Palo Alto, California that develops software to secure server data through server attestation and memory encryption. The company's attestation and memory encryption technology fills a gap that exists between \u201cdata in motion\u201d encryption (TLS, email encryption) and \u201cdata at rest\u201d encryption (disk encryption, tape encryption) by protecting \u201cdata in use\u201d (random access memory).  PrivateCore memory encryption technology protects against threats to servers such as cold boot attacks, hardware advanced persistent threats, rootkits/bootkits, computer hardware supply chain attacks, and physical threats to servers from insiders. PrivateCore was acquired by Facebook (now Meta Platforms) on 7 August 2014.\n\n\n\n== Technology ==\nPrivateCore's focus is securing data-in-use on x86 servers.  The company has taken advantage of recent microprocessor innovations including larger microprocessor caches and hardware cryptographic acceleration technology that enable more effective methods of encrypting memory while maintaining acceptable application performance.  The technology approach goes beyond previous academic research efforts such as TRESOR.\nPrivateCore assumes that the only element that needs to be trusted in a system is the Central Processing Unit (CPU).   The firm uses Trusted Platform Module (TPM) chips and Intel Trusted Execution Technology (Intel TXT) to provide remote server attestation.  PrivateCore also supports the cryptographic hardware acceleration provided by Intel AES-NI technology.\nPrivateCore technology is positioned as being most applicable to outsourced or hosted environments where the enterprise cannot have trust in the computing infrastructure.\n\n== Products ==\nThe PrivateCore vCage product portfolio comprises vCage Manager and vCage Host.  vCage Manager validates the integrity of x86 servers running Linux as well as the vCage Host. vCage Host installs on bare-metal  servers and provides a hardened hypervisor based on KVM that can secure server random access memory (RAM) with AES encryption.   vCage Host does this by loading a secure hypervisor into the CPU cache and acting as a gateway to encrypt memory paging in and out between the CPU cache and RAM.  vCage memory encryption leverages the KVM hypervisor but also has the potential to support other hypervisors.  vCage Host supports existing KVM management tools.\nvCage supports a number of use cases including creating OpenStack trusted computing pools as well as protecting x86 servers in co-location and bare-metal cloud environments.\nvCage Manager and vCage Host became generally available on 11 February 2014."
    }
  },
  {
    "instruction": "Public-key cryptography\n\n==Introduction==\nPublic-key cryptography, or asymmetric cryptography, is the field of cryptographic systems that use pairs of related keys. Each key pair consists of a public key and a corresponding private key. Key pairs are generated with cryptographic algorithms based on mathematical problems termed one-way functions. Security of public-key cryptography depends on keeping the private key secret; the public key can be openly distributed without compromising security.In a public-key encryption system, anyone with a public key can encrypt a message, yielding a ciphertext, but only those who know the corresponding private key can decrypt the ciphertext to obtain the original message.For example, a journalist can publish the public key of an encryption key pair on a web site so that sources can send secret messages to the news organization in ciphertext.\nOnly the journalist who knows the corresponding private key can decrypt the ciphertexts to obtain the sources' messages\u2014an eavesdropper reading email on its way to the journalist cannot decrypt the ciphertexts.\nHowever, public-key encryption does not conceal metadata like what computer a source used to send a message, when they sent it, or how long it is.\nPublic-key encryption on its own also does not tell the recipient anything about who sent a message\u2014it just conceals the content of a message in a ciphertext that can only be decrypted with the private key.\nIn a digital signature system, a sender can use a private key together with a message to create a signature.\nAnyone with the corresponding public key can verify whether the signature matches the message, but a forger who does not know the private key cannot find any message/signature pair that will pass verification with the public key.For example, a software publisher can create a signature key pair and include the public key in software installed on computers.\nLater, the publisher can distribute an update to the software signed using the private key, and any computer receiving an update can confirm it is genuine by verifying the signature using the public key.\nAs long as the software publisher keeps the private key secret, even if a forger can distribute malicious updates to computers, they cannot convince the computers that any malicious updates are genuine.\nPublic key algorithms are fundamental security primitives in modern cryptosystems, including applications and protocols which offer assurance of the confidentiality, authenticity and non-repudiability of electronic communications and data storage. They underpin numerous Internet standards, such as Transport Layer Security (TLS), SSH, S/MIME and PGP. Some public key algorithms provide key distribution and secrecy (e.g., Diffie\u2013Hellman key exchange), some provide digital signatures (e.g., Digital Signature Algorithm), and some provide both (e.g., RSA). Compared to symmetric encryption, asymmetric encryption is rather slower than good symmetric encryption, too slow for many purposes. Today's cryptosystems (such as TLS, Secure Shell) use both symmetric encryption and asymmetric encryption, often by using asymmetric encryption to securely exchange a secret key which is then used for symmetric encryption.\n\n\n\n== Description ==\nBefore the mid-1970s, all cipher systems used symmetric key algorithms, in which the same cryptographic key is used with the underlying algorithm by both the sender and the recipient, who must both keep it secret. Of necessity, the key in every such system had to be exchanged between the communicating parties in some secure way prior to any use of the system \u2013 for instance, via a secure channel. This requirement is never trivial and very rapidly becomes unmanageable as the number of participants increases, or when secure channels are not available, or when, (as is sensible cryptographic practice), keys are frequently changed. In particular, if messages are meant to be secure from other users, a separate key is required for each possible pair of users.\nBy contrast, in a public key system, the public keys can be disseminated widely and openly, and only the corresponding private keys need be kept secret by its owner.\nTwo of the best-known uses of public key cryptography are:\n\nPublic key encryption, in which a message is encrypted with the intended recipient's public key. For properly chosen and used algorithms, messages cannot in practice be decrypted by anyone who does not possess the matching private key, who is thus presumed to be the owner of that key and so the person associated with the public key. This can be used to ensure confidentiality of a message.\nDigital signatures, in which a message is signed with the sender's private key and can be verified by anyone who has access to the sender's public key. This verification proves that the sender had access to the private key, and therefore is very likely to be the person associated with the public key. It also proves that the signature was prepared for that exact message, since verification will fail for any other message one could devise without using the private key.One important issue is confidence/proof that a particular public key is authentic, i.e. that it is correct and belongs to the person or entity claimed, and has not been tampered with or replaced by some (perhaps malicious) third party. There are several possible approaches, including:\nA public key infrastructure (PKI), in which one or more third parties \u2013 known as certificate authorities \u2013 certify ownership of key pairs. TLS relies upon this. This implies that the PKI system (software, hardware, and management) is trust-able by all involved.\nA \"web of trust\" which decentralizes authentication by using individual endorsements of links between a user and the public key belonging to that user. PGP uses this approach, in addition to lookup in the domain name system (DNS). The DKIM system for digitally signing emails also uses this approach.\n\n== Applications ==\nThe most obvious application of a public key encryption system is for encrypting communication to provide confidentiality \u2013 a message that a sender encrypts using the recipient's public key which can be decrypted only by the recipient's paired private key.\nAnother application in public key cryptography is the digital signature. Digital signature schemes can be used for sender authentication.\nNon-repudiation systems use digital signatures to ensure that one party cannot successfully dispute its authorship of a document or communication.\nFurther applications built on this foundation include: digital cash, password-authenticated key agreement, time-stamping services and non-repudiation protocols.\n\n\n*** Hybrid cryptosystems ***\nBecause asymmetric key algorithms are nearly always much more computationally intensive than symmetric ones, it is common to use a public/private asymmetric key-exchange algorithm to encrypt and exchange a symmetric key, which is then used by  symmetric-key cryptography to transmit data using the now-shared symmetric key for a symmetric key encryption algorithm. PGP, SSH, and the SSL/TLS family of schemes use this procedure;  they are thus called hybrid cryptosystems. The initial asymmetric cryptography-based key exchange to share a server-generated symmetric key from the server to client has the advantage of not requiring that a symmetric key be pre-shared manually, such as on printed paper or discs transported by a courier, while providing the higher data throughput of symmetric key cryptography over asymmetric key cryptography for the remainder of the shared connection.\n\n== Weaknesses ==\nAs with all security-related systems, it is important to identify potential weaknesses.  Aside from poor choice of an asymmetric key algorithm (there are few which are widely regarded as satisfactory) or too short a key length, the chief security risk is that the private key of a pair becomes known.  All security of messages, authentication, etc., will then be lost.\n\n\n*** Algorithms ***\nAll public key schemes are in theory susceptible to a \"brute-force key search attack\". However, such an attack is impractical if the amount of computation needed to succeed \u2013 termed the \"work factor\" by Claude Shannon \u2013 is out of reach of all potential attackers. In many cases, the work factor can be increased by simply choosing a longer key. But other algorithms may inherently have much lower work factors, making resistance to a brute-force attack (e.g., from longer keys) irrelevant. Some special and specific algorithms have been developed to aid in attacking some public key encryption algorithms; both RSA and ElGamal encryption have known attacks that are much faster than the brute-force approach. None of these are sufficiently improved to be actually practical, however.\nMajor weaknesses have been found for several formerly promising asymmetric key algorithms. The \"knapsack packing\" algorithm was found to be insecure after the development of a new attack. As with all cryptographic functions, public-key implementations may be vulnerable to side-channel attacks that exploit information leakage to simplify the search for a secret key. These are often independent of the algorithm being used. Research is underway to both discover, and to protect against, new attacks.\n\n\n*** Alteration of public keys ***\nAnother potential security vulnerability in using asymmetric keys is the possibility of a \"man-in-the-middle\" attack, in which the communication of public keys is intercepted by a third party (the \"man in the middle\") and then modified to provide different public keys instead. Encrypted messages and responses must, in all instances, be intercepted, decrypted, and re-encrypted by the attacker using the correct public keys for the different communication segments so as to avoid suspicion.\nA communication is said to be insecure where data is transmitted in a manner that allows for interception (also called \"sniffing\"). These terms refer to reading the sender's private data in its entirety. A communication is particularly unsafe when interceptions can't be prevented or monitored by the sender.A man-in-the-middle attack can be difficult to implement due to the complexities of modern security protocols. However, the task becomes simpler when a sender is using insecure media such as public networks, the Internet, or wireless communication. In these cases an attacker can compromise the communications infrastructure rather than the data itself. A hypothetical malicious staff member at an Internet Service Provider (ISP) might find a man-in-the-middle attack relatively straightforward. Capturing the public key would only require searching for the key as it gets sent through the ISP's communications hardware;  in properly implemented asymmetric key schemes, this is not a significant risk.\nIn some advanced man-in-the-middle attacks, one side of the communication will see the original data while the other will receive a malicious variant. Asymmetric man-in-the-middle attacks can prevent users from realizing their connection is compromised. This remains so even when one user's data is known to be compromised because the data appears fine to the other user. This can lead to confusing disagreements between users such as \"it must be on your end!\" when neither user is at fault. Hence, man-in-the-middle attacks are only fully preventable when the communications infrastructure is physically controlled by one or both parties; such as via a wired route inside the sender's own building. In summation, public keys are easier to alter when the communications hardware used by a sender is controlled by an attacker.\n\n\n*** Public key infrastructure ***\nOne approach to prevent such attacks involves the use of a public key infrastructure (PKI); a set of roles, policies, and procedures needed to create, manage, distribute, use, store and revoke digital certificates and manage public-key encryption. However, this has potential weaknesses.\nFor example, the certificate authority issuing the certificate must be trusted by all participating parties to have properly checked the identity of the key-holder, to have ensured the correctness of the public key when it issues a certificate, to be secure from computer piracy, and to have made arrangements with all participants to check all their certificates before protected communications can begin. Web browsers, for instance, are supplied with a long list of \"self-signed identity certificates\" from PKI providers \u2013 these are used to check the bona fides of the certificate authority and then, in a second step, the certificates of potential communicators. An attacker who could subvert one of those certificate authorities into issuing a certificate for a bogus public key could then mount a \"man-in-the-middle\" attack as easily as if the certificate scheme were not used at all. In an alternative scenario rarely discussed, an attacker who penetrates an authority's servers and obtains its store of certificates and keys (public and private) would be able to spoof, masquerade, decrypt, and forge transactions without limit.\nDespite its theoretical and potential problems, this approach is widely used. Examples include TLS and its predecessor SSL, which are commonly used to provide security for web browser transactions (for example, to securely send credit card details to an online store).\nAside from the resistance to attack of a particular key pair, the security of the certification hierarchy must be considered when deploying public key systems. Some certificate authority \u2013 usually a purpose-built program running on a server computer \u2013 vouches for the identities assigned to specific private keys by producing a digital certificate. Public key digital certificates are typically valid for several years at a time, so the associated private keys must be held securely over that time. When a private key used for certificate creation higher in the PKI server hierarchy is compromised, or accidentally disclosed, then a \"man-in-the-middle attack\" is possible, making any subordinate certificate wholly insecure.\n\n== Examples ==\nExamples of well-regarded asymmetric key techniques for varied purposes include:\n\nDiffie\u2013Hellman key exchange protocol\nDSS (Digital Signature Standard), which incorporates the Digital Signature Algorithm\nElGamal\nElliptic-curve cryptography\nElliptic Curve Digital Signature Algorithm (ECDSA)\nElliptic-curve Diffie\u2013Hellman (ECDH)\nEd25519 and Ed448 (EdDSA)\nX25519 and X448 (ECDH/EdDH)\nVarious password-authenticated key agreement techniques\nPaillier cryptosystem\nRSA encryption algorithm (PKCS#1)\nCramer\u2013Shoup cryptosystem\nYAK authenticated key agreement protocolExamples of asymmetric key algorithms not yet widely adopted include:\n\nNTRUEncrypt cryptosystem\nKyber\nMcEliece cryptosystemExamples of notable \u2013 yet insecure \u2013 asymmetric key algorithms include:\n\nMerkle\u2013Hellman knapsack cryptosystemExamples of protocols using asymmetric key algorithms include:\n\nS/MIME\nGPG, an implementation of OpenPGP, and an Internet Standard\nEMV, EMV Certificate Authority\nIPsec\nPGP\nZRTP, a secure VoIP protocol\nTransport Layer Security standardized by IETF and its predecessor Secure Socket Layer\nSILC\nSSH\nBitcoin\nOff-the-Record Messaging\n\nAnswer this question based on the above context: How can a public key infrastructure be used to prevent man-in-the-middle attacks?",
    "context": "",
    "output": "A public key infrastructure (PKI) can be used to prevent man-in-the-middle attacks by ensuring the correctness of public keys when they are issued and by making arrangements with all participants to check all certificates before protected communications can begin. This can help to prevent the alteration of public keys and the compromise of the security of the system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a public key infrastructure be used to prevent man-in-the-middle attacks?",
      "answer": "A public key infrastructure (PKI) can be used to prevent man-in-the-middle attacks by ensuring the correctness of public keys when they are issued and by making arrangements with all participants to check all certificates before protected communications can begin. This can help to prevent the alteration of public keys and the compromise of the security of the system.",
      "context": "Public-key cryptography\n\n==Introduction==\nPublic-key cryptography, or asymmetric cryptography, is the field of cryptographic systems that use pairs of related keys. Each key pair consists of a public key and a corresponding private key. Key pairs are generated with cryptographic algorithms based on mathematical problems termed one-way functions. Security of public-key cryptography depends on keeping the private key secret; the public key can be openly distributed without compromising security.In a public-key encryption system, anyone with a public key can encrypt a message, yielding a ciphertext, but only those who know the corresponding private key can decrypt the ciphertext to obtain the original message.For example, a journalist can publish the public key of an encryption key pair on a web site so that sources can send secret messages to the news organization in ciphertext.\nOnly the journalist who knows the corresponding private key can decrypt the ciphertexts to obtain the sources' messages\u2014an eavesdropper reading email on its way to the journalist cannot decrypt the ciphertexts.\nHowever, public-key encryption does not conceal metadata like what computer a source used to send a message, when they sent it, or how long it is.\nPublic-key encryption on its own also does not tell the recipient anything about who sent a message\u2014it just conceals the content of a message in a ciphertext that can only be decrypted with the private key.\nIn a digital signature system, a sender can use a private key together with a message to create a signature.\nAnyone with the corresponding public key can verify whether the signature matches the message, but a forger who does not know the private key cannot find any message/signature pair that will pass verification with the public key.For example, a software publisher can create a signature key pair and include the public key in software installed on computers.\nLater, the publisher can distribute an update to the software signed using the private key, and any computer receiving an update can confirm it is genuine by verifying the signature using the public key.\nAs long as the software publisher keeps the private key secret, even if a forger can distribute malicious updates to computers, they cannot convince the computers that any malicious updates are genuine.\nPublic key algorithms are fundamental security primitives in modern cryptosystems, including applications and protocols which offer assurance of the confidentiality, authenticity and non-repudiability of electronic communications and data storage. They underpin numerous Internet standards, such as Transport Layer Security (TLS), SSH, S/MIME and PGP. Some public key algorithms provide key distribution and secrecy (e.g., Diffie\u2013Hellman key exchange), some provide digital signatures (e.g., Digital Signature Algorithm), and some provide both (e.g., RSA). Compared to symmetric encryption, asymmetric encryption is rather slower than good symmetric encryption, too slow for many purposes. Today's cryptosystems (such as TLS, Secure Shell) use both symmetric encryption and asymmetric encryption, often by using asymmetric encryption to securely exchange a secret key which is then used for symmetric encryption.\n\n\n\n== Description ==\nBefore the mid-1970s, all cipher systems used symmetric key algorithms, in which the same cryptographic key is used with the underlying algorithm by both the sender and the recipient, who must both keep it secret. Of necessity, the key in every such system had to be exchanged between the communicating parties in some secure way prior to any use of the system \u2013 for instance, via a secure channel. This requirement is never trivial and very rapidly becomes unmanageable as the number of participants increases, or when secure channels are not available, or when, (as is sensible cryptographic practice), keys are frequently changed. In particular, if messages are meant to be secure from other users, a separate key is required for each possible pair of users.\nBy contrast, in a public key system, the public keys can be disseminated widely and openly, and only the corresponding private keys need be kept secret by its owner.\nTwo of the best-known uses of public key cryptography are:\n\nPublic key encryption, in which a message is encrypted with the intended recipient's public key. For properly chosen and used algorithms, messages cannot in practice be decrypted by anyone who does not possess the matching private key, who is thus presumed to be the owner of that key and so the person associated with the public key. This can be used to ensure confidentiality of a message.\nDigital signatures, in which a message is signed with the sender's private key and can be verified by anyone who has access to the sender's public key. This verification proves that the sender had access to the private key, and therefore is very likely to be the person associated with the public key. It also proves that the signature was prepared for that exact message, since verification will fail for any other message one could devise without using the private key.One important issue is confidence/proof that a particular public key is authentic, i.e. that it is correct and belongs to the person or entity claimed, and has not been tampered with or replaced by some (perhaps malicious) third party. There are several possible approaches, including:\nA public key infrastructure (PKI), in which one or more third parties \u2013 known as certificate authorities \u2013 certify ownership of key pairs. TLS relies upon this. This implies that the PKI system (software, hardware, and management) is trust-able by all involved.\nA \"web of trust\" which decentralizes authentication by using individual endorsements of links between a user and the public key belonging to that user. PGP uses this approach, in addition to lookup in the domain name system (DNS). The DKIM system for digitally signing emails also uses this approach.\n\n== Applications ==\nThe most obvious application of a public key encryption system is for encrypting communication to provide confidentiality \u2013 a message that a sender encrypts using the recipient's public key which can be decrypted only by the recipient's paired private key.\nAnother application in public key cryptography is the digital signature. Digital signature schemes can be used for sender authentication.\nNon-repudiation systems use digital signatures to ensure that one party cannot successfully dispute its authorship of a document or communication.\nFurther applications built on this foundation include: digital cash, password-authenticated key agreement, time-stamping services and non-repudiation protocols.\n\n\n*** Hybrid cryptosystems ***\nBecause asymmetric key algorithms are nearly always much more computationally intensive than symmetric ones, it is common to use a public/private asymmetric key-exchange algorithm to encrypt and exchange a symmetric key, which is then used by  symmetric-key cryptography to transmit data using the now-shared symmetric key for a symmetric key encryption algorithm. PGP, SSH, and the SSL/TLS family of schemes use this procedure;  they are thus called hybrid cryptosystems. The initial asymmetric cryptography-based key exchange to share a server-generated symmetric key from the server to client has the advantage of not requiring that a symmetric key be pre-shared manually, such as on printed paper or discs transported by a courier, while providing the higher data throughput of symmetric key cryptography over asymmetric key cryptography for the remainder of the shared connection.\n\n== Weaknesses ==\nAs with all security-related systems, it is important to identify potential weaknesses.  Aside from poor choice of an asymmetric key algorithm (there are few which are widely regarded as satisfactory) or too short a key length, the chief security risk is that the private key of a pair becomes known.  All security of messages, authentication, etc., will then be lost.\n\n\n*** Algorithms ***\nAll public key schemes are in theory susceptible to a \"brute-force key search attack\". However, such an attack is impractical if the amount of computation needed to succeed \u2013 termed the \"work factor\" by Claude Shannon \u2013 is out of reach of all potential attackers. In many cases, the work factor can be increased by simply choosing a longer key. But other algorithms may inherently have much lower work factors, making resistance to a brute-force attack (e.g., from longer keys) irrelevant. Some special and specific algorithms have been developed to aid in attacking some public key encryption algorithms; both RSA and ElGamal encryption have known attacks that are much faster than the brute-force approach. None of these are sufficiently improved to be actually practical, however.\nMajor weaknesses have been found for several formerly promising asymmetric key algorithms. The \"knapsack packing\" algorithm was found to be insecure after the development of a new attack. As with all cryptographic functions, public-key implementations may be vulnerable to side-channel attacks that exploit information leakage to simplify the search for a secret key. These are often independent of the algorithm being used. Research is underway to both discover, and to protect against, new attacks.\n\n\n*** Alteration of public keys ***\nAnother potential security vulnerability in using asymmetric keys is the possibility of a \"man-in-the-middle\" attack, in which the communication of public keys is intercepted by a third party (the \"man in the middle\") and then modified to provide different public keys instead. Encrypted messages and responses must, in all instances, be intercepted, decrypted, and re-encrypted by the attacker using the correct public keys for the different communication segments so as to avoid suspicion.\nA communication is said to be insecure where data is transmitted in a manner that allows for interception (also called \"sniffing\"). These terms refer to reading the sender's private data in its entirety. A communication is particularly unsafe when interceptions can't be prevented or monitored by the sender.A man-in-the-middle attack can be difficult to implement due to the complexities of modern security protocols. However, the task becomes simpler when a sender is using insecure media such as public networks, the Internet, or wireless communication. In these cases an attacker can compromise the communications infrastructure rather than the data itself. A hypothetical malicious staff member at an Internet Service Provider (ISP) might find a man-in-the-middle attack relatively straightforward. Capturing the public key would only require searching for the key as it gets sent through the ISP's communications hardware;  in properly implemented asymmetric key schemes, this is not a significant risk.\nIn some advanced man-in-the-middle attacks, one side of the communication will see the original data while the other will receive a malicious variant. Asymmetric man-in-the-middle attacks can prevent users from realizing their connection is compromised. This remains so even when one user's data is known to be compromised because the data appears fine to the other user. This can lead to confusing disagreements between users such as \"it must be on your end!\" when neither user is at fault. Hence, man-in-the-middle attacks are only fully preventable when the communications infrastructure is physically controlled by one or both parties; such as via a wired route inside the sender's own building. In summation, public keys are easier to alter when the communications hardware used by a sender is controlled by an attacker.\n\n\n*** Public key infrastructure ***\nOne approach to prevent such attacks involves the use of a public key infrastructure (PKI); a set of roles, policies, and procedures needed to create, manage, distribute, use, store and revoke digital certificates and manage public-key encryption. However, this has potential weaknesses.\nFor example, the certificate authority issuing the certificate must be trusted by all participating parties to have properly checked the identity of the key-holder, to have ensured the correctness of the public key when it issues a certificate, to be secure from computer piracy, and to have made arrangements with all participants to check all their certificates before protected communications can begin. Web browsers, for instance, are supplied with a long list of \"self-signed identity certificates\" from PKI providers \u2013 these are used to check the bona fides of the certificate authority and then, in a second step, the certificates of potential communicators. An attacker who could subvert one of those certificate authorities into issuing a certificate for a bogus public key could then mount a \"man-in-the-middle\" attack as easily as if the certificate scheme were not used at all. In an alternative scenario rarely discussed, an attacker who penetrates an authority's servers and obtains its store of certificates and keys (public and private) would be able to spoof, masquerade, decrypt, and forge transactions without limit.\nDespite its theoretical and potential problems, this approach is widely used. Examples include TLS and its predecessor SSL, which are commonly used to provide security for web browser transactions (for example, to securely send credit card details to an online store).\nAside from the resistance to attack of a particular key pair, the security of the certification hierarchy must be considered when deploying public key systems. Some certificate authority \u2013 usually a purpose-built program running on a server computer \u2013 vouches for the identities assigned to specific private keys by producing a digital certificate. Public key digital certificates are typically valid for several years at a time, so the associated private keys must be held securely over that time. When a private key used for certificate creation higher in the PKI server hierarchy is compromised, or accidentally disclosed, then a \"man-in-the-middle attack\" is possible, making any subordinate certificate wholly insecure.\n\n== Examples ==\nExamples of well-regarded asymmetric key techniques for varied purposes include:\n\nDiffie\u2013Hellman key exchange protocol\nDSS (Digital Signature Standard), which incorporates the Digital Signature Algorithm\nElGamal\nElliptic-curve cryptography\nElliptic Curve Digital Signature Algorithm (ECDSA)\nElliptic-curve Diffie\u2013Hellman (ECDH)\nEd25519 and Ed448 (EdDSA)\nX25519 and X448 (ECDH/EdDH)\nVarious password-authenticated key agreement techniques\nPaillier cryptosystem\nRSA encryption algorithm (PKCS#1)\nCramer\u2013Shoup cryptosystem\nYAK authenticated key agreement protocolExamples of asymmetric key algorithms not yet widely adopted include:\n\nNTRUEncrypt cryptosystem\nKyber\nMcEliece cryptosystemExamples of notable \u2013 yet insecure \u2013 asymmetric key algorithms include:\n\nMerkle\u2013Hellman knapsack cryptosystemExamples of protocols using asymmetric key algorithms include:\n\nS/MIME\nGPG, an implementation of OpenPGP, and an Internet Standard\nEMV, EMV Certificate Authority\nIPsec\nPGP\nZRTP, a secure VoIP protocol\nTransport Layer Security standardized by IETF and its predecessor Secure Socket Layer\nSILC\nSSH\nBitcoin\nOff-the-Record Messaging"
    }
  },
  {
    "instruction": "Write an answer to the following question: How has Microsoft responded to Ryuk ransomware attacks?",
    "context": "",
    "output": "Microsoft invoked trademark law to disrupt a Ryuk botnet in response to Ryuk ransomware attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has Microsoft responded to Ryuk ransomware attacks?",
      "answer": "Microsoft invoked trademark law to disrupt a Ryuk botnet in response to Ryuk ransomware attacks."
    }
  },
  {
    "instruction": "Common Vulnerabilities and Exposures\n\n==Introduction==\nThe Common Vulnerabilities and Exposures (CVE) system provides a reference method for publicly known information-security vulnerabilities and exposures. The United States' National Cybersecurity FFRDC, operated by The MITRE Corporation, maintains the system, with funding from the US National Cyber Security Division of the US Department of Homeland Security. The system was officially launched for the public in September 1999.The Security Content Automation Protocol uses CVE, and CVE IDs are listed on Mitre's system as well as in the US National Vulnerability Database.\n\n\n\n== Background ==\nA vulnerability is a weakness in a piece of computer software which can be used to access things one should not be able to gain access to. For example, software which processes credit cards should not allow people to read the credit card numbers it processes, but hackers might use a vulnerability to steal credit card numbers. Talking about one specific vulnerability is hard because there are many pieces of software, sometimes with many vulnerabilities. CVE Identifiers give each vulnerability one different name, so people can talk about specific vulnerabilities by using their names.\n\n== CVE identifiers ==\nMITRE Corporation's documentation defines CVE Identifiers (also called \"CVE names\", \"CVE numbers\", \"CVE-IDs\", and \"CVEs\") as unique, common identifiers for publicly known information-security vulnerabilities in publicly released software packages. Historically, CVE identifiers had a status of \"candidate\" (\"CAN-\") and could then be promoted to entries (\"CVE-\"), however this practice was ended in 2005 and all identifiers are now assigned as CVEs. The assignment of a CVE number is not a guarantee that it will become an official CVE entry (e.g. a CVE may be improperly assigned to an issue which is not a security vulnerability, or which duplicates an existing entry).\nCVEs are assigned by a CVE Numbering Authority (CNA). While some vendors acted as a CNA before, the name and designation was not created until February 1, 2005. there are three primary types of CVE number assignments:\n\nThe Mitre Corporation functions as Editor and Primary CNA\nVarious CNAs assign CVE numbers for their own products (e.g. Microsoft, Oracle, HP, Red Hat, etc.)\nA third-party coordinator such as CERT Coordination Center may assign CVE numbers for products not covered by other CNAsWhen investigating a vulnerability or potential vulnerability it helps to acquire a CVE number early on. CVE numbers may not appear in the MITRE or NVD CVE databases for some time (days, weeks, months or potentially years) due to issues that are embargoed (the CVE number has been assigned but the issue has not been made public), or in cases where the entry is not researched and written up by MITRE due to resource issues. The benefit of early CVE candidacy is that all future correspondence can refer to the CVE number. Information on getting CVE identifiers for issues with open source projects is available from Red Hat and GitHubCVEs are for software that has been publicly released; this can include betas and other pre-release versions if they are widely used. Commercial software is included in the \"publicly released\" category, however custom-built software that is not distributed would generally not be given a CVE. Additionally services (e.g. a Web-based email provider) are not assigned CVEs for vulnerabilities found in the service (e.g. an XSS vulnerability) unless the issue exists in an underlying software product that is publicly distributed.\n\n== CVE data fields ==\nThe CVE database contains several fields:\n\n\n*** Description ***\nThis is a standardized text description of the issue(s). One common entry is:\n\n** RESERVED ** This candidate has been reserved by an organization or individual that will use it when announcing a new security problem. When the candidate has been publicized, the details for this candidate will be provided.\nThis means that the entry number has been reserved by Mitre for an issue or a CNA has reserved the number. So in the case where a CNA requests a block of CVE numbers in advance (e.g. Red Hat currently requests CVEs in blocks of 500), the CVE number will be marked as reserved even though the CVE itself may not be assigned by the CNA for some time. Until the CVE is assigned, Mitre is made aware of it (i.e., the embargo passes and the issue is made public), and Mitre has researched the issue and written a description of it, entries will show up as \"** RESERVED **\".\n\n\n*** References ***\nThis is a list of URLs and other information\n\n\n*** Record Creation Date ***\nThis is the date the entry was created. For CVEs assigned directly by Mitre, this is the date Mitre created the CVE entry. For CVEs assigned by CNAs (e.g. Microsoft, Oracle, HP, Red Hat, etc.) this is also the date that was created by Mitre, not by the CNA. The case where a CNA requests a block of CVE numbers in advance (e.g. Red Hat currently requests CVEs in blocks of 500) the entry date that CVE is assigned to the CNA.\n\n\n*** Obsolete fields ***\nThe following fields were previously used in older CVE records, but are no longer used.\n\nPhase: The phase the CVE is in (e.g. CAN, CVE).\nVotes: Previously board members would vote yea or nay on whether or not the CAN should be accepted and turned into a CVE.\nComments: Comments on the issue.\nProposed: When the issue was first proposed.\n\n== Changes to syntax ==\nIn order to support CVE ID's beyond CVE-YEAR-9999 (aka the CVE10k problem) a change was made to the CVE syntax in 2014 and took effect on Jan 13, 2015.The new CVE-ID syntax is variable length and includes:\nCVE prefix + Year + Arbitrary Digits\nNOTE: The variable length arbitrary digits will begin at four fixed digits and expand with arbitrary digits only when needed in a calendar year, for example, CVE-YYYY-NNNN and if needed CVE-YYYY-NNNNN, CVE-YYYY-NNNNNN, and so on. This also means there will be no changes needed to previously assigned CVE-IDs, which all include a minimum of four digits.\n\n== CVE SPLIT and MERGE ==\nCVE attempts to assign one CVE per security issue, however in many cases this would lead to an extremely large number of CVEs (e.g. where several dozen cross-site scripting vulnerabilities are found in a PHP application due to lack of use of htmlspecialchars() or the insecure creation of files in /tmp).\nTo deal with this, there are guidelines (subject to change) that cover the splitting and merging of issues into distinct CVE numbers. As a general guideline one should first consider issues to be merged, then issues should be split by the type of vulnerability (e.g. buffer overflow vs. stack overflow), then by the software version affected (e.g. if one issue affects version 1.3.4 through 2.5.4 and the other affects 1.3.4 through 2.5.8 they would be SPLIT) and then by the reporter of the issue (e.g. Alice reports one issue and Bob reports another issue the issues would be SPLIT into separate CVE numbers).\nAnother example is Alice reports a /tmp file creation vulnerability in version 1.2.3 and earlier of ExampleSoft web browser, in addition to this issue several other /tmp file creation issues are found, in some cases this may be considered as two reporters (and thus SPLIT into two separate CVEs, or if Alice works for ExampleSoft and an ExampleSoft internal team finds the rest it may be MERGE'ed into a single CVE). Conversely, issues can be merged, e.g. if Bob finds 145 XSS vulnerabilities in ExamplePlugin for ExampleFrameWork regardless of the versions affected and so on they may be merged into a single CVE.\n\n== Search CVE identifiers ==\nThe Mitre CVE database can be searched at the CVE List Search, and the NVD CVE database can be searched at Search CVE and CCE Vulnerability Database.\n\n== CVE usage ==\nCVE identifiers are intended for use with respect to identifying vulnerabilities:\n\nCommon Vulnerabilities and Exposures (CVE) is a dictionary of common names (i.e., CVE Identifiers) for publicly known information security vulnerabilities. CVE\u2019s common identifiers make it easier to share data across separate network security databases and tools, and provide a baseline for evaluating the coverage of an organization\u2019s security tools. If a report from one of your security tools incorporates CVE Identifiers, you may then quickly and accurately access fix information in one or more separate CVE-compatible databases to remediate the problem.\n\nUsers who have been assigned a CVE identifier for a vulnerability are encouraged to ensure that they place the identifier in any related security reports, web pages, emails, and so on.\n\n== CVE assignment issues ==\nPer section 7.1 of the CNA Rules, a vendor which received a report about a security vulnerability has full discretion in regards to it. This can lead to a conflict of interest as a vendor may attempt to leave flaws unpatched by denying a CVE assignment at first place \u2013 a decision which Mitre can't reverse.\n\nBased on the above text, answer a question. What potential issues can arise from the discretion that vendors have in regards to CVE assignments?",
    "context": "",
    "output": "The discretion that vendors have in regards to CVE assignments can lead to a conflict of interest, as a vendor may attempt to leave flaws unpatched by denying a CVE assignment. This is a decision that Mitre cannot reverse, and can potentially lead to security vulnerabilities going unaddressed.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What potential issues can arise from the discretion that vendors have in regards to CVE assignments?",
      "answer": "The discretion that vendors have in regards to CVE assignments can lead to a conflict of interest, as a vendor may attempt to leave flaws unpatched by denying a CVE assignment. This is a decision that Mitre cannot reverse, and can potentially lead to security vulnerabilities going unaddressed.",
      "context": "Common Vulnerabilities and Exposures\n\n==Introduction==\nThe Common Vulnerabilities and Exposures (CVE) system provides a reference method for publicly known information-security vulnerabilities and exposures. The United States' National Cybersecurity FFRDC, operated by The MITRE Corporation, maintains the system, with funding from the US National Cyber Security Division of the US Department of Homeland Security. The system was officially launched for the public in September 1999.The Security Content Automation Protocol uses CVE, and CVE IDs are listed on Mitre's system as well as in the US National Vulnerability Database.\n\n\n\n== Background ==\nA vulnerability is a weakness in a piece of computer software which can be used to access things one should not be able to gain access to. For example, software which processes credit cards should not allow people to read the credit card numbers it processes, but hackers might use a vulnerability to steal credit card numbers. Talking about one specific vulnerability is hard because there are many pieces of software, sometimes with many vulnerabilities. CVE Identifiers give each vulnerability one different name, so people can talk about specific vulnerabilities by using their names.\n\n== CVE identifiers ==\nMITRE Corporation's documentation defines CVE Identifiers (also called \"CVE names\", \"CVE numbers\", \"CVE-IDs\", and \"CVEs\") as unique, common identifiers for publicly known information-security vulnerabilities in publicly released software packages. Historically, CVE identifiers had a status of \"candidate\" (\"CAN-\") and could then be promoted to entries (\"CVE-\"), however this practice was ended in 2005 and all identifiers are now assigned as CVEs. The assignment of a CVE number is not a guarantee that it will become an official CVE entry (e.g. a CVE may be improperly assigned to an issue which is not a security vulnerability, or which duplicates an existing entry).\nCVEs are assigned by a CVE Numbering Authority (CNA). While some vendors acted as a CNA before, the name and designation was not created until February 1, 2005. there are three primary types of CVE number assignments:\n\nThe Mitre Corporation functions as Editor and Primary CNA\nVarious CNAs assign CVE numbers for their own products (e.g. Microsoft, Oracle, HP, Red Hat, etc.)\nA third-party coordinator such as CERT Coordination Center may assign CVE numbers for products not covered by other CNAsWhen investigating a vulnerability or potential vulnerability it helps to acquire a CVE number early on. CVE numbers may not appear in the MITRE or NVD CVE databases for some time (days, weeks, months or potentially years) due to issues that are embargoed (the CVE number has been assigned but the issue has not been made public), or in cases where the entry is not researched and written up by MITRE due to resource issues. The benefit of early CVE candidacy is that all future correspondence can refer to the CVE number. Information on getting CVE identifiers for issues with open source projects is available from Red Hat and GitHubCVEs are for software that has been publicly released; this can include betas and other pre-release versions if they are widely used. Commercial software is included in the \"publicly released\" category, however custom-built software that is not distributed would generally not be given a CVE. Additionally services (e.g. a Web-based email provider) are not assigned CVEs for vulnerabilities found in the service (e.g. an XSS vulnerability) unless the issue exists in an underlying software product that is publicly distributed.\n\n== CVE data fields ==\nThe CVE database contains several fields:\n\n\n*** Description ***\nThis is a standardized text description of the issue(s). One common entry is:\n\n** RESERVED ** This candidate has been reserved by an organization or individual that will use it when announcing a new security problem. When the candidate has been publicized, the details for this candidate will be provided.\nThis means that the entry number has been reserved by Mitre for an issue or a CNA has reserved the number. So in the case where a CNA requests a block of CVE numbers in advance (e.g. Red Hat currently requests CVEs in blocks of 500), the CVE number will be marked as reserved even though the CVE itself may not be assigned by the CNA for some time. Until the CVE is assigned, Mitre is made aware of it (i.e., the embargo passes and the issue is made public), and Mitre has researched the issue and written a description of it, entries will show up as \"** RESERVED **\".\n\n\n*** References ***\nThis is a list of URLs and other information\n\n\n*** Record Creation Date ***\nThis is the date the entry was created. For CVEs assigned directly by Mitre, this is the date Mitre created the CVE entry. For CVEs assigned by CNAs (e.g. Microsoft, Oracle, HP, Red Hat, etc.) this is also the date that was created by Mitre, not by the CNA. The case where a CNA requests a block of CVE numbers in advance (e.g. Red Hat currently requests CVEs in blocks of 500) the entry date that CVE is assigned to the CNA.\n\n\n*** Obsolete fields ***\nThe following fields were previously used in older CVE records, but are no longer used.\n\nPhase: The phase the CVE is in (e.g. CAN, CVE).\nVotes: Previously board members would vote yea or nay on whether or not the CAN should be accepted and turned into a CVE.\nComments: Comments on the issue.\nProposed: When the issue was first proposed.\n\n== Changes to syntax ==\nIn order to support CVE ID's beyond CVE-YEAR-9999 (aka the CVE10k problem) a change was made to the CVE syntax in 2014 and took effect on Jan 13, 2015.The new CVE-ID syntax is variable length and includes:\nCVE prefix + Year + Arbitrary Digits\nNOTE: The variable length arbitrary digits will begin at four fixed digits and expand with arbitrary digits only when needed in a calendar year, for example, CVE-YYYY-NNNN and if needed CVE-YYYY-NNNNN, CVE-YYYY-NNNNNN, and so on. This also means there will be no changes needed to previously assigned CVE-IDs, which all include a minimum of four digits.\n\n== CVE SPLIT and MERGE ==\nCVE attempts to assign one CVE per security issue, however in many cases this would lead to an extremely large number of CVEs (e.g. where several dozen cross-site scripting vulnerabilities are found in a PHP application due to lack of use of htmlspecialchars() or the insecure creation of files in /tmp).\nTo deal with this, there are guidelines (subject to change) that cover the splitting and merging of issues into distinct CVE numbers. As a general guideline one should first consider issues to be merged, then issues should be split by the type of vulnerability (e.g. buffer overflow vs. stack overflow), then by the software version affected (e.g. if one issue affects version 1.3.4 through 2.5.4 and the other affects 1.3.4 through 2.5.8 they would be SPLIT) and then by the reporter of the issue (e.g. Alice reports one issue and Bob reports another issue the issues would be SPLIT into separate CVE numbers).\nAnother example is Alice reports a /tmp file creation vulnerability in version 1.2.3 and earlier of ExampleSoft web browser, in addition to this issue several other /tmp file creation issues are found, in some cases this may be considered as two reporters (and thus SPLIT into two separate CVEs, or if Alice works for ExampleSoft and an ExampleSoft internal team finds the rest it may be MERGE'ed into a single CVE). Conversely, issues can be merged, e.g. if Bob finds 145 XSS vulnerabilities in ExamplePlugin for ExampleFrameWork regardless of the versions affected and so on they may be merged into a single CVE.\n\n== Search CVE identifiers ==\nThe Mitre CVE database can be searched at the CVE List Search, and the NVD CVE database can be searched at Search CVE and CCE Vulnerability Database.\n\n== CVE usage ==\nCVE identifiers are intended for use with respect to identifying vulnerabilities:\n\nCommon Vulnerabilities and Exposures (CVE) is a dictionary of common names (i.e., CVE Identifiers) for publicly known information security vulnerabilities. CVE\u2019s common identifiers make it easier to share data across separate network security databases and tools, and provide a baseline for evaluating the coverage of an organization\u2019s security tools. If a report from one of your security tools incorporates CVE Identifiers, you may then quickly and accurately access fix information in one or more separate CVE-compatible databases to remediate the problem.\n\nUsers who have been assigned a CVE identifier for a vulnerability are encouraged to ensure that they place the identifier in any related security reports, web pages, emails, and so on.\n\n== CVE assignment issues ==\nPer section 7.1 of the CNA Rules, a vendor which received a report about a security vulnerability has full discretion in regards to it. This can lead to a conflict of interest as a vendor may attempt to leave flaws unpatched by denying a CVE assignment at first place \u2013 a decision which Mitre can't reverse."
    }
  },
  {
    "instruction": "Write an answer to the following question: In what ways do AAA servers differ from HLR in CDMA wireless voice network architecture?",
    "context": "",
    "output": "AAA servers provide Internet Protocol (IP) functionality to support authentication, authorization, and accounting, while HLR in CDMA wireless voice network architecture does not provide IP functionality.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In what ways do AAA servers differ from HLR in CDMA wireless voice network architecture?",
      "answer": "AAA servers provide Internet Protocol (IP) functionality to support authentication, authorization, and accounting, while HLR in CDMA wireless voice network architecture does not provide IP functionality."
    }
  },
  {
    "instruction": "context: Key risk indicators in the Risk IT framework are metrics capable of showing that the organization is subject or has a high probability of being subject to a risk that exceeds the defined risk appetite.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are key risk indicators in the Risk IT framework?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are key risk indicators in the Risk IT framework?",
      "answer": "Key risk indicators in the Risk IT framework are metrics capable of showing that the organization is subject or has a high probability of being subject to a risk that exceeds the defined risk appetite."
    }
  },
  {
    "instruction": "context: Anonym.OS included various encryption and anonymization tools, but the specific details of these tools are not provided in the given text.\n\nAsk a question about this context.",
    "context": "",
    "output": "What encryption tools were included with Anonym.OS?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What encryption tools were included with Anonym.OS?",
      "answer": "Anonym.OS included various encryption and anonymization tools, but the specific details of these tools are not provided in the given text."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the 383rd Information Technology Battalion in the CIDS organization?",
    "context": "",
    "output": "The 383rd Information Technology Battalion is responsible for managing the CIDS' information technology research and development, ensuring that the organization has access to the latest and most advanced technology.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the 383rd Information Technology Battalion in the CIDS organization?",
      "answer": "The 383rd Information Technology Battalion is responsible for managing the CIDS' information technology research and development, ensuring that the organization has access to the latest and most advanced technology."
    }
  },
  {
    "instruction": "Write an answer to the following question: How is information security awareness evolving in response to the changing nature of cyber attacks and the increased targeting of personal information?",
    "context": "",
    "output": "Information security awareness is evolving in response to the increased cost and scale of information security breaches, as well as the need to understand and measure the human threat landscape and measure and reduce organizational risk.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is information security awareness evolving in response to the changing nature of cyber attacks and the increased targeting of personal information?",
      "answer": "Information security awareness is evolving in response to the increased cost and scale of information security breaches, as well as the need to understand and measure the human threat landscape and measure and reduce organizational risk."
    }
  },
  {
    "instruction": "Slow DoS Attack\n\n==Introduction==\nThe term Slow DoS Attack (abbreviated to SDA) was introduced in 2013, to clearly define a specific category of denial of service attacks which make use of low-bandwidth rate to accomplish their purpose.\nSimilar terms can be found in literature, such as:\n\napplication layer DoS, focusing on attacks targeting the application layer only, while a Slow DoS Attack may exploit lower-layers of the ISO/OSI stack\nlow-rate DoS, focusing on the characteristics of using a limited amount of attack bandwidth, hence, for instance, including also exploit-based threatsParticularly, in order to reduce bandwidth, a Slow DoS Attack often acts at the application layer of the ISO/OSI stack (e.g. in case of timeout exploiting threats), although this is not a requirement. Such layer is however easier to exploit in order to successfully attack a victim even by sending it few bytes of malicious requests.\nThe purpose of a Slow DoS Attack is (often, but not always) to cause unavailability of a network service, by seizing all the connections the daemon is able to concurrently manage, at the application layer. Under such condition, any new incoming connection, even from potentially legitimate clients, will not be accepted by the daemon, hence leading to a denial of service. In addition, once a connection is established/sized by the attacker, the adversary would keep it alive as long as possible (hence, avoiding connection closures, which could potentially free-up resources for legitimate clients). In order to keep connections alive, reducing at the same time the attack bandwidth, considering a single connection, data are sent to the target service only at specific times, by exploiting the so-called Wait Timeout parameter, scheduling a periodic data sending activity (at the application layer): once the timeout expires, a specific payload (depending on the attack type and the approach used by the malicious user) is sent to the targeted daemon. While at lower layers of the ISO/OSI stack, timeouts may be relatively short, in this case, it may assume particularly long values, in the order of minutes.\n\n== Exploited parameters ==\nAccording to Cambiaso et al, Slow DoS Attacks exploit one or more parameters characteristics of TCP-based connections. Such parameters are exploited to keep connections alive longer than expected by preserving the attack bandwidth, hence seizing the server resources for long times, by at the same time reducing attack resources.\n\nBased on the above text, answer a question. What is the potential impact of Slow DoS Attacks on businesses and organizations?",
    "context": "",
    "output": "Slow DoS Attacks can have significant impact on businesses and organizations by causing unavailability of network services, leading to loss of productivity, revenue, and reputation, and requiring significant resources to mitigate and recover from the attacks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the potential impact of Slow DoS Attacks on businesses and organizations?",
      "answer": "Slow DoS Attacks can have significant impact on businesses and organizations by causing unavailability of network services, leading to loss of productivity, revenue, and reputation, and requiring significant resources to mitigate and recover from the attacks.",
      "context": "Slow DoS Attack\n\n==Introduction==\nThe term Slow DoS Attack (abbreviated to SDA) was introduced in 2013, to clearly define a specific category of denial of service attacks which make use of low-bandwidth rate to accomplish their purpose.\nSimilar terms can be found in literature, such as:\n\napplication layer DoS, focusing on attacks targeting the application layer only, while a Slow DoS Attack may exploit lower-layers of the ISO/OSI stack\nlow-rate DoS, focusing on the characteristics of using a limited amount of attack bandwidth, hence, for instance, including also exploit-based threatsParticularly, in order to reduce bandwidth, a Slow DoS Attack often acts at the application layer of the ISO/OSI stack (e.g. in case of timeout exploiting threats), although this is not a requirement. Such layer is however easier to exploit in order to successfully attack a victim even by sending it few bytes of malicious requests.\nThe purpose of a Slow DoS Attack is (often, but not always) to cause unavailability of a network service, by seizing all the connections the daemon is able to concurrently manage, at the application layer. Under such condition, any new incoming connection, even from potentially legitimate clients, will not be accepted by the daemon, hence leading to a denial of service. In addition, once a connection is established/sized by the attacker, the adversary would keep it alive as long as possible (hence, avoiding connection closures, which could potentially free-up resources for legitimate clients). In order to keep connections alive, reducing at the same time the attack bandwidth, considering a single connection, data are sent to the target service only at specific times, by exploiting the so-called Wait Timeout parameter, scheduling a periodic data sending activity (at the application layer): once the timeout expires, a specific payload (depending on the attack type and the approach used by the malicious user) is sent to the targeted daemon. While at lower layers of the ISO/OSI stack, timeouts may be relatively short, in this case, it may assume particularly long values, in the order of minutes.\n\n== Exploited parameters ==\nAccording to Cambiaso et al, Slow DoS Attacks exploit one or more parameters characteristics of TCP-based connections. Such parameters are exploited to keep connections alive longer than expected by preserving the attack bandwidth, hence seizing the server resources for long times, by at the same time reducing attack resources."
    }
  },
  {
    "instruction": "Context: Advanced Encryption Standard\n\n==Introduction==\nThe Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [\u02c8r\u025binda\u02d0l]), is a specification for the encryption of electronic data established by the U.S. National Institute of Standards and Technology (NIST) in 2001.AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process. Rijndael is a family of ciphers with different key and block sizes. For AES, NIST selected three members of the Rijndael family, each with a block size of 128 bits, but three different key lengths: 128, 192 and 256 bits.\nAES has been adopted by the U.S. government. It supersedes the Data Encryption Standard (DES), which was published in 1977. The algorithm described by AES is a symmetric-key algorithm, meaning the same key is used for both encrypting and decrypting the data.\nIn the United States, AES was announced by the NIST as U.S. FIPS PUB 197 (FIPS 197) on November 26, 2001. This announcement followed a five-year standardization process in which fifteen competing designs were presented and evaluated, before the Rijndael cipher was selected as the most suitable.AES is included in the ISO/IEC 18033-3 standard.  AES became effective as a U.S. federal government standard on May 26, 2002, after approval by the U.S. Secretary of Commerce. AES is available in many different encryption packages, and is the first (and only) publicly accessible cipher approved by the U.S. National Security Agency (NSA) for top secret information when used in an NSA approved cryptographic module.\n\n\n\n== Definitive standards ==\nThe Advanced Encryption Standard (AES) is defined in each of:\n\nFIPS PUB 197: Advanced Encryption Standard (AES)\nISO/IEC 18033-3: Block ciphers\n\n== Description of the ciphers ==\nAES is based on a design principle known as a substitution\u2013permutation network, and is efficient in both software and hardware. Unlike its predecessor DES, AES does not use a Feistel network. AES is a variant of Rijndael, with a fixed block size of 128 bits, and a key size of 128, 192, or 256 bits. By contrast, Rijndael per se is specified with block and key sizes that may be any multiple of 32 bits, with a minimum of 128 and a maximum of 256 bits. Most AES calculations are done in a particular finite field.\nAES operates on a 4 \u00d7 4 column-major order array of 16 bytes b0,\u2009b1,\u2009...,\u2009b15 termed the state:\n\n  \n    \n      \n        \n          \n            [\n            \n              \n                \n                  \n                    b\n                    \n                      0\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      8\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      12\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      1\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      9\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      13\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      10\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      14\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      11\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      15\n                    \n                  \n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle {\\begin{bmatrix}b_{0}&b_{4}&b_{8}&b_{12}\\\\b_{1}&b_{5}&b_{9}&b_{13}\\\\b_{2}&b_{6}&b_{10}&b_{14}\\\\b_{3}&b_{7}&b_{11}&b_{15}\\end{bmatrix}}}\n  The key size used for an AES cipher specifies the number of transformation rounds that convert the input, called the plaintext, into the final output, called the ciphertext. The number of rounds are as follows:\n\n10 rounds for 128-bit keys.\n12 rounds for 192-bit keys.\n14 rounds for 256-bit keys.Each round consists of several processing steps, including one that depends on the encryption key itself. A set of reverse rounds are applied to transform ciphertext back into the original plaintext using the same encryption key.\n\n\n*** High-level description of the algorithm ***\n KeyExpansion \u2013 round keys are derived from the cipher key using the AES key schedule. AES requires a separate 128-bit round key block for each round plus one more.\nInitial round key addition:\n AddRoundKey \u2013 each byte of the state is combined with a byte of the round key using bitwise xor.\n9, 11 or 13 rounds:\n SubBytes \u2013 a non-linear substitution step where each byte is replaced with another according to a lookup table.\n ShiftRows \u2013 a transposition step where the last three rows of the state are shifted cyclically a certain number of steps.\n MixColumns \u2013 a linear mixing operation which operates on the columns of the state, combining the four bytes in each column.\n AddRoundKey\nFinal round (making 10, 12 or 14 rounds in total):\n SubBytes\n ShiftRows\n AddRoundKey\n\n\n*** The  SubBytes step ***\n\nIn the  SubBytes step, each byte \n  \n    \n      \n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n      \n    \n    {\\displaystyle a_{i,j}}\n   in the state array is replaced with a  SubByte \n  \n    \n      \n        S\n        (\n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n        )\n      \n    \n    {\\displaystyle S(a_{i,j})}\n   using an 8-bit substitution box. Note that before round 0, the state array is simply the plaintext/input. This operation provides the non-linearity in the cipher. The S-box used is derived from the multiplicative inverse over GF(28), known to have good non-linearity properties. To avoid attacks based on simple algebraic properties, the S-box is constructed by combining the inverse function with an invertible affine transformation. The S-box is also chosen to avoid any fixed points (and so is a derangement), i.e., \n  \n    \n      \n        S\n        (\n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n        )\n        \u2260\n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n      \n    \n    {\\displaystyle S(a_{i,j})\\neq a_{i,j}}\n  , and also any opposite fixed points, i.e., \n  \n    \n      \n        S\n        (\n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n        )\n        \u2295\n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n        \u2260\n        \n          \n            FF\n          \n          \n            16\n          \n        \n      \n    \n    {\\displaystyle S(a_{i,j})\\oplus a_{i,j}\\neq {\\text{FF}}_{16}}\n  .\nWhile performing the decryption, the  InvSubBytes step (the inverse of  SubBytes) is used, which requires first taking the inverse of the affine transformation and then finding the multiplicative inverse.\n\n\n*** The  ShiftRows step ***\n\nThe  ShiftRows step operates on the rows of the state; it cyclically shifts the bytes in each row by a certain offset. For AES, the first row is left unchanged. Each byte of the second row is shifted one to the left. Similarly, the third and fourth rows are shifted by offsets of two and three respectively. In this way, each column of the output state of the  ShiftRows step is composed of bytes from each column of the input state. The importance of this step is to avoid the columns being encrypted independently, in which case AES would degenerate into four independent block ciphers.\n\n\n*** The  MixColumns step ***\n\nIn the  MixColumns step, the four bytes of each column of the state are combined using an invertible linear transformation. The  MixColumns function takes four bytes as input and outputs four bytes, where each input byte affects all four output bytes. Together with  ShiftRows,  MixColumns provides diffusion in the cipher.\nDuring this operation, each column is transformed using a fixed matrix (matrix left-multiplied by column gives new value of column in the state):\n\n  \n    \n      \n        \n          \n            [\n            \n              \n                \n                  \n                    b\n                    \n                      0\n                      ,\n                      j\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      1\n                      ,\n                      j\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      2\n                      ,\n                      j\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      3\n                      ,\n                      j\n                    \n                  \n                \n              \n            \n            ]\n\n== Security ==\nThe National Security Agency (NSA) reviewed all the AES finalists, including Rijndael, and stated that all of them were secure enough for U.S. Government non-classified data. In June 2003, the U.S. Government announced that AES could be used to protect classified information:\n\nThe design and strength of all key lengths of the AES algorithm (i.e., 128, 192 and 256) are sufficient to protect classified information up to the SECRET level. TOP SECRET information will require use of either the 192 or 256 key lengths. The implementation of AES in products intended to protect national security systems and/or information must be reviewed and certified by NSA prior to their acquisition and use.\nAES has 10 rounds for 128-bit keys, 12 rounds for 192-bit keys, and 14 rounds for 256-bit keys.\nBy 2006, the best known attacks were on 7 rounds for 128-bit keys, 8 rounds for 192-bit keys, and 9 rounds for 256-bit keys.\n\n\n*** Known attacks ***\nFor cryptographers, a cryptographic \"break\" is anything faster than a brute-force attack \u2013 i.e., performing one trial decryption for each possible key in sequence. A break can thus include results that are infeasible with current technology. Despite being impractical, theoretical breaks can sometimes provide insight into vulnerability patterns. The largest successful publicly known brute-force attack against a widely implemented block-cipher encryption algorithm was against a 64-bit RC5 key by distributed.net in 2006.The key space increases by a factor of 2 for each additional bit of key length, and if every possible value of the key is equiprobable, this translates into a doubling of the average brute-force key search time. This implies that the effort of a brute-force search increases exponentially with key length. Key length in itself does not imply security against attacks, since there are ciphers with very long keys that have been found to be vulnerable.\nAES has a fairly simple algebraic framework. In 2002, a theoretical attack, named the \"XSL attack\", was announced by Nicolas Courtois and Josef Pieprzyk, purporting to show a weakness in the AES algorithm, partially due to the low complexity of its nonlinear components. Since then, other papers have shown that the attack, as originally presented, is unworkable; see XSL attack on block ciphers.\nDuring the AES selection process, developers of competing algorithms wrote of Rijndael's algorithm \"we are concerned about [its] use ... in security-critical applications.\" In October 2000, however, at the end of the AES selection process, Bruce Schneier, a developer of the competing algorithm Twofish, wrote that while he thought successful academic attacks on Rijndael would be developed someday, he \"did not believe that anyone will ever discover an attack that will allow someone to read Rijndael traffic.\"Until May 2009, the only successful published attacks against the full AES were side-channel attacks on some specific implementations. In 2009, a new related-key attack was discovered that exploits the simplicity of AES's key schedule and has a complexity of 2119. In December 2009 it was improved to 299.5. This is a follow-up to an attack discovered earlier in 2009 by Alex Biryukov, Dmitry Khovratovich, and Ivica Nikoli\u0107, with a complexity of 296 for one out of every 235 keys. However, related-key attacks are not of concern in any properly designed cryptographic protocol, as a properly designed protocol (i.e., implementational software) will take care not to allow related keys, essentially by constraining an attacker's means of selecting keys for relatedness.\nAnother attack was blogged by Bruce Schneier\non July 30, 2009, and released as a preprint\non August 3, 2009. This new attack, by Alex Biryukov, Orr Dunkelman, Nathan Keller, Dmitry Khovratovich, and Adi Shamir, is against AES-256 that uses only two related keys and 239 time to recover the complete 256-bit key of a 9-round version, or 245 time for a 10-round version with a stronger type of related subkey attack, or 270 time for an 11-round version. 256-bit AES uses 14 rounds, so these attacks are not effective against full AES.\nThe practicality of these attacks with stronger related keys has been criticized, for instance, by the paper on chosen-key-relations-in-the-middle attacks on AES-128 authored by Vincent Rijmen in 2010.In November 2009, the first known-key distinguishing attack against a reduced 8-round version of AES-128 was released as a preprint.\nThis known-key distinguishing attack is an improvement of the rebound, or the start-from-the-middle attack, against AES-like permutations, which view two consecutive rounds of permutation as the application of a so-called Super-S-box. It works on the 8-round version of AES-128, with a time complexity of 248, and a memory complexity of 232.  128-bit AES uses 10 rounds, so this attack is not effective against full AES-128.\nThe first key-recovery attacks on full AES were by Andrey Bogdanov, Dmitry Khovratovich, and Christian Rechberger, and were published in 2011. The attack is a biclique attack and is faster than brute force by a factor of about four. It requires 2126.2 operations to recover an AES-128 key. For AES-192 and AES-256, 2190.2 and 2254.6 operations are needed, respectively. This result has been further improved to 2126.0 for AES-128, 2189.9 for AES-192 and 2254.3 for AES-256, which are the current best results in key recovery attack against AES.\nThis is a very small gain, as a 126-bit key (instead of 128-bits) would still take billions of years to brute force on current and foreseeable hardware. Also, the authors calculate the best attack using their technique on AES with a 128-bit key requires storing 288 bits of data. That works out to about 38 trillion terabytes of data, which is more than all the data stored on all the computers on the planet in 2016. As such, there are no practical implications on AES security. The space complexity has later been improved to 256 bits, which is 9007 terabytes (while still keeping a time complexity of 2126.2).\nAccording to the Snowden documents, the NSA is doing research on whether a cryptographic attack based on tau statistic may help to break AES.At present, there is no known practical attack that would allow someone without knowledge of the key to read data encrypted by AES when correctly implemented.\n\n\n*** Side-channel attacks ***\nSide-channel attacks do not attack the cipher as a black box, and thus are not related to cipher security as defined in the classical context, but are important in practice. They attack implementations of the cipher on hardware or software systems that inadvertently leak data. There are several such known attacks on various implementations of AES.\nIn April 2005, D. J. Bernstein announced a cache-timing attack that he used to break a custom server that used OpenSSL's AES encryption. The attack required over 200 million chosen plaintexts. The custom server was designed to give out as much timing information as possible (the server reports back the number of machine cycles taken by the encryption operation). However, as Bernstein pointed out, \"reducing the precision of the server's timestamps, or eliminating them from the server's responses, does not stop the attack: the client simply uses round-trip timings based on its local clock, and compensates for the increased noise by averaging over a larger number of samples\".In October 2005, Dag Arne Osvik, Adi Shamir and Eran Tromer presented a paper demonstrating several cache-timing attacks against the implementations in AES found in OpenSSL and Linux's dm-crypt partition encryption function. One attack was able to obtain an entire AES key after only 800 operations triggering encryptions, in a total of 65 milliseconds. This attack requires the attacker to be able to run programs on the same system or platform that is performing AES.\nIn December 2009 an attack on some hardware implementations was published that used differential fault analysis and allows recovery of a key with a complexity of 232.In November 2010 Endre Bangerter, David Gullasch and Stephan Krenn published a paper which described a practical approach to a \"near real time\" recovery of secret keys from AES-128 without the need for either cipher text or plaintext. The approach also works on AES-128 implementations that use compression tables, such as OpenSSL. Like some earlier attacks, this one requires the ability to run unprivileged code on the system performing the AES encryption, which may be achieved by malware infection far more easily than commandeering the root account.In March 2016, Ashokkumar C., Ravi Prakash Giri and Bernard Menezes presented a side-channel attack on AES implementations that can recover the complete 128-bit AES key in just 6\u20137 blocks of plaintext/ciphertext, which is a substantial improvement over previous works that require between 100 and a million encryptions. The proposed attack requires standard user privilege and key-retrieval algorithms run under a minute.\nMany modern CPUs have built-in hardware instructions for AES, which protect against timing-related side-channel attacks.\n\n== NIST/CSEC validation ==\nThe Cryptographic Module Validation Program (CMVP) is operated jointly by the United States Government's National Institute of Standards and Technology (NIST) Computer Security Division and the Communications Security Establishment (CSE) of the Government of Canada. The use of cryptographic modules validated to NIST FIPS 140-2 is required by the United States Government for encryption of all data that has a classification of Sensitive but Unclassified (SBU) or above. From NSTISSP #11, National Policy Governing the Acquisition of Information Assurance: \u201cEncryption products for protecting classified information will be certified by NSA, and encryption products intended for protecting sensitive information will be certified in accordance with NIST FIPS 140-2.\u201dThe Government of Canada also recommends the use of FIPS 140 validated cryptographic modules in unclassified applications of its departments.\nAlthough NIST publication 197 (\u201cFIPS 197\u201d) is the unique document that covers the AES algorithm, vendors typically approach the CMVP under FIPS 140 and ask to have several algorithms (such as Triple DES or SHA1) validated at the same time. Therefore, it is rare to find cryptographic modules that are uniquely FIPS 197 validated and NIST itself does not generally take the time to list FIPS 197 validated modules separately on its public web site. Instead, FIPS 197 validation is typically just listed as an \"FIPS approved: AES\" notation (with a specific FIPS 197 certificate number) in the current list of FIPS 140 validated cryptographic modules.\nThe Cryptographic Algorithm Validation Program (CAVP) allows for independent validation of the correct implementation of the AES algorithm. Successful validation results in being listed on the NIST validations page. This testing is a pre-requisite for the FIPS 140-2 module validation. However, successful CAVP validation in no way implies that the cryptographic module implementing the algorithm is secure. A cryptographic module lacking FIPS 140-2 validation or specific approval by the NSA is not deemed secure by the US Government and cannot be used to protect government data.FIPS 140-2 validation is challenging to achieve both technically and fiscally. There is a standardized battery of tests as well as an element of source code review that must be passed over a period of a few weeks. The cost to perform these tests through an approved laboratory can be significant (e.g., well over $30,000 US) and does not include the time it takes to write, test, document and prepare a module for validation. After validation, modules must be re-submitted and re-evaluated if they are changed in any way. This can vary from simple paperwork updates if the security functionality did not change to a more substantial set of re-testing if the security functionality was impacted by the change.\n\n== Test vectors ==\nTest vectors are a set of known ciphers for a given input and key. NIST distributes the reference of AES test vectors as AES Known Answer Test (KAT) Vectors.\n\n== Performance ==\nHigh speed and low RAM requirements were some of the criteria of the AES selection process. As the chosen algorithm, AES performed well on a wide variety of hardware, from 8-bit smart cards to high-performance computers.\nOn a Pentium Pro, AES encryption requires 18 clock cycles per byte, equivalent to a throughput of about 11 MiB/s for a 200 MHz processor.\nOn Intel Core and AMD Ryzen CPUs supporting AES-NI instruction set extensions, throughput can be multiple GiB/s (even over 15 GiB/s on an i7-12700k).\n\n== Implementations ==\n\nQuestion: What is the significance of the number of rounds in AES for different key sizes?\n\nAnswer:",
    "context": "",
    "output": "The number of rounds in AES for different key sizes (10 for 128-bit keys, 12 for 192-bit keys, and 14 for 256-bit keys) is designed to provide sufficient security for classified information up to the SECRET level for 128-bit keys and TOP SECRET information for 192 or 256-bit keys.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the number of rounds in AES for different key sizes?",
      "answer": "The number of rounds in AES for different key sizes (10 for 128-bit keys, 12 for 192-bit keys, and 14 for 256-bit keys) is designed to provide sufficient security for classified information up to the SECRET level for 128-bit keys and TOP SECRET information for 192 or 256-bit keys.",
      "context": "Advanced Encryption Standard\n\n==Introduction==\nThe Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [\u02c8r\u025binda\u02d0l]), is a specification for the encryption of electronic data established by the U.S. National Institute of Standards and Technology (NIST) in 2001.AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process. Rijndael is a family of ciphers with different key and block sizes. For AES, NIST selected three members of the Rijndael family, each with a block size of 128 bits, but three different key lengths: 128, 192 and 256 bits.\nAES has been adopted by the U.S. government. It supersedes the Data Encryption Standard (DES), which was published in 1977. The algorithm described by AES is a symmetric-key algorithm, meaning the same key is used for both encrypting and decrypting the data.\nIn the United States, AES was announced by the NIST as U.S. FIPS PUB 197 (FIPS 197) on November 26, 2001. This announcement followed a five-year standardization process in which fifteen competing designs were presented and evaluated, before the Rijndael cipher was selected as the most suitable.AES is included in the ISO/IEC 18033-3 standard.  AES became effective as a U.S. federal government standard on May 26, 2002, after approval by the U.S. Secretary of Commerce. AES is available in many different encryption packages, and is the first (and only) publicly accessible cipher approved by the U.S. National Security Agency (NSA) for top secret information when used in an NSA approved cryptographic module.\n\n\n\n== Definitive standards ==\nThe Advanced Encryption Standard (AES) is defined in each of:\n\nFIPS PUB 197: Advanced Encryption Standard (AES)\nISO/IEC 18033-3: Block ciphers\n\n== Description of the ciphers ==\nAES is based on a design principle known as a substitution\u2013permutation network, and is efficient in both software and hardware. Unlike its predecessor DES, AES does not use a Feistel network. AES is a variant of Rijndael, with a fixed block size of 128 bits, and a key size of 128, 192, or 256 bits. By contrast, Rijndael per se is specified with block and key sizes that may be any multiple of 32 bits, with a minimum of 128 and a maximum of 256 bits. Most AES calculations are done in a particular finite field.\nAES operates on a 4 \u00d7 4 column-major order array of 16 bytes b0,\u2009b1,\u2009...,\u2009b15 termed the state:\n\n  \n    \n      \n        \n          \n            [\n            \n              \n                \n                  \n                    b\n                    \n                      0\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      4\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      8\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      12\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      1\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      5\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      9\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      13\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      2\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      6\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      10\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      14\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      3\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      7\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      11\n                    \n                  \n                \n                \n                  \n                    b\n                    \n                      15\n                    \n                  \n                \n              \n            \n            ]\n          \n        \n      \n    \n    {\\displaystyle {\\begin{bmatrix}b_{0}&b_{4}&b_{8}&b_{12}\\\\b_{1}&b_{5}&b_{9}&b_{13}\\\\b_{2}&b_{6}&b_{10}&b_{14}\\\\b_{3}&b_{7}&b_{11}&b_{15}\\end{bmatrix}}}\n  The key size used for an AES cipher specifies the number of transformation rounds that convert the input, called the plaintext, into the final output, called the ciphertext. The number of rounds are as follows:\n\n10 rounds for 128-bit keys.\n12 rounds for 192-bit keys.\n14 rounds for 256-bit keys.Each round consists of several processing steps, including one that depends on the encryption key itself. A set of reverse rounds are applied to transform ciphertext back into the original plaintext using the same encryption key.\n\n\n*** High-level description of the algorithm ***\n KeyExpansion \u2013 round keys are derived from the cipher key using the AES key schedule. AES requires a separate 128-bit round key block for each round plus one more.\nInitial round key addition:\n AddRoundKey \u2013 each byte of the state is combined with a byte of the round key using bitwise xor.\n9, 11 or 13 rounds:\n SubBytes \u2013 a non-linear substitution step where each byte is replaced with another according to a lookup table.\n ShiftRows \u2013 a transposition step where the last three rows of the state are shifted cyclically a certain number of steps.\n MixColumns \u2013 a linear mixing operation which operates on the columns of the state, combining the four bytes in each column.\n AddRoundKey\nFinal round (making 10, 12 or 14 rounds in total):\n SubBytes\n ShiftRows\n AddRoundKey\n\n\n*** The  SubBytes step ***\n\nIn the  SubBytes step, each byte \n  \n    \n      \n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n      \n    \n    {\\displaystyle a_{i,j}}\n   in the state array is replaced with a  SubByte \n  \n    \n      \n        S\n        (\n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n        )\n      \n    \n    {\\displaystyle S(a_{i,j})}\n   using an 8-bit substitution box. Note that before round 0, the state array is simply the plaintext/input. This operation provides the non-linearity in the cipher. The S-box used is derived from the multiplicative inverse over GF(28), known to have good non-linearity properties. To avoid attacks based on simple algebraic properties, the S-box is constructed by combining the inverse function with an invertible affine transformation. The S-box is also chosen to avoid any fixed points (and so is a derangement), i.e., \n  \n    \n      \n        S\n        (\n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n        )\n        \u2260\n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n      \n    \n    {\\displaystyle S(a_{i,j})\\neq a_{i,j}}\n  , and also any opposite fixed points, i.e., \n  \n    \n      \n        S\n        (\n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n        )\n        \u2295\n        \n          a\n          \n            i\n            ,\n            j\n          \n        \n        \u2260\n        \n          \n            FF\n          \n          \n            16\n          \n        \n      \n    \n    {\\displaystyle S(a_{i,j})\\oplus a_{i,j}\\neq {\\text{FF}}_{16}}\n  .\nWhile performing the decryption, the  InvSubBytes step (the inverse of  SubBytes) is used, which requires first taking the inverse of the affine transformation and then finding the multiplicative inverse.\n\n\n*** The  ShiftRows step ***\n\nThe  ShiftRows step operates on the rows of the state; it cyclically shifts the bytes in each row by a certain offset. For AES, the first row is left unchanged. Each byte of the second row is shifted one to the left. Similarly, the third and fourth rows are shifted by offsets of two and three respectively. In this way, each column of the output state of the  ShiftRows step is composed of bytes from each column of the input state. The importance of this step is to avoid the columns being encrypted independently, in which case AES would degenerate into four independent block ciphers.\n\n\n*** The  MixColumns step ***\n\nIn the  MixColumns step, the four bytes of each column of the state are combined using an invertible linear transformation. The  MixColumns function takes four bytes as input and outputs four bytes, where each input byte affects all four output bytes. Together with  ShiftRows,  MixColumns provides diffusion in the cipher.\nDuring this operation, each column is transformed using a fixed matrix (matrix left-multiplied by column gives new value of column in the state):\n\n  \n    \n      \n        \n          \n            [\n            \n              \n                \n                  \n                    b\n                    \n                      0\n                      ,\n                      j\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      1\n                      ,\n                      j\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      2\n                      ,\n                      j\n                    \n                  \n                \n              \n              \n                \n                  \n                    b\n                    \n                      3\n                      ,\n                      j\n                    \n                  \n                \n              \n            \n            ]\n\n== Security ==\nThe National Security Agency (NSA) reviewed all the AES finalists, including Rijndael, and stated that all of them were secure enough for U.S. Government non-classified data. In June 2003, the U.S. Government announced that AES could be used to protect classified information:\n\nThe design and strength of all key lengths of the AES algorithm (i.e., 128, 192 and 256) are sufficient to protect classified information up to the SECRET level. TOP SECRET information will require use of either the 192 or 256 key lengths. The implementation of AES in products intended to protect national security systems and/or information must be reviewed and certified by NSA prior to their acquisition and use.\nAES has 10 rounds for 128-bit keys, 12 rounds for 192-bit keys, and 14 rounds for 256-bit keys.\nBy 2006, the best known attacks were on 7 rounds for 128-bit keys, 8 rounds for 192-bit keys, and 9 rounds for 256-bit keys.\n\n\n*** Known attacks ***\nFor cryptographers, a cryptographic \"break\" is anything faster than a brute-force attack \u2013 i.e., performing one trial decryption for each possible key in sequence. A break can thus include results that are infeasible with current technology. Despite being impractical, theoretical breaks can sometimes provide insight into vulnerability patterns. The largest successful publicly known brute-force attack against a widely implemented block-cipher encryption algorithm was against a 64-bit RC5 key by distributed.net in 2006.The key space increases by a factor of 2 for each additional bit of key length, and if every possible value of the key is equiprobable, this translates into a doubling of the average brute-force key search time. This implies that the effort of a brute-force search increases exponentially with key length. Key length in itself does not imply security against attacks, since there are ciphers with very long keys that have been found to be vulnerable.\nAES has a fairly simple algebraic framework. In 2002, a theoretical attack, named the \"XSL attack\", was announced by Nicolas Courtois and Josef Pieprzyk, purporting to show a weakness in the AES algorithm, partially due to the low complexity of its nonlinear components. Since then, other papers have shown that the attack, as originally presented, is unworkable; see XSL attack on block ciphers.\nDuring the AES selection process, developers of competing algorithms wrote of Rijndael's algorithm \"we are concerned about [its] use ... in security-critical applications.\" In October 2000, however, at the end of the AES selection process, Bruce Schneier, a developer of the competing algorithm Twofish, wrote that while he thought successful academic attacks on Rijndael would be developed someday, he \"did not believe that anyone will ever discover an attack that will allow someone to read Rijndael traffic.\"Until May 2009, the only successful published attacks against the full AES were side-channel attacks on some specific implementations. In 2009, a new related-key attack was discovered that exploits the simplicity of AES's key schedule and has a complexity of 2119. In December 2009 it was improved to 299.5. This is a follow-up to an attack discovered earlier in 2009 by Alex Biryukov, Dmitry Khovratovich, and Ivica Nikoli\u0107, with a complexity of 296 for one out of every 235 keys. However, related-key attacks are not of concern in any properly designed cryptographic protocol, as a properly designed protocol (i.e., implementational software) will take care not to allow related keys, essentially by constraining an attacker's means of selecting keys for relatedness.\nAnother attack was blogged by Bruce Schneier\non July 30, 2009, and released as a preprint\non August 3, 2009. This new attack, by Alex Biryukov, Orr Dunkelman, Nathan Keller, Dmitry Khovratovich, and Adi Shamir, is against AES-256 that uses only two related keys and 239 time to recover the complete 256-bit key of a 9-round version, or 245 time for a 10-round version with a stronger type of related subkey attack, or 270 time for an 11-round version. 256-bit AES uses 14 rounds, so these attacks are not effective against full AES.\nThe practicality of these attacks with stronger related keys has been criticized, for instance, by the paper on chosen-key-relations-in-the-middle attacks on AES-128 authored by Vincent Rijmen in 2010.In November 2009, the first known-key distinguishing attack against a reduced 8-round version of AES-128 was released as a preprint.\nThis known-key distinguishing attack is an improvement of the rebound, or the start-from-the-middle attack, against AES-like permutations, which view two consecutive rounds of permutation as the application of a so-called Super-S-box. It works on the 8-round version of AES-128, with a time complexity of 248, and a memory complexity of 232.  128-bit AES uses 10 rounds, so this attack is not effective against full AES-128.\nThe first key-recovery attacks on full AES were by Andrey Bogdanov, Dmitry Khovratovich, and Christian Rechberger, and were published in 2011. The attack is a biclique attack and is faster than brute force by a factor of about four. It requires 2126.2 operations to recover an AES-128 key. For AES-192 and AES-256, 2190.2 and 2254.6 operations are needed, respectively. This result has been further improved to 2126.0 for AES-128, 2189.9 for AES-192 and 2254.3 for AES-256, which are the current best results in key recovery attack against AES.\nThis is a very small gain, as a 126-bit key (instead of 128-bits) would still take billions of years to brute force on current and foreseeable hardware. Also, the authors calculate the best attack using their technique on AES with a 128-bit key requires storing 288 bits of data. That works out to about 38 trillion terabytes of data, which is more than all the data stored on all the computers on the planet in 2016. As such, there are no practical implications on AES security. The space complexity has later been improved to 256 bits, which is 9007 terabytes (while still keeping a time complexity of 2126.2).\nAccording to the Snowden documents, the NSA is doing research on whether a cryptographic attack based on tau statistic may help to break AES.At present, there is no known practical attack that would allow someone without knowledge of the key to read data encrypted by AES when correctly implemented.\n\n\n*** Side-channel attacks ***\nSide-channel attacks do not attack the cipher as a black box, and thus are not related to cipher security as defined in the classical context, but are important in practice. They attack implementations of the cipher on hardware or software systems that inadvertently leak data. There are several such known attacks on various implementations of AES.\nIn April 2005, D. J. Bernstein announced a cache-timing attack that he used to break a custom server that used OpenSSL's AES encryption. The attack required over 200 million chosen plaintexts. The custom server was designed to give out as much timing information as possible (the server reports back the number of machine cycles taken by the encryption operation). However, as Bernstein pointed out, \"reducing the precision of the server's timestamps, or eliminating them from the server's responses, does not stop the attack: the client simply uses round-trip timings based on its local clock, and compensates for the increased noise by averaging over a larger number of samples\".In October 2005, Dag Arne Osvik, Adi Shamir and Eran Tromer presented a paper demonstrating several cache-timing attacks against the implementations in AES found in OpenSSL and Linux's dm-crypt partition encryption function. One attack was able to obtain an entire AES key after only 800 operations triggering encryptions, in a total of 65 milliseconds. This attack requires the attacker to be able to run programs on the same system or platform that is performing AES.\nIn December 2009 an attack on some hardware implementations was published that used differential fault analysis and allows recovery of a key with a complexity of 232.In November 2010 Endre Bangerter, David Gullasch and Stephan Krenn published a paper which described a practical approach to a \"near real time\" recovery of secret keys from AES-128 without the need for either cipher text or plaintext. The approach also works on AES-128 implementations that use compression tables, such as OpenSSL. Like some earlier attacks, this one requires the ability to run unprivileged code on the system performing the AES encryption, which may be achieved by malware infection far more easily than commandeering the root account.In March 2016, Ashokkumar C., Ravi Prakash Giri and Bernard Menezes presented a side-channel attack on AES implementations that can recover the complete 128-bit AES key in just 6\u20137 blocks of plaintext/ciphertext, which is a substantial improvement over previous works that require between 100 and a million encryptions. The proposed attack requires standard user privilege and key-retrieval algorithms run under a minute.\nMany modern CPUs have built-in hardware instructions for AES, which protect against timing-related side-channel attacks.\n\n== NIST/CSEC validation ==\nThe Cryptographic Module Validation Program (CMVP) is operated jointly by the United States Government's National Institute of Standards and Technology (NIST) Computer Security Division and the Communications Security Establishment (CSE) of the Government of Canada. The use of cryptographic modules validated to NIST FIPS 140-2 is required by the United States Government for encryption of all data that has a classification of Sensitive but Unclassified (SBU) or above. From NSTISSP #11, National Policy Governing the Acquisition of Information Assurance: \u201cEncryption products for protecting classified information will be certified by NSA, and encryption products intended for protecting sensitive information will be certified in accordance with NIST FIPS 140-2.\u201dThe Government of Canada also recommends the use of FIPS 140 validated cryptographic modules in unclassified applications of its departments.\nAlthough NIST publication 197 (\u201cFIPS 197\u201d) is the unique document that covers the AES algorithm, vendors typically approach the CMVP under FIPS 140 and ask to have several algorithms (such as Triple DES or SHA1) validated at the same time. Therefore, it is rare to find cryptographic modules that are uniquely FIPS 197 validated and NIST itself does not generally take the time to list FIPS 197 validated modules separately on its public web site. Instead, FIPS 197 validation is typically just listed as an \"FIPS approved: AES\" notation (with a specific FIPS 197 certificate number) in the current list of FIPS 140 validated cryptographic modules.\nThe Cryptographic Algorithm Validation Program (CAVP) allows for independent validation of the correct implementation of the AES algorithm. Successful validation results in being listed on the NIST validations page. This testing is a pre-requisite for the FIPS 140-2 module validation. However, successful CAVP validation in no way implies that the cryptographic module implementing the algorithm is secure. A cryptographic module lacking FIPS 140-2 validation or specific approval by the NSA is not deemed secure by the US Government and cannot be used to protect government data.FIPS 140-2 validation is challenging to achieve both technically and fiscally. There is a standardized battery of tests as well as an element of source code review that must be passed over a period of a few weeks. The cost to perform these tests through an approved laboratory can be significant (e.g., well over $30,000 US) and does not include the time it takes to write, test, document and prepare a module for validation. After validation, modules must be re-submitted and re-evaluated if they are changed in any way. This can vary from simple paperwork updates if the security functionality did not change to a more substantial set of re-testing if the security functionality was impacted by the change.\n\n== Test vectors ==\nTest vectors are a set of known ciphers for a given input and key. NIST distributes the reference of AES test vectors as AES Known Answer Test (KAT) Vectors.\n\n== Performance ==\nHigh speed and low RAM requirements were some of the criteria of the AES selection process. As the chosen algorithm, AES performed well on a wide variety of hardware, from 8-bit smart cards to high-performance computers.\nOn a Pentium Pro, AES encryption requires 18 clock cycles per byte, equivalent to a throughput of about 11 MiB/s for a 200 MHz processor.\nOn Intel Core and AMD Ryzen CPUs supporting AES-NI instruction set extensions, throughput can be multiple GiB/s (even over 15 GiB/s on an i7-12700k).\n\n== Implementations =="
    }
  },
  {
    "instruction": "context: The ransomware cyber attack had a significant impact on hospital appointments across the country, with many appointments cancelled including all outpatient and radiology services. Several hospitals described situations where they could not access electronic systems and records and had to rely on paper records. Some have warned of significant disruption with routine appointments being cancelled, including maternity checkups and scans.\n\nAsk a question about this context.",
    "context": "",
    "output": "How did the cyber attack impact hospital appointments and services?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the cyber attack impact hospital appointments and services?",
      "answer": "The ransomware cyber attack had a significant impact on hospital appointments across the country, with many appointments cancelled including all outpatient and radiology services. Several hospitals described situations where they could not access electronic systems and records and had to rely on paper records. Some have warned of significant disruption with routine appointments being cancelled, including maternity checkups and scans."
    }
  },
  {
    "instruction": "Write an answer to the following question: What ciphers are used to encrypt the underlying database files in Microsoft SQL Server TDE?",
    "context": "",
    "output": "The Database Encryption Key (DEK) is used to encrypt the underlying database files with either the AES or 3DES cipher in Microsoft SQL Server TDE.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What ciphers are used to encrypt the underlying database files in Microsoft SQL Server TDE?",
      "answer": "The Database Encryption Key (DEK) is used to encrypt the underlying database files with either the AES or 3DES cipher in Microsoft SQL Server TDE."
    }
  },
  {
    "instruction": "context: CRAM-MD5 provides authentication, freshness (replay prevention), and secrecy. It is resistant to duplication and replay attacks, and observers cannot learn the password.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are the strengths of CRAM-MD5?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the strengths of CRAM-MD5?",
      "answer": "CRAM-MD5 provides authentication, freshness (replay prevention), and secrecy. It is resistant to duplication and replay attacks, and observers cannot learn the password."
    }
  },
  {
    "instruction": "context: The German weekly ZEIT published an article in 2018 about the proposed direct access tracks for electronic evidence.\n\nAsk a question about this context.",
    "context": "",
    "output": "Which German weekly published an article in 2018 about the proposed direct access tracks for electronic evidence?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which German weekly published an article in 2018 about the proposed direct access tracks for electronic evidence?",
      "answer": "The German weekly ZEIT published an article in 2018 about the proposed direct access tracks for electronic evidence."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of PIPEDA and when did it become law?",
    "context": "",
    "output": "PIPEDA, or the Personal Information Protection and Electronic Documents Act, is a Canadian law that governs how private sector organizations collect, use, and disclose personal information in commercial activities. It also facilitates the use of electronic documents. PIPEDA became law on April 13, 2000, with the aim of promoting consumer trust in electronic commerce and reassuring the European Union about the protection of personal information of European citizens.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of PIPEDA and when did it become law?",
      "answer": "PIPEDA, or the Personal Information Protection and Electronic Documents Act, is a Canadian law that governs how private sector organizations collect, use, and disclose personal information in commercial activities. It also facilitates the use of electronic documents. PIPEDA became law on April 13, 2000, with the aim of promoting consumer trust in electronic commerce and reassuring the European Union about the protection of personal information of European citizens."
    }
  },
  {
    "instruction": "context: The use of a guard in an IEG splits the IEG's DMZ into two and provides additional security measures, including IPS and NPS functions, to ensure the safe and secure exchange of information.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the use of a guard impact the functionality of an IEG?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the use of a guard impact the functionality of an IEG?",
      "answer": "The use of a guard in an IEG splits the IEG's DMZ into two and provides additional security measures, including IPS and NPS functions, to ensure the safe and secure exchange of information."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Pr\u00eat \u00e0 Voter comply with voting laws that require a specific ordering of candidates?",
    "context": "",
    "output": "Pr\u00eat \u00e0 Voter uses a permutation of indirection symbols instead of candidate names, allowing it to comply with voting laws that require a specific ordering of candidates.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Pr\u00eat \u00e0 Voter comply with voting laws that require a specific ordering of candidates?",
      "answer": "Pr\u00eat \u00e0 Voter uses a permutation of indirection symbols instead of candidate names, allowing it to comply with voting laws that require a specific ordering of candidates."
    }
  },
  {
    "instruction": "context: The device key in U2F is vulnerable to malicious manufacturer duplication. In 2020, independent security researchers found a method to extract private keys from Google Titan Key, a popular U2F hardware security token. The attack required physical access to the key for several hours, several thousand euros-worth of equipment, and was destructive to the plastic case of the key.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can the device key in U2F be vulnerable and what was the 2020 attack on Google Titan Key?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can the device key in U2F be vulnerable and what was the 2020 attack on Google Titan Key?",
      "answer": "The device key in U2F is vulnerable to malicious manufacturer duplication. In 2020, independent security researchers found a method to extract private keys from Google Titan Key, a popular U2F hardware security token. The attack required physical access to the key for several hours, several thousand euros-worth of equipment, and was destructive to the plastic case of the key."
    }
  },
  {
    "instruction": "Write an answer to the following question: Who served as the project manager for the Tallinn 2.0 project?",
    "context": "",
    "output": "Ms. Liis Vihul of the NATO Cooperative Cyber Defence Centre of Excellence served as the project manager for the Tallinn 2.0 project.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who served as the project manager for the Tallinn 2.0 project?",
      "answer": "Ms. Liis Vihul of the NATO Cooperative Cyber Defence Centre of Excellence served as the project manager for the Tallinn 2.0 project."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does PKIoverheid, the public key infrastructure (PKI) from the Dutch government, ensure the authenticity and integrity of digital certificates?",
    "context": "",
    "output": "PKIoverheid uses a combination of public key cryptography and digital certificates to ensure the authenticity and integrity of digital certificates. Public key cryptography involves the use of two keys, a public key and a private key, to encrypt and decrypt data. Digital certificates, which are issued and managed by PKIoverheid, bind a public key to the identity of an individual, organization, or device. This allows users to verify the identity of the certificate holder and encrypt data using the certificate holder's public key, knowing that only the certificate holder's private key can be used to decrypt it.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does PKIoverheid, the public key infrastructure (PKI) from the Dutch government, ensure the authenticity and integrity of digital certificates?",
      "answer": "PKIoverheid uses a combination of public key cryptography and digital certificates to ensure the authenticity and integrity of digital certificates. Public key cryptography involves the use of two keys, a public key and a private key, to encrypt and decrypt data. Digital certificates, which are issued and managed by PKIoverheid, bind a public key to the identity of an individual, organization, or device. This allows users to verify the identity of the certificate holder and encrypt data using the certificate holder's public key, knowing that only the certificate holder's private key can be used to decrypt it."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does an APIDS monitor the application protocol between two connected devices?",
    "context": "",
    "output": "An APIDS monitors the application protocol between two connected devices by sitting between the two devices and examining the use of the protocol.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does an APIDS monitor the application protocol between two connected devices?",
      "answer": "An APIDS monitors the application protocol between two connected devices by sitting between the two devices and examining the use of the protocol."
    }
  },
  {
    "instruction": "Answer based on context:\n\nKey Management Interoperability Protocol\n\n==Introduction==\nThe Key Management Interoperability Protocol (KMIP) is an extensible communication protocol that defines message formats for the manipulation of cryptographic keys on a key management server. This facilitates data encryption by simplifying encryption key management. Keys may be created on a server and then retrieved, possibly wrapped by other keys. Both symmetric and asymmetric keys are supported, including the ability to sign certificates. KMIP also allows for clients to ask a server to encrypt or decrypt data, without needing direct access to the key.\nThe KMIP standard was first released in 2010. Clients and servers are commercially available from multiple vendors. The KMIP standard effort is governed by the OASIS standards body. Technical details can also be found on the official KMIP page and kmip wiki.\n\n== Description ==\nA KMIP server stores and controls Managed Objects like symmetric and asymmetric keys, certificates, and user defined objects. Clients then use the protocol for accessing these objects subject to a security model that is implemented by the servers. Operations are provided to create, locate, retrieve and update managed objects.\nEach managed object comprises an immutable Value like a key-block containing a cryptographic-key. These objects comprise mutable Attributes which can be used for storing metadata about their keys. Some attributes are derived directly from the Value, like the cryptographic-algorithm and key-length. Other attributes are defined in the specification for the management of objects like the Application-Specific Identifier which is usually derived from tape-identification data. Additional identifiers can be defined by the server or client per application need.\nEach object is identified by a unique and immutable object-identifier generated by the server and is used for getting object-values. Managed-objects may also be given a number of mutable yet globally unique Name attribute which can be used for Locating objects.\n\n\n*** Objects ***\nThe types of managed-objects being managed by KMIP include:\n\nSymmetric-Keys used for algorithms like AES.\nPublic and Private Keys used for asymmetric-algorithms like RSA and ECDH. Separate objects are used for storing the public and private key, thus a user may have permission to access one but not the other.  Related objects usually contain Link attributes containing the other object's unique identifier.\nCertificates and PGP Keys.\nSplit Keys, with each split being a distinct object that can be managed independently from the other splits.\nSecret Data, such as passwords.\nOpaque Data for client and server defined extensions.\nCertificate Signing Requests.\n\n\n*** Operations ***\nThe operations provided by KMIP include:\n\nCreate, creating a new managed object such as a symmetric key, and return the identifier.\nCreate Key Pair, creating two objects that represent asymmetric keys.\nGet, retrieving an object's value given its unique identifier.  The returned value may be wrapped (encrypted) with another key that is on the server for additional security.\nRegister, storing an externally generated key value.\nAdd Attributes, Get Attributes, Modify Attributes and Set Attribute.  These can be used to manipulate mutable attributes of a managed object.\nLocate, retrieving a list of objects based on a predicates.\nRe-Key, creating a new key that can replace an existing key.  There are also attributes that can be used to have the server automatically rotate keys after a given period or number of uses.  The Name is moved to the new key and is normally used to retrieve a key for protection operations such as encrypt and sign.  The old key can also be retrieved using the Unique Identifier for process operations such as decryption and signature verification.\n(Re-)Certify - certifies a certificate.\nSplit and Join N of M keys.\nEncrypt, Decrypt, MAC etc. Cryptographic operations performed on the key management server. A key itself could be marked being not-Extractable, in which case its value never leaves the server.\nExport and Import keys to and from other KMIP servers.\nOperations to implement the NIST key life cycle.\n\n\n*** Key life cycle ***\nEach key has a cryptographic state defined by the National Institute of Standards and Technology (NIST). Keys are created in an Initial state, and must be Activated before they can be used. Keys may then be Deactivated and eventually Destroyed. A key may also be marked being Compromised.\nOperations are provided for manipulating Key-state in conformance with the NIST life-cycle guidelines. A Key-state may be interrogated using the State attribute or the attributes that record dates of each transformation such as Activation Date. Dates can be specified into the future thus keys automatically become unavailable for specified operations when they expire.\n\n\n*** Message structure ***\nKMIP is a stateless protocol in which messages are sent from a client to a server and then the client normally awaits on a reply. Each request may contain many operations thus enables the protocol to efficiently handle large numbers of keys.  There are also advanced features for processing requests asynchronously.\nThe KMIP protocol specifies several different types of encodings.  The main one is a type\u2013length\u2013value encoding of messages, called TTLV (tag, type, length, value). Nested TTLV structures allow for encoding of complex, multi-operation messages in a single binary message.\nThere are also well defined XML and JSON encodings of the protocol for environments where binary is not appropriate.  A very compact CBOR encoding is also provided for applications that require it.\nAll of these protocols are expected to be transmitted using TLS protocol in order to ensure integrity and security.  However, it is also possible to register and retrieve keys that are wrapped (encrypted) using another key on the server, which provides an additional level of security.\n\n\n*** System management ***\nKMIP provides standardized mechanisms to manage a KMIP server by suitably authorized administrative clients using System Objects.  \nUser objects can be created and authorized to perform specific operations on specific managed objects.  Both Managed Objects and Users can be assigned to groups, and those groups can form a hierarchy which facilitates efficient management of complex operating environments.\nKMIP also provides a provisioning system that facilitates providing end points with credentials using simple one time passwords.\nDefault values of attributes can be provided, so that simple clients need not specify cryptographic and other parameters.  For example, an administrative user might specify that all \"SecretAgent\" keys should be 192 bit  AES keys with  CBC block chaining.  A client then only needs to specify that they wish to create a \"SecretAgent\" key to have those defaults provided.  It is also possible to enforce constraints on key parameters that implement security policy.\n\n\n*** KMIP profiles ***\nKMIP also defines a set of profiles, which are subsets of the KMIP specification showing common usage for a particular context. A particular KMIP implementation is said to be conformant to a profile when it fulfills all the requirements set forth in a profile specification document. OASIS has put forth various profiles describing the requirements for compliance towards storage arrays and tape libraries, but any organization can create a profile.\n\n\n*** Relationship to PKCS#11 ***\nPKCS#11 is a C API used to control a hardware security module. PKCS#11 provides cryptographic operations to encrypt and decrypt, as well as operations for simple key management. There is considerable amount of overlap between the PKCS#11 API and the KMIP protocol.\nThe two standards were originally developed independently. PKCS#11 was created by RSA Security, but the standard is now also governed by an OASIS technical committee. It is the stated objective of both the PKCS#11 and KMIP committees to align the standards where practical. For example, the PKCS#11 Sensitive and Extractable attributes are being added to KMIP version 1.4. Many of the same people are on the technical committees of both KMIP and PKCS#11.\nKMIP 2.0 provides a standardized mechanism to transport PKCS#11 messages from clients to servers.  This can be used to target different PKCS#11 implementations without the need to recompile the programs that use it.\n\n== KMIP implementations ==\nThe OASIS KMIP Technical Committee maintains a list of known KMIP implementations, which can be found on the OASIS website. As of March 2017, there are 28 implementations and 61 KMIP products in this list.\n\n\n*** Interoperability between implementations ***\nThe KMIP standard is defined using a formal specification document, testcases, and profiles put forth by the OASIS KMIP technical committee. These documents are publicly available on the OASIS website.\n\nVendors demonstrate interoperability during a process organized by the OASIS KMIP technical committee in the months before each RSA security conference. These demonstrations are informally known as interops. KMIP interops have been held every year since 2010. The following chart shows the number of individual tests performed by each client and server vendor combination since 2012.\n\n== Example ==\nThe following shows the XML encoding of a request to Locate a key named \"MyKeyName\" and return its value wrapped in a different key with ID \"c6d14516-4d38-0644-b810-1913b9aef4da\".  (TTLV is a more common wire protocol, but XML is more human readable.)\n\n== Documentation ==\nDocumentation is freely available from the OASIS website. This includes the formal technical specification and a usage guide to assist people that are unfamiliar with the specification. A substantial library of test cases is also provided. These are used to test the interoperability of clients and servers, but they also provide concrete examples of the usage of each standard KMIP feature.\n\n== Version history ==\n\nHow are keys managed in KMIP according to the NIST key life cycle guidelines?",
    "context": "",
    "output": "KMIP manages keys according to the NIST key life cycle, which includes creating keys in an Initial state, Activating them before use, Deactivating, Destroying, and marking them as Compromised.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are keys managed in KMIP according to the NIST key life cycle guidelines?",
      "answer": "KMIP manages keys according to the NIST key life cycle, which includes creating keys in an Initial state, Activating them before use, Deactivating, Destroying, and marking them as Compromised.",
      "context": "Key Management Interoperability Protocol\n\n==Introduction==\nThe Key Management Interoperability Protocol (KMIP) is an extensible communication protocol that defines message formats for the manipulation of cryptographic keys on a key management server. This facilitates data encryption by simplifying encryption key management. Keys may be created on a server and then retrieved, possibly wrapped by other keys. Both symmetric and asymmetric keys are supported, including the ability to sign certificates. KMIP also allows for clients to ask a server to encrypt or decrypt data, without needing direct access to the key.\nThe KMIP standard was first released in 2010. Clients and servers are commercially available from multiple vendors. The KMIP standard effort is governed by the OASIS standards body. Technical details can also be found on the official KMIP page and kmip wiki.\n\n== Description ==\nA KMIP server stores and controls Managed Objects like symmetric and asymmetric keys, certificates, and user defined objects. Clients then use the protocol for accessing these objects subject to a security model that is implemented by the servers. Operations are provided to create, locate, retrieve and update managed objects.\nEach managed object comprises an immutable Value like a key-block containing a cryptographic-key. These objects comprise mutable Attributes which can be used for storing metadata about their keys. Some attributes are derived directly from the Value, like the cryptographic-algorithm and key-length. Other attributes are defined in the specification for the management of objects like the Application-Specific Identifier which is usually derived from tape-identification data. Additional identifiers can be defined by the server or client per application need.\nEach object is identified by a unique and immutable object-identifier generated by the server and is used for getting object-values. Managed-objects may also be given a number of mutable yet globally unique Name attribute which can be used for Locating objects.\n\n\n*** Objects ***\nThe types of managed-objects being managed by KMIP include:\n\nSymmetric-Keys used for algorithms like AES.\nPublic and Private Keys used for asymmetric-algorithms like RSA and ECDH. Separate objects are used for storing the public and private key, thus a user may have permission to access one but not the other.  Related objects usually contain Link attributes containing the other object's unique identifier.\nCertificates and PGP Keys.\nSplit Keys, with each split being a distinct object that can be managed independently from the other splits.\nSecret Data, such as passwords.\nOpaque Data for client and server defined extensions.\nCertificate Signing Requests.\n\n\n*** Operations ***\nThe operations provided by KMIP include:\n\nCreate, creating a new managed object such as a symmetric key, and return the identifier.\nCreate Key Pair, creating two objects that represent asymmetric keys.\nGet, retrieving an object's value given its unique identifier.  The returned value may be wrapped (encrypted) with another key that is on the server for additional security.\nRegister, storing an externally generated key value.\nAdd Attributes, Get Attributes, Modify Attributes and Set Attribute.  These can be used to manipulate mutable attributes of a managed object.\nLocate, retrieving a list of objects based on a predicates.\nRe-Key, creating a new key that can replace an existing key.  There are also attributes that can be used to have the server automatically rotate keys after a given period or number of uses.  The Name is moved to the new key and is normally used to retrieve a key for protection operations such as encrypt and sign.  The old key can also be retrieved using the Unique Identifier for process operations such as decryption and signature verification.\n(Re-)Certify - certifies a certificate.\nSplit and Join N of M keys.\nEncrypt, Decrypt, MAC etc. Cryptographic operations performed on the key management server. A key itself could be marked being not-Extractable, in which case its value never leaves the server.\nExport and Import keys to and from other KMIP servers.\nOperations to implement the NIST key life cycle.\n\n\n*** Key life cycle ***\nEach key has a cryptographic state defined by the National Institute of Standards and Technology (NIST). Keys are created in an Initial state, and must be Activated before they can be used. Keys may then be Deactivated and eventually Destroyed. A key may also be marked being Compromised.\nOperations are provided for manipulating Key-state in conformance with the NIST life-cycle guidelines. A Key-state may be interrogated using the State attribute or the attributes that record dates of each transformation such as Activation Date. Dates can be specified into the future thus keys automatically become unavailable for specified operations when they expire.\n\n\n*** Message structure ***\nKMIP is a stateless protocol in which messages are sent from a client to a server and then the client normally awaits on a reply. Each request may contain many operations thus enables the protocol to efficiently handle large numbers of keys.  There are also advanced features for processing requests asynchronously.\nThe KMIP protocol specifies several different types of encodings.  The main one is a type\u2013length\u2013value encoding of messages, called TTLV (tag, type, length, value). Nested TTLV structures allow for encoding of complex, multi-operation messages in a single binary message.\nThere are also well defined XML and JSON encodings of the protocol for environments where binary is not appropriate.  A very compact CBOR encoding is also provided for applications that require it.\nAll of these protocols are expected to be transmitted using TLS protocol in order to ensure integrity and security.  However, it is also possible to register and retrieve keys that are wrapped (encrypted) using another key on the server, which provides an additional level of security.\n\n\n*** System management ***\nKMIP provides standardized mechanisms to manage a KMIP server by suitably authorized administrative clients using System Objects.  \nUser objects can be created and authorized to perform specific operations on specific managed objects.  Both Managed Objects and Users can be assigned to groups, and those groups can form a hierarchy which facilitates efficient management of complex operating environments.\nKMIP also provides a provisioning system that facilitates providing end points with credentials using simple one time passwords.\nDefault values of attributes can be provided, so that simple clients need not specify cryptographic and other parameters.  For example, an administrative user might specify that all \"SecretAgent\" keys should be 192 bit  AES keys with  CBC block chaining.  A client then only needs to specify that they wish to create a \"SecretAgent\" key to have those defaults provided.  It is also possible to enforce constraints on key parameters that implement security policy.\n\n\n*** KMIP profiles ***\nKMIP also defines a set of profiles, which are subsets of the KMIP specification showing common usage for a particular context. A particular KMIP implementation is said to be conformant to a profile when it fulfills all the requirements set forth in a profile specification document. OASIS has put forth various profiles describing the requirements for compliance towards storage arrays and tape libraries, but any organization can create a profile.\n\n\n*** Relationship to PKCS#11 ***\nPKCS#11 is a C API used to control a hardware security module. PKCS#11 provides cryptographic operations to encrypt and decrypt, as well as operations for simple key management. There is considerable amount of overlap between the PKCS#11 API and the KMIP protocol.\nThe two standards were originally developed independently. PKCS#11 was created by RSA Security, but the standard is now also governed by an OASIS technical committee. It is the stated objective of both the PKCS#11 and KMIP committees to align the standards where practical. For example, the PKCS#11 Sensitive and Extractable attributes are being added to KMIP version 1.4. Many of the same people are on the technical committees of both KMIP and PKCS#11.\nKMIP 2.0 provides a standardized mechanism to transport PKCS#11 messages from clients to servers.  This can be used to target different PKCS#11 implementations without the need to recompile the programs that use it.\n\n== KMIP implementations ==\nThe OASIS KMIP Technical Committee maintains a list of known KMIP implementations, which can be found on the OASIS website. As of March 2017, there are 28 implementations and 61 KMIP products in this list.\n\n\n*** Interoperability between implementations ***\nThe KMIP standard is defined using a formal specification document, testcases, and profiles put forth by the OASIS KMIP technical committee. These documents are publicly available on the OASIS website.\n\nVendors demonstrate interoperability during a process organized by the OASIS KMIP technical committee in the months before each RSA security conference. These demonstrations are informally known as interops. KMIP interops have been held every year since 2010. The following chart shows the number of individual tests performed by each client and server vendor combination since 2012.\n\n== Example ==\nThe following shows the XML encoding of a request to Locate a key named \"MyKeyName\" and return its value wrapped in a different key with ID \"c6d14516-4d38-0644-b810-1913b9aef4da\".  (TTLV is a more common wire protocol, but XML is more human readable.)\n\n== Documentation ==\nDocumentation is freely available from the OASIS website. This includes the formal technical specification and a usage guide to assist people that are unfamiliar with the specification. A substantial library of test cases is also provided. These are used to test the interoperability of clients and servers, but they also provide concrete examples of the usage of each standard KMIP feature.\n\n== Version history =="
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the benefits of passwordless authentication?",
    "context": "",
    "output": "Passwordless authentication provides several benefits, including greater security, a better user experience, reduced IT costs, better visibility of credential use, and scalability.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the benefits of passwordless authentication?",
      "answer": "Passwordless authentication provides several benefits, including greater security, a better user experience, reduced IT costs, better visibility of credential use, and scalability."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Monitor mode help in designing Wi-Fi networks?",
    "context": "",
    "output": "Monitor mode can be used to discover the number of Wi-Fi devices currently being used on a given area and channel. This information can help in creating a better Wi-Fi network that reduces interference with other Wi-Fi devices by choosing the least used Wi-Fi channels.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Monitor mode help in designing Wi-Fi networks?",
      "answer": "Monitor mode can be used to discover the number of Wi-Fi devices currently being used on a given area and channel. This information can help in creating a better Wi-Fi network that reduces interference with other Wi-Fi devices by choosing the least used Wi-Fi channels."
    }
  },
  {
    "instruction": "Database encryption\n\n==Introduction==\nDatabase encryption can generally be defined as a process that uses an algorithm to transform data stored in a database into \"cipher text\" that is incomprehensible without first being decrypted. It can therefore be said that the purpose of database encryption is to protect the data stored in a database from being accessed by individuals with potentially \"malicious\" intentions. The act of encrypting a database also reduces the incentive for individuals to hack the aforementioned database as \"meaningless\" encrypted data is of little to no use for hackers. There are multiple techniques and technologies available for database encryption, the most important of which will be detailed in this article.\n\n\n\n== Transparent/External database encryption ==\nTransparent data encryption (often abbreviated as TDE) is used to encrypt an entire database, which therefore involves encrypting \"data at rest\". Data at rest can generally be defined as \"inactive\" data that is not currently being edited or pushed across a network. As an example, a text file stored on a computer is \"at rest\" until it is opened and edited. Data at rest are stored on physical storage media solutions such as tapes or hard disk drives. The act of storing large amounts of sensitive data on physical storage media naturally raises concerns of security and theft. TDE ensures that the data on physical storage media cannot be read by malicious individuals that may have the intention to steal them. Data that cannot be read is worthless, thus reducing the incentive for theft. Perhaps the most important strength that is attributed to TDE is its transparency. Given that TDE encrypts all data it can be said that no applications need to be altered in order for TDE to run correctly. It is important to note that TDE encrypts the entirety of the database as well as backups of the database. The transparent element of TDE has to do with the fact that TDE encrypts on \"the page level\", which essentially means that data is encrypted when stored and decrypted when it is called into the system's memory. The contents of the database are encrypted using a symmetric key that is often referred to as a \"database encryption key\".\n\n== Column-level encryption ==\nIn order to explain column-level encryption it is important to outline basic database structure. A typical relational database is divided into tables that are divided into columns that each have rows of data. Whilst TDE usually encrypts an entire database, column-level encryption allows for individual columns within a database to be encrypted. It is important to establish that the granularity of column-level encryption causes specific strengths and weaknesses to arise when compared to encrypting an entire database. Firstly, the ability to encrypt individual columns allows for column-level encryption to be significantly more flexible when compared to encryption systems that encrypt an entire database such as TDE. Secondly, it is possible to use an entirely unique and separate encryption key for each column within a database. This effectively increases the difficulty of generating rainbow tables which thus implies that the data stored within each column is less likely to be lost or leaked. The main disadvantage associated with column-level database encryption is speed, or a loss thereof. Encrypting separate columns with different unique keys in the same database can cause database performance to decrease, and additionally also decreases the speed at which the contents of the database can be indexed or searched.\n\n== Field-level encryption ==\nExperimental work is being done on providing database operations (like searching or arithmetical operations) on encrypted fields without the need to decrypt them. Strong encryption is required to be randomized - a different result must be generated each time.  This is known as probabilistic encryption.  Field-level encryption is weaker than randomized encryption, but it allows users to test for equality without decrypting the data.\n\n== Filesystem-level encryption ==\n\n\n*** Encrypting File System (EFS) ***\n\nIt is important to note that traditional database encryption techniques normally encrypt and decrypt the contents of a database. Databases are managed by \"Database Management Systems\" (DBMS) that run on top of an existing operating system (OS). This raises a potential security concern, as an encrypted database may be running on an accessible and potentially vulnerable operating system. EFS can encrypt data that is not part of a database system, which implies that the scope of encryption for EFS is much wider when compared to a system such as TDE that is only capable of encrypting database files. Whilst EFS does widen the scope of encryption, it also decreases database performance and can cause administration issues as system administrators require operating system access to use EFS. Due to the issues concerning performance, EFS is not typically used in databasing applications that require frequent database input and output. In order to offset the performance issues it is often recommended that EFS systems be used in environments with few users.\n\n== Full disk encryption ==\n\nBitLocker does not have the same performance concerns associated with EFS.\n\n== Symmetric and asymmetric database encryption ==\n\n\n*** Symmetric database encryption ***\nSymmetric encryption in the context of database encryption involves a private key being applied to data that is stored and called from a database. This private key alters the data in a way that causes it to be unreadable without first being decrypted. Data is encrypted when saved, and decrypted when opened given that the user knows the private key. Thus if the data is to be shared through a database the receiving individual must have a copy of the secret key used by the sender in order to decrypt and view the data. A clear disadvantage related to symmetric encryption is that sensitive data can be leaked if the private key is spread to individuals that should not have access to the data. However, given that only one key is involved in the encryption process it can generally be said that speed is an advantage of symmetric encryption.\n\n\n*** Asymmetric database encryption ***\nAsymmetric encryption expands on symmetric encryption by incorporating two different types of keys into the encryption method: private and public keys. A public key can be accessed by anyone and is unique to one user whereas a private key is a secret key that is unique to and only known by one user. In most scenarios the public key is the encryption key whereas the private key is the decryption key. As an example, if individual A would like to send a message to individual B using asymmetric encryption, he would encrypt the message using Individual B's public key and then send the encrypted version. Individual B would then be able to decrypt the message using his private key. Individual C would not be able to decrypt Individual A's message, as Individual C's private key is not the same as Individual B's private key. Asymmetric encryption is often described as being more secure in comparison to symmetric database encryption given that private keys do not need to be shared as two separate keys handle encryption and decryption processes. For performance reasons, asymmetric encryption is used in Key management rather than to encrypt the data which is usually done with symmetric encryption.\n\n== Key management ==\nThe Symmetric & Asymmetric Database Encryption section introduced the concept of public and private keys with basic examples in which users exchange keys. The act of exchanging keys becomes impractical from a logistical point of view, when many different individuals need to communicate with each-other. In database encryption the system handles the storage and exchange of keys. This process is called key management. If encryption keys are not managed and stored properly, highly sensitive data may be leaked. Additionally, if a key management system deletes or loses a key, the information that was encrypted via said key is essentially rendered \"lost\" as well. The complexity of key management logistics is also a topic that needs to be taken into consideration. As the number of application that a firm uses increases, the number of keys that need to be stored and managed increases as well. Thus it is necessary to establish a way in which keys from all applications can be managed through a single channel, which is also known as enterprise key management. Enterprise Key Management Solutions are sold by a great number of suppliers in the technology industry. These systems essentially provide a centralised key management solution that allows administrators to manage all keys in a system through one hub. Thus it can be said that the introduction of enterprise key management solutions has the potential to lessen the risks associated with key management in the context of database encryption, as well as to reduce the logistical troubles that arise when many individuals attempt to manually share keys.\n\n== Hashing ==\nHashing is used in database systems as a method to protect sensitive data such as passwords; however it is also used to improve the efficiency of database referencing. Inputted data is manipulated by a hashing algorithm. The hashing algorithm converts the inputted data into a string of fixed length that can then be stored in a database. Hashing systems have two crucially important characteristics that will now be outlined. Firstly, hashes are \"unique and repeatable\". As an example, running the word \"cat\" through the same hashing algorithm multiple times will always yield the same hash, however it is extremely difficult to find a word that will return the same hash that \"cat\" does. Secondly, hashing algorithms are not reversible. To relate this back to the example provided above, it would be nearly impossible to convert the output of the hashing algorithm back to the original input, which was \"cat\". In the context of database encryption, hashing is often used in password systems. When a user first creates their password it is run through a hashing algorithm and saved as a hash. When the user logs back into the website, the password that they enter is run through the hashing algorithm and is then compared to the stored hash. Given the fact that hashes are unique, if both hashes match then it is said that the user inputted the correct password. One example of a popular hash function is SHA (Secure Hash Algorithm) 256.\n\n\n*** Salting ***\nOne issue that arises when using hashing for password management in the context of database encryption is the fact that a malicious user could potentially use an Input to Hash table rainbow table for the specific hashing algorithm that the system uses. This would effectively allow the individual to decrypt the hash and thus have access to stored passwords. A solution for this issue is to 'salt' the hash. Salting is the process of encrypting more than just the password in a database. The more information that is added to a string that is to be hashed, the more difficult it becomes to collate rainbow tables. As an example, a system may combine a user's email and password into a single hash. This increase in the complexity of a hash means that it is far more difficult and thus less likely for rainbow tables to be generated. This naturally implies that the threat of sensitive data loss is minimised through salting hashes.\n\n\n*** Pepper ***\nSome systems incorporate a \"pepper\" in addition to salts in their hashing systems. Pepper systems are controversial, however it is still necessary to explain their use. A pepper is a value that is added to a hashed password that has been salted. This pepper is often unique to one website or service, and it is important to note that the same pepper is usually added to all passwords saved in a database. In theory the inclusion of peppers in password hashing systems has the potential to decrease the risk of rainbow (Input : Hash) tables, given the system-level specificity of peppers, however the real world benefits of pepper implementation are highly disputed.\n\n== Application-level encryption ==\nIn application-level encryption, the process of encrypting data is completed by the application that has been used to generate or modify the data that is to be encrypted. Essentially this means that data is encrypted before it is written to the database. This unique approach to encryption allows for the encryption process to be tailored to each user based on the information (such as entitlements or roles) that the application knows about its users.According to Eugene Pilyankevich, \"Application-level encryption is becoming a good practice for systems with increased security requirements, with a general drift toward perimeter-less and more exposed cloud systems\".\n\n\n*** Advantages of application-level encryption ***\nOne of the most important advantages of application-level encryption is the fact that application-level encryption has the potential to simplify the encryption process used by a company. If an application encrypts the data that it writes/modifies from a database then a secondary encryption tool will not need to be integrated into the system. The second main advantage relates to the overarching theme of theft. Given that data is encrypted before it is written to the server, a hacker would need to have access to the database contents as well as the applications that were used to encrypt and decrypt the contents of the database in order to decrypt sensitive data.\n\n\n*** Disadvantages of application-level encryption ***\nThe first important disadvantage of Application-level encryption is that applications used by a firm will need to be modified to encrypt data themselves. This has the potential to consume a significant amount of time and other resources. Given the nature of opportunity cost firms may not believe that application-level encryption is worth the investment. In addition, application-level encryption may have a limiting effect on database performance. If all data on a database is encrypted by a multitude of different applications then it becomes impossible to index or search data on the database. To ground this in reality in the form of a basic example: it would be impossible to construct a glossary in a single language for a book that was written in 30 languages. Lastly the complexity of key management increases, as multiple different applications need to have the authority and access to encrypt data and write it to the database.\n\n== Risks of database encryption ==\nWhen discussing the topic of database encryption it is imperative to be aware of the risks that are involved in the process. The first set of risks are related to key management. If private keys are not managed in an \"isolated system\", system administrators with malicious intentions may have the ability to decrypt sensitive data using keys that they have access to. The fundamental principle of keys also gives rise to a potentially devastating risk: if keys are lost then the encrypted data is essentially lost as well, as decryption without keys is almost impossible.\n\nQ: What is hashing and how is it used in database systems?",
    "context": "",
    "output": "A: Hashing is a method used in database systems to protect sensitive data such as passwords and improve the efficiency of database referencing. It converts inputted data into a string of fixed length that can then be stored in a database.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is hashing and how is it used in database systems?",
      "answer": "Hashing is a method used in database systems to protect sensitive data such as passwords and improve the efficiency of database referencing. It converts inputted data into a string of fixed length that can then be stored in a database.",
      "context": "Database encryption\n\n==Introduction==\nDatabase encryption can generally be defined as a process that uses an algorithm to transform data stored in a database into \"cipher text\" that is incomprehensible without first being decrypted. It can therefore be said that the purpose of database encryption is to protect the data stored in a database from being accessed by individuals with potentially \"malicious\" intentions. The act of encrypting a database also reduces the incentive for individuals to hack the aforementioned database as \"meaningless\" encrypted data is of little to no use for hackers. There are multiple techniques and technologies available for database encryption, the most important of which will be detailed in this article.\n\n\n\n== Transparent/External database encryption ==\nTransparent data encryption (often abbreviated as TDE) is used to encrypt an entire database, which therefore involves encrypting \"data at rest\". Data at rest can generally be defined as \"inactive\" data that is not currently being edited or pushed across a network. As an example, a text file stored on a computer is \"at rest\" until it is opened and edited. Data at rest are stored on physical storage media solutions such as tapes or hard disk drives. The act of storing large amounts of sensitive data on physical storage media naturally raises concerns of security and theft. TDE ensures that the data on physical storage media cannot be read by malicious individuals that may have the intention to steal them. Data that cannot be read is worthless, thus reducing the incentive for theft. Perhaps the most important strength that is attributed to TDE is its transparency. Given that TDE encrypts all data it can be said that no applications need to be altered in order for TDE to run correctly. It is important to note that TDE encrypts the entirety of the database as well as backups of the database. The transparent element of TDE has to do with the fact that TDE encrypts on \"the page level\", which essentially means that data is encrypted when stored and decrypted when it is called into the system's memory. The contents of the database are encrypted using a symmetric key that is often referred to as a \"database encryption key\".\n\n== Column-level encryption ==\nIn order to explain column-level encryption it is important to outline basic database structure. A typical relational database is divided into tables that are divided into columns that each have rows of data. Whilst TDE usually encrypts an entire database, column-level encryption allows for individual columns within a database to be encrypted. It is important to establish that the granularity of column-level encryption causes specific strengths and weaknesses to arise when compared to encrypting an entire database. Firstly, the ability to encrypt individual columns allows for column-level encryption to be significantly more flexible when compared to encryption systems that encrypt an entire database such as TDE. Secondly, it is possible to use an entirely unique and separate encryption key for each column within a database. This effectively increases the difficulty of generating rainbow tables which thus implies that the data stored within each column is less likely to be lost or leaked. The main disadvantage associated with column-level database encryption is speed, or a loss thereof. Encrypting separate columns with different unique keys in the same database can cause database performance to decrease, and additionally also decreases the speed at which the contents of the database can be indexed or searched.\n\n== Field-level encryption ==\nExperimental work is being done on providing database operations (like searching or arithmetical operations) on encrypted fields without the need to decrypt them. Strong encryption is required to be randomized - a different result must be generated each time.  This is known as probabilistic encryption.  Field-level encryption is weaker than randomized encryption, but it allows users to test for equality without decrypting the data.\n\n== Filesystem-level encryption ==\n\n\n*** Encrypting File System (EFS) ***\n\nIt is important to note that traditional database encryption techniques normally encrypt and decrypt the contents of a database. Databases are managed by \"Database Management Systems\" (DBMS) that run on top of an existing operating system (OS). This raises a potential security concern, as an encrypted database may be running on an accessible and potentially vulnerable operating system. EFS can encrypt data that is not part of a database system, which implies that the scope of encryption for EFS is much wider when compared to a system such as TDE that is only capable of encrypting database files. Whilst EFS does widen the scope of encryption, it also decreases database performance and can cause administration issues as system administrators require operating system access to use EFS. Due to the issues concerning performance, EFS is not typically used in databasing applications that require frequent database input and output. In order to offset the performance issues it is often recommended that EFS systems be used in environments with few users.\n\n== Full disk encryption ==\n\nBitLocker does not have the same performance concerns associated with EFS.\n\n== Symmetric and asymmetric database encryption ==\n\n\n*** Symmetric database encryption ***\nSymmetric encryption in the context of database encryption involves a private key being applied to data that is stored and called from a database. This private key alters the data in a way that causes it to be unreadable without first being decrypted. Data is encrypted when saved, and decrypted when opened given that the user knows the private key. Thus if the data is to be shared through a database the receiving individual must have a copy of the secret key used by the sender in order to decrypt and view the data. A clear disadvantage related to symmetric encryption is that sensitive data can be leaked if the private key is spread to individuals that should not have access to the data. However, given that only one key is involved in the encryption process it can generally be said that speed is an advantage of symmetric encryption.\n\n\n*** Asymmetric database encryption ***\nAsymmetric encryption expands on symmetric encryption by incorporating two different types of keys into the encryption method: private and public keys. A public key can be accessed by anyone and is unique to one user whereas a private key is a secret key that is unique to and only known by one user. In most scenarios the public key is the encryption key whereas the private key is the decryption key. As an example, if individual A would like to send a message to individual B using asymmetric encryption, he would encrypt the message using Individual B's public key and then send the encrypted version. Individual B would then be able to decrypt the message using his private key. Individual C would not be able to decrypt Individual A's message, as Individual C's private key is not the same as Individual B's private key. Asymmetric encryption is often described as being more secure in comparison to symmetric database encryption given that private keys do not need to be shared as two separate keys handle encryption and decryption processes. For performance reasons, asymmetric encryption is used in Key management rather than to encrypt the data which is usually done with symmetric encryption.\n\n== Key management ==\nThe Symmetric & Asymmetric Database Encryption section introduced the concept of public and private keys with basic examples in which users exchange keys. The act of exchanging keys becomes impractical from a logistical point of view, when many different individuals need to communicate with each-other. In database encryption the system handles the storage and exchange of keys. This process is called key management. If encryption keys are not managed and stored properly, highly sensitive data may be leaked. Additionally, if a key management system deletes or loses a key, the information that was encrypted via said key is essentially rendered \"lost\" as well. The complexity of key management logistics is also a topic that needs to be taken into consideration. As the number of application that a firm uses increases, the number of keys that need to be stored and managed increases as well. Thus it is necessary to establish a way in which keys from all applications can be managed through a single channel, which is also known as enterprise key management. Enterprise Key Management Solutions are sold by a great number of suppliers in the technology industry. These systems essentially provide a centralised key management solution that allows administrators to manage all keys in a system through one hub. Thus it can be said that the introduction of enterprise key management solutions has the potential to lessen the risks associated with key management in the context of database encryption, as well as to reduce the logistical troubles that arise when many individuals attempt to manually share keys.\n\n== Hashing ==\nHashing is used in database systems as a method to protect sensitive data such as passwords; however it is also used to improve the efficiency of database referencing. Inputted data is manipulated by a hashing algorithm. The hashing algorithm converts the inputted data into a string of fixed length that can then be stored in a database. Hashing systems have two crucially important characteristics that will now be outlined. Firstly, hashes are \"unique and repeatable\". As an example, running the word \"cat\" through the same hashing algorithm multiple times will always yield the same hash, however it is extremely difficult to find a word that will return the same hash that \"cat\" does. Secondly, hashing algorithms are not reversible. To relate this back to the example provided above, it would be nearly impossible to convert the output of the hashing algorithm back to the original input, which was \"cat\". In the context of database encryption, hashing is often used in password systems. When a user first creates their password it is run through a hashing algorithm and saved as a hash. When the user logs back into the website, the password that they enter is run through the hashing algorithm and is then compared to the stored hash. Given the fact that hashes are unique, if both hashes match then it is said that the user inputted the correct password. One example of a popular hash function is SHA (Secure Hash Algorithm) 256.\n\n\n*** Salting ***\nOne issue that arises when using hashing for password management in the context of database encryption is the fact that a malicious user could potentially use an Input to Hash table rainbow table for the specific hashing algorithm that the system uses. This would effectively allow the individual to decrypt the hash and thus have access to stored passwords. A solution for this issue is to 'salt' the hash. Salting is the process of encrypting more than just the password in a database. The more information that is added to a string that is to be hashed, the more difficult it becomes to collate rainbow tables. As an example, a system may combine a user's email and password into a single hash. This increase in the complexity of a hash means that it is far more difficult and thus less likely for rainbow tables to be generated. This naturally implies that the threat of sensitive data loss is minimised through salting hashes.\n\n\n*** Pepper ***\nSome systems incorporate a \"pepper\" in addition to salts in their hashing systems. Pepper systems are controversial, however it is still necessary to explain their use. A pepper is a value that is added to a hashed password that has been salted. This pepper is often unique to one website or service, and it is important to note that the same pepper is usually added to all passwords saved in a database. In theory the inclusion of peppers in password hashing systems has the potential to decrease the risk of rainbow (Input : Hash) tables, given the system-level specificity of peppers, however the real world benefits of pepper implementation are highly disputed.\n\n== Application-level encryption ==\nIn application-level encryption, the process of encrypting data is completed by the application that has been used to generate or modify the data that is to be encrypted. Essentially this means that data is encrypted before it is written to the database. This unique approach to encryption allows for the encryption process to be tailored to each user based on the information (such as entitlements or roles) that the application knows about its users.According to Eugene Pilyankevich, \"Application-level encryption is becoming a good practice for systems with increased security requirements, with a general drift toward perimeter-less and more exposed cloud systems\".\n\n\n*** Advantages of application-level encryption ***\nOne of the most important advantages of application-level encryption is the fact that application-level encryption has the potential to simplify the encryption process used by a company. If an application encrypts the data that it writes/modifies from a database then a secondary encryption tool will not need to be integrated into the system. The second main advantage relates to the overarching theme of theft. Given that data is encrypted before it is written to the server, a hacker would need to have access to the database contents as well as the applications that were used to encrypt and decrypt the contents of the database in order to decrypt sensitive data.\n\n\n*** Disadvantages of application-level encryption ***\nThe first important disadvantage of Application-level encryption is that applications used by a firm will need to be modified to encrypt data themselves. This has the potential to consume a significant amount of time and other resources. Given the nature of opportunity cost firms may not believe that application-level encryption is worth the investment. In addition, application-level encryption may have a limiting effect on database performance. If all data on a database is encrypted by a multitude of different applications then it becomes impossible to index or search data on the database. To ground this in reality in the form of a basic example: it would be impossible to construct a glossary in a single language for a book that was written in 30 languages. Lastly the complexity of key management increases, as multiple different applications need to have the authority and access to encrypt data and write it to the database.\n\n== Risks of database encryption ==\nWhen discussing the topic of database encryption it is imperative to be aware of the risks that are involved in the process. The first set of risks are related to key management. If private keys are not managed in an \"isolated system\", system administrators with malicious intentions may have the ability to decrypt sensitive data using keys that they have access to. The fundamental principle of keys also gives rise to a potentially devastating risk: if keys are lost then the encrypted data is essentially lost as well, as decryption without keys is almost impossible."
    }
  },
  {
    "instruction": "context: Session border controllers allow network operators to manage calls on their networks by fixing or changing protocols and protocol syntax to achieve interoperability, and overcoming some of the problems that firewalls and network address translators (NATs) present for VoIP calls.\n\nAsk a question about this context.",
    "context": "",
    "output": "In what ways do session border controllers allow network operators to manage calls on their networks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In what ways do session border controllers allow network operators to manage calls on their networks?",
      "answer": "Session border controllers allow network operators to manage calls on their networks by fixing or changing protocols and protocol syntax to achieve interoperability, and overcoming some of the problems that firewalls and network address translators (NATs) present for VoIP calls."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is OCSP stapling and how does it help with privacy concerns?",
    "context": "",
    "output": "OCSP stapling is a way to verify validity without disclosing browsing behavior to the CA. It allows the client to confirm certificate validity without contacting the third-party OCSP responder, thus addressing privacy concerns.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is OCSP stapling and how does it help with privacy concerns?",
      "answer": "OCSP stapling is a way to verify validity without disclosing browsing behavior to the CA. It allows the client to confirm certificate validity without contacting the third-party OCSP responder, thus addressing privacy concerns."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of Ettercap's plugin support feature?",
    "context": "",
    "output": "Ettercap's plugin support feature allows users to extend and customize its functionality by adding new plugins, which can enhance its capabilities for various network attacks and security auditing tasks.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of Ettercap's plugin support feature?",
      "answer": "Ettercap's plugin support feature allows users to extend and customize its functionality by adding new plugins, which can enhance its capabilities for various network attacks and security auditing tasks."
    }
  },
  {
    "instruction": "context: Incorporating security controls into the design and implementation of a project is important to ensure the security and integrity of the project and to address any security gaps identified in the security assessment process.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the importance of incorporating security controls into the design and implementation of a project?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the importance of incorporating security controls into the design and implementation of a project?",
      "answer": "Incorporating security controls into the design and implementation of a project is important to ensure the security and integrity of the project and to address any security gaps identified in the security assessment process."
    }
  },
  {
    "instruction": "context: XEX mode of operation is also commonly used for key whitening, which is a method of improving the security of a cryptographic system by combining a secret key with the plaintext or ciphertext using the XOR operation. This can help to protect against certain types of attacks, such as known-plaintext attacks. Furthermore, XEX mode is used in some smart card proposals. Smart cards are small, tamper-resistant devices that can store and process sensitive information, such as cryptographic keys. By using XEX mode, these smart card proposals can provide a higher level of security for the data stored on the card.\n\nAsk a question about this context.",
    "context": "",
    "output": "How is XEX mode of operation used for key whitening and in smart card proposals?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is XEX mode of operation used for key whitening and in smart card proposals?",
      "answer": "XEX mode of operation is also commonly used for key whitening, which is a method of improving the security of a cryptographic system by combining a secret key with the plaintext or ciphertext using the XOR operation. This can help to protect against certain types of attacks, such as known-plaintext attacks. Furthermore, XEX mode is used in some smart card proposals. Smart cards are small, tamper-resistant devices that can store and process sensitive information, such as cryptographic keys. By using XEX mode, these smart card proposals can provide a higher level of security for the data stored on the card."
    }
  },
  {
    "instruction": "context: No, TunnelBear does not offer a freeware client for Linux, but Linux distros can be configured to use TunnelBear.\n\nAsk a question about this context.",
    "context": "",
    "output": "Does TunnelBear have a freeware client available for Linux?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Does TunnelBear have a freeware client available for Linux?",
      "answer": "No, TunnelBear does not offer a freeware client for Linux, but Linux distros can be configured to use TunnelBear."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the MAC address table in a network switch?",
    "context": "",
    "output": "The MAC address table in a network switch maps individual MAC addresses on the network to the physical ports on the switch, allowing the switch to direct data out of the physical port where the recipient is located.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the MAC address table in a network switch?",
      "answer": "The MAC address table in a network switch maps individual MAC addresses on the network to the physical ports on the switch, allowing the switch to direct data out of the physical port where the recipient is located."
    }
  },
  {
    "instruction": "Write an answer to the following question: What was the reason behind the change from \"federal interest computer\" to \"computer used in interstate commerce or communications\" in the Computer Fraud and Abuse Act (CFAA)?",
    "context": "",
    "output": "The change from \"federal interest computer\" to \"computer used in interstate commerce or communications\" in the Computer Fraud and Abuse Act (CFAA) was made to broaden the reach of the statute and cover a computer which is one of two or more computers used in committing the offense, not all of which are located in the same State. This was done to ensure jurisdiction over international computer crime cases.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the reason behind the change from \"federal interest computer\" to \"computer used in interstate commerce or communications\" in the Computer Fraud and Abuse Act (CFAA)?",
      "answer": "The change from \"federal interest computer\" to \"computer used in interstate commerce or communications\" in the Computer Fraud and Abuse Act (CFAA) was made to broaden the reach of the statute and cover a computer which is one of two or more computers used in committing the offense, not all of which are located in the same State. This was done to ensure jurisdiction over international computer crime cases."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can black-bag cryptanalysis be used to steal passwords?",
    "context": "",
    "output": "Black-bag cryptanalysis can be used to steal passwords by installing keystroke logging or trojan horse software on target computers or ancillary devices, or by simply copying a password that has been written down. This allows an attacker to gain access to a system or account protected by the stolen password.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can black-bag cryptanalysis be used to steal passwords?",
      "answer": "Black-bag cryptanalysis can be used to steal passwords by installing keystroke logging or trojan horse software on target computers or ancillary devices, or by simply copying a password that has been written down. This allows an attacker to gain access to a system or account protected by the stolen password."
    }
  },
  {
    "instruction": "Kryha\n\n==Introduction==\nIn the history of cryptography, the Kryha machine was a device for encryption and decryption, appearing in the early 1920s and used until the 1950s. The machine was the invention of Alexander von Kryha (born 31.10.1891 in Charkow, Russian Empire, committed suicide in Baden-Baden in 1955). During the Second World War, Kryha worked as an officer for the German Wehrmacht. There were several versions; the standard Kryha machine weighed around five kilograms, and was totally mechanical. A scaled down pocket version was introduced later on, termed the \"Lilliput\" model. There was also a more bulky electrical version.\nThe machine was used for a time by the German Diplomatic Corps, and was adopted by Marconi in England.\n\n== Operation ==\n\nThe machine consisted of two concentric rings each containing an alphabet. The inner alphabet was stepped a variable number of places by pushing a lever. In operation, the user would encrypt by finding the plaintext letter on one ring (usually the outer ring), and reading the corresponding letter on the other ring; this was then used as the ciphertext letter. When the lever was pressed, the inner ring would step, causing the relationship between the two alphabets to change. The stepping was irregular and governed by the use of a disk with a number of sectors, each containing a number of teeth.\n\n== Cryptanalysis ==\n\nThe security of the machine was evaluated by the mathematician Georg Hamel, who calculated the size of the key space. The US Army was also contacted to see if they would be interested in using the machine, and were persuaded to accept a challenge message to evaluate the security of the device. The challenge message, 1135 characters long, was solved  by William Friedman, assisted by Solomon Kullback, Frank Rowlett and Abraham Sinkov, in 2 hours and 41 minutes.\n\nWho solved the challenge message sent by the US Army to evaluate the security of the Kryha machine?",
    "context": "",
    "output": "The challenge message was solved by William Friedman, assisted by Solomon Kullback, Frank Rowlett and Abraham Sinkov.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who solved the challenge message sent by the US Army to evaluate the security of the Kryha machine?",
      "answer": "The challenge message was solved by William Friedman, assisted by Solomon Kullback, Frank Rowlett and Abraham Sinkov.",
      "context": "Kryha\n\n==Introduction==\nIn the history of cryptography, the Kryha machine was a device for encryption and decryption, appearing in the early 1920s and used until the 1950s. The machine was the invention of Alexander von Kryha (born 31.10.1891 in Charkow, Russian Empire, committed suicide in Baden-Baden in 1955). During the Second World War, Kryha worked as an officer for the German Wehrmacht. There were several versions; the standard Kryha machine weighed around five kilograms, and was totally mechanical. A scaled down pocket version was introduced later on, termed the \"Lilliput\" model. There was also a more bulky electrical version.\nThe machine was used for a time by the German Diplomatic Corps, and was adopted by Marconi in England.\n\n== Operation ==\n\nThe machine consisted of two concentric rings each containing an alphabet. The inner alphabet was stepped a variable number of places by pushing a lever. In operation, the user would encrypt by finding the plaintext letter on one ring (usually the outer ring), and reading the corresponding letter on the other ring; this was then used as the ciphertext letter. When the lever was pressed, the inner ring would step, causing the relationship between the two alphabets to change. The stepping was irregular and governed by the use of a disk with a number of sectors, each containing a number of teeth.\n\n== Cryptanalysis ==\n\nThe security of the machine was evaluated by the mathematician Georg Hamel, who calculated the size of the key space. The US Army was also contacted to see if they would be interested in using the machine, and were persuaded to accept a challenge message to evaluate the security of the device. The challenge message, 1135 characters long, was solved  by William Friedman, assisted by Solomon Kullback, Frank Rowlett and Abraham Sinkov, in 2 hours and 41 minutes."
    }
  },
  {
    "instruction": "Write an answer to the following question: What security guarantees does LSH provide in the ideal cipher model?",
    "context": "",
    "output": "LSH is collision-resistant for q < 2^(n/2), and preimage-resistant and second-preimage-resistant for q < 2^n in the ideal cipher model, where q is the number of queries for LSH structure.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What security guarantees does LSH provide in the ideal cipher model?",
      "answer": "LSH is collision-resistant for q < 2^(n/2), and preimage-resistant and second-preimage-resistant for q < 2^n in the ideal cipher model, where q is the number of queries for LSH structure."
    }
  },
  {
    "instruction": "context: Atomic authorization improves the security of access to individual data by defining policy that permits access to specific data and securing it independently from the intermediary applications and parties involved. This makes it more difficult to tamper with or falsify the policy, ensuring that access to the data is properly controlled and managed.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does atomic authorization improve the security of access to individual data?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does atomic authorization improve the security of access to individual data?",
      "answer": "Atomic authorization improves the security of access to individual data by defining policy that permits access to specific data and securing it independently from the intermediary applications and parties involved. This makes it more difficult to tamper with or falsify the policy, ensuring that access to the data is properly controlled and managed."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does SaferSurf's geolocation function benefit users?",
    "context": "",
    "output": "SaferSurf's geolocation function enables users to adopt the IP of a specific country, allowing them to bypass country restrictions and access content that might otherwise be unavailable in their location.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SaferSurf's geolocation function benefit users?",
      "answer": "SaferSurf's geolocation function enables users to adopt the IP of a specific country, allowing them to bypass country restrictions and access content that might otherwise be unavailable in their location."
    }
  },
  {
    "instruction": "context: Dream Market provided an escrow service and handled disputes with the assistance of staff.\n\nAsk a question about this context.",
    "context": "",
    "output": "What was Dream Market's policy on disputes?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was Dream Market's policy on disputes?",
      "answer": "Dream Market provided an escrow service and handled disputes with the assistance of staff."
    }
  },
  {
    "instruction": "context: In a capability-based model, holding an unforgeable reference or capability to an object provides access to the object.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does a capability-based model provide access to an object?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a capability-based model provide access to an object?",
      "answer": "In a capability-based model, holding an unforgeable reference or capability to an object provides access to the object."
    }
  },
  {
    "instruction": "context: The distribution updates, including bash43-027 from Red Hat and updates from Red Hat Enterprise Linux, Fedora 21, Canonical Ltd. for Ubuntu Long Term Support versions, SUSE Linux Enterprise, Mac OS X, and IBM Hardware Management Console, covered all six Shellshock vulnerabilities. These updates were released in the days and weeks following the initial discovery of the vulnerabilities.\n\nAsk a question about this context.",
    "context": "",
    "output": "How did the distribution updates cover all six Shellshock vulnerabilities, and what was the response from different organizations?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the distribution updates cover all six Shellshock vulnerabilities, and what was the response from different organizations?",
      "answer": "The distribution updates, including bash43-027 from Red Hat and updates from Red Hat Enterprise Linux, Fedora 21, Canonical Ltd. for Ubuntu Long Term Support versions, SUSE Linux Enterprise, Mac OS X, and IBM Hardware Management Console, covered all six Shellshock vulnerabilities. These updates were released in the days and weeks following the initial discovery of the vulnerabilities."
    }
  },
  {
    "instruction": "Context: Traceroute\n\n==Introduction==\nIn computing, traceroute and tracert are computer network diagnostic commands for displaying possible routes (paths) and measuring transit delays of packets across an Internet Protocol (IP) network. The history of the route is recorded as the round-trip times of the packets received from each successive host (remote node) in the route (path); the sum of the mean times in each hop is a measure of the total time spent to establish the connection. Traceroute proceeds unless all (usually three) sent packets are lost more than twice; then the connection is lost and the route cannot be evaluated.  Ping, on the other hand, only computes the final round-trip times from the destination point.\nFor Internet Protocol Version 6 (IPv6) the tool sometimes has the name traceroute6 and tracert6.\n\n\n\n== Implementations ==\nThe command traceroute is available on many modern operating systems. On Unix-like systems such as FreeBSD, macOS, and Linux it is available as a command line tool. Traceroute is also graphically accessible in macOS within the Network Utilities suite; these utilities have been deprecated since the release of macOS Big Sur.Microsoft Windows and ReactOS provide a program named tracert that performs the same route-tracing function. Windows NT-based operating systems also provide PathPing, which combines the functionality of ping with that of tracert. The ReactOS version was developed by Ged Murphy and is licensed under the GPL.On Unix-like operating systems, traceroute sends, by default, a sequence of User Datagram Protocol (UDP) packets, with destination port numbers ranging from 33434 to 33534; the implementations of traceroute shipped with Linux, FreeBSD, NetBSD, OpenBSD, DragonFly BSD, and macOS include an option to use ICMP Echo Request packets (-I), or any arbitrary protocol (-P) such as UDP, TCP using TCP SYN packets, or ICMP.On Windows, tracert sends ICMP Echo Request packets, rather than the UDP packets traceroute sends by default.The time-to-live (TTL) value, also known as hop limit, is used in determining the intermediate routers being traversed towards the destination. Traceroute sends packets with TTL values that gradually increase from packet to packet, starting with TTL value of one. Routers decrement TTL values of packets by one when routing and discard packets whose TTL value has reached zero, returning the ICMP error message ICMP Time Exceeded. For the first set of packets, the first router receives the packet, decrements the TTL value and drops the packet because it then has TTL value zero. The router sends an ICMP Time Exceeded message back to the source. The next set of packets are given a TTL value of two, so the first router forwards the packets, but the second router drops them and replies with ICMP Time Exceeded. Proceeding in this way, traceroute uses the returned ICMP Time Exceeded messages to build a list of routers that packets traverse, until the destination is reached and returns an ICMP Destination Unreachable message if UDP packets are being used or an ICMP Echo Reply message if ICMP Echo messages are being used.The timestamp values returned for each router along the path are the delay (latency) values, typically measured in milliseconds for each packet.\nThe sender expects a reply within a specified number of seconds. If a packet is not acknowledged within the expected interval, an asterisk is displayed. The Internet Protocol does not require packets to take the same route towards a particular destination, thus hosts listed might be hosts that other packets have traversed. If the host at hop #N does not reply, the hop is skipped in the output.\nIf a network has a firewall and operates both Windows and Unix-like systems, more than one protocol must be enabled inbound through the firewall for traceroute to work and receive replies.\nSome traceroute implementations use TCP packets, such as tcptraceroute and layer four traceroute (lft).  PathPing is a utility introduced with Windows NT that combines ping and traceroute functionality. MTR is an enhanced version of ICMP traceroute available for Unix-like and Windows systems. The various implementations of traceroute all rely on ICMP Time Exceeded (type 11) packets being sent to the source.\n\nOn Linux, tracepath is a utility similar to traceroute, with the primary difference of not requiring superuser privileges.Cisco's implementation of traceroute also uses a sequence of UDP datagrams, each with incrementing TTL values, to an invalid port number at the remote host; by default, UDP port 33434 is used. An extended version of this command (known as the extended traceroute command) can change the destination port number used by the UDP probe messages.\n\n== Usage ==\n\nMost implementations include at least options to specify the number of queries to send per hop, time to wait for a response, the hop limit and port to use.  Invoking traceroute with no specified options displays the list of available options, while man traceroute presents more details, including the displayed error flags.  An example on Linux:\n\nIn the example above, selected options are to wait for three seconds (instead of five), send out only one query to each hop (instead of three), limit the maximum number of hops to 16 before giving up (instead of 30), with example.com as the final host. On line 8 and 9 (TTLs 8 and 9) it shows asterisks where the router did not respond within the timeout.\nTraceroute can be used to help identify incorrect routing table definitions or firewalls that may be blocking ICMP traffic, or high port UDP in Unix ping, to a site. A correct traceroute response does not guarantee connectivity for applications as a firewall may permit ICMP packets but not permit packets of other protocols.\nTraceroute is also used by penetration testers to gather information about network infrastructure and IP address ranges around a given host.\nIt can also be used when downloading data, and if there are multiple mirrors available for the same piece of data, each mirror can be traced to get an idea of which mirror would be the fastest to use.\n\n== Origins ==\nThe traceroute manual page states that the original traceroute program was written by Van Jacobson in 1987 from a suggestion by Steve Deering, with particularly cogent suggestions or fixes from C. Philip Wood, Tim Seaver and Ken Adelman.  The author of the ping program, Mike Muuss, states on his website that traceroute was written using kernel ICMP support that he had earlier coded to enable raw ICMP sockets when he first wrote the ping program.\n\n== Limitations ==\nTraceroute limitations are well known and should be taken into account when using the tool. For example, traceroute does not discover paths at the router level, but at the interface level. Another limitation appears when routers do not respond to probes or when routers have a limit for ICMP responses. In the presence of traffic load balancing, traceroute may indicate a path that does not actually exist; to minimize this problem there is a traceroute modification called Paris-traceroute, which maintains the flow identifier of the probes to avoid load balancing.\nAnswer this question: How does traceroute use time-to-live (TTL) values to determine intermediate routers in a network path?",
    "context": "",
    "output": "Traceroute uses TTL values to incrementally determine intermediate routers in a network path. It starts with a TTL value of one for the first set of packets, which are dropped by the first router, which then sends an ICMP Time Exceeded message back to the source. The next set of packets are given a TTL value of two, and this process continues until the destination is reached and returns an ICMP Destination Unreachable message.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does traceroute use time-to-live (TTL) values to determine intermediate routers in a network path?",
      "answer": "Traceroute uses TTL values to incrementally determine intermediate routers in a network path. It starts with a TTL value of one for the first set of packets, which are dropped by the first router, which then sends an ICMP Time Exceeded message back to the source. The next set of packets are given a TTL value of two, and this process continues until the destination is reached and returns an ICMP Destination Unreachable message.",
      "context": "Traceroute\n\n==Introduction==\nIn computing, traceroute and tracert are computer network diagnostic commands for displaying possible routes (paths) and measuring transit delays of packets across an Internet Protocol (IP) network. The history of the route is recorded as the round-trip times of the packets received from each successive host (remote node) in the route (path); the sum of the mean times in each hop is a measure of the total time spent to establish the connection. Traceroute proceeds unless all (usually three) sent packets are lost more than twice; then the connection is lost and the route cannot be evaluated.  Ping, on the other hand, only computes the final round-trip times from the destination point.\nFor Internet Protocol Version 6 (IPv6) the tool sometimes has the name traceroute6 and tracert6.\n\n\n\n== Implementations ==\nThe command traceroute is available on many modern operating systems. On Unix-like systems such as FreeBSD, macOS, and Linux it is available as a command line tool. Traceroute is also graphically accessible in macOS within the Network Utilities suite; these utilities have been deprecated since the release of macOS Big Sur.Microsoft Windows and ReactOS provide a program named tracert that performs the same route-tracing function. Windows NT-based operating systems also provide PathPing, which combines the functionality of ping with that of tracert. The ReactOS version was developed by Ged Murphy and is licensed under the GPL.On Unix-like operating systems, traceroute sends, by default, a sequence of User Datagram Protocol (UDP) packets, with destination port numbers ranging from 33434 to 33534; the implementations of traceroute shipped with Linux, FreeBSD, NetBSD, OpenBSD, DragonFly BSD, and macOS include an option to use ICMP Echo Request packets (-I), or any arbitrary protocol (-P) such as UDP, TCP using TCP SYN packets, or ICMP.On Windows, tracert sends ICMP Echo Request packets, rather than the UDP packets traceroute sends by default.The time-to-live (TTL) value, also known as hop limit, is used in determining the intermediate routers being traversed towards the destination. Traceroute sends packets with TTL values that gradually increase from packet to packet, starting with TTL value of one. Routers decrement TTL values of packets by one when routing and discard packets whose TTL value has reached zero, returning the ICMP error message ICMP Time Exceeded. For the first set of packets, the first router receives the packet, decrements the TTL value and drops the packet because it then has TTL value zero. The router sends an ICMP Time Exceeded message back to the source. The next set of packets are given a TTL value of two, so the first router forwards the packets, but the second router drops them and replies with ICMP Time Exceeded. Proceeding in this way, traceroute uses the returned ICMP Time Exceeded messages to build a list of routers that packets traverse, until the destination is reached and returns an ICMP Destination Unreachable message if UDP packets are being used or an ICMP Echo Reply message if ICMP Echo messages are being used.The timestamp values returned for each router along the path are the delay (latency) values, typically measured in milliseconds for each packet.\nThe sender expects a reply within a specified number of seconds. If a packet is not acknowledged within the expected interval, an asterisk is displayed. The Internet Protocol does not require packets to take the same route towards a particular destination, thus hosts listed might be hosts that other packets have traversed. If the host at hop #N does not reply, the hop is skipped in the output.\nIf a network has a firewall and operates both Windows and Unix-like systems, more than one protocol must be enabled inbound through the firewall for traceroute to work and receive replies.\nSome traceroute implementations use TCP packets, such as tcptraceroute and layer four traceroute (lft).  PathPing is a utility introduced with Windows NT that combines ping and traceroute functionality. MTR is an enhanced version of ICMP traceroute available for Unix-like and Windows systems. The various implementations of traceroute all rely on ICMP Time Exceeded (type 11) packets being sent to the source.\n\nOn Linux, tracepath is a utility similar to traceroute, with the primary difference of not requiring superuser privileges.Cisco's implementation of traceroute also uses a sequence of UDP datagrams, each with incrementing TTL values, to an invalid port number at the remote host; by default, UDP port 33434 is used. An extended version of this command (known as the extended traceroute command) can change the destination port number used by the UDP probe messages.\n\n== Usage ==\n\nMost implementations include at least options to specify the number of queries to send per hop, time to wait for a response, the hop limit and port to use.  Invoking traceroute with no specified options displays the list of available options, while man traceroute presents more details, including the displayed error flags.  An example on Linux:\n\nIn the example above, selected options are to wait for three seconds (instead of five), send out only one query to each hop (instead of three), limit the maximum number of hops to 16 before giving up (instead of 30), with example.com as the final host. On line 8 and 9 (TTLs 8 and 9) it shows asterisks where the router did not respond within the timeout.\nTraceroute can be used to help identify incorrect routing table definitions or firewalls that may be blocking ICMP traffic, or high port UDP in Unix ping, to a site. A correct traceroute response does not guarantee connectivity for applications as a firewall may permit ICMP packets but not permit packets of other protocols.\nTraceroute is also used by penetration testers to gather information about network infrastructure and IP address ranges around a given host.\nIt can also be used when downloading data, and if there are multiple mirrors available for the same piece of data, each mirror can be traced to get an idea of which mirror would be the fastest to use.\n\n== Origins ==\nThe traceroute manual page states that the original traceroute program was written by Van Jacobson in 1987 from a suggestion by Steve Deering, with particularly cogent suggestions or fixes from C. Philip Wood, Tim Seaver and Ken Adelman.  The author of the ping program, Mike Muuss, states on his website that traceroute was written using kernel ICMP support that he had earlier coded to enable raw ICMP sockets when he first wrote the ping program.\n\n== Limitations ==\nTraceroute limitations are well known and should be taken into account when using the tool. For example, traceroute does not discover paths at the router level, but at the interface level. Another limitation appears when routers do not respond to probes or when routers have a limit for ICMP responses. In the presence of traffic load balancing, traceroute may indicate a path that does not actually exist; to minimize this problem there is a traceroute modification called Paris-traceroute, which maintains the flow identifier of the probes to avoid load balancing."
    }
  },
  {
    "instruction": "Write an answer to the following question: How was the National Strategy for Trusted Identities in Cyberspace (NSTIC) developed and what are its four guiding principles?",
    "context": "",
    "output": "The NSTIC was developed with input from private sector lobbyists, organizations representing various business groups and nonprofit federal advisory groups, as well as comments and dialogue from the public. The strategy has four guiding principles: privacy-enhancing and voluntary, secure and resilient, interoperable, and cost-effective and easy to use.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How was the National Strategy for Trusted Identities in Cyberspace (NSTIC) developed and what are its four guiding principles?",
      "answer": "The NSTIC was developed with input from private sector lobbyists, organizations representing various business groups and nonprofit federal advisory groups, as well as comments and dialogue from the public. The strategy has four guiding principles: privacy-enhancing and voluntary, secure and resilient, interoperable, and cost-effective and easy to use."
    }
  },
  {
    "instruction": "SWAPGS (security vulnerability)\n\n==Introduction==\nSWAPGS, also known as Spectre variant 1 (swapgs), is a computer security vulnerability that utilizes the branch prediction used in modern microprocessors. Most processors use a form of speculative execution, this feature allows the processors to make educated guesses about the instructions that will most likely need to be executed in the near future. This speculation can leave traces in the cache, which attackers use to extract data using a timing attack, similar to side-channel exploitation of Spectre.The Common Vulnerabilities and Exposures ID issued to this vulnerability is CVE-2019-1125.\n\n== Affected systems ==\nAny Intel-based processor that support SWAPGS and WRGSBASE instructions is affected. This includes every Intel processor starting from the Intel Ivy Bridge CPUs up to the most recent Intel processors.\nDevices equipped with AMD processors are not affected, according to the company's product security update.\nAMD is aware of new research claiming new speculative execution attacks that may allow access to privileged kernel data. Based on external and internal analysis, AMD believes it is not vulnerable to the SWAPGS variant attacks because AMD products are designed not to speculate on the new GS value following a speculative SWAPGS. For the attack that is not a SWAPGS variant, the mitigation is to implement our existing recommendations for Spectre variant 1.\n\n== Mitigation ==\nFor Windows operating system-based devices, Microsoft's security advisory lists the patches released in July 2019, which fix the vulnerability.For Linux distributions, it is advised to check whether there are SWAPGS-specific patches that need to be applied. The kernel documentation describes the nature of the attacks and the in-kernel mitigations.Bitdefender mentions in its original report that Apple devices are unlikely to be at risk.\n\nAnswer this question based on the above context: What is recommended for Linux distributions to mitigate the SWAPGS vulnerability?",
    "context": "",
    "output": "For Linux distributions, it is advised to check whether there are SWAPGS-specific patches that need to be applied. The kernel documentation describes the nature of the attacks and the in-kernel mitigations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is recommended for Linux distributions to mitigate the SWAPGS vulnerability?",
      "answer": "For Linux distributions, it is advised to check whether there are SWAPGS-specific patches that need to be applied. The kernel documentation describes the nature of the attacks and the in-kernel mitigations.",
      "context": "SWAPGS (security vulnerability)\n\n==Introduction==\nSWAPGS, also known as Spectre variant 1 (swapgs), is a computer security vulnerability that utilizes the branch prediction used in modern microprocessors. Most processors use a form of speculative execution, this feature allows the processors to make educated guesses about the instructions that will most likely need to be executed in the near future. This speculation can leave traces in the cache, which attackers use to extract data using a timing attack, similar to side-channel exploitation of Spectre.The Common Vulnerabilities and Exposures ID issued to this vulnerability is CVE-2019-1125.\n\n== Affected systems ==\nAny Intel-based processor that support SWAPGS and WRGSBASE instructions is affected. This includes every Intel processor starting from the Intel Ivy Bridge CPUs up to the most recent Intel processors.\nDevices equipped with AMD processors are not affected, according to the company's product security update.\nAMD is aware of new research claiming new speculative execution attacks that may allow access to privileged kernel data. Based on external and internal analysis, AMD believes it is not vulnerable to the SWAPGS variant attacks because AMD products are designed not to speculate on the new GS value following a speculative SWAPGS. For the attack that is not a SWAPGS variant, the mitigation is to implement our existing recommendations for Spectre variant 1.\n\n== Mitigation ==\nFor Windows operating system-based devices, Microsoft's security advisory lists the patches released in July 2019, which fix the vulnerability.For Linux distributions, it is advised to check whether there are SWAPGS-specific patches that need to be applied. The kernel documentation describes the nature of the attacks and the in-kernel mitigations.Bitdefender mentions in its original report that Apple devices are unlikely to be at risk."
    }
  },
  {
    "instruction": "Silver Sparrow (malware)\n\n==Introduction==\nThe Silver Sparrow computer virus is malware that runs on x86- and Apple M1-based Macintosh computers. Engineers at the cyber security firm Red Canary have detected two versions of the malware in January and February 2021.\n\n\n\n== Description ==\nTwo versions of the malware were reported. The first version (described as the \"non-M1\" version) is compiled for Intel x86-64. It was first detected in January 2021. The second version contains code that runs natively on Apple's proprietary M1 processor, and was probably released in December 2020 and discovered in February 2021. The virus connects to a server hosted on Amazon Web Services.  The software includes a self-destruct mechanism.As of 23 February 2021, information about how the malware is spread and what system may be compromised is sparse. It is uncertain whether Silver Sparrow is embedded inside malicious advertisements, pirated software, or bogus Adobe Flash Player updaters. Red Canary has theorized that systems could have been infected through malicious search engine results that might have directed them to download the code. The ultimate object of the malware's release is also still unknown.Silver Sparrow is the second malware virus observed to include M1-native code.\n\n== Impact ==\nAs of 23 February 2021, Internet security company Malwarebytes has discovered over 29,000 Macs worldwide running their anti-malware software to be infected with Silver Sparrow. Silver Sparrow infected Macs have been found in 153 countries as of February 17, with higher concentrations reported in the US, UK, Canada, France, and Germany, according to data from Malwarebytes. Over 39,000 Macs were affected in the beginning of March 2021.On 23 February 2021, a spokesperson of Apple Inc. stated that \"there is no evidence to suggest the malware they identified has delivered a malicious payload to infected users.\" Apple also revoked the certificates of the developer accounts used to sign the packages, thereby preventing any additional Macs from becoming infected.\n\nAnswer this question based on the above context: In which countries has Silver Sparrow been found to have infected Macs?",
    "context": "",
    "output": "Silver Sparrow has been found to have infected Macs in 153 countries as of February 17, with higher concentrations reported in the US, UK, Canada, France, and Germany.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In which countries has Silver Sparrow been found to have infected Macs?",
      "answer": "Silver Sparrow has been found to have infected Macs in 153 countries as of February 17, with higher concentrations reported in the US, UK, Canada, France, and Germany.",
      "context": "Silver Sparrow (malware)\n\n==Introduction==\nThe Silver Sparrow computer virus is malware that runs on x86- and Apple M1-based Macintosh computers. Engineers at the cyber security firm Red Canary have detected two versions of the malware in January and February 2021.\n\n\n\n== Description ==\nTwo versions of the malware were reported. The first version (described as the \"non-M1\" version) is compiled for Intel x86-64. It was first detected in January 2021. The second version contains code that runs natively on Apple's proprietary M1 processor, and was probably released in December 2020 and discovered in February 2021. The virus connects to a server hosted on Amazon Web Services.  The software includes a self-destruct mechanism.As of 23 February 2021, information about how the malware is spread and what system may be compromised is sparse. It is uncertain whether Silver Sparrow is embedded inside malicious advertisements, pirated software, or bogus Adobe Flash Player updaters. Red Canary has theorized that systems could have been infected through malicious search engine results that might have directed them to download the code. The ultimate object of the malware's release is also still unknown.Silver Sparrow is the second malware virus observed to include M1-native code.\n\n== Impact ==\nAs of 23 February 2021, Internet security company Malwarebytes has discovered over 29,000 Macs worldwide running their anti-malware software to be infected with Silver Sparrow. Silver Sparrow infected Macs have been found in 153 countries as of February 17, with higher concentrations reported in the US, UK, Canada, France, and Germany, according to data from Malwarebytes. Over 39,000 Macs were affected in the beginning of March 2021.On 23 February 2021, a spokesperson of Apple Inc. stated that \"there is no evidence to suggest the malware they identified has delivered a malicious payload to infected users.\" Apple also revoked the certificates of the developer accounts used to sign the packages, thereby preventing any additional Macs from becoming infected."
    }
  },
  {
    "instruction": "context: The Computer Security and Industrial Cryptography (COSIC) research group, which focuses on symmetric key, public key, and post-quantum security for embedded systems, is located at the Department of Electrical Engineering of KU Leuven.\n\nAsk a question about this context.",
    "context": "",
    "output": "In which department of KU Leuven is the research group that focuses on symmetric key, public key, and post-quantum security for embedded systems located?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "In which department of KU Leuven is the research group that focuses on symmetric key, public key, and post-quantum security for embedded systems located?",
      "answer": "The Computer Security and Industrial Cryptography (COSIC) research group, which focuses on symmetric key, public key, and post-quantum security for embedded systems, is located at the Department of Electrical Engineering of KU Leuven."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can a security switch protect against unauthorized access or operation?",
    "context": "",
    "output": "A security switch protects against unauthorized access or operation by being isolated from other devices, preventing any unauthorized access, and it should not be possible to bypass it, in order to prevent malicious manipulation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a security switch protect against unauthorized access or operation?",
      "answer": "A security switch protects against unauthorized access or operation by being isolated from other devices, preventing any unauthorized access, and it should not be possible to bypass it, in order to prevent malicious manipulation."
    }
  },
  {
    "instruction": "Context: Bagle (computer worm)\n\n==Introduction==\nBagle (also known as Beagle) was a mass-mailing computer worm affecting Microsoft Windows. The first strain, Bagle.A, did not propagate widely. A second variant, Bagle.B, was considerably more virulent.\n\n\n\n== Overview ==\nBagle used its own SMTP engine to mass-mail itself as an attachment to recipients gathered from the infected computer by combing through all of the computer's .htm, .html, .txt, and .wab files for any email addresses. It does not mail itself to addresses containing certain strings such as \"@hotmail.com\", \"@msn.com\", \"@microsoft\", \"@avp\", or \u201c.r1\u201d. Bagle pretends to be a different file type (a 15,872 byte Windows Calculator for Bagle.A and an 11,264 byte audio file for Bagle.B), with a randomized name, and it will then open that file type as a cover for opening its own .exe file. It copies itself to the Windows system directory (Bagle.A as bbeagle.exe, Bagle.B as au.exe), adds HKCU run keys to the registry, and opens a backdoor on a TCP port (6777 for Bagle.A and 8866 for Bagle.B). Using an HTTP GET request, Bagle.B also informs the virus's programmer that the machine has been successfully infected. Bagle variants, including Bagle.A and Bagle.B, generally have a date at which they stop spreading included in their programming. Computers infected with older versions of Bagle are updated when newer ones are released.\n\n== Botnet ==\nThe Bagle botnet (Initial discovery early 2004), also known by its aliases Beagle, Mitglieder and Lodeight, is a botnet mostly involved in proxy-to-relay e-mail spam.\nThe Bagle botnet consists of an estimated 150,000-230,000  computers infected with the Bagle Computer worm. It was estimated that the botnet was responsible for about 10.39% of the worldwide spam volume on December 29, 2009, with a surge up to 14% on New Year's Day, though the actual percentage seems to rise and drop rapidly. As of April 2010 it is estimated that the botnet sends roughly 5.7 billion spam messages a day, or about 4.3% of the global spam volume.\nAnswer this question: What kind of information does Bagle.B send to the virus's programmer after infecting a machine?",
    "context": "",
    "output": "Bagle.B sends an HTTP GET request to the virus's programmer to inform them that the machine has been successfully infected.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What kind of information does Bagle.B send to the virus's programmer after infecting a machine?",
      "answer": "Bagle.B sends an HTTP GET request to the virus's programmer to inform them that the machine has been successfully infected.",
      "context": "Bagle (computer worm)\n\n==Introduction==\nBagle (also known as Beagle) was a mass-mailing computer worm affecting Microsoft Windows. The first strain, Bagle.A, did not propagate widely. A second variant, Bagle.B, was considerably more virulent.\n\n\n\n== Overview ==\nBagle used its own SMTP engine to mass-mail itself as an attachment to recipients gathered from the infected computer by combing through all of the computer's .htm, .html, .txt, and .wab files for any email addresses. It does not mail itself to addresses containing certain strings such as \"@hotmail.com\", \"@msn.com\", \"@microsoft\", \"@avp\", or \u201c.r1\u201d. Bagle pretends to be a different file type (a 15,872 byte Windows Calculator for Bagle.A and an 11,264 byte audio file for Bagle.B), with a randomized name, and it will then open that file type as a cover for opening its own .exe file. It copies itself to the Windows system directory (Bagle.A as bbeagle.exe, Bagle.B as au.exe), adds HKCU run keys to the registry, and opens a backdoor on a TCP port (6777 for Bagle.A and 8866 for Bagle.B). Using an HTTP GET request, Bagle.B also informs the virus's programmer that the machine has been successfully infected. Bagle variants, including Bagle.A and Bagle.B, generally have a date at which they stop spreading included in their programming. Computers infected with older versions of Bagle are updated when newer ones are released.\n\n== Botnet ==\nThe Bagle botnet (Initial discovery early 2004), also known by its aliases Beagle, Mitglieder and Lodeight, is a botnet mostly involved in proxy-to-relay e-mail spam.\nThe Bagle botnet consists of an estimated 150,000-230,000  computers infected with the Bagle Computer worm. It was estimated that the botnet was responsible for about 10.39% of the worldwide spam volume on December 29, 2009, with a surge up to 14% on New Year's Day, though the actual percentage seems to rise and drop rapidly. As of April 2010 it is estimated that the botnet sends roughly 5.7 billion spam messages a day, or about 4.3% of the global spam volume."
    }
  },
  {
    "instruction": "List of security hacking incidents\n\n==Introduction==\nThe list of security hacking incidents covers important or noteworthy events in the history of security hacking and cracking.\n\n== 1900 ==\n\n\n*** 1903 ***\nMagician and inventor Nevil Maskelyne disrupts John Ambrose Fleming's public demonstration of Guglielmo Marconi's purportedly secure wireless telegraphy technology, sending insulting Morse code messages through the auditorium's projector.\n\n== 1930s ==\n\n\n*** 1932 ***\nPolish cryptologists Marian Rejewski, Henryk Zygalski and Jerzy R\u00f3\u017cycki broke the Enigma machine code.\n\n\n*** 1939 ***\nAlan Turing, Gordon Welchman and Harold Keen worked together to develop the Bombe (on the basis of Rejewski's works on Bomba). The Enigma machine's use of a reliably small key space makes it vulnerable to brute force.\n\n== 1940s ==\n\n\n*** 1943 ***\nRen\u00e9 Carmille, comptroller general of the Vichy French Army, hacked the punched card system used by the Nazis to locate Jews.\n\n\n*** 1949 ***\nThe theory that underlies computer viruses was first made public in 1949, when computer pioneer John von Neumann presented a paper titled \"Theory and Organization of Complicated Automata\". In the paper von Neumann speculated that computer programs could reproduce themselves.\n\n== 1950s ==\n\n\n*** 1955 ***\nAt MIT, \"hack\" first came to mean fussing with machines. The minutes of an April 1955 meeting of the Tech Model Railroad Club state that \"Mr. Eccles requests that anyone working or hacking on the electrical system turn the power off to avoid fuse blowing.\"\n\n\n*** 1957 ***\nJoe \"Joybubbles\" Engressia, a blind seven-year-old boy with perfect pitch, discovered that whistling the fourth E above middle C (a frequency of 2600 Hz) would interfere with AT&T's automated telephone systems, thereby inadvertently opening the door for phreaking.\n\n== 1960s ==\nVarious phreaking boxes are used to interact with automated telephone systems.\n\n\n*** 1963 ***\nThe first ever reference to malicious hacking is 'telephone hackers' in MIT's student newspaper, The Tech of hackers tying up the lines with Harvard, configuring the PDP-1 to make free calls, war dialing and accumulating large phone bills.\n\n\n*** 1965 ***\nWilliam D. Mathews from MIT found a vulnerability in a CTSS running on an IBM 7094. The standard text editor on the system was designed to be used by one user at a time, working in one directory, and so created a temporary file with a constant name for all instantiations of the editor. The flaw was discovered when two system programmers were editing at the same time and the temporary files for the message-of-the day and the password file became swapped, causing the contents of the system CTSS password file to display to any user logging into the system.\n\n\n*** 1967 ***\nThe first known incidence of network penetration hacking took place when members of a computer club at a suburban Chicago area high school were provided access to IBM's APL network. In the Fall of 1967, IBM (through Science Research Associates) approached Evanston Township High School with the offer of four 2741 Selectric teletypewriter based terminals with dial-up modem connectivity to an experimental computer system which implemented an early version of the APL programming language. The APL network system was structured in Workspaces which were assigned to various clients using the system. Working independently, the students quickly learned the language and the system. They were free to explore the system, often using existing code available in public Workspaces as models for their own creations. Eventually, curiosity drove the students to explore the system's wider context. This first informal network penetration effort was later acknowledged as helping harden the security of one of the first publicly accessible networks:Science Research Associates undertook to write a full APL system for the IBM 1500. They modeled their system after APL/360, which had by that time been developed and seen substantial use inside of IBM, using code borrowed from MAT/1500 where possible. In their documentation they acknowledge their gratitude to \"a number of high school students for their compulsion to bomb the system\". This was an early example of a kind of sportive, but very effective, debugging that was often repeated in the evolution of APL systems.\n\n== 1970s ==\n\n\n*** 1971 ***\nJohn T. Draper (later nicknamed Captain Crunch), his friend Joe Engressia (also known as Joybubbles), and blue box phone phreaking hit the news with an Esquire magazine feature story.\n\n\n*** 1979 ***\nKevin Mitnick breaks into his first major computer system, the Ark, the computer system Digital Equipment Corporation (DEC) used for developing their RSTS/E operating system software.\n\n== 1980s ==\n\n\n*** 1980 ***\nThe FBI investigates a breach of security at National CSS (NCSS). The New York Times, reporting on the incident in 1981, describes hackers astechnical experts; skilled, often young, computer programmers, who almost whimsically probe the defenses of a computer system, searching out the limits and the possibilities of the machine. Despite their seemingly subversive role, hackers are a recognized asset in the computer industry, often highly prizedThe newspaper describes white hat activities as part of a \"mischievous but perversely positive 'hacker' tradition\". When a National CSS employee revealed the existence of his password cracker, which he had used on customer accounts, the company chastised him not for writing the software but for not disclosing it sooner. The letter of reprimand stated that \"The Company realizes the benefit to NCSS and in fact encourages the efforts of employees to identify security weaknesses to the VP, the directory, and other sensitive software in files\".\n\n\n*** 1981 ***\nChaos Computer Club forms in Germany.\nIan Murphy aka Captain Zap, was the first cracker to be tried and convicted as a felon. Murphy broke into AT&T's computers in 1981 and changed the internal clocks that metered billing rates. People were getting late-night discount rates when they called at midday. Of course, the bargain-seekers who waited until midnight to call long distance were hit with high bills.\n\n\n*** 1983 ***\nThe 414s break into 60 computer systems at institutions ranging from the Los Alamos National Laboratory to Manhattan's Memorial Sloan-Kettering Cancer Center. The incident appeared as the cover story of Newsweek with the title \"Beware: Hackers at play\". As a result, the U.S. House of Representatives held hearings on computer security and passed several laws.\nThe group KILOBAUD is formed in February, kicking off a series of other hacker groups which form soon after.\nThe movie WarGames introduces the wider public to the phenomenon of hacking and creates a degree of mass paranoia of hackers and their supposed abilities to bring the world to a screeching halt by launching nuclear ICBMs.\nThe U.S. House of Representatives begins hearings on computer security hacking.\nIn his Turing Award lecture, Ken Thompson mentions \"hacking\" and describes a security exploit that he calls a \"Trojan horse\".\n\n\n*** 1984 ***\nSomeone calling himself Lex Luthor founds the Legion of Doom. Named after a Saturday morning cartoon, the LOD had the reputation of attracting \"the best of the best\"\u2014until one of the most talented members called Phiber Optik feuded with Legion of Doomer Erik Bloodaxe and got 'tossed out of the clubhouse'. Phiber's friends formed a rival group, the Masters of Deception.\nThe Comprehensive Crime Control Act gives the Secret Service jurisdiction over computer fraud.\nCult of the Dead Cow forms in Lubbock, Texas, and begins publishing its ezine.\nThe hacker magazine 2600 begins regular publication, right when TAP was putting out its final issue. The editor of 2600, \"Emmanuel Goldstein\" (whose real name is Eric Corley), takes his handle from the leader of the resistance in George Orwell's 1984. The publication provides tips for would-be hackers and phone phreaks, as well as commentary on the hacker issues of the day. Today, copies of 2600 are sold at most large retail bookstores.\nThe Chaos Communication Congress, the annual European hacker conference organized by the Chaos Computer Club, is held in Hamburg, Germany.\nWilliam Gibson's groundbreaking science fiction novel Neuromancer, about \"Case\", a futuristic computer hacker, is published. Considered the first major cyberpunk novel, it brought into hacker jargon such terms as \"cyberspace\", \"the matrix\", \"simstim\", and \"ICE\".\n\n\n*** 1985 ***\nKILOBAUD is re-organized into The P.H.I.R.M. and begins sysopping hundreds of BBSs throughout the United States, Canada, and Europe.\nThe online 'zine Phrack is established.\nThe Hacker's Handbook is published in the UK.\nThe FBI, Secret Service, Middlesex County NJ Prosecutor's Office and various local law enforcement agencies execute seven search warrants concurrently across New Jersey on July 12, 1985, seizing equipment from BBS operators and users alike for \"complicity in computer theft\", under a newly passed, and yet untested criminal statute. This is famously known as the Private Sector Bust, or the 2600 BBS Seizure, and implicated the Private Sector BBS sysop, Store Manager (also a BBS sysop), Beowulf, Red Barchetta, The Vampire, the NJ Hack Shack BBS sysop, and the Treasure Chest BBS sysop.\n\n\n*** 1986 ***\nAfter more and more break-ins to government and corporate computers, Congress passes the Computer Fraud and Abuse Act, which makes it a crime to break into computer systems. The law, however, does not cover juveniles.\nRobert Schifreen and Stephen Gold are convicted of accessing the Telecom Gold account belonging to the Duke of Edinburgh under the Forgery and Counterfeiting Act 1981 in the United Kingdom, the first conviction for illegally accessing a computer system. On appeal, the conviction is overturned as hacking is not within the legal definition of forgery.\nArrest of a hacker who calls himself The Mentor. He published a now-famous treatise shortly after his arrest that came to be known as the Hacker Manifesto in the e-zine Phrack. This still serves as the most famous piece of hacker literature and is frequently used to illustrate the mindset of hackers.\nAstronomer Clifford Stoll plays a pivotal role in tracking down hacker Markus Hess, events later covered in Stoll's 1990 book The Cuckoo's Egg.\n\n\n*** 1987 ***\nThe Christmas Tree EXEC \"worm\" causes major disruption to the VNET, BITNET and EARN networks.\n\n\n*** 1988 ***\nThe Morris Worm. Graduate student Robert T. Morris, Jr. of Cornell University launches a worm on the government's ARPAnet (precursor to the Internet). The worm spreads to 6,000 networked computers, clogging government and university systems. Robert Morris is dismissed from Cornell, sentenced to three years' probation, and fined $10,000.\nFirst National Bank of Chicago is the victim of $70 million computer theft.\nThe Computer Emergency Response Team (CERT) is created by DARPA to address network security.\nThe Father Christmas (computer worm) spreads over DECnet networks.\n\n\n*** 1989 ***\nJude Milhon (aka St Jude) and R. U. Sirius launch MONDO 2000, a major '90s tech-lifestyle magazine, in Berkeley, California.\nThe politically motivated WANK worm spreads over DECnet.\nDutch magazine Hack-Tic begins.\nThe Cuckoo's Egg by Clifford Stoll is published.\nThe detection of AIDS (Trojan horse) is the first instance of a ransomware detection.\n\n== 1990s ==\n\n\n*** 1990 ***\nOperation Sundevil introduced. After a prolonged sting investigation, Secret Service agents swoop down on organizers and prominent members of BBSs in 14 U.S. cities including the Legion of Doom, conducting early-morning raids and arrests. The arrests involve and are aimed at cracking down on credit-card theft and telephone and wire fraud. The result is a breakdown in the hacking community, with members informing on each other in exchange for immunity. The offices of Steve Jackson Games are also raided, and the role-playing sourcebook GURPS Cyberpunk is confiscated, possibly because the government fears it is a \"handbook for computer crime\". Legal battles arise that prompt the formation of the Electronic Frontier Foundation, including the trial of Knight Lightning.\nAustralian federal police tracking Realm members Phoenix, Electron and Nom are the first in the world to use a remote data intercept to gain evidence for a computer crime prosecution.\nThe Computer Misuse Act 1990 is passed in the United Kingdom, criminalising any unauthorised access to computer systems.\n\n\n*** 1992 ***\nRelease of the movie Sneakers, in which security experts are blackmailed into stealing a universal decoder for encryption systems.\nOne of the first ISPs, MindVox, opens to the public.\nBulgarian virus writer Dark Avenger wrote 1260, the first known use of polymorphic code, used to circumvent the type of pattern recognition used by antivirus software, and nowadays also intrusion detection systems.\nPublication of a hacking instruction manual for penetrating TRW credit reporting agency by Infinite Possibilities Society (IPS) gets Dr. Ripco, the sysop of Ripco BBS mentioned in the IPS manual, arrested by the United States Secret Service.\n\n\n*** 1993 ***\nThe first DEF CON hacking conference takes place in Las Vegas. The conference is meant to be a one-time party to say good-bye to BBSs (now replaced by the Web), but the gathering was so popular it became an annual event.\nAOL gives its users access to Usenet, precipitating Eternal September.\n\n\n*** 1994 ***\nSummer: Russian crackers siphon $10 million from Citibank and transfer the money to bank accounts around the world. Vladimir Levin, the 30-year-old ringleader, used his work laptop after hours to transfer the funds to accounts in Finland and Israel. Levin stands trial in the United States and is sentenced to three years in prison. Authorities recover all but $400,000 of the stolen money.\nHackers adapt to emergence of the World Wide Web quickly, moving all their how-to information and hacking programs from the old BBSs to new hacker web sites.\nAOHell is released, a freeware application that allows a burgeoning community of unskilled script kiddies to wreak havoc on America Online. For days, hundreds of thousands of AOL users find their mailboxes flooded with multi-megabyte email bombs and their chat rooms disrupted with spam messages.\nDecember 27: After experiencing an IP spoofing attack by Kevin Mitnick, computer security expert Tsutomu Shimomura started to receive prank calls that popularized the phrase \"My kung fu is stronger than yours\".\n\n\n*** 1995 ***\nThe movies The Net and Hackers are released.\nThe Canadian ISP dlcwest.com is hacked and website replaced with a graphic and the caption \"You've been hacked MOFO\"\nThe US Secret Service raid 12 and arrest 6 cellular phone hackers in Operation Cybersnare\nFebruary 22: The FBI raids the \"Phone Masters\".\n\n\n*** 1996 ***\nHackers alter Web sites of the United States Department of Justice (August), the CIA (October), and the U.S. Air Force (December).\nCanadian hacker group, Brotherhood, breaks into the Canadian Broadcasting Corporation.\nArizona hacker, John Sabo A.K.A FizzleB/Peanut, was arrested for hacking Canadian ISP dlcwest.com claiming the company was defrauding customers through over billing.\nThe US general accounting office reports that hackers attempted to break into Defense Department computer files some 250,000 times in 1995 alone with a success rate of about 65% and doubling annually.\nCryptovirology is born with the invention of the cryptoviral extortion protocol that would later form the basis of modern ransomware.\n\n\n*** 1997 ***\nA 16-year-old Croatian youth penetrates computers at a U.S. Air Force base in Guam.\nJune: Eligible Receiver 97 tests the American government's readiness against cyberattacks.\nDecember: Information Security publishes first issue.\nFirst high-profile attacks on Microsoft's Windows NT operating system\n\n\n*** 1998 ***\nJanuary: Yahoo! notifies Internet users that anyone visiting its site in the past month might have downloaded a logic bomb and worm planted by hackers claiming a \"logic bomb\" will go off if computer hacker Kevin Mitnick is not released from prison.\nFebruary: The Internet Software Consortium proposes the use of DNSSEC (Domain Name System Security Extensions) to secure DNS servers.\nMay 19: The seven members of the hacker think tank known as L0pht testify in front of the US congressional Government Affairs committee on \"Weak Computer Security in Government\".\nJune: Information Security publishes its first annual Industry Survey, finding that nearly three-quarters of organizations suffered a security incident in the previous year.\nSeptember: Electronic Disturbance Theater, an online political performance-art group, attacks the websites of The Pentagon, Mexican president Ernesto Zedillo, and the Frankfurt Stock Exchange, calling it conceptual art and claiming it to be a protest against the suppression of the Zapatista Army of National Liberation in southern Mexico. EDT uses the FloodNet software to bombard its opponents with access requests.\nOctober: \"U.S. Attorney General Janet Reno announces National Infrastructure Protection Center.\"\n\n\n*** 1999 ***\nSoftware security goes mainstream In the wake of Microsoft's Windows 98 release, 1999 becomes a banner year for security (and hacking). Hundreds of advisories and patches are released in response to newfound (and widely publicized) bugs in Windows and other commercial software products. A host of security software vendors release anti-hacking products for use on home computers.\nU.S. President Bill Clinton announces a $1.46 billion initiative to improve government computer security. The plan would establish a network of intrusion detection monitors for certain federal agencies and encourage the private sector to do the same.\nJanuary 7: The \"Legion of the Underground\" (LoU) declares \"war\" against the governments of Iraq and the People's Republic of China. An international coalition of hackers (including Cult of the Dead Cow, 2600's staff, Phrack's staff, L0pht, and the Chaos Computer Club) issued a joint statement (CRD 990107 - Hackers on planet earth against infowar) condemning the LoU's declaration of war. The LoU responded by withdrawing its declaration.\nMarch: The Melissa worm is released and quickly becomes the most costly malware outbreak to date.\nJuly: Cult of the Dead Cow releases Back Orifice 2000 at DEF CON.\nAugust: Kevin Mitnick, is sentenced to 5 years, of which over 4 years had already been spent pre-trial including 8 months' solitary confinement.\nSeptember: Level Seven Crew hacks the U.S. Embassy in China's website and places racist, anti-government slogans on embassy site in regards to 1998 U.S. embassy bombings.\nSeptember 16: The United States Department of Justice sentences the \"Phone Masters\".\nOctober: American Express introduces the \"Blue\" smart card, the industry's first chip-based credit card in the US.\nNovember 17: A hacker interviewed by Hilly Rose during the radio show Coast to Coast AM (then hosted by Art Bell) exposes a plot by al-Qaeda to derail Amtrak trains. This results in all trains being forcibly stopped over Y2K as a safety measure.\n\n== 2000s ==\n\n\n*** 2000 ***\nMay: The ILOVEYOU worm, also known as VBS/Loveletter and Love Bug worm, is a computer worm written in VBScript. It infected millions of computers worldwide within a few hours of its release. It is considered to be one of the most damaging worms ever. It originated in the Philippines; made by an AMA Computer College student Onel de Guzman for his thesis.\nSeptember: Computer hacker Jonathan James became the first juvenile to serve jail time for hacking.\n\n\n*** 2001 ***\nMicrosoft becomes the prominent victim of a new type of hack that attacks the domain name server. In these denial-of-service attacks, the DNS paths that take users to Microsoft's websites are corrupted.\nFebruary: A Dutch cracker releases the Anna Kournikova virus, initiating a wave of viruses that tempts users to open the infected attachment by promising a sexy picture of the Russian tennis star.\nApril: FBI agents trick two Russian crackers into coming to the U.S. and revealing how they were hacking U.S. banks.\nJuly: Russian programmer Dmitry Sklyarov is arrested at the annual DEF CON hacker convention. He was the first person criminally charged with violating the Digital Millennium Copyright Act (DMCA).\nAugust: Code Red worm, infects tens of thousands of machines.\nThe National Cyber Security Alliance (NCSA) is established in response to the September 11 attacks on the World Trade Center.\n\n\n*** 2002 ***\nJanuary: Bill Gates decrees that Microsoft will secure its products and services, and kicks off a massive internal training and quality control campaign.\nMarch: Gary McKinnon is arrested following unauthorized access to US military and NASA computers.\nMay: Klez.H, a variant of the worm discovered in November 2001, becomes the biggest malware outbreak in terms of machines infected, but causes little monetary damage.\nJune: The Bush administration files a bill to create the Department of Homeland Security, which, among other things, will be responsible for protecting the nation's critical IT infrastructure.\nAugust: Researcher Chris Paget publishes a paper describing \"shatter attacks\", detailing how Windows' unauthenticated messaging system can be used to take over a machine. The paper raises questions about how securable Windows could ever be. It is however largely derided as irrelevant as the vulnerabilities it described are caused by vulnerable applications (placing windows on the desktop with inappropriate privileges) rather than an inherent flaw within the Operating System.\nOctober: The International Information Systems Security Certification Consortium\u2014(ISC)\u00b2\u2014confers its 10,000th CISSP certification.\n\n\n*** 2003 ***\nThe hacktivist group Anonymous was formed.\nMarch: Cult of the Dead Cow and Hacktivismo are given permission by the United States Department of Commerce to export software utilizing strong encryption.\n\n\n*** 2004 ***\nMarch: New Zealand's Government (National Party) website defaced by hacktivist group BlackMask\nJuly: North Korea claims to have trained 500 hackers who successfully crack South Korean, Japanese, and their allies' computer systems.\nOctober: National Cyber Security Awareness Month was launched by the National Cyber Security Alliance and U.S. Department of Homeland Security.\n\n\n*** 2005 ***\nApril 2: Rafael N\u00fa\u00f1ez (aka RaFa), a notorious member of the hacking group World of Hell, is arrested following his arrival at Miami International Airport for breaking into the Defense Information Systems Agency computer system in June 2001.\nSeptember 13: Cameron Lacroix is sentenced to 11 months for gaining access to T-Mobile's network and exploiting Paris Hilton's Sidekick.\nNovember 3: Jeanson James Ancheta, whom prosecutors say was a member of the \"Botmaster Underground\", a group of script kiddies mostly noted for their excessive use of bot attacks and propagating vast amounts of spam, was taken into custody after being lured to FBI offices in Los Angeles.\n\n\n*** 2006 ***\nJanuary: One of the few worms to take after the old form of malware, destruction of data rather than the accumulation of zombie networks to launch attacks from, is discovered. It had various names, including Kama Sutra (used by most media reports), Black Worm, Mywife, Blackmal, Nyxem version D, Kapser, KillAV, Grew and CME-24. The worm would spread through e-mail client address books, and would search for documents and fill them with garbage, instead of deleting them to confuse the user. It would also hit a web page counter when it took control, allowing the programmer who created it as well as the world to track the progress of the worm. It would replace documents with random garbage on the third of every month. It was hyped by the media but actually affected relatively few computers, and was not a real threat for most users.\nMay: Jeanson James Ancheta receives a 57-month prison sentence, and is ordered to pay damages amounting to $15,000 to the Naval Air Warfare Center in China Lake and the Defense Information Systems Agency, for damage done due to DDoS attacks and hacking. Ancheta also had to forfeit his gains to the government, which include $60,000 in cash, a BMW, and computer equipment.\nMay: The largest defacement in Web History as of that time is performed by the Turkish hacker iSKORPiTX who successfully hacked 21,549 websites in one shot.\nJuly: Robert Moore and Edwin Pena were the first people to be charged by U.S. authorities for VoIP hacking. Robert Moore served 2 years in federal prison and was given $152,000 restitution. Once Edwin Pena was caught after fleeing the country, evading authorities for almost 2 years, he was sentenced to 10 years and given $1 million restitution.\nSeptember: Viodentia releases FairUse4WM tool which would remove DRM information off Windows Media Audio (WMA) files downloaded from music services such as Yahoo! Unlimited, Napster, Rhapsody Music and Urge.\n\n\n*** 2007 ***\nMay 17: Estonia recovers from massive denial-of-service attack\nJune 13: FBI Operation Bot Roast finds over 1 million botnet victims\nJune 21: A spear phishing incident at the Office of the Secretary of Defense steals sensitive U.S. defense information, leading to significant changes in identity and message-source verification at OSD.August 11: United Nations website hacked by Indian Hacker Pankaj Kumar Singh.\nNovember 14: Panda Burning Incense which is known by several other names, including Fujacks and Radoppan.T lead to the arrest of eight people in China. Panda Burning Incense was a parasitic virus that infected executable files on a PC. When infected, the icon of the executable file changes to an image of a panda holding three sticks of incense. The arrests were the first for virus writing in China.\n\n\n*** 2008 ***\nJanuary 17: Project Chanology; Anonymous attacks Scientology website servers around the world. Private documents are stolen from Scientology computers and distributed over the Internet.\nMarch 7: Around 20 Chinese hackers claim to have gained access to the world's most sensitive sites, including the Pentagon. They operated from an apartment on a Chinese Island.\nMarch 14: Trend Micro website successfully hacked by Turkish hacker Janizary (aka Utku).\n\n\n*** 2009 ***\nApril 4: Conficker worm infiltrated millions of PCs worldwide including many government-level top-security computer networks.\n\n== 2010s ==\n\n\n*** 2010 ***\nJanuary 12: Operation Aurora Google publicly reveals that it has been on the receiving end of a \"highly sophisticated and targeted attack on our corporate infrastructure originating from China that resulted in the theft of intellectual property from Google\"\nJune: Stuxnet The Stuxnet worm is found by VirusBlokAda. Stuxnet was unusual in that while it spread via Windows computers, its payload targeted just one specific model and type of SCADA systems. It slowly became clear that it was a cyber attack on Iran's nuclear facilities\u2014with most experts believing that Israel was behind it\u2014perhaps with US help.\nDecember 3: The first Malware Conference, MALCON took place in India. Founded by Rajshekhar Murthy, malware coders are invited to showcase their skills at this annual event supported by the Government of India. An advanced malware for Symbian OS is released by hacker A0drul3z.\n\n\n*** 2011 ***\nThe hacker group Lulz Security is formed.\nApril 9: Bank of America website got hacked by a Turkish hacker named JeOPaRDY. An estimated 85,000 credit card numbers and accounts were reported to have been stolen due to the hack. Bank officials say no personal customer bank information is available on that web-page. Investigations are being conducted by the FBI to trace down the incriminated hacker.\nApril 17: An \"external intrusion\" sends the PlayStation Network offline, and compromises personally identifying information (possibly including credit card details) of its 77 million accounts, in what is claimed to be one of the five largest data breaches ever.\nComputer hacker sl1nk releases information of his penetration in the servers of the Department of Defense (DoD), Pentagon, NASA, NSA, US Military, Department of the Navy, Space and Naval Warfare System Command and other UK/US government websites.\nSeptember: Bangladeshi hacker TiGER-M@TE made a world record in defacement history by hacking 700,000 websites in a single shot.\nOctober 16: The YouTube channel of Sesame Street was hacked, streaming pornographic content for about 22 minutes.\nNovember 1: The main phone and Internet networks of the Palestinian territories sustained a hacker attack from multiple locations worldwide.\nNovember 7: The forums for Valve's Steam service were hacked. Redirects for a hacking website, Fkn0wned, appeared on the Steam users' forums, offering \"hacking tutorials and tools, porn, free giveaways and much more.\"\nDecember 14: Five members of the Norwegian hacker group, Noria, were arrested, allegedly suspected for hacking into the email account of the militant extremist Anders Behring Breivik (who perpetrated the 2011 attacks in the country).\n\n\n*** 2012 ***\nA hacker published over 400,000 credit cards online, and threatened Israel to release 1 million credit cards in the future. In response to that incident, an Israeli hacker published over 200 Albanian' credit cards online.\nGottfrid Svartholm Warg, the co-founder of Pirate Bay, was convicted in Denmark of hacking a mainframe computer, what was then Denmark's biggest hacking case.\nJanuary 7: \"Team Appunity\", a group of Norwegian hackers, were arrested for breaking into Norway's largest prostitution website then publishing the user database online.\nFebruary 3: Marriott was hacked by a New Age ideologist, Attila Nemeth who was resisting against the New World Order where he said that corporations are allegedly controlling the world. As a response Marriott reported him to the United States Secret Service.\nFebruary 8: Foxconn is hacked by a hacker group, \"Swagg Security\", releasing a massive amount of data including email and server logins, and even more alarming\u2014bank account credentials of large companies like Apple and Microsoft. Swagg Security stages the attack just as a Foxconn protest ignites against terrible working conditions in southern China.\nMay 4: The websites of several Turkish representative offices of international IT-companies are defaced within the same day by F0RTYS3V3N (Turkish Hacker), including the websites of Google, Yandex, Microsoft, Gmail, MSN, Hotmail, PayPal.\nMay 24: WHMCS is hacked by UGNazi, they claim that the reason for this is because of the illegal sites that are using their software.\nMay 31: MyBB is hacked by newly founded hacker group, UGNazi, the website was defaced for about a day, they claim their reasoning for this was because they were upset that the forum board Hackforums.net uses their software.\nJune 5: The social networking website LinkedIn has been hacked and the passwords for nearly 6.5 million user accounts are stolen by cybercriminals. As a result, a United States grand jury indicted Nikulin and three unnamed co-conspirators on charges of aggravated identity theft and computer intrusion.\nAugust 15: Saudi Aramco is crippled by a cyber warfare attack for months by malware called Shamoon. Considered the biggest hack in history in terms of cost and destructiveness. Carried out by an Iranian attacker group called Cutting Sword of Justice. Iranian hackers retaliated against Stuxnet by releasing Shamoon. The malware destroyed over 35,000 Saudi Aramco computers, affecting business operations for months.\nDecember 17: Computer hacker sl1nk announced that he has hacked a total of 9 countries' SCADA systems. The proof includes 6 countries: France, Norway, Russia, Spain, Sweden and the United States.\n\n\n*** 2013 ***\nThe social networking website Tumblr is attacked by hackers. Consequently, 65,469,298 unique emails and passwords were leaked from Tumblr. The data breach's legitimacy is confirmed by computer security researcher Troy Hunt.\nAugust: Yahoo! data breaches occurred.  More than 3 billion users data are being leaked.\n\n\n*** 2014 ***\nFebruary 7: The bitcoin exchange Mt. Gox filed for bankruptcy after $460 million was apparently stolen by hackers due to \"weaknesses in [their] system\" and another $27.4 million went missing from its bank accounts.\nOctober: The White House computer system was hacked. It was said that the FBI, the Secret Service, and other U.S. intelligence agencies categorized the attacks \"among the most sophisticated attacks ever launched against U.S. government systems.\"\nNovember 24: In response to the release of the film The Interview, the servers of Sony Pictures are hacked by a hacker group calling itself \"Guardian of Peace\".\nNovember 28: The website of the Philippine telecommunications company Globe Telecom was hacked in response to the poor internet service they are distributing.\n\n\n*** 2015 ***\nJune: the records of 21.5 million people, including social security numbers, dates of birth, addresses, fingerprints, and security clearance-related information, are stolen from the United States Office of Personnel Management (OPM). Most of the victims are employees of the United States government and unsuccessful applicants to it. The Wall Street Journal and The Washington Post report that government sources believe the hacker is the government of China.\nJuly: The servers of extramarital affairs website Ashley Madison were breached.\n\n\n*** 2016 ***\nFebruary: The 2016 Bangladesh Bank heist attempted to steal US$951 million from a Bangladesh Bank, and succeeded in getting $101 million\u2014although some of this was later recovered.\nJuly 22: WikiLeaks published the documents from the 2016 Democratic National Committee email leak.\nJuly 29: a group suspected coming from China launched hacker attacks on the website of Vietnam Airlines.\nAugust 13: The Shadow Brokers (TSB) started publishing several leaks containing hacking tools from the National Security Agency (NSA), including several zero-day exploits. Ongoing leaks until April 2017 (The Shadow Brokers)\nSeptember: Hacker Ardit Ferizi is sentenced to 20 years in prison after being arrested for hacking U.S. servers and passing the leaked information to members of ISIL terrorist group back in 2015.\nOctober: The 2016 Dyn cyberattack is being conducted with a botnet consisting of IOTs infected with Mirai by the hacktivist groups SpainSquad, Anonymous, and New World Hackers, reportedly in retaliation for Ecuador's rescinding Internet access to WikiLeaks founder Julian Assange at their embassy in London, where he has been granted asylum.\nLate 2016: Hackers steal international personal user data from the company Uber, including phone numbers, email addresses, and names, of 57 million people and 600,000 driver's license numbers of drivers for the company. Uber's GitHub account was accessed through Amazon's cloud-based service. Uber paid the hackers $100,000 for assurances the data was destroyed.\nDecember 2016: Yahoo! data breaches reported and affected more than 1 billion users.  The data leakage includes user names, email addresses, telephone numbers, encrypted or unencrypted security questions and answers, dates of birth, and hashed passwords\n\n\n*** 2017 ***\nApril: A hacker group calling itself \"The Dark Overlord\" posted unreleased episodes of Orange Is the New Black TV series online after failing to extort the online entertainment company Netflix.\nMay: WannaCry ransomware attack started on Friday, May 12, 2017, and has been described as unprecedented in scale, infecting more than 230,000 computers in over 150 countries. A hacked unreleased Disney film is held for ransom, to be paid in Bitcoin.\nMay: 25,000 digital photos and ID scans relating to patients of the Grozio Chirurgija cosmetic surgery clinic in Lithuania were obtained and published without consent by an unknown group demanding ransoms. Thousands of clients from more than 60 countries were affected. The breach brought attention to weaknesses in Lithuania's information security.\nJune: 2017 Petya cyberattack.\nJune: TRITON (TRISIS), a malware framework designed to reprogram Triconex safety instrumented systems (SIS) of industrial control systems (ICS), discovered in Saudi Arabian Petrochemical plant.\nAugust: Hackers demand $7.5 million in Bitcoin to stop pre-releasing HBO shows and scripts, including Ballers, Room 104 and Game of Thrones.\nMay\u2013July 2017: The Equifax breach.\nSeptember 2017: Deloitte breach.\nDecember: Mecklenburg County, North Carolina computer systems were hacked. They did not pay the ransom.\n\n\n*** 2018 ***\nMarch: Computer systems in the city of Atlanta, in the U.S. state of Georgia, are seized by hackers with ransomware. They did not pay the ransom, and two Iranians were indicted by the FBI on cyber crime charges for the breach.\nThe town of Wasaga Beach in Ontario, Canada computer systems are seized by hackers with ransomware.\nSeptember: Facebook was hacked, exposing to hackers the personal information of an estimated 30 million Facebook users (initially estimated at 50 million) when the hackers \"stole\" the \"access tokens\" of 400,000 Facebook users. The information accessible to the hackers included users' email addresses, phone numbers, their lists of friends, Groups they are members of, users' search information, posts on their timelines, and names of recent Messenger conversations.\nOctober: West Haven, Connecticut USA computer systems are seized by hackers with ransomware, they paid $2,000 in ransom.\nNovember:\nThe first U.S. indictment of individual people for ransomware attacks occurs. The U.S. Justice Department indicted two men Faramarz Shahi Savandi and Mohammad Mehdi Shah Mansouri who allegedly used the SamSam ransomware for extortion, netting them more than $6 million in ransom payments. The companies infected with the ransomware included Allscripts, Medstar Health, and Hollywood Presbyterian Medical Center. Altogether, the attacks caused victims to lose more than $30 million, in addition to the ransom payments.\nMarriott disclosed that its Starwood Hotel brand had been subject to a security breach.\n\n\n*** 2019 ***\nMarch: Jackson County computer systems in the U.S. state of Georgia are seized by hackers with ransomware, they paid $400,000 in ransom. The city of Albany in the U.S. state of New York experiences a ransomware cyber attack.\nApril: Computer systems in the city of Augusta, in the U.S. state of Maine, are seized by hackers using ransomware. The City of Greenville (North Carolina)'s computer systems are seized by hackers using ransomware known as RobbinHood. Imperial County, in the U.S. state of California, computer systems are seized by hackers using Ryuk ransomware.\nMay: computer systems belonging to the City of Baltimore are seized by hackers using ransomware known as RobbinHood that encrypts files with a \"file-locking\" virus, as well as the tool EternalBlue.\nJune: The city of Riviera Beach, Florida paid roughly $600,000 ransom in Bitcoin to hackers who seized their computers using ransomware. Hackers stole 18 hours of unreleased music from the band Radiohead demanding $150,000 ransom. Radiohead released the music to the public anyway and did not pay the ransom.\nNovember: The Anonymous hacktivist collective announced that they have hacked into four Chinese computer databases and donated those to data breach indexing/notification service vigilante.pw. The hack was conducted in order to support the 2019 Hong Kong protests, amidst the Hong Kong police's siege of the city's Polytechnic University. They also brought up a possible peace plan first proposed by a professor at Inha University in hopes of having the Korean reunification and the five key demands of the Hong Kong protest being fulfilled at once.\n\n== 2020s ==\n\n\n*** 2020 ***\nFebruary: Anonymous hacked the United Nations website and created a page for Taiwan, a country which had not had a seat at the UN since 1971. The hacked page featured the Flag of Taiwan, the KMT emblem, a Taiwan Independence flag, the Anonymous logo, embedded YouTube videos such as the Taiwanese national anthem and the closing score for the 2019 film Avengers: Endgame titled \"It's Been a Long, Long Time\", and a caption. The hacked server belonged to the United Nations Department of Economic and Social Affairs.\nMay: Anonymous declared a large hack on May 28, three days after the murder of George Floyd. An individual claiming to represent Anonymous stated that \"We are Legion. We do not forgive. We do not forget. Expect us.\" in a now-deleted video. Anonymous addressed police brutality and said they \"will be exposing [their] many crimes to the world\". It was suspected that Anonymous were the cause for the downtime and public suspension of the Minneapolis Police Department website and its parent site, the website of the City of Minneapolis.\nMay: Indian national Shubham Upadhyay posed as Superintendent of Police and, using social engineering, used a free caller identification app to call up the in-charge of the Kotwali police station, K. K. Gupta, in order to threaten him to get his phone repaired amidst the COVID-19 lockdown. The attempt was foiled.\nJune: Anonymous claimed responsibility for stealing and leaking a trove of documents collectively nicknamed 'BlueLeaks'. The 269-gigabyte collection was published by a leak-focused activist group known as Distributed Denial of Secrets. Furthermore, the collective took down Atlanta Police Department's website via DDoS, and defaced websites such as a Filipino governmental webpage and that of Brookhaven National Labs. They expressed support for Julian Assange and press freedom, while briefly \"taking a swing\" against Facebook, Reddit and Wikipedia for having 'engaged in shady practices behind our prying eyes'. In the case of Reddit, they posted a link to a court document describing the possible involvement of a moderator of a large traffic subreddit (/r/news) in an online harassment-related case.\nJune: The Buffalo, NY police department's website was supposedly hacked by Anonymous. While the website was up and running after a few minutes, Anonymous tweeted again on Twitter urging that it be taken down. A few minutes later, the Buffalo NY website was brought down again. They also hacked Chicago police radios to play N.W.A's \"Fuck tha Police\".\nJune: Over 1,000 accounts on multiplayer online game Roblox were hacked to display that they supported U.S. President Donald Trump.\nJuly: The 2020 Twitter bitcoin scam occurred.\nJuly: User credentials of writing website Wattpad were stolen and leaked on a hacker forum. The database contained over 200 million records.\nAugust: A large number of subreddits were hacked to post materials endorsing Donald Trump. The affected subreddits included r/BlackPeopleTwitter, r/3amJokes, r/NFL, r/PhotoshopBattles. An entity with the name of \"calvin goh and Melvern\" had purportedly claimed responsibility for the massive defacement, and also made violent threats against a Chinese embassy.\nAugust: The US Air Force's Hack-A-Sat event was hosted at DEF CON's virtual conference where groups such as Poland Can Into Space, FluxRepeatRocket, AddVulcan, Samurai, Solar Wine, PFS, 15 Fitty Tree, and 1064CBread competed in order to control a satellite in space. The Poland Can Into Space team stood out for having successfully manipulated a satellite to take a picture of the Moon.\nAugust: The website of Belarusian company \"BrestTorgTeknika\" was defaced by a hacker nicknaming herself \"Queen Elsa\", in order to support the 2020\u201321 Belarusian protests. In it, the page hacker exclaimed \"Get Iced Iced already\" and \"Free Belarus, revolution of our times\" with the latter alluding to the famous slogan used by 2019 Hong Kong protests. The results of the hack were then announced on Reddit's /r/Belarus subreddit by a poster under the username \"Socookre\".\nAugust: Multiple DDoS attacks forced New Zealand's stock market to temporarily shut down.\nSeptember: The first suspected death from a cyberattack was reported after cybercriminals hit a hospital in D\u00fcsseldorf, Germany with ransomware.\nOctober: A wave of botnet-coordinated ransomware attacks against hospital infrastructure occurred in the United States, identified as associated with Russia.  State security officials and American corporate security officers were concerned that these attacks might be a prelude to hacking of election infrastructure during the elections of the subsequent month, like similar incidents during the 2016 United States elections and other attacks; there was, however, no evidence that they performed attacks on election infrastructure in 2020.\nDecember: A supply chain attack targeting upstream dependencies from Texas IT service provider \"SolarWinds\" results in serious, wide-ranging security breaches at the U.S. Treasury and Commerce departments. White House officials did not immediately publicly identify a culprit; Reuters, citing sources \"familiar with the investigation\", pointed toward the Russian government. An official statement shared by Senate Finance Committee ranking member, Ron Wyden said: \"Hackers broke into systems in the Departmental Offices division of Treasury, home to the department\u2019s highest-ranking officials.\"\nDecember: A bomb threat posted from a Twitter account that was seemingly hacked by persons with the aliases of \"Omnipotent\" and \"choonkeat\",  against the Aeroflot Flight 102, a passenger flight with the plane tail number of VQ-BIL coming from Moscow to New York City. Due to that, a runway of New York's John F. Kennedy International Airport was temporarily closed and resulted in the delay of Aeroflot Flight 103, a return flight back to Moscow.\nDecember: The Anonymous group initiated 'Christmas gift' defacements against multiple Russian portals including a municipal website in Tomsk and that of a regional football club. Inside the defacements, they made multiple references such as Russian opposition activist Alexei Navalny, freedom protests in Thailand and Belarus, and opposition to the Chinese Communist Party. They also held a mock award based on an event on the game platform Roblox that was called \"RB Battles\" where YouTubers Tanqr and KreekCraft, the winner and the runner up of the actual game event, were compared to both Taiwan and New Zealand respectively due to the latter's reportedly stellar performance in fighting the COVID-19 pandemic.\n\n\n*** 2021 ***\nJanuary: Microsoft Exchange Server data breach\nFebruary: Anonymous announced cyber-attacks of at least five Malaysian websites. As a result, eleven individuals were nabbed as suspects.\nFebruary: Hackers including those with names of \"\u5f20\u536b\u80fd utoyo\" and \"full_discl0sure\" hijacked an events website Aucklife in order to craft a phony bomb threat against the Chinese consulate in Auckland, New Zealand, and also a similar facility in Sydney, Australia. Their motive was a punitive response against China due to COVID-19. As a result, a physical search was conducted at the consulate by New Zealand's Police Specialist Search Group while Aucklife owner Hailey Newton had since regained her access to the website. Wellington-based cybersecurity consultant Adam Boileau remarked that the hack isn't 'highly technical'.\nFebruary: The group \"Myanmar Hackers\" attacked several websites belonging to Myanmar government agencies such as the Central Bank of Myanmar and the military-run Tatmadaw True News Information Team. The group also targeted the Directorate of Investment and Company Administration, Trade Department, Customs Department, Ministry of Commerce, Myawady TV and state-owned broadcaster Myanmar Radio and Television and some private media outlets. A computer technician in Yangon found that the hacks were denial-of-service attacks, while the group's motive is to protest the 2021 Myanmar coup.\nApril: Over 500 million Facebook users' personal info\u2014including info on 32 million in the United States\u2014was discovered posted on a hackers' website, though Facebook claimed that the information was from a 2019 hack, and that the company had already taken mitigation measures; however, the company declined to say whether it had notified the affected users of the breach.\nApril: The Ivanti Pulse Connect Secure data breach of unauthorized access to the networks of high-value targets since at least June 2020 via CVE-2021-22893 across the U.S. and some E.U. nations due to their use of vulnerable, proprietary software was reported.\nMay: Operation of the U.S. Colonial Pipeline is interrupted by a ransomware cyber operation.\nMay: On 21 May 2021 Air India was subjected to a cyberattack wherein the personal details of about 4.5 million customers around the world were compromised including passport, credit card details, birth dates, name and ticket information.\nJuly: On 22 July 2021 Saudi Aramco data were leaked by a third-party contractor and demanded $50 million ransom from Saudi Aramco. Saudi Aramco confirmed the incident after a hacker claimed on dark web that he had stolen 1 terabyte of data about location of oil refineries and employees data in a post that was posted on June 23.\nAugust: T-Mobile reported that data files with information from about 40 million former or prospective T-Mobile customers, including first and last names, date of birth, SSN, and driver's license/ID information, were compromised.\nSeptember and October: 2021 Epik data breach. Anonymous obtained and released over 400 gigabytes of data from the domain registrar and web hosting company Epik. The data was shared in three releases between September 13 and October 4. The first release included domain purchase and transfer details, account credentials and logins, payment history, employee emails, and unidentified private keys. The hackers claimed they had obtained \"a decade's worth of data\", including all customer data and records for all domains ever hosted or registered through the company, and which included poorly encrypted passwords and other sensitive data stored in plaintext. The second release consisted of bootable disk images and API keys for third-party services used by Epik; the third contained additional disk images and an archive of data belonging to the Republican Party of Texas, who are an Epik customer.\nOctober: On October 6, 2021, an anonymous 4chan reportedly hacked and leaked the source code of Twitch, as well as information on how much the streaming service paid almost 2.4 million streamers since August 2019. Source code from almost 6,000 GitHub repositories was leaked, and the 4chan user said it was \"part one\" of a much larger release.\nNovember and December: On November 24th, Chen Zhaojun of Alibaba's Cloud Security Team reported a zero-day vulnerability (later dubbed Log4Shell) involving the use of arbitrary code execution in the ubiquitous Java logging framework software Log4j. The report was privately disclosed to project developers of Log4j, a team at The Apache Software Foundation, on November 24. On December 8, Zhaojun contacted the developers again detailing how the vulnerability was being discussed in public security chat rooms, was already known by some security researchers, and pleaded that the team expedite the solution to the vulnerability in the official release version of Log4j. Early exploitations were noticed on Minecraft servers on December 9; however, forensic analysis indicates that Log4Shell may have been exploited as early as December 1 or 2nd. Due to the ubiquity of devices with the Log4j software (hundreds of millions) and the simplicity in executing the vulnerability, it is considered to be arguably one of the largest and most critical vulnerabilities ever. Yet, big names in security hacking helped in regaining control over server, like Graham Ivan Clark, and Elhamy A. Elsebaey.  A portion of the vulnerability was fixed in a patch distributed on December 6, three days before the vulnerability was publicly disclosed on December 9.\n\n\n*** 2022 ***\nFebruary: The German Chaos Computer Club has reported more than fifty data leaks. Government institutions and companies from various business sectors were affected. In total, the researchers had access to over 6.4 million personal data records as well as terabytes of log data and source code.\nMarch: The website of a local newspaper in Sumy, Ukraine was hacked by a person identifying themselves as \"zehang\u9648\". They claimed that they and other individuals \"P_srim_asap\", \"Mrthanthomthebomber\", \"mister-handsomekai\" and \"RiansJohnson\" had placed bombs at Chinese and Russian diplomatic facilities in Malaysia with the former containing a photo of Huanan Seafood Wholesale Market, Hong Kong's International Finance Centre and MTR Airport Station, and the headquarters office of American game company ROBLOX. Besides that, they claimed responsibility for the delivery of an envelope containing white powders against the Russian embassy in Canberra, Australia. As a result the area surrounding the embassy was briefly cordoned off.\nMarch: As a response to the 2022 Russian invasion of Ukraine, Anonymous performed many attacks against computer systems in Russia. Most notably, Anonymous committed a cyberattack against Roskomnadzor.\nMarch: On 23 March 2022, hackers compromised the Ronin Network, stealing approximately US$620 million in Ether and USDC. A total of 173,600 Ether and 25.5 million USDC tokens were stolen in two transactions.  It took the company six days to notice the hack. The hack currently sits as the largest-ever breach in the cryptocurrency sector by dollar value. It further damaged the value of SLP. On 8 April 2022, Sky Mavis said it expected it would be able to recover some of the funds, but it would take several years. The company raised additional venture capital and reimbursed all users affected in the hack. On 14 April 2022, the FBI issued a statement that the Lazarus Group and APT38, which are North Korean state-sponsored hacker groups, were responsible for the theft. Accordingly, the US Treasury has sanctioned the cryptocurrency address. Some of the cryptocurrency has been laundered through a cryptocurrency tumbler known as \"Tornado Cash\".\nApril: Anonymous hacked Russian companies Aerogas, Forest, and Petrovsky Fort. From there they leaked around 437,500 emails which they donated to non-profit whistleblower organization Distributed Denial of Secrets. Furthermore, they leaked 446 GB of data from Russian Ministry of Culture.\nApril: On April 19, Gij\u00f3n City Council (Spain) was attacked by the GERVASIA computer virus and suffered data hijacking.\nMay: Network Battalion 65 (NB65), a hacktivist group affiliated with Anonymous, has reportedly hacked Russian payment processor Qiwi. A total of 10.5 terabytes of data including transaction records and customers' credit cards had been exfiltrated. They further infected Qiwi with ransomwares and threatened to release more customer records.\nMay: During the Victory Day in Russia, anti-war messages were inserted into Russian TV schedules including that of Russia-1, Channel 1, and NTV-Plus. One of the messages were \"On your hands is the blood of thousands of Ukrainians and their hundreds of murdered children. TV and the authorities are lying. No to war.\"\nJune: A hacker on the Breach Forums claimed to have leaked more than 1 billion people's personal records from the Shanghai National Police Database.\nAugust: During the visit of Speaker of the United States House of Representatives Nancy Pelosi to Taiwan, the website of Taiwan's Office of the President website was affected by a distributed denial of service attack. Anonymous then hacked into a China Heilongjiang province's Society Scientific Community Federation website and a Chinese gasoline generator factory\u2019s website.\n\nWhen did the first alleged death from a cyberattack occur, and where did it happen?",
    "context": "",
    "output": "A: The first alleged death from a cyberattack occurred in September 2019 in Germany, after cybercriminals hit a hospital in D\u00fcsseldorf with ransomware.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When did the first alleged death from a cyberattack occur, and where did it happen?",
      "answer": "The first alleged death from a cyberattack occurred in September 2019 in Germany, after cybercriminals hit a hospital in D\u00fcsseldorf with ransomware.",
      "context": "List of security hacking incidents\n\n==Introduction==\nThe list of security hacking incidents covers important or noteworthy events in the history of security hacking and cracking.\n\n== 1900 ==\n\n\n*** 1903 ***\nMagician and inventor Nevil Maskelyne disrupts John Ambrose Fleming's public demonstration of Guglielmo Marconi's purportedly secure wireless telegraphy technology, sending insulting Morse code messages through the auditorium's projector.\n\n== 1930s ==\n\n\n*** 1932 ***\nPolish cryptologists Marian Rejewski, Henryk Zygalski and Jerzy R\u00f3\u017cycki broke the Enigma machine code.\n\n\n*** 1939 ***\nAlan Turing, Gordon Welchman and Harold Keen worked together to develop the Bombe (on the basis of Rejewski's works on Bomba). The Enigma machine's use of a reliably small key space makes it vulnerable to brute force.\n\n== 1940s ==\n\n\n*** 1943 ***\nRen\u00e9 Carmille, comptroller general of the Vichy French Army, hacked the punched card system used by the Nazis to locate Jews.\n\n\n*** 1949 ***\nThe theory that underlies computer viruses was first made public in 1949, when computer pioneer John von Neumann presented a paper titled \"Theory and Organization of Complicated Automata\". In the paper von Neumann speculated that computer programs could reproduce themselves.\n\n== 1950s ==\n\n\n*** 1955 ***\nAt MIT, \"hack\" first came to mean fussing with machines. The minutes of an April 1955 meeting of the Tech Model Railroad Club state that \"Mr. Eccles requests that anyone working or hacking on the electrical system turn the power off to avoid fuse blowing.\"\n\n\n*** 1957 ***\nJoe \"Joybubbles\" Engressia, a blind seven-year-old boy with perfect pitch, discovered that whistling the fourth E above middle C (a frequency of 2600 Hz) would interfere with AT&T's automated telephone systems, thereby inadvertently opening the door for phreaking.\n\n== 1960s ==\nVarious phreaking boxes are used to interact with automated telephone systems.\n\n\n*** 1963 ***\nThe first ever reference to malicious hacking is 'telephone hackers' in MIT's student newspaper, The Tech of hackers tying up the lines with Harvard, configuring the PDP-1 to make free calls, war dialing and accumulating large phone bills.\n\n\n*** 1965 ***\nWilliam D. Mathews from MIT found a vulnerability in a CTSS running on an IBM 7094. The standard text editor on the system was designed to be used by one user at a time, working in one directory, and so created a temporary file with a constant name for all instantiations of the editor. The flaw was discovered when two system programmers were editing at the same time and the temporary files for the message-of-the day and the password file became swapped, causing the contents of the system CTSS password file to display to any user logging into the system.\n\n\n*** 1967 ***\nThe first known incidence of network penetration hacking took place when members of a computer club at a suburban Chicago area high school were provided access to IBM's APL network. In the Fall of 1967, IBM (through Science Research Associates) approached Evanston Township High School with the offer of four 2741 Selectric teletypewriter based terminals with dial-up modem connectivity to an experimental computer system which implemented an early version of the APL programming language. The APL network system was structured in Workspaces which were assigned to various clients using the system. Working independently, the students quickly learned the language and the system. They were free to explore the system, often using existing code available in public Workspaces as models for their own creations. Eventually, curiosity drove the students to explore the system's wider context. This first informal network penetration effort was later acknowledged as helping harden the security of one of the first publicly accessible networks:Science Research Associates undertook to write a full APL system for the IBM 1500. They modeled their system after APL/360, which had by that time been developed and seen substantial use inside of IBM, using code borrowed from MAT/1500 where possible. In their documentation they acknowledge their gratitude to \"a number of high school students for their compulsion to bomb the system\". This was an early example of a kind of sportive, but very effective, debugging that was often repeated in the evolution of APL systems.\n\n== 1970s ==\n\n\n*** 1971 ***\nJohn T. Draper (later nicknamed Captain Crunch), his friend Joe Engressia (also known as Joybubbles), and blue box phone phreaking hit the news with an Esquire magazine feature story.\n\n\n*** 1979 ***\nKevin Mitnick breaks into his first major computer system, the Ark, the computer system Digital Equipment Corporation (DEC) used for developing their RSTS/E operating system software.\n\n== 1980s ==\n\n\n*** 1980 ***\nThe FBI investigates a breach of security at National CSS (NCSS). The New York Times, reporting on the incident in 1981, describes hackers astechnical experts; skilled, often young, computer programmers, who almost whimsically probe the defenses of a computer system, searching out the limits and the possibilities of the machine. Despite their seemingly subversive role, hackers are a recognized asset in the computer industry, often highly prizedThe newspaper describes white hat activities as part of a \"mischievous but perversely positive 'hacker' tradition\". When a National CSS employee revealed the existence of his password cracker, which he had used on customer accounts, the company chastised him not for writing the software but for not disclosing it sooner. The letter of reprimand stated that \"The Company realizes the benefit to NCSS and in fact encourages the efforts of employees to identify security weaknesses to the VP, the directory, and other sensitive software in files\".\n\n\n*** 1981 ***\nChaos Computer Club forms in Germany.\nIan Murphy aka Captain Zap, was the first cracker to be tried and convicted as a felon. Murphy broke into AT&T's computers in 1981 and changed the internal clocks that metered billing rates. People were getting late-night discount rates when they called at midday. Of course, the bargain-seekers who waited until midnight to call long distance were hit with high bills.\n\n\n*** 1983 ***\nThe 414s break into 60 computer systems at institutions ranging from the Los Alamos National Laboratory to Manhattan's Memorial Sloan-Kettering Cancer Center. The incident appeared as the cover story of Newsweek with the title \"Beware: Hackers at play\". As a result, the U.S. House of Representatives held hearings on computer security and passed several laws.\nThe group KILOBAUD is formed in February, kicking off a series of other hacker groups which form soon after.\nThe movie WarGames introduces the wider public to the phenomenon of hacking and creates a degree of mass paranoia of hackers and their supposed abilities to bring the world to a screeching halt by launching nuclear ICBMs.\nThe U.S. House of Representatives begins hearings on computer security hacking.\nIn his Turing Award lecture, Ken Thompson mentions \"hacking\" and describes a security exploit that he calls a \"Trojan horse\".\n\n\n*** 1984 ***\nSomeone calling himself Lex Luthor founds the Legion of Doom. Named after a Saturday morning cartoon, the LOD had the reputation of attracting \"the best of the best\"\u2014until one of the most talented members called Phiber Optik feuded with Legion of Doomer Erik Bloodaxe and got 'tossed out of the clubhouse'. Phiber's friends formed a rival group, the Masters of Deception.\nThe Comprehensive Crime Control Act gives the Secret Service jurisdiction over computer fraud.\nCult of the Dead Cow forms in Lubbock, Texas, and begins publishing its ezine.\nThe hacker magazine 2600 begins regular publication, right when TAP was putting out its final issue. The editor of 2600, \"Emmanuel Goldstein\" (whose real name is Eric Corley), takes his handle from the leader of the resistance in George Orwell's 1984. The publication provides tips for would-be hackers and phone phreaks, as well as commentary on the hacker issues of the day. Today, copies of 2600 are sold at most large retail bookstores.\nThe Chaos Communication Congress, the annual European hacker conference organized by the Chaos Computer Club, is held in Hamburg, Germany.\nWilliam Gibson's groundbreaking science fiction novel Neuromancer, about \"Case\", a futuristic computer hacker, is published. Considered the first major cyberpunk novel, it brought into hacker jargon such terms as \"cyberspace\", \"the matrix\", \"simstim\", and \"ICE\".\n\n\n*** 1985 ***\nKILOBAUD is re-organized into The P.H.I.R.M. and begins sysopping hundreds of BBSs throughout the United States, Canada, and Europe.\nThe online 'zine Phrack is established.\nThe Hacker's Handbook is published in the UK.\nThe FBI, Secret Service, Middlesex County NJ Prosecutor's Office and various local law enforcement agencies execute seven search warrants concurrently across New Jersey on July 12, 1985, seizing equipment from BBS operators and users alike for \"complicity in computer theft\", under a newly passed, and yet untested criminal statute. This is famously known as the Private Sector Bust, or the 2600 BBS Seizure, and implicated the Private Sector BBS sysop, Store Manager (also a BBS sysop), Beowulf, Red Barchetta, The Vampire, the NJ Hack Shack BBS sysop, and the Treasure Chest BBS sysop.\n\n\n*** 1986 ***\nAfter more and more break-ins to government and corporate computers, Congress passes the Computer Fraud and Abuse Act, which makes it a crime to break into computer systems. The law, however, does not cover juveniles.\nRobert Schifreen and Stephen Gold are convicted of accessing the Telecom Gold account belonging to the Duke of Edinburgh under the Forgery and Counterfeiting Act 1981 in the United Kingdom, the first conviction for illegally accessing a computer system. On appeal, the conviction is overturned as hacking is not within the legal definition of forgery.\nArrest of a hacker who calls himself The Mentor. He published a now-famous treatise shortly after his arrest that came to be known as the Hacker Manifesto in the e-zine Phrack. This still serves as the most famous piece of hacker literature and is frequently used to illustrate the mindset of hackers.\nAstronomer Clifford Stoll plays a pivotal role in tracking down hacker Markus Hess, events later covered in Stoll's 1990 book The Cuckoo's Egg.\n\n\n*** 1987 ***\nThe Christmas Tree EXEC \"worm\" causes major disruption to the VNET, BITNET and EARN networks.\n\n\n*** 1988 ***\nThe Morris Worm. Graduate student Robert T. Morris, Jr. of Cornell University launches a worm on the government's ARPAnet (precursor to the Internet). The worm spreads to 6,000 networked computers, clogging government and university systems. Robert Morris is dismissed from Cornell, sentenced to three years' probation, and fined $10,000.\nFirst National Bank of Chicago is the victim of $70 million computer theft.\nThe Computer Emergency Response Team (CERT) is created by DARPA to address network security.\nThe Father Christmas (computer worm) spreads over DECnet networks.\n\n\n*** 1989 ***\nJude Milhon (aka St Jude) and R. U. Sirius launch MONDO 2000, a major '90s tech-lifestyle magazine, in Berkeley, California.\nThe politically motivated WANK worm spreads over DECnet.\nDutch magazine Hack-Tic begins.\nThe Cuckoo's Egg by Clifford Stoll is published.\nThe detection of AIDS (Trojan horse) is the first instance of a ransomware detection.\n\n== 1990s ==\n\n\n*** 1990 ***\nOperation Sundevil introduced. After a prolonged sting investigation, Secret Service agents swoop down on organizers and prominent members of BBSs in 14 U.S. cities including the Legion of Doom, conducting early-morning raids and arrests. The arrests involve and are aimed at cracking down on credit-card theft and telephone and wire fraud. The result is a breakdown in the hacking community, with members informing on each other in exchange for immunity. The offices of Steve Jackson Games are also raided, and the role-playing sourcebook GURPS Cyberpunk is confiscated, possibly because the government fears it is a \"handbook for computer crime\". Legal battles arise that prompt the formation of the Electronic Frontier Foundation, including the trial of Knight Lightning.\nAustralian federal police tracking Realm members Phoenix, Electron and Nom are the first in the world to use a remote data intercept to gain evidence for a computer crime prosecution.\nThe Computer Misuse Act 1990 is passed in the United Kingdom, criminalising any unauthorised access to computer systems.\n\n\n*** 1992 ***\nRelease of the movie Sneakers, in which security experts are blackmailed into stealing a universal decoder for encryption systems.\nOne of the first ISPs, MindVox, opens to the public.\nBulgarian virus writer Dark Avenger wrote 1260, the first known use of polymorphic code, used to circumvent the type of pattern recognition used by antivirus software, and nowadays also intrusion detection systems.\nPublication of a hacking instruction manual for penetrating TRW credit reporting agency by Infinite Possibilities Society (IPS) gets Dr. Ripco, the sysop of Ripco BBS mentioned in the IPS manual, arrested by the United States Secret Service.\n\n\n*** 1993 ***\nThe first DEF CON hacking conference takes place in Las Vegas. The conference is meant to be a one-time party to say good-bye to BBSs (now replaced by the Web), but the gathering was so popular it became an annual event.\nAOL gives its users access to Usenet, precipitating Eternal September.\n\n\n*** 1994 ***\nSummer: Russian crackers siphon $10 million from Citibank and transfer the money to bank accounts around the world. Vladimir Levin, the 30-year-old ringleader, used his work laptop after hours to transfer the funds to accounts in Finland and Israel. Levin stands trial in the United States and is sentenced to three years in prison. Authorities recover all but $400,000 of the stolen money.\nHackers adapt to emergence of the World Wide Web quickly, moving all their how-to information and hacking programs from the old BBSs to new hacker web sites.\nAOHell is released, a freeware application that allows a burgeoning community of unskilled script kiddies to wreak havoc on America Online. For days, hundreds of thousands of AOL users find their mailboxes flooded with multi-megabyte email bombs and their chat rooms disrupted with spam messages.\nDecember 27: After experiencing an IP spoofing attack by Kevin Mitnick, computer security expert Tsutomu Shimomura started to receive prank calls that popularized the phrase \"My kung fu is stronger than yours\".\n\n\n*** 1995 ***\nThe movies The Net and Hackers are released.\nThe Canadian ISP dlcwest.com is hacked and website replaced with a graphic and the caption \"You've been hacked MOFO\"\nThe US Secret Service raid 12 and arrest 6 cellular phone hackers in Operation Cybersnare\nFebruary 22: The FBI raids the \"Phone Masters\".\n\n\n*** 1996 ***\nHackers alter Web sites of the United States Department of Justice (August), the CIA (October), and the U.S. Air Force (December).\nCanadian hacker group, Brotherhood, breaks into the Canadian Broadcasting Corporation.\nArizona hacker, John Sabo A.K.A FizzleB/Peanut, was arrested for hacking Canadian ISP dlcwest.com claiming the company was defrauding customers through over billing.\nThe US general accounting office reports that hackers attempted to break into Defense Department computer files some 250,000 times in 1995 alone with a success rate of about 65% and doubling annually.\nCryptovirology is born with the invention of the cryptoviral extortion protocol that would later form the basis of modern ransomware.\n\n\n*** 1997 ***\nA 16-year-old Croatian youth penetrates computers at a U.S. Air Force base in Guam.\nJune: Eligible Receiver 97 tests the American government's readiness against cyberattacks.\nDecember: Information Security publishes first issue.\nFirst high-profile attacks on Microsoft's Windows NT operating system\n\n\n*** 1998 ***\nJanuary: Yahoo! notifies Internet users that anyone visiting its site in the past month might have downloaded a logic bomb and worm planted by hackers claiming a \"logic bomb\" will go off if computer hacker Kevin Mitnick is not released from prison.\nFebruary: The Internet Software Consortium proposes the use of DNSSEC (Domain Name System Security Extensions) to secure DNS servers.\nMay 19: The seven members of the hacker think tank known as L0pht testify in front of the US congressional Government Affairs committee on \"Weak Computer Security in Government\".\nJune: Information Security publishes its first annual Industry Survey, finding that nearly three-quarters of organizations suffered a security incident in the previous year.\nSeptember: Electronic Disturbance Theater, an online political performance-art group, attacks the websites of The Pentagon, Mexican president Ernesto Zedillo, and the Frankfurt Stock Exchange, calling it conceptual art and claiming it to be a protest against the suppression of the Zapatista Army of National Liberation in southern Mexico. EDT uses the FloodNet software to bombard its opponents with access requests.\nOctober: \"U.S. Attorney General Janet Reno announces National Infrastructure Protection Center.\"\n\n\n*** 1999 ***\nSoftware security goes mainstream In the wake of Microsoft's Windows 98 release, 1999 becomes a banner year for security (and hacking). Hundreds of advisories and patches are released in response to newfound (and widely publicized) bugs in Windows and other commercial software products. A host of security software vendors release anti-hacking products for use on home computers.\nU.S. President Bill Clinton announces a $1.46 billion initiative to improve government computer security. The plan would establish a network of intrusion detection monitors for certain federal agencies and encourage the private sector to do the same.\nJanuary 7: The \"Legion of the Underground\" (LoU) declares \"war\" against the governments of Iraq and the People's Republic of China. An international coalition of hackers (including Cult of the Dead Cow, 2600's staff, Phrack's staff, L0pht, and the Chaos Computer Club) issued a joint statement (CRD 990107 - Hackers on planet earth against infowar) condemning the LoU's declaration of war. The LoU responded by withdrawing its declaration.\nMarch: The Melissa worm is released and quickly becomes the most costly malware outbreak to date.\nJuly: Cult of the Dead Cow releases Back Orifice 2000 at DEF CON.\nAugust: Kevin Mitnick, is sentenced to 5 years, of which over 4 years had already been spent pre-trial including 8 months' solitary confinement.\nSeptember: Level Seven Crew hacks the U.S. Embassy in China's website and places racist, anti-government slogans on embassy site in regards to 1998 U.S. embassy bombings.\nSeptember 16: The United States Department of Justice sentences the \"Phone Masters\".\nOctober: American Express introduces the \"Blue\" smart card, the industry's first chip-based credit card in the US.\nNovember 17: A hacker interviewed by Hilly Rose during the radio show Coast to Coast AM (then hosted by Art Bell) exposes a plot by al-Qaeda to derail Amtrak trains. This results in all trains being forcibly stopped over Y2K as a safety measure.\n\n== 2000s ==\n\n\n*** 2000 ***\nMay: The ILOVEYOU worm, also known as VBS/Loveletter and Love Bug worm, is a computer worm written in VBScript. It infected millions of computers worldwide within a few hours of its release. It is considered to be one of the most damaging worms ever. It originated in the Philippines; made by an AMA Computer College student Onel de Guzman for his thesis.\nSeptember: Computer hacker Jonathan James became the first juvenile to serve jail time for hacking.\n\n\n*** 2001 ***\nMicrosoft becomes the prominent victim of a new type of hack that attacks the domain name server. In these denial-of-service attacks, the DNS paths that take users to Microsoft's websites are corrupted.\nFebruary: A Dutch cracker releases the Anna Kournikova virus, initiating a wave of viruses that tempts users to open the infected attachment by promising a sexy picture of the Russian tennis star.\nApril: FBI agents trick two Russian crackers into coming to the U.S. and revealing how they were hacking U.S. banks.\nJuly: Russian programmer Dmitry Sklyarov is arrested at the annual DEF CON hacker convention. He was the first person criminally charged with violating the Digital Millennium Copyright Act (DMCA).\nAugust: Code Red worm, infects tens of thousands of machines.\nThe National Cyber Security Alliance (NCSA) is established in response to the September 11 attacks on the World Trade Center.\n\n\n*** 2002 ***\nJanuary: Bill Gates decrees that Microsoft will secure its products and services, and kicks off a massive internal training and quality control campaign.\nMarch: Gary McKinnon is arrested following unauthorized access to US military and NASA computers.\nMay: Klez.H, a variant of the worm discovered in November 2001, becomes the biggest malware outbreak in terms of machines infected, but causes little monetary damage.\nJune: The Bush administration files a bill to create the Department of Homeland Security, which, among other things, will be responsible for protecting the nation's critical IT infrastructure.\nAugust: Researcher Chris Paget publishes a paper describing \"shatter attacks\", detailing how Windows' unauthenticated messaging system can be used to take over a machine. The paper raises questions about how securable Windows could ever be. It is however largely derided as irrelevant as the vulnerabilities it described are caused by vulnerable applications (placing windows on the desktop with inappropriate privileges) rather than an inherent flaw within the Operating System.\nOctober: The International Information Systems Security Certification Consortium\u2014(ISC)\u00b2\u2014confers its 10,000th CISSP certification.\n\n\n*** 2003 ***\nThe hacktivist group Anonymous was formed.\nMarch: Cult of the Dead Cow and Hacktivismo are given permission by the United States Department of Commerce to export software utilizing strong encryption.\n\n\n*** 2004 ***\nMarch: New Zealand's Government (National Party) website defaced by hacktivist group BlackMask\nJuly: North Korea claims to have trained 500 hackers who successfully crack South Korean, Japanese, and their allies' computer systems.\nOctober: National Cyber Security Awareness Month was launched by the National Cyber Security Alliance and U.S. Department of Homeland Security.\n\n\n*** 2005 ***\nApril 2: Rafael N\u00fa\u00f1ez (aka RaFa), a notorious member of the hacking group World of Hell, is arrested following his arrival at Miami International Airport for breaking into the Defense Information Systems Agency computer system in June 2001.\nSeptember 13: Cameron Lacroix is sentenced to 11 months for gaining access to T-Mobile's network and exploiting Paris Hilton's Sidekick.\nNovember 3: Jeanson James Ancheta, whom prosecutors say was a member of the \"Botmaster Underground\", a group of script kiddies mostly noted for their excessive use of bot attacks and propagating vast amounts of spam, was taken into custody after being lured to FBI offices in Los Angeles.\n\n\n*** 2006 ***\nJanuary: One of the few worms to take after the old form of malware, destruction of data rather than the accumulation of zombie networks to launch attacks from, is discovered. It had various names, including Kama Sutra (used by most media reports), Black Worm, Mywife, Blackmal, Nyxem version D, Kapser, KillAV, Grew and CME-24. The worm would spread through e-mail client address books, and would search for documents and fill them with garbage, instead of deleting them to confuse the user. It would also hit a web page counter when it took control, allowing the programmer who created it as well as the world to track the progress of the worm. It would replace documents with random garbage on the third of every month. It was hyped by the media but actually affected relatively few computers, and was not a real threat for most users.\nMay: Jeanson James Ancheta receives a 57-month prison sentence, and is ordered to pay damages amounting to $15,000 to the Naval Air Warfare Center in China Lake and the Defense Information Systems Agency, for damage done due to DDoS attacks and hacking. Ancheta also had to forfeit his gains to the government, which include $60,000 in cash, a BMW, and computer equipment.\nMay: The largest defacement in Web History as of that time is performed by the Turkish hacker iSKORPiTX who successfully hacked 21,549 websites in one shot.\nJuly: Robert Moore and Edwin Pena were the first people to be charged by U.S. authorities for VoIP hacking. Robert Moore served 2 years in federal prison and was given $152,000 restitution. Once Edwin Pena was caught after fleeing the country, evading authorities for almost 2 years, he was sentenced to 10 years and given $1 million restitution.\nSeptember: Viodentia releases FairUse4WM tool which would remove DRM information off Windows Media Audio (WMA) files downloaded from music services such as Yahoo! Unlimited, Napster, Rhapsody Music and Urge.\n\n\n*** 2007 ***\nMay 17: Estonia recovers from massive denial-of-service attack\nJune 13: FBI Operation Bot Roast finds over 1 million botnet victims\nJune 21: A spear phishing incident at the Office of the Secretary of Defense steals sensitive U.S. defense information, leading to significant changes in identity and message-source verification at OSD.August 11: United Nations website hacked by Indian Hacker Pankaj Kumar Singh.\nNovember 14: Panda Burning Incense which is known by several other names, including Fujacks and Radoppan.T lead to the arrest of eight people in China. Panda Burning Incense was a parasitic virus that infected executable files on a PC. When infected, the icon of the executable file changes to an image of a panda holding three sticks of incense. The arrests were the first for virus writing in China.\n\n\n*** 2008 ***\nJanuary 17: Project Chanology; Anonymous attacks Scientology website servers around the world. Private documents are stolen from Scientology computers and distributed over the Internet.\nMarch 7: Around 20 Chinese hackers claim to have gained access to the world's most sensitive sites, including the Pentagon. They operated from an apartment on a Chinese Island.\nMarch 14: Trend Micro website successfully hacked by Turkish hacker Janizary (aka Utku).\n\n\n*** 2009 ***\nApril 4: Conficker worm infiltrated millions of PCs worldwide including many government-level top-security computer networks.\n\n== 2010s ==\n\n\n*** 2010 ***\nJanuary 12: Operation Aurora Google publicly reveals that it has been on the receiving end of a \"highly sophisticated and targeted attack on our corporate infrastructure originating from China that resulted in the theft of intellectual property from Google\"\nJune: Stuxnet The Stuxnet worm is found by VirusBlokAda. Stuxnet was unusual in that while it spread via Windows computers, its payload targeted just one specific model and type of SCADA systems. It slowly became clear that it was a cyber attack on Iran's nuclear facilities\u2014with most experts believing that Israel was behind it\u2014perhaps with US help.\nDecember 3: The first Malware Conference, MALCON took place in India. Founded by Rajshekhar Murthy, malware coders are invited to showcase their skills at this annual event supported by the Government of India. An advanced malware for Symbian OS is released by hacker A0drul3z.\n\n\n*** 2011 ***\nThe hacker group Lulz Security is formed.\nApril 9: Bank of America website got hacked by a Turkish hacker named JeOPaRDY. An estimated 85,000 credit card numbers and accounts were reported to have been stolen due to the hack. Bank officials say no personal customer bank information is available on that web-page. Investigations are being conducted by the FBI to trace down the incriminated hacker.\nApril 17: An \"external intrusion\" sends the PlayStation Network offline, and compromises personally identifying information (possibly including credit card details) of its 77 million accounts, in what is claimed to be one of the five largest data breaches ever.\nComputer hacker sl1nk releases information of his penetration in the servers of the Department of Defense (DoD), Pentagon, NASA, NSA, US Military, Department of the Navy, Space and Naval Warfare System Command and other UK/US government websites.\nSeptember: Bangladeshi hacker TiGER-M@TE made a world record in defacement history by hacking 700,000 websites in a single shot.\nOctober 16: The YouTube channel of Sesame Street was hacked, streaming pornographic content for about 22 minutes.\nNovember 1: The main phone and Internet networks of the Palestinian territories sustained a hacker attack from multiple locations worldwide.\nNovember 7: The forums for Valve's Steam service were hacked. Redirects for a hacking website, Fkn0wned, appeared on the Steam users' forums, offering \"hacking tutorials and tools, porn, free giveaways and much more.\"\nDecember 14: Five members of the Norwegian hacker group, Noria, were arrested, allegedly suspected for hacking into the email account of the militant extremist Anders Behring Breivik (who perpetrated the 2011 attacks in the country).\n\n\n*** 2012 ***\nA hacker published over 400,000 credit cards online, and threatened Israel to release 1 million credit cards in the future. In response to that incident, an Israeli hacker published over 200 Albanian' credit cards online.\nGottfrid Svartholm Warg, the co-founder of Pirate Bay, was convicted in Denmark of hacking a mainframe computer, what was then Denmark's biggest hacking case.\nJanuary 7: \"Team Appunity\", a group of Norwegian hackers, were arrested for breaking into Norway's largest prostitution website then publishing the user database online.\nFebruary 3: Marriott was hacked by a New Age ideologist, Attila Nemeth who was resisting against the New World Order where he said that corporations are allegedly controlling the world. As a response Marriott reported him to the United States Secret Service.\nFebruary 8: Foxconn is hacked by a hacker group, \"Swagg Security\", releasing a massive amount of data including email and server logins, and even more alarming\u2014bank account credentials of large companies like Apple and Microsoft. Swagg Security stages the attack just as a Foxconn protest ignites against terrible working conditions in southern China.\nMay 4: The websites of several Turkish representative offices of international IT-companies are defaced within the same day by F0RTYS3V3N (Turkish Hacker), including the websites of Google, Yandex, Microsoft, Gmail, MSN, Hotmail, PayPal.\nMay 24: WHMCS is hacked by UGNazi, they claim that the reason for this is because of the illegal sites that are using their software.\nMay 31: MyBB is hacked by newly founded hacker group, UGNazi, the website was defaced for about a day, they claim their reasoning for this was because they were upset that the forum board Hackforums.net uses their software.\nJune 5: The social networking website LinkedIn has been hacked and the passwords for nearly 6.5 million user accounts are stolen by cybercriminals. As a result, a United States grand jury indicted Nikulin and three unnamed co-conspirators on charges of aggravated identity theft and computer intrusion.\nAugust 15: Saudi Aramco is crippled by a cyber warfare attack for months by malware called Shamoon. Considered the biggest hack in history in terms of cost and destructiveness. Carried out by an Iranian attacker group called Cutting Sword of Justice. Iranian hackers retaliated against Stuxnet by releasing Shamoon. The malware destroyed over 35,000 Saudi Aramco computers, affecting business operations for months.\nDecember 17: Computer hacker sl1nk announced that he has hacked a total of 9 countries' SCADA systems. The proof includes 6 countries: France, Norway, Russia, Spain, Sweden and the United States.\n\n\n*** 2013 ***\nThe social networking website Tumblr is attacked by hackers. Consequently, 65,469,298 unique emails and passwords were leaked from Tumblr. The data breach's legitimacy is confirmed by computer security researcher Troy Hunt.\nAugust: Yahoo! data breaches occurred.  More than 3 billion users data are being leaked.\n\n\n*** 2014 ***\nFebruary 7: The bitcoin exchange Mt. Gox filed for bankruptcy after $460 million was apparently stolen by hackers due to \"weaknesses in [their] system\" and another $27.4 million went missing from its bank accounts.\nOctober: The White House computer system was hacked. It was said that the FBI, the Secret Service, and other U.S. intelligence agencies categorized the attacks \"among the most sophisticated attacks ever launched against U.S. government systems.\"\nNovember 24: In response to the release of the film The Interview, the servers of Sony Pictures are hacked by a hacker group calling itself \"Guardian of Peace\".\nNovember 28: The website of the Philippine telecommunications company Globe Telecom was hacked in response to the poor internet service they are distributing.\n\n\n*** 2015 ***\nJune: the records of 21.5 million people, including social security numbers, dates of birth, addresses, fingerprints, and security clearance-related information, are stolen from the United States Office of Personnel Management (OPM). Most of the victims are employees of the United States government and unsuccessful applicants to it. The Wall Street Journal and The Washington Post report that government sources believe the hacker is the government of China.\nJuly: The servers of extramarital affairs website Ashley Madison were breached.\n\n\n*** 2016 ***\nFebruary: The 2016 Bangladesh Bank heist attempted to steal US$951 million from a Bangladesh Bank, and succeeded in getting $101 million\u2014although some of this was later recovered.\nJuly 22: WikiLeaks published the documents from the 2016 Democratic National Committee email leak.\nJuly 29: a group suspected coming from China launched hacker attacks on the website of Vietnam Airlines.\nAugust 13: The Shadow Brokers (TSB) started publishing several leaks containing hacking tools from the National Security Agency (NSA), including several zero-day exploits. Ongoing leaks until April 2017 (The Shadow Brokers)\nSeptember: Hacker Ardit Ferizi is sentenced to 20 years in prison after being arrested for hacking U.S. servers and passing the leaked information to members of ISIL terrorist group back in 2015.\nOctober: The 2016 Dyn cyberattack is being conducted with a botnet consisting of IOTs infected with Mirai by the hacktivist groups SpainSquad, Anonymous, and New World Hackers, reportedly in retaliation for Ecuador's rescinding Internet access to WikiLeaks founder Julian Assange at their embassy in London, where he has been granted asylum.\nLate 2016: Hackers steal international personal user data from the company Uber, including phone numbers, email addresses, and names, of 57 million people and 600,000 driver's license numbers of drivers for the company. Uber's GitHub account was accessed through Amazon's cloud-based service. Uber paid the hackers $100,000 for assurances the data was destroyed.\nDecember 2016: Yahoo! data breaches reported and affected more than 1 billion users.  The data leakage includes user names, email addresses, telephone numbers, encrypted or unencrypted security questions and answers, dates of birth, and hashed passwords\n\n\n*** 2017 ***\nApril: A hacker group calling itself \"The Dark Overlord\" posted unreleased episodes of Orange Is the New Black TV series online after failing to extort the online entertainment company Netflix.\nMay: WannaCry ransomware attack started on Friday, May 12, 2017, and has been described as unprecedented in scale, infecting more than 230,000 computers in over 150 countries. A hacked unreleased Disney film is held for ransom, to be paid in Bitcoin.\nMay: 25,000 digital photos and ID scans relating to patients of the Grozio Chirurgija cosmetic surgery clinic in Lithuania were obtained and published without consent by an unknown group demanding ransoms. Thousands of clients from more than 60 countries were affected. The breach brought attention to weaknesses in Lithuania's information security.\nJune: 2017 Petya cyberattack.\nJune: TRITON (TRISIS), a malware framework designed to reprogram Triconex safety instrumented systems (SIS) of industrial control systems (ICS), discovered in Saudi Arabian Petrochemical plant.\nAugust: Hackers demand $7.5 million in Bitcoin to stop pre-releasing HBO shows and scripts, including Ballers, Room 104 and Game of Thrones.\nMay\u2013July 2017: The Equifax breach.\nSeptember 2017: Deloitte breach.\nDecember: Mecklenburg County, North Carolina computer systems were hacked. They did not pay the ransom.\n\n\n*** 2018 ***\nMarch: Computer systems in the city of Atlanta, in the U.S. state of Georgia, are seized by hackers with ransomware. They did not pay the ransom, and two Iranians were indicted by the FBI on cyber crime charges for the breach.\nThe town of Wasaga Beach in Ontario, Canada computer systems are seized by hackers with ransomware.\nSeptember: Facebook was hacked, exposing to hackers the personal information of an estimated 30 million Facebook users (initially estimated at 50 million) when the hackers \"stole\" the \"access tokens\" of 400,000 Facebook users. The information accessible to the hackers included users' email addresses, phone numbers, their lists of friends, Groups they are members of, users' search information, posts on their timelines, and names of recent Messenger conversations.\nOctober: West Haven, Connecticut USA computer systems are seized by hackers with ransomware, they paid $2,000 in ransom.\nNovember:\nThe first U.S. indictment of individual people for ransomware attacks occurs. The U.S. Justice Department indicted two men Faramarz Shahi Savandi and Mohammad Mehdi Shah Mansouri who allegedly used the SamSam ransomware for extortion, netting them more than $6 million in ransom payments. The companies infected with the ransomware included Allscripts, Medstar Health, and Hollywood Presbyterian Medical Center. Altogether, the attacks caused victims to lose more than $30 million, in addition to the ransom payments.\nMarriott disclosed that its Starwood Hotel brand had been subject to a security breach.\n\n\n*** 2019 ***\nMarch: Jackson County computer systems in the U.S. state of Georgia are seized by hackers with ransomware, they paid $400,000 in ransom. The city of Albany in the U.S. state of New York experiences a ransomware cyber attack.\nApril: Computer systems in the city of Augusta, in the U.S. state of Maine, are seized by hackers using ransomware. The City of Greenville (North Carolina)'s computer systems are seized by hackers using ransomware known as RobbinHood. Imperial County, in the U.S. state of California, computer systems are seized by hackers using Ryuk ransomware.\nMay: computer systems belonging to the City of Baltimore are seized by hackers using ransomware known as RobbinHood that encrypts files with a \"file-locking\" virus, as well as the tool EternalBlue.\nJune: The city of Riviera Beach, Florida paid roughly $600,000 ransom in Bitcoin to hackers who seized their computers using ransomware. Hackers stole 18 hours of unreleased music from the band Radiohead demanding $150,000 ransom. Radiohead released the music to the public anyway and did not pay the ransom.\nNovember: The Anonymous hacktivist collective announced that they have hacked into four Chinese computer databases and donated those to data breach indexing/notification service vigilante.pw. The hack was conducted in order to support the 2019 Hong Kong protests, amidst the Hong Kong police's siege of the city's Polytechnic University. They also brought up a possible peace plan first proposed by a professor at Inha University in hopes of having the Korean reunification and the five key demands of the Hong Kong protest being fulfilled at once.\n\n== 2020s ==\n\n\n*** 2020 ***\nFebruary: Anonymous hacked the United Nations website and created a page for Taiwan, a country which had not had a seat at the UN since 1971. The hacked page featured the Flag of Taiwan, the KMT emblem, a Taiwan Independence flag, the Anonymous logo, embedded YouTube videos such as the Taiwanese national anthem and the closing score for the 2019 film Avengers: Endgame titled \"It's Been a Long, Long Time\", and a caption. The hacked server belonged to the United Nations Department of Economic and Social Affairs.\nMay: Anonymous declared a large hack on May 28, three days after the murder of George Floyd. An individual claiming to represent Anonymous stated that \"We are Legion. We do not forgive. We do not forget. Expect us.\" in a now-deleted video. Anonymous addressed police brutality and said they \"will be exposing [their] many crimes to the world\". It was suspected that Anonymous were the cause for the downtime and public suspension of the Minneapolis Police Department website and its parent site, the website of the City of Minneapolis.\nMay: Indian national Shubham Upadhyay posed as Superintendent of Police and, using social engineering, used a free caller identification app to call up the in-charge of the Kotwali police station, K. K. Gupta, in order to threaten him to get his phone repaired amidst the COVID-19 lockdown. The attempt was foiled.\nJune: Anonymous claimed responsibility for stealing and leaking a trove of documents collectively nicknamed 'BlueLeaks'. The 269-gigabyte collection was published by a leak-focused activist group known as Distributed Denial of Secrets. Furthermore, the collective took down Atlanta Police Department's website via DDoS, and defaced websites such as a Filipino governmental webpage and that of Brookhaven National Labs. They expressed support for Julian Assange and press freedom, while briefly \"taking a swing\" against Facebook, Reddit and Wikipedia for having 'engaged in shady practices behind our prying eyes'. In the case of Reddit, they posted a link to a court document describing the possible involvement of a moderator of a large traffic subreddit (/r/news) in an online harassment-related case.\nJune: The Buffalo, NY police department's website was supposedly hacked by Anonymous. While the website was up and running after a few minutes, Anonymous tweeted again on Twitter urging that it be taken down. A few minutes later, the Buffalo NY website was brought down again. They also hacked Chicago police radios to play N.W.A's \"Fuck tha Police\".\nJune: Over 1,000 accounts on multiplayer online game Roblox were hacked to display that they supported U.S. President Donald Trump.\nJuly: The 2020 Twitter bitcoin scam occurred.\nJuly: User credentials of writing website Wattpad were stolen and leaked on a hacker forum. The database contained over 200 million records.\nAugust: A large number of subreddits were hacked to post materials endorsing Donald Trump. The affected subreddits included r/BlackPeopleTwitter, r/3amJokes, r/NFL, r/PhotoshopBattles. An entity with the name of \"calvin goh and Melvern\" had purportedly claimed responsibility for the massive defacement, and also made violent threats against a Chinese embassy.\nAugust: The US Air Force's Hack-A-Sat event was hosted at DEF CON's virtual conference where groups such as Poland Can Into Space, FluxRepeatRocket, AddVulcan, Samurai, Solar Wine, PFS, 15 Fitty Tree, and 1064CBread competed in order to control a satellite in space. The Poland Can Into Space team stood out for having successfully manipulated a satellite to take a picture of the Moon.\nAugust: The website of Belarusian company \"BrestTorgTeknika\" was defaced by a hacker nicknaming herself \"Queen Elsa\", in order to support the 2020\u201321 Belarusian protests. In it, the page hacker exclaimed \"Get Iced Iced already\" and \"Free Belarus, revolution of our times\" with the latter alluding to the famous slogan used by 2019 Hong Kong protests. The results of the hack were then announced on Reddit's /r/Belarus subreddit by a poster under the username \"Socookre\".\nAugust: Multiple DDoS attacks forced New Zealand's stock market to temporarily shut down.\nSeptember: The first suspected death from a cyberattack was reported after cybercriminals hit a hospital in D\u00fcsseldorf, Germany with ransomware.\nOctober: A wave of botnet-coordinated ransomware attacks against hospital infrastructure occurred in the United States, identified as associated with Russia.  State security officials and American corporate security officers were concerned that these attacks might be a prelude to hacking of election infrastructure during the elections of the subsequent month, like similar incidents during the 2016 United States elections and other attacks; there was, however, no evidence that they performed attacks on election infrastructure in 2020.\nDecember: A supply chain attack targeting upstream dependencies from Texas IT service provider \"SolarWinds\" results in serious, wide-ranging security breaches at the U.S. Treasury and Commerce departments. White House officials did not immediately publicly identify a culprit; Reuters, citing sources \"familiar with the investigation\", pointed toward the Russian government. An official statement shared by Senate Finance Committee ranking member, Ron Wyden said: \"Hackers broke into systems in the Departmental Offices division of Treasury, home to the department\u2019s highest-ranking officials.\"\nDecember: A bomb threat posted from a Twitter account that was seemingly hacked by persons with the aliases of \"Omnipotent\" and \"choonkeat\",  against the Aeroflot Flight 102, a passenger flight with the plane tail number of VQ-BIL coming from Moscow to New York City. Due to that, a runway of New York's John F. Kennedy International Airport was temporarily closed and resulted in the delay of Aeroflot Flight 103, a return flight back to Moscow.\nDecember: The Anonymous group initiated 'Christmas gift' defacements against multiple Russian portals including a municipal website in Tomsk and that of a regional football club. Inside the defacements, they made multiple references such as Russian opposition activist Alexei Navalny, freedom protests in Thailand and Belarus, and opposition to the Chinese Communist Party. They also held a mock award based on an event on the game platform Roblox that was called \"RB Battles\" where YouTubers Tanqr and KreekCraft, the winner and the runner up of the actual game event, were compared to both Taiwan and New Zealand respectively due to the latter's reportedly stellar performance in fighting the COVID-19 pandemic.\n\n\n*** 2021 ***\nJanuary: Microsoft Exchange Server data breach\nFebruary: Anonymous announced cyber-attacks of at least five Malaysian websites. As a result, eleven individuals were nabbed as suspects.\nFebruary: Hackers including those with names of \"\u5f20\u536b\u80fd utoyo\" and \"full_discl0sure\" hijacked an events website Aucklife in order to craft a phony bomb threat against the Chinese consulate in Auckland, New Zealand, and also a similar facility in Sydney, Australia. Their motive was a punitive response against China due to COVID-19. As a result, a physical search was conducted at the consulate by New Zealand's Police Specialist Search Group while Aucklife owner Hailey Newton had since regained her access to the website. Wellington-based cybersecurity consultant Adam Boileau remarked that the hack isn't 'highly technical'.\nFebruary: The group \"Myanmar Hackers\" attacked several websites belonging to Myanmar government agencies such as the Central Bank of Myanmar and the military-run Tatmadaw True News Information Team. The group also targeted the Directorate of Investment and Company Administration, Trade Department, Customs Department, Ministry of Commerce, Myawady TV and state-owned broadcaster Myanmar Radio and Television and some private media outlets. A computer technician in Yangon found that the hacks were denial-of-service attacks, while the group's motive is to protest the 2021 Myanmar coup.\nApril: Over 500 million Facebook users' personal info\u2014including info on 32 million in the United States\u2014was discovered posted on a hackers' website, though Facebook claimed that the information was from a 2019 hack, and that the company had already taken mitigation measures; however, the company declined to say whether it had notified the affected users of the breach.\nApril: The Ivanti Pulse Connect Secure data breach of unauthorized access to the networks of high-value targets since at least June 2020 via CVE-2021-22893 across the U.S. and some E.U. nations due to their use of vulnerable, proprietary software was reported.\nMay: Operation of the U.S. Colonial Pipeline is interrupted by a ransomware cyber operation.\nMay: On 21 May 2021 Air India was subjected to a cyberattack wherein the personal details of about 4.5 million customers around the world were compromised including passport, credit card details, birth dates, name and ticket information.\nJuly: On 22 July 2021 Saudi Aramco data were leaked by a third-party contractor and demanded $50 million ransom from Saudi Aramco. Saudi Aramco confirmed the incident after a hacker claimed on dark web that he had stolen 1 terabyte of data about location of oil refineries and employees data in a post that was posted on June 23.\nAugust: T-Mobile reported that data files with information from about 40 million former or prospective T-Mobile customers, including first and last names, date of birth, SSN, and driver's license/ID information, were compromised.\nSeptember and October: 2021 Epik data breach. Anonymous obtained and released over 400 gigabytes of data from the domain registrar and web hosting company Epik. The data was shared in three releases between September 13 and October 4. The first release included domain purchase and transfer details, account credentials and logins, payment history, employee emails, and unidentified private keys. The hackers claimed they had obtained \"a decade's worth of data\", including all customer data and records for all domains ever hosted or registered through the company, and which included poorly encrypted passwords and other sensitive data stored in plaintext. The second release consisted of bootable disk images and API keys for third-party services used by Epik; the third contained additional disk images and an archive of data belonging to the Republican Party of Texas, who are an Epik customer.\nOctober: On October 6, 2021, an anonymous 4chan reportedly hacked and leaked the source code of Twitch, as well as information on how much the streaming service paid almost 2.4 million streamers since August 2019. Source code from almost 6,000 GitHub repositories was leaked, and the 4chan user said it was \"part one\" of a much larger release.\nNovember and December: On November 24th, Chen Zhaojun of Alibaba's Cloud Security Team reported a zero-day vulnerability (later dubbed Log4Shell) involving the use of arbitrary code execution in the ubiquitous Java logging framework software Log4j. The report was privately disclosed to project developers of Log4j, a team at The Apache Software Foundation, on November 24. On December 8, Zhaojun contacted the developers again detailing how the vulnerability was being discussed in public security chat rooms, was already known by some security researchers, and pleaded that the team expedite the solution to the vulnerability in the official release version of Log4j. Early exploitations were noticed on Minecraft servers on December 9; however, forensic analysis indicates that Log4Shell may have been exploited as early as December 1 or 2nd. Due to the ubiquity of devices with the Log4j software (hundreds of millions) and the simplicity in executing the vulnerability, it is considered to be arguably one of the largest and most critical vulnerabilities ever. Yet, big names in security hacking helped in regaining control over server, like Graham Ivan Clark, and Elhamy A. Elsebaey.  A portion of the vulnerability was fixed in a patch distributed on December 6, three days before the vulnerability was publicly disclosed on December 9.\n\n\n*** 2022 ***\nFebruary: The German Chaos Computer Club has reported more than fifty data leaks. Government institutions and companies from various business sectors were affected. In total, the researchers had access to over 6.4 million personal data records as well as terabytes of log data and source code.\nMarch: The website of a local newspaper in Sumy, Ukraine was hacked by a person identifying themselves as \"zehang\u9648\". They claimed that they and other individuals \"P_srim_asap\", \"Mrthanthomthebomber\", \"mister-handsomekai\" and \"RiansJohnson\" had placed bombs at Chinese and Russian diplomatic facilities in Malaysia with the former containing a photo of Huanan Seafood Wholesale Market, Hong Kong's International Finance Centre and MTR Airport Station, and the headquarters office of American game company ROBLOX. Besides that, they claimed responsibility for the delivery of an envelope containing white powders against the Russian embassy in Canberra, Australia. As a result the area surrounding the embassy was briefly cordoned off.\nMarch: As a response to the 2022 Russian invasion of Ukraine, Anonymous performed many attacks against computer systems in Russia. Most notably, Anonymous committed a cyberattack against Roskomnadzor.\nMarch: On 23 March 2022, hackers compromised the Ronin Network, stealing approximately US$620 million in Ether and USDC. A total of 173,600 Ether and 25.5 million USDC tokens were stolen in two transactions.  It took the company six days to notice the hack. The hack currently sits as the largest-ever breach in the cryptocurrency sector by dollar value. It further damaged the value of SLP. On 8 April 2022, Sky Mavis said it expected it would be able to recover some of the funds, but it would take several years. The company raised additional venture capital and reimbursed all users affected in the hack. On 14 April 2022, the FBI issued a statement that the Lazarus Group and APT38, which are North Korean state-sponsored hacker groups, were responsible for the theft. Accordingly, the US Treasury has sanctioned the cryptocurrency address. Some of the cryptocurrency has been laundered through a cryptocurrency tumbler known as \"Tornado Cash\".\nApril: Anonymous hacked Russian companies Aerogas, Forest, and Petrovsky Fort. From there they leaked around 437,500 emails which they donated to non-profit whistleblower organization Distributed Denial of Secrets. Furthermore, they leaked 446 GB of data from Russian Ministry of Culture.\nApril: On April 19, Gij\u00f3n City Council (Spain) was attacked by the GERVASIA computer virus and suffered data hijacking.\nMay: Network Battalion 65 (NB65), a hacktivist group affiliated with Anonymous, has reportedly hacked Russian payment processor Qiwi. A total of 10.5 terabytes of data including transaction records and customers' credit cards had been exfiltrated. They further infected Qiwi with ransomwares and threatened to release more customer records.\nMay: During the Victory Day in Russia, anti-war messages were inserted into Russian TV schedules including that of Russia-1, Channel 1, and NTV-Plus. One of the messages were \"On your hands is the blood of thousands of Ukrainians and their hundreds of murdered children. TV and the authorities are lying. No to war.\"\nJune: A hacker on the Breach Forums claimed to have leaked more than 1 billion people's personal records from the Shanghai National Police Database.\nAugust: During the visit of Speaker of the United States House of Representatives Nancy Pelosi to Taiwan, the website of Taiwan's Office of the President website was affected by a distributed denial of service attack. Anonymous then hacked into a China Heilongjiang province's Society Scientific Community Federation website and a Chinese gasoline generator factory\u2019s website."
    }
  },
  {
    "instruction": "context: Authorized credit card fraud occurs when the genuine customer themselves processes payment to another account which is controlled by a criminal, while unauthorized credit card fraud occurs when the account holder does not provide authorization for the payment to proceed and the transaction is carried out by a third party.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the difference between authorized and unauthorized credit card fraud?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between authorized and unauthorized credit card fraud?",
      "answer": "Authorized credit card fraud occurs when the genuine customer themselves processes payment to another account which is controlled by a criminal, while unauthorized credit card fraud occurs when the account holder does not provide authorization for the payment to proceed and the transaction is carried out by a third party."
    }
  },
  {
    "instruction": "Offensive Security\n\n==Introduction==\nOffensive Security (also known as OffSec) is an American international company working in information security, penetration testing and digital forensics. Operating from around 2007, the company created open source projects, advanced security courses, the ExploitDB vulnerability database, and the Kali Linux distribution. The company was started by Mati Aharoni, and employs security professionals with experience in security penetration testing and system security evaluation. The company has provided security counseling and training to many technology companies.The company also provides training courses and certifications.\n\n== Background and history ==\nMati Aharoni, Offensive Security's co-founder, started the business around 2006 with his wife Iris. Offensive Security LLC was formed in 2008. The company was structured as Offensive Security Services, LLC in 2012 in North Carolina. In September 2019 the company received its first venture capital investment, from Spectrum Equity, and CEO Ning Wang replaced Joe Steinbach, the previous CEO for four years, who ran the business from the Philippines. Jim O\u2019Gorman, the company's chief strategy officer, also gives training and writes books. Customers include Cisco, Wells Fargo, Booz Allen Hamilton, and defense-related U.S. government agencies. The company gives training sessions at the annual Black Hat hacker conference.In 2019, J.M. Porup of CSO online wrote \"few infosec certifications have developed the prestige in recent years of the Offensive Security Certified Professional (OSCP),\" and said it has \"a reputation for being one of the most difficult,\" because it requires student to hack into a test network during a difficult \"24-hour exam.\" He also summarized accusations of cheating, and Offensive Security's responses, concluding hiring based only on credentials was a mistake, and an applicants skills should be validated. In 2020, cybersecurity professional Matt Day of Start a Cyber Career, writing a detailed review and comparison of OSCP and CompTIA PenTest+, said OSCP was \"well known in the pentesting community, and therefore well known by the managers that hire them.\"\n\n== Projects ==\nIn addition to their training and security services, the company also founded open source projects, online exploit databases and security information teaching aids.\n\n\n*** Kali Linux ***\nThe company is known for developing Kali Linux, which is a Debian Linux based distribution modeled after BackTrack. It succeeds BackTrack Linux, and is designed for security information needs, such as penetration testing and digital forensics. Kali NetHunter is Offensive Security's project for the ARM architecture and Android devices. Kali Linux contains over 600 security programs. The release of the second version (2.0) received a wide coverage in the digital media Offensive Security provides a book, Kali Linux Revealed, and makes the first edition available for free download. Users and employees have been inspired to have careers in social engineering. In 2019, in a detailed review, Cyberpunk called Offensive Security's Kali Linux, \"formally [sic] known as BackTrack,\" the \"best penetration testing distribution.\"\n\n\n*** BackTrack ***\nBackTrack Linux was an open source GNU General Public License Linux distribution developed by programmers from around the world with assistance, coordination, and funding from Offensive Security. The distribution was originally developed under the names Whoppix, IWHAX, and Auditor. It was designed to delete any trace of its usage. The distribution was widely known and used by security experts.\n\n\n*** ExploitDB ***\nExploit Database is an archive of vulnerable software and exploits that have been made public by the information security community. The database is designated to help penetration testers test small projects easily by sharing information with each other. The database also contains proof-of-concepts (POC), helping information security professionals learn new exploits variations. In Ethical Hacking and Penetration Testing Guide, Rafay Baloch said Exploit-db had over 20,000 exploits, and was available in BackTrack Linux by default. In CEH v10 Certified Ethical Hacker Study Guide, Ric Messier called exploit-db a \"great resource,\" and stated it was available within Kali Linux by default, or could be added to other Linux distributions.\n\n\n*** Metasploit ***\nMetasploit Unleashed is a charity project created by Offensive Security for the sake of Hackers for Charity, which was started by Johnny Long. The projects teaches Metasploit and is designed especially for people who consider starting a career in penetration testing.\n\n\n*** Google Hacking Database ***\nGoogle Hacking Database was created by Johnny Long and is now hosted by Offensive Security. The project was created as a part of Hackers for Charity. The database helps security professionals determine whether a given application or website is compromised. The database uses Google search to establish whether usernames and passwords had been compromised.\nQuestion: How does Offensive Security's Exploit Database benefit information security professionals?",
    "context": "",
    "output": "Answer: Offensive Security's Exploit Database benefits information security professionals by providing over 20,000 exploits and proof-of-concepts (POC) to help them learn new exploits variations and test small projects easily.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Offensive Security's Exploit Database benefit information security professionals?",
      "answer": "Offensive Security's Exploit Database benefits information security professionals by providing over 20,000 exploits and proof-of-concepts (POC) to help them learn new exploits variations and test small projects easily.",
      "context": "Offensive Security\n\n==Introduction==\nOffensive Security (also known as OffSec) is an American international company working in information security, penetration testing and digital forensics. Operating from around 2007, the company created open source projects, advanced security courses, the ExploitDB vulnerability database, and the Kali Linux distribution. The company was started by Mati Aharoni, and employs security professionals with experience in security penetration testing and system security evaluation. The company has provided security counseling and training to many technology companies.The company also provides training courses and certifications.\n\n== Background and history ==\nMati Aharoni, Offensive Security's co-founder, started the business around 2006 with his wife Iris. Offensive Security LLC was formed in 2008. The company was structured as Offensive Security Services, LLC in 2012 in North Carolina. In September 2019 the company received its first venture capital investment, from Spectrum Equity, and CEO Ning Wang replaced Joe Steinbach, the previous CEO for four years, who ran the business from the Philippines. Jim O\u2019Gorman, the company's chief strategy officer, also gives training and writes books. Customers include Cisco, Wells Fargo, Booz Allen Hamilton, and defense-related U.S. government agencies. The company gives training sessions at the annual Black Hat hacker conference.In 2019, J.M. Porup of CSO online wrote \"few infosec certifications have developed the prestige in recent years of the Offensive Security Certified Professional (OSCP),\" and said it has \"a reputation for being one of the most difficult,\" because it requires student to hack into a test network during a difficult \"24-hour exam.\" He also summarized accusations of cheating, and Offensive Security's responses, concluding hiring based only on credentials was a mistake, and an applicants skills should be validated. In 2020, cybersecurity professional Matt Day of Start a Cyber Career, writing a detailed review and comparison of OSCP and CompTIA PenTest+, said OSCP was \"well known in the pentesting community, and therefore well known by the managers that hire them.\"\n\n== Projects ==\nIn addition to their training and security services, the company also founded open source projects, online exploit databases and security information teaching aids.\n\n\n*** Kali Linux ***\nThe company is known for developing Kali Linux, which is a Debian Linux based distribution modeled after BackTrack. It succeeds BackTrack Linux, and is designed for security information needs, such as penetration testing and digital forensics. Kali NetHunter is Offensive Security's project for the ARM architecture and Android devices. Kali Linux contains over 600 security programs. The release of the second version (2.0) received a wide coverage in the digital media Offensive Security provides a book, Kali Linux Revealed, and makes the first edition available for free download. Users and employees have been inspired to have careers in social engineering. In 2019, in a detailed review, Cyberpunk called Offensive Security's Kali Linux, \"formally [sic] known as BackTrack,\" the \"best penetration testing distribution.\"\n\n\n*** BackTrack ***\nBackTrack Linux was an open source GNU General Public License Linux distribution developed by programmers from around the world with assistance, coordination, and funding from Offensive Security. The distribution was originally developed under the names Whoppix, IWHAX, and Auditor. It was designed to delete any trace of its usage. The distribution was widely known and used by security experts.\n\n\n*** ExploitDB ***\nExploit Database is an archive of vulnerable software and exploits that have been made public by the information security community. The database is designated to help penetration testers test small projects easily by sharing information with each other. The database also contains proof-of-concepts (POC), helping information security professionals learn new exploits variations. In Ethical Hacking and Penetration Testing Guide, Rafay Baloch said Exploit-db had over 20,000 exploits, and was available in BackTrack Linux by default. In CEH v10 Certified Ethical Hacker Study Guide, Ric Messier called exploit-db a \"great resource,\" and stated it was available within Kali Linux by default, or could be added to other Linux distributions.\n\n\n*** Metasploit ***\nMetasploit Unleashed is a charity project created by Offensive Security for the sake of Hackers for Charity, which was started by Johnny Long. The projects teaches Metasploit and is designed especially for people who consider starting a career in penetration testing.\n\n\n*** Google Hacking Database ***\nGoogle Hacking Database was created by Johnny Long and is now hosted by Offensive Security. The project was created as a part of Hackers for Charity. The database helps security professionals determine whether a given application or website is compromised. The database uses Google search to establish whether usernames and passwords had been compromised."
    }
  },
  {
    "instruction": "Context: Privilege Management Infrastructure\n\n==Introduction==\nIn cryptography Privilege Management is the process of managing user authorisations based on the ITU-T Recommendation X.509. The 2001 edition of X.509  specifies most (but not all) of the components of a Privilege Management Infrastructure (PMI), based on X.509 attribute certificates (ACs). Later editions of X.509 (2005 and 2009) have added further components to the PMI, including a delegation service (in 2005 ) and interdomain authorisation (in the 2009 edition ).\nPrivilege management infrastructures (PMIs) are to authorisation what public key infrastructures (PKIs) are to authentication. PMIs use attribute certificates (ACs) to hold user privileges, in the form of attributes, instead of public key certificates (PKCs) to hold public keys. PMIs have Sources of Authority (SoAs) and Attribute Authorities (AAs) that issue ACs to users, instead of certification authorities (CAs) that issue PKCs to users. Usually PMIs rely on an underlying PKI, since ACs have to be digitally signed by the issuing AA, and the PKI is used to validate the AA's signature.\nAn X.509 AC is a generalisation of the well known X.509 public key certificate (PKC), in which the public key of the PKC has been replaced by any set of attributes of the certificate holder (or subject). Therefore, one could in theory use X.509 ACs to hold a user's public key as well as any other attribute of the user. (In a similar vein, X.509 PKCs can also be used to hold privilege attributes of the subject, by adding them to the subject directory attributes extension of an X.509 PKC). However, the life cycle of public keys and user privileges are usually very different, and therefore it isn't usually a good idea to combine both of them in the same certificate. Similarly, the  authority that assigns a privilege to someone is usually different from the authority that certifies someone's public key. Therefore, it isn't usually a good idea to combine the functions of the SoA/AA and the CA in the same trusted authority. PMIs allow privileges and authorisations to be managed separately from keys and authentication.\nThe first open source implementation of an X.509 PMI was built with funding under the EC PERMIS project, and the software is available from here. A description of the implementation can be found in.X.509 ACs and PMIs are used today in Grids (see Grid computing), to assign privileges to users, and to carry the privileges around the Grid. In the most popular Grid privilege management system today, called VOMS, user privileges, in the shape of VO memberships and roles, are placed inside an X.509 AC by the VOMS server, signed by the VOMS server, and then embedded in the user's X.509 proxy certificate for carrying around the Grid.\nBecause of the rise in popularity of XML SOAP based services, SAML attribute assertions are now more popular than X.509 ACs for transporting user attributes. However, they both have similar functionality, which is to strongly bind a set of privilege attributes to a user.\n\n\n\nQuestion: How do Privilege Management Infrastructures (PMI) and Public Key Infrastructures (PKI) differ in their purpose and components?\n\nAnswer:",
    "context": "",
    "output": "Privilege Management Infrastructures (PMI) use attribute certificates (ACs) to manage user authorizations based on the ITU-T Recommendation X.509, while Public Key Infrastructures (PKI) use public key certificates (PKCs) to manage public keys. PMIs have Sources of Authority (SoAs) and Attribute Authorities (AAs) that issue ACs, while PKIs have certification authorities (CAs) that issue PKCs. PMIs usually rely on an underlying PKI for digital signature validation, as ACs need to be signed by the issuing AA.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do Privilege Management Infrastructures (PMI) and Public Key Infrastructures (PKI) differ in their purpose and components?",
      "answer": "Privilege Management Infrastructures (PMI) use attribute certificates (ACs) to manage user authorizations based on the ITU-T Recommendation X.509, while Public Key Infrastructures (PKI) use public key certificates (PKCs) to manage public keys. PMIs have Sources of Authority (SoAs) and Attribute Authorities (AAs) that issue ACs, while PKIs have certification authorities (CAs) that issue PKCs. PMIs usually rely on an underlying PKI for digital signature validation, as ACs need to be signed by the issuing AA.",
      "context": "Privilege Management Infrastructure\n\n==Introduction==\nIn cryptography Privilege Management is the process of managing user authorisations based on the ITU-T Recommendation X.509. The 2001 edition of X.509  specifies most (but not all) of the components of a Privilege Management Infrastructure (PMI), based on X.509 attribute certificates (ACs). Later editions of X.509 (2005 and 2009) have added further components to the PMI, including a delegation service (in 2005 ) and interdomain authorisation (in the 2009 edition ).\nPrivilege management infrastructures (PMIs) are to authorisation what public key infrastructures (PKIs) are to authentication. PMIs use attribute certificates (ACs) to hold user privileges, in the form of attributes, instead of public key certificates (PKCs) to hold public keys. PMIs have Sources of Authority (SoAs) and Attribute Authorities (AAs) that issue ACs to users, instead of certification authorities (CAs) that issue PKCs to users. Usually PMIs rely on an underlying PKI, since ACs have to be digitally signed by the issuing AA, and the PKI is used to validate the AA's signature.\nAn X.509 AC is a generalisation of the well known X.509 public key certificate (PKC), in which the public key of the PKC has been replaced by any set of attributes of the certificate holder (or subject). Therefore, one could in theory use X.509 ACs to hold a user's public key as well as any other attribute of the user. (In a similar vein, X.509 PKCs can also be used to hold privilege attributes of the subject, by adding them to the subject directory attributes extension of an X.509 PKC). However, the life cycle of public keys and user privileges are usually very different, and therefore it isn't usually a good idea to combine both of them in the same certificate. Similarly, the  authority that assigns a privilege to someone is usually different from the authority that certifies someone's public key. Therefore, it isn't usually a good idea to combine the functions of the SoA/AA and the CA in the same trusted authority. PMIs allow privileges and authorisations to be managed separately from keys and authentication.\nThe first open source implementation of an X.509 PMI was built with funding under the EC PERMIS project, and the software is available from here. A description of the implementation can be found in.X.509 ACs and PMIs are used today in Grids (see Grid computing), to assign privileges to users, and to carry the privileges around the Grid. In the most popular Grid privilege management system today, called VOMS, user privileges, in the shape of VO memberships and roles, are placed inside an X.509 AC by the VOMS server, signed by the VOMS server, and then embedded in the user's X.509 proxy certificate for carrying around the Grid.\nBecause of the rise in popularity of XML SOAP based services, SAML attribute assertions are now more popular than X.509 ACs for transporting user attributes. However, they both have similar functionality, which is to strongly bind a set of privilege attributes to a user.\n\n"
    }
  },
  {
    "instruction": "Context: Disaster recovery and business continuity auditing\n\n==Introduction==\nGiven organizations' increasing dependency on information technology to run their operations, Business continuity planning covers the entire organization, and Disaster recovery focuses on IT.\nAuditing of documents covering an organization's business continuity  and disaster recovery plans provides a third-party validation to stakeholders that the documentation is complete and does not contain material misrepresentations.\nLack of completeness can result in overlooking secondary effects, such as when vastly increased work-at-home overloads incoming recovery site telecommunications capacity, and the bi-weekly payroll that was not critical within the first 48 hours is now causing perceived problems in ever recovering, complicated by  governmental and possibly union reaction.\n\n== Overview ==\nOften used together, the terms Business Continuity and Disaster Recovery are very different. Business Continuity refers to the ability of a business to continue critical functions and business processes after the occurrence of a disaster, whereas Disaster Recovery refers specifically to the Information Technology (IT) and data-centric functions of the business, and is a subset of Business \nContinuity.\n\n== Metrics ==\nThe primary objective is to protect the organization in the event that all or part of its operations and/or computer services are rendered partially or completely unusable. \n\nMinimizing downtime and data loss during disaster recovery is measured in terms of two concepts: \n\nRecovery Time Objective (RTO), time until a system is completely up and running\nRecovery Point Objective (RPO), a measure of the ability to recover files by specifying a point in time restore of the backup copy.\n\n== The auditor's role ==\nAn auditor examines and assesses \n\nthe procedures stated in the BCP and DR plan are actually consistent with real practice\na specific individual within the organization, who may be referred to as the disaster recovery officer, the disaster recovery liaison, the DR coordinator, or some other similar title, has the technical skills, training, experience, and abilities to analyze the capabilities of the team members to complete assigned tasks\nmore than one individual is trained and capable of doing a particular function during the Disaster Recovery exercise. Tests and inquiries of personnel can help achieve this objective.\n\n== Documentation ==\nTo maximize their effectiveness, disaster recovery plans are most effective when updated frequently, and should:\n\nbe an integral part of all business analysis processes,\nbe revisited at every major corporate acquisition, at every new product launch and at every new system development milestone.Adequate records need to be retained by the organization.  The auditor examines records, billings, and contracts to verify that records are being kept.  One such record is a current list of the organization's hardware and software vendors. Such list is made and periodically updated to reflect changing business practice. Copies of it are stored on and off site and are made available or accessible to those who require them.  An auditor tests the procedures used to meet this objective and determine their effectiveness.\n\n\n*** Disaster recovery plan ***\nA disaster recovery plan (DRP) is a documented process or set of procedures to \nexecute an organization's disaster recovery processes and recover and protect a business IT infrastructure in the event of a disaster.  It is \"a comprehensive statement of consistent actions to be taken before, during and after a disaster\". The disaster could be natural, environmental or man-made. Man-made disasters could be intentional (for example, an act of a terrorist) or unintentional (that is, accidental, such as the breakage of a man-made dam or even \"fat fingers\" - or errant commands entered - on a computer system).\n\n\n**** Types of plans ****\nAlthough there is no one-size-fits-all plan, there are three basic strategies:\nprevention, including proper backups, having surge protectors and generators\ndetection, a byproduct of routine inspections, which may discover new (potential) threats\ncorrectionThe latter may include securing proper insurance policies, and holding a \"lessons learned\" brainstorming session.\n\n\n*** Relationship to the Business Continuity Plan ***\nDisaster recovery is a subset of business continuity. Where DRP encompasses the policies, tools and procedures to enable recovery of data following a catastrophic event, business continuity planning (BCP) involves keeping all aspects of a business functioning regardless of potential disruptive events. As such, a business continuity plan is a comprehensive organizational strategy that includes the DRP as well as threat prevention, detection, recovery, and resumption of operations should a data breach or other disaster event occur. Therefore, BCP consists of five component plans:\nBusiness Resumption Plan\nOccupant Emergency Plan\nContinuity of Operations Plan\nIncident Management Plan\nDisaster Recovery PlanThe first three components (Business Resumption, Occupant Emergency, and Continuity of Operations Plans) do not deal with the IT infrastructure. The Incident Management Plan (IMP) does deal with the IT infrastructure, but since it establishes structure and procedures to address cyber attacks against an organization\u2019s IT systems, it generally does not represent an agent for activating the Disaster Recovery Plan, leaving The Disaster Recovery Plan as the only BCP component of interest to IT.\n\n== Benefits ==\nLike every insurance plan, there are benefits that can be obtained from proper business continuity planning, including:\nMinimizing risk of delays\nGuaranteeing the reliability of standby systems (even automating the failure detection and recovery in certain scenarios)\nProviding a standard for testing the plan\nMinimizing decision-making during a disaster\nReducing potential legal liabilities\nLowering unnecessarily stressful work environment\n\n\n*** Planning and testing methodology ***\nAccording to Geoffrey H. Wold of the Disaster Recovery Journal, the entire process involved in developing a Disaster Recovery Plan consists of 10 steps:\nPerforming a risk assessment: The planning committee prepares a risk analysis and a business impact analysis (BIA) that includes a range of possible disasters. Each functional area of the organization is analyzed to determine potential consequences. Traditionally, fire has posed the greatest threat. A thorough plan provides for \"worst case\" situations, such as destruction of the main building.\nEstablishing priorities for processing and operations: Critical needs of each department are evaluated and prioritized. Written agreements for alternatives selected are prepared, with details specifying duration, termination conditions, system testing, cost, any special security procedures, procedure for the notification of system changes, hours of operation, the specific hardware and other equipment required for processing, personnel requirements, definition of the circumstances constituting an emergency, process to negotiate service extensions, guarantee of compatibility, availability, non-mainframe resource requirements, priorities, and other contractual issues.\nCollecting data: This includes various lists (employee backup position listing, critical telephone numbers list, master call list, master vendor list, notification checklist), inventories (communications equipment, documentation, office equipment, forms, insurance policies, workgroup and data center computer hardware, microcomputer hardware and software, office supply, off-site storage location equipment, telephones, etc.), distribution register, software and data files backup/retention schedules, temporary location specifications, any other such lists, materials, inventories, and documentation. Pre-formatted forms are often used to facilitate the data gathering process.\nOrganizing and documenting a written plan\nDeveloping testing criteria and procedures: reasons for testing include\nDetermining the feasibility and compatibility of backup facilities and procedures.\nIdentifying areas in the plan that need modification.\nProviding training to the team managers and team members.\nDemonstrating the ability of the organization to recover.\nProviding motivation for maintaining and updating the disaster recovery plan.\nTesting the plan: An initial \"dry run\" of the plan is performed by conducting a structured walk-through test. An actual test-run must be performed. Problems are corrected.Initial testing can be plan is done in sections and after normal business hours to minimize disruptions.\nSubsequent tests occur during normal business hours.\nTypes of tests include: checklist tests, simulation tests, parallel tests, and full interruption tests.\n\n\n*** Caveats/controversies ***\nDue to high cost, various  plans are not without critics. Dell has identified five \"common mistakes\" organizations often make related to BCP/DR planning:\nLack of buy-in: When executive management sees DR planning as \"just another fake earthquake drill\" or CEOs fail to make DR planning and preparation a priority\nIncomplete RTOs and RPOs: Failure to include each and every important business process or a block of data. Ripples can extend a disaster's impact. Payroll may not initially be mission-critical, but left alone for several days, it can become more important than any of your initial problems.\nSystems myopia: A third point of failure involves focusing only on DR without considering the larger business continuity needs. Corporate office space lost to a disaster can result in an instant pool of teleworkers which, in turn, can overload a company's VPN overnight, overwork the IT support staff at the blink of an eye and cause serious bottlenecks and monopolies with the dial-in PBX system.\nLax security: When there is a disaster, an organization's data and business processes become vulnerable. As such, security can be more important than the raw speed involved in a disaster recovery plan's RTO. The most critical consideration then becomes securing the new data pipelines: from new VPNs to the connection from offsite backup services.\nIn disasters, planning for post-mortem forensics\nLocking down or remotely wiping lost handheld devices\n\n== Decisions and strategies ==\nSite designation:  hot site vs. cold site.  A hot site is fully equipped to resume operations while a cold site does not have that capability.  A warm site has the capability to resume some, but not all operations.A cost-benefit analysis is needed.\nOccasional tests and trials verify the viability and effectiveness of the plan.  An auditor looks into the probability that operations of the organization can be sustained at the level that is assumed in the plan, and the ability of the entity to actually establish operations at the site.\nThe auditor can verify this through paper and paperless documentation and actual physical observation. The security of the storage site is also confirmed.Data backup: An audit of backup processes determines if (a) they are effective, and (b) if they are actually being implemented by the involved personnel.The disaster recovery plan also includes information on how best to recover any data that has not been copied. Controls and protections are put in place to ensure that data is not damaged, altered, or destroyed during this process.Drills: Practice drills conducted periodically to determine how effective the plan is and to determine what changes may be necessary.  The auditor\u2019s primary concern here is verifying that these drills are being conducted properly and that problems uncovered during these drills are addressed.\nBackup of key personnel - including periodic training, cross-training, and personnel redundancy.\n\n== Other considerations ==\n\n\n*** Insurance issues ***\nThe auditor determines the adequacy of the company's insurance coverage (particularly property and casualty insurance) through a review of the company's insurance policies and other research.  Among the items that the auditor needs to verify are: the scope of the policy (including any stated exclusions), that the amount of coverage is sufficient to cover the organization\u2019s needs, and that the policy is current and in force. The auditor also ascertains, through a review of the ratings assigned by independent rating agencies, that the insurance company or companies providing the coverage have the financial viability to cover the losses in the event of a disaster.\nEffective DR plans take into account the extent of a company's responsibilities to other entities and its ability to fulfill those commitments despite a major disaster.  A good DR audit will include a review of existing MOA and contracts to ensure that the organization's legal liability for lack of performance in the event of disaster or any other unusual circumstance is minimized. Agreements pertaining to establishing support and assisting with recovery for the entity are also outlined. Techniques used for evaluating this area include an examination of the reasonableness of the plan, a determination of whether or not the plan takes all factors into account, and a verification of the contracts and agreements reasonableness through documentation and outside research.\n\n\n*** Communication issues ***\nThe auditor must verify that planning ensures that both management and the recovery team have effective communication hardware, contact information for both internal communication and external issues, such as business partners and key customers. \nAudit techniques include \n\ntesting of procedures, interviewing  employees, making comparison against the plans of other company and against industry standards,\nexamining company manuals and other written procedures.\ndirect observation that emergency telephone numbers are listed and easily accessible in the event of a disaster.\n\n\n*** Emergency procedures ***\nProcedures to sustain staff during a round-the clock disaster recovery effort are included in any good disaster recovery plan. Procedures for the stocking of food and water, capabilities of administering CPR/first aid, and dealing with family emergencies are clearly written and tested.  This can generally be accomplished by the company through good training programs and a clear definition of job responsibilities.  A review of the readiness capacity of a plan often includes tasks such as inquires of personnel, direct physical observation, and examination of training records and any certifications.\n\n\n*** Environmental issues ***\nThe auditor must review procedures that take into account the possibility of power failures or other situations that are of a non-IT nature.  \n\nFlashlights and candles may be needed.\nSafety procedures in case of gas leaks, fires or other such phenomena and PPE may be needed.\n\nQuestion: How does a disaster recovery plan address emergency procedures?\n\nAnswer:",
    "context": "",
    "output": "A disaster recovery plan addresses emergency procedures by including procedures to sustain staff during a round-the clock disaster recovery effort. This includes procedures for the stocking of food and water, capabilities of administering CPR/first aid, and dealing with family emergencies. These procedures are clearly written and tested, and can be accomplished by the company through good training programs and a clear definition of job responsibilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a disaster recovery plan address emergency procedures?",
      "answer": "A disaster recovery plan addresses emergency procedures by including procedures to sustain staff during a round-the clock disaster recovery effort. This includes procedures for the stocking of food and water, capabilities of administering CPR/first aid, and dealing with family emergencies. These procedures are clearly written and tested, and can be accomplished by the company through good training programs and a clear definition of job responsibilities.",
      "context": "Disaster recovery and business continuity auditing\n\n==Introduction==\nGiven organizations' increasing dependency on information technology to run their operations, Business continuity planning covers the entire organization, and Disaster recovery focuses on IT.\nAuditing of documents covering an organization's business continuity  and disaster recovery plans provides a third-party validation to stakeholders that the documentation is complete and does not contain material misrepresentations.\nLack of completeness can result in overlooking secondary effects, such as when vastly increased work-at-home overloads incoming recovery site telecommunications capacity, and the bi-weekly payroll that was not critical within the first 48 hours is now causing perceived problems in ever recovering, complicated by  governmental and possibly union reaction.\n\n== Overview ==\nOften used together, the terms Business Continuity and Disaster Recovery are very different. Business Continuity refers to the ability of a business to continue critical functions and business processes after the occurrence of a disaster, whereas Disaster Recovery refers specifically to the Information Technology (IT) and data-centric functions of the business, and is a subset of Business \nContinuity.\n\n== Metrics ==\nThe primary objective is to protect the organization in the event that all or part of its operations and/or computer services are rendered partially or completely unusable. \n\nMinimizing downtime and data loss during disaster recovery is measured in terms of two concepts: \n\nRecovery Time Objective (RTO), time until a system is completely up and running\nRecovery Point Objective (RPO), a measure of the ability to recover files by specifying a point in time restore of the backup copy.\n\n== The auditor's role ==\nAn auditor examines and assesses \n\nthe procedures stated in the BCP and DR plan are actually consistent with real practice\na specific individual within the organization, who may be referred to as the disaster recovery officer, the disaster recovery liaison, the DR coordinator, or some other similar title, has the technical skills, training, experience, and abilities to analyze the capabilities of the team members to complete assigned tasks\nmore than one individual is trained and capable of doing a particular function during the Disaster Recovery exercise. Tests and inquiries of personnel can help achieve this objective.\n\n== Documentation ==\nTo maximize their effectiveness, disaster recovery plans are most effective when updated frequently, and should:\n\nbe an integral part of all business analysis processes,\nbe revisited at every major corporate acquisition, at every new product launch and at every new system development milestone.Adequate records need to be retained by the organization.  The auditor examines records, billings, and contracts to verify that records are being kept.  One such record is a current list of the organization's hardware and software vendors. Such list is made and periodically updated to reflect changing business practice. Copies of it are stored on and off site and are made available or accessible to those who require them.  An auditor tests the procedures used to meet this objective and determine their effectiveness.\n\n\n*** Disaster recovery plan ***\nA disaster recovery plan (DRP) is a documented process or set of procedures to \nexecute an organization's disaster recovery processes and recover and protect a business IT infrastructure in the event of a disaster.  It is \"a comprehensive statement of consistent actions to be taken before, during and after a disaster\". The disaster could be natural, environmental or man-made. Man-made disasters could be intentional (for example, an act of a terrorist) or unintentional (that is, accidental, such as the breakage of a man-made dam or even \"fat fingers\" - or errant commands entered - on a computer system).\n\n\n**** Types of plans ****\nAlthough there is no one-size-fits-all plan, there are three basic strategies:\nprevention, including proper backups, having surge protectors and generators\ndetection, a byproduct of routine inspections, which may discover new (potential) threats\ncorrectionThe latter may include securing proper insurance policies, and holding a \"lessons learned\" brainstorming session.\n\n\n*** Relationship to the Business Continuity Plan ***\nDisaster recovery is a subset of business continuity. Where DRP encompasses the policies, tools and procedures to enable recovery of data following a catastrophic event, business continuity planning (BCP) involves keeping all aspects of a business functioning regardless of potential disruptive events. As such, a business continuity plan is a comprehensive organizational strategy that includes the DRP as well as threat prevention, detection, recovery, and resumption of operations should a data breach or other disaster event occur. Therefore, BCP consists of five component plans:\nBusiness Resumption Plan\nOccupant Emergency Plan\nContinuity of Operations Plan\nIncident Management Plan\nDisaster Recovery PlanThe first three components (Business Resumption, Occupant Emergency, and Continuity of Operations Plans) do not deal with the IT infrastructure. The Incident Management Plan (IMP) does deal with the IT infrastructure, but since it establishes structure and procedures to address cyber attacks against an organization\u2019s IT systems, it generally does not represent an agent for activating the Disaster Recovery Plan, leaving The Disaster Recovery Plan as the only BCP component of interest to IT.\n\n== Benefits ==\nLike every insurance plan, there are benefits that can be obtained from proper business continuity planning, including:\nMinimizing risk of delays\nGuaranteeing the reliability of standby systems (even automating the failure detection and recovery in certain scenarios)\nProviding a standard for testing the plan\nMinimizing decision-making during a disaster\nReducing potential legal liabilities\nLowering unnecessarily stressful work environment\n\n\n*** Planning and testing methodology ***\nAccording to Geoffrey H. Wold of the Disaster Recovery Journal, the entire process involved in developing a Disaster Recovery Plan consists of 10 steps:\nPerforming a risk assessment: The planning committee prepares a risk analysis and a business impact analysis (BIA) that includes a range of possible disasters. Each functional area of the organization is analyzed to determine potential consequences. Traditionally, fire has posed the greatest threat. A thorough plan provides for \"worst case\" situations, such as destruction of the main building.\nEstablishing priorities for processing and operations: Critical needs of each department are evaluated and prioritized. Written agreements for alternatives selected are prepared, with details specifying duration, termination conditions, system testing, cost, any special security procedures, procedure for the notification of system changes, hours of operation, the specific hardware and other equipment required for processing, personnel requirements, definition of the circumstances constituting an emergency, process to negotiate service extensions, guarantee of compatibility, availability, non-mainframe resource requirements, priorities, and other contractual issues.\nCollecting data: This includes various lists (employee backup position listing, critical telephone numbers list, master call list, master vendor list, notification checklist), inventories (communications equipment, documentation, office equipment, forms, insurance policies, workgroup and data center computer hardware, microcomputer hardware and software, office supply, off-site storage location equipment, telephones, etc.), distribution register, software and data files backup/retention schedules, temporary location specifications, any other such lists, materials, inventories, and documentation. Pre-formatted forms are often used to facilitate the data gathering process.\nOrganizing and documenting a written plan\nDeveloping testing criteria and procedures: reasons for testing include\nDetermining the feasibility and compatibility of backup facilities and procedures.\nIdentifying areas in the plan that need modification.\nProviding training to the team managers and team members.\nDemonstrating the ability of the organization to recover.\nProviding motivation for maintaining and updating the disaster recovery plan.\nTesting the plan: An initial \"dry run\" of the plan is performed by conducting a structured walk-through test. An actual test-run must be performed. Problems are corrected.Initial testing can be plan is done in sections and after normal business hours to minimize disruptions.\nSubsequent tests occur during normal business hours.\nTypes of tests include: checklist tests, simulation tests, parallel tests, and full interruption tests.\n\n\n*** Caveats/controversies ***\nDue to high cost, various  plans are not without critics. Dell has identified five \"common mistakes\" organizations often make related to BCP/DR planning:\nLack of buy-in: When executive management sees DR planning as \"just another fake earthquake drill\" or CEOs fail to make DR planning and preparation a priority\nIncomplete RTOs and RPOs: Failure to include each and every important business process or a block of data. Ripples can extend a disaster's impact. Payroll may not initially be mission-critical, but left alone for several days, it can become more important than any of your initial problems.\nSystems myopia: A third point of failure involves focusing only on DR without considering the larger business continuity needs. Corporate office space lost to a disaster can result in an instant pool of teleworkers which, in turn, can overload a company's VPN overnight, overwork the IT support staff at the blink of an eye and cause serious bottlenecks and monopolies with the dial-in PBX system.\nLax security: When there is a disaster, an organization's data and business processes become vulnerable. As such, security can be more important than the raw speed involved in a disaster recovery plan's RTO. The most critical consideration then becomes securing the new data pipelines: from new VPNs to the connection from offsite backup services.\nIn disasters, planning for post-mortem forensics\nLocking down or remotely wiping lost handheld devices\n\n== Decisions and strategies ==\nSite designation:  hot site vs. cold site.  A hot site is fully equipped to resume operations while a cold site does not have that capability.  A warm site has the capability to resume some, but not all operations.A cost-benefit analysis is needed.\nOccasional tests and trials verify the viability and effectiveness of the plan.  An auditor looks into the probability that operations of the organization can be sustained at the level that is assumed in the plan, and the ability of the entity to actually establish operations at the site.\nThe auditor can verify this through paper and paperless documentation and actual physical observation. The security of the storage site is also confirmed.Data backup: An audit of backup processes determines if (a) they are effective, and (b) if they are actually being implemented by the involved personnel.The disaster recovery plan also includes information on how best to recover any data that has not been copied. Controls and protections are put in place to ensure that data is not damaged, altered, or destroyed during this process.Drills: Practice drills conducted periodically to determine how effective the plan is and to determine what changes may be necessary.  The auditor\u2019s primary concern here is verifying that these drills are being conducted properly and that problems uncovered during these drills are addressed.\nBackup of key personnel - including periodic training, cross-training, and personnel redundancy.\n\n== Other considerations ==\n\n\n*** Insurance issues ***\nThe auditor determines the adequacy of the company's insurance coverage (particularly property and casualty insurance) through a review of the company's insurance policies and other research.  Among the items that the auditor needs to verify are: the scope of the policy (including any stated exclusions), that the amount of coverage is sufficient to cover the organization\u2019s needs, and that the policy is current and in force. The auditor also ascertains, through a review of the ratings assigned by independent rating agencies, that the insurance company or companies providing the coverage have the financial viability to cover the losses in the event of a disaster.\nEffective DR plans take into account the extent of a company's responsibilities to other entities and its ability to fulfill those commitments despite a major disaster.  A good DR audit will include a review of existing MOA and contracts to ensure that the organization's legal liability for lack of performance in the event of disaster or any other unusual circumstance is minimized. Agreements pertaining to establishing support and assisting with recovery for the entity are also outlined. Techniques used for evaluating this area include an examination of the reasonableness of the plan, a determination of whether or not the plan takes all factors into account, and a verification of the contracts and agreements reasonableness through documentation and outside research.\n\n\n*** Communication issues ***\nThe auditor must verify that planning ensures that both management and the recovery team have effective communication hardware, contact information for both internal communication and external issues, such as business partners and key customers. \nAudit techniques include \n\ntesting of procedures, interviewing  employees, making comparison against the plans of other company and against industry standards,\nexamining company manuals and other written procedures.\ndirect observation that emergency telephone numbers are listed and easily accessible in the event of a disaster.\n\n\n*** Emergency procedures ***\nProcedures to sustain staff during a round-the clock disaster recovery effort are included in any good disaster recovery plan. Procedures for the stocking of food and water, capabilities of administering CPR/first aid, and dealing with family emergencies are clearly written and tested.  This can generally be accomplished by the company through good training programs and a clear definition of job responsibilities.  A review of the readiness capacity of a plan often includes tasks such as inquires of personnel, direct physical observation, and examination of training records and any certifications.\n\n\n*** Environmental issues ***\nThe auditor must review procedures that take into account the possibility of power failures or other situations that are of a non-IT nature.  \n\nFlashlights and candles may be needed.\nSafety procedures in case of gas leaks, fires or other such phenomena and PPE may be needed."
    }
  },
  {
    "instruction": "context: Users can protect themselves by using unique passwords for each account, enabling two-factor authentication, and employing password managers to generate strong passwords.\n\nAsk a question about this context.",
    "context": "",
    "output": "What measures can users take to protect themselves against credential stuffing attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What measures can users take to protect themselves against credential stuffing attacks?",
      "answer": "Users can protect themselves by using unique passwords for each account, enabling two-factor authentication, and employing password managers to generate strong passwords."
    }
  },
  {
    "instruction": "context: The Honeynet Project uses unmodified computers with the same specifications, operating systems, and security as those used by many companies to gather data about hackers and their malicious software.\n\nAsk a question about this context.",
    "context": "",
    "output": "What types of systems does The Honeynet Project use to gather data about hackers and their malicious software?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What types of systems does The Honeynet Project use to gather data about hackers and their malicious software?",
      "answer": "The Honeynet Project uses unmodified computers with the same specifications, operating systems, and security as those used by many companies to gather data about hackers and their malicious software."
    }
  },
  {
    "instruction": "Key Management Interoperability Protocol\n\n==Introduction==\nThe Key Management Interoperability Protocol (KMIP) is an extensible communication protocol that defines message formats for the manipulation of cryptographic keys on a key management server. This facilitates data encryption by simplifying encryption key management. Keys may be created on a server and then retrieved, possibly wrapped by other keys. Both symmetric and asymmetric keys are supported, including the ability to sign certificates. KMIP also allows for clients to ask a server to encrypt or decrypt data, without needing direct access to the key.\nThe KMIP standard was first released in 2010. Clients and servers are commercially available from multiple vendors. The KMIP standard effort is governed by the OASIS standards body. Technical details can also be found on the official KMIP page and kmip wiki.\n\n== Description ==\nA KMIP server stores and controls Managed Objects like symmetric and asymmetric keys, certificates, and user defined objects. Clients then use the protocol for accessing these objects subject to a security model that is implemented by the servers. Operations are provided to create, locate, retrieve and update managed objects.\nEach managed object comprises an immutable Value like a key-block containing a cryptographic-key. These objects comprise mutable Attributes which can be used for storing metadata about their keys. Some attributes are derived directly from the Value, like the cryptographic-algorithm and key-length. Other attributes are defined in the specification for the management of objects like the Application-Specific Identifier which is usually derived from tape-identification data. Additional identifiers can be defined by the server or client per application need.\nEach object is identified by a unique and immutable object-identifier generated by the server and is used for getting object-values. Managed-objects may also be given a number of mutable yet globally unique Name attribute which can be used for Locating objects.\n\n\n*** Objects ***\nThe types of managed-objects being managed by KMIP include:\n\nSymmetric-Keys used for algorithms like AES.\nPublic and Private Keys used for asymmetric-algorithms like RSA and ECDH. Separate objects are used for storing the public and private key, thus a user may have permission to access one but not the other.  Related objects usually contain Link attributes containing the other object's unique identifier.\nCertificates and PGP Keys.\nSplit Keys, with each split being a distinct object that can be managed independently from the other splits.\nSecret Data, such as passwords.\nOpaque Data for client and server defined extensions.\nCertificate Signing Requests.\n\n\n*** Operations ***\nThe operations provided by KMIP include:\n\nCreate, creating a new managed object such as a symmetric key, and return the identifier.\nCreate Key Pair, creating two objects that represent asymmetric keys.\nGet, retrieving an object's value given its unique identifier.  The returned value may be wrapped (encrypted) with another key that is on the server for additional security.\nRegister, storing an externally generated key value.\nAdd Attributes, Get Attributes, Modify Attributes and Set Attribute.  These can be used to manipulate mutable attributes of a managed object.\nLocate, retrieving a list of objects based on a predicates.\nRe-Key, creating a new key that can replace an existing key.  There are also attributes that can be used to have the server automatically rotate keys after a given period or number of uses.  The Name is moved to the new key and is normally used to retrieve a key for protection operations such as encrypt and sign.  The old key can also be retrieved using the Unique Identifier for process operations such as decryption and signature verification.\n(Re-)Certify - certifies a certificate.\nSplit and Join N of M keys.\nEncrypt, Decrypt, MAC etc. Cryptographic operations performed on the key management server. A key itself could be marked being not-Extractable, in which case its value never leaves the server.\nExport and Import keys to and from other KMIP servers.\nOperations to implement the NIST key life cycle.\n\n\n*** Key life cycle ***\nEach key has a cryptographic state defined by the National Institute of Standards and Technology (NIST). Keys are created in an Initial state, and must be Activated before they can be used. Keys may then be Deactivated and eventually Destroyed. A key may also be marked being Compromised.\nOperations are provided for manipulating Key-state in conformance with the NIST life-cycle guidelines. A Key-state may be interrogated using the State attribute or the attributes that record dates of each transformation such as Activation Date. Dates can be specified into the future thus keys automatically become unavailable for specified operations when they expire.\n\n\n*** Message structure ***\nKMIP is a stateless protocol in which messages are sent from a client to a server and then the client normally awaits on a reply. Each request may contain many operations thus enables the protocol to efficiently handle large numbers of keys.  There are also advanced features for processing requests asynchronously.\nThe KMIP protocol specifies several different types of encodings.  The main one is a type\u2013length\u2013value encoding of messages, called TTLV (tag, type, length, value). Nested TTLV structures allow for encoding of complex, multi-operation messages in a single binary message.\nThere are also well defined XML and JSON encodings of the protocol for environments where binary is not appropriate.  A very compact CBOR encoding is also provided for applications that require it.\nAll of these protocols are expected to be transmitted using TLS protocol in order to ensure integrity and security.  However, it is also possible to register and retrieve keys that are wrapped (encrypted) using another key on the server, which provides an additional level of security.\n\n\n*** System management ***\nKMIP provides standardized mechanisms to manage a KMIP server by suitably authorized administrative clients using System Objects.  \nUser objects can be created and authorized to perform specific operations on specific managed objects.  Both Managed Objects and Users can be assigned to groups, and those groups can form a hierarchy which facilitates efficient management of complex operating environments.\nKMIP also provides a provisioning system that facilitates providing end points with credentials using simple one time passwords.\nDefault values of attributes can be provided, so that simple clients need not specify cryptographic and other parameters.  For example, an administrative user might specify that all \"SecretAgent\" keys should be 192 bit  AES keys with  CBC block chaining.  A client then only needs to specify that they wish to create a \"SecretAgent\" key to have those defaults provided.  It is also possible to enforce constraints on key parameters that implement security policy.\n\n\n*** KMIP profiles ***\nKMIP also defines a set of profiles, which are subsets of the KMIP specification showing common usage for a particular context. A particular KMIP implementation is said to be conformant to a profile when it fulfills all the requirements set forth in a profile specification document. OASIS has put forth various profiles describing the requirements for compliance towards storage arrays and tape libraries, but any organization can create a profile.\n\n\n*** Relationship to PKCS#11 ***\nPKCS#11 is a C API used to control a hardware security module. PKCS#11 provides cryptographic operations to encrypt and decrypt, as well as operations for simple key management. There is considerable amount of overlap between the PKCS#11 API and the KMIP protocol.\nThe two standards were originally developed independently. PKCS#11 was created by RSA Security, but the standard is now also governed by an OASIS technical committee. It is the stated objective of both the PKCS#11 and KMIP committees to align the standards where practical. For example, the PKCS#11 Sensitive and Extractable attributes are being added to KMIP version 1.4. Many of the same people are on the technical committees of both KMIP and PKCS#11.\nKMIP 2.0 provides a standardized mechanism to transport PKCS#11 messages from clients to servers.  This can be used to target different PKCS#11 implementations without the need to recompile the programs that use it.\n\n== KMIP implementations ==\nThe OASIS KMIP Technical Committee maintains a list of known KMIP implementations, which can be found on the OASIS website. As of March 2017, there are 28 implementations and 61 KMIP products in this list.\n\n\n*** Interoperability between implementations ***\nThe KMIP standard is defined using a formal specification document, testcases, and profiles put forth by the OASIS KMIP technical committee. These documents are publicly available on the OASIS website.\n\nVendors demonstrate interoperability during a process organized by the OASIS KMIP technical committee in the months before each RSA security conference. These demonstrations are informally known as interops. KMIP interops have been held every year since 2010. The following chart shows the number of individual tests performed by each client and server vendor combination since 2012.\n\n== Example ==\nThe following shows the XML encoding of a request to Locate a key named \"MyKeyName\" and return its value wrapped in a different key with ID \"c6d14516-4d38-0644-b810-1913b9aef4da\".  (TTLV is a more common wire protocol, but XML is more human readable.)\n\n== Documentation ==\nDocumentation is freely available from the OASIS website. This includes the formal technical specification and a usage guide to assist people that are unfamiliar with the specification. A substantial library of test cases is also provided. These are used to test the interoperability of clients and servers, but they also provide concrete examples of the usage of each standard KMIP feature.\n\n== Version history ==\n\nQ: What is the role of the Application-Specific Identifier attribute in KMIP?",
    "context": "",
    "output": "A: The Application-Specific Identifier attribute in KMIP is used for storing metadata about keys, and it is usually derived from tape-identification data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Application-Specific Identifier attribute in KMIP?",
      "answer": "The Application-Specific Identifier attribute in KMIP is used for storing metadata about keys, and it is usually derived from tape-identification data.",
      "context": "Key Management Interoperability Protocol\n\n==Introduction==\nThe Key Management Interoperability Protocol (KMIP) is an extensible communication protocol that defines message formats for the manipulation of cryptographic keys on a key management server. This facilitates data encryption by simplifying encryption key management. Keys may be created on a server and then retrieved, possibly wrapped by other keys. Both symmetric and asymmetric keys are supported, including the ability to sign certificates. KMIP also allows for clients to ask a server to encrypt or decrypt data, without needing direct access to the key.\nThe KMIP standard was first released in 2010. Clients and servers are commercially available from multiple vendors. The KMIP standard effort is governed by the OASIS standards body. Technical details can also be found on the official KMIP page and kmip wiki.\n\n== Description ==\nA KMIP server stores and controls Managed Objects like symmetric and asymmetric keys, certificates, and user defined objects. Clients then use the protocol for accessing these objects subject to a security model that is implemented by the servers. Operations are provided to create, locate, retrieve and update managed objects.\nEach managed object comprises an immutable Value like a key-block containing a cryptographic-key. These objects comprise mutable Attributes which can be used for storing metadata about their keys. Some attributes are derived directly from the Value, like the cryptographic-algorithm and key-length. Other attributes are defined in the specification for the management of objects like the Application-Specific Identifier which is usually derived from tape-identification data. Additional identifiers can be defined by the server or client per application need.\nEach object is identified by a unique and immutable object-identifier generated by the server and is used for getting object-values. Managed-objects may also be given a number of mutable yet globally unique Name attribute which can be used for Locating objects.\n\n\n*** Objects ***\nThe types of managed-objects being managed by KMIP include:\n\nSymmetric-Keys used for algorithms like AES.\nPublic and Private Keys used for asymmetric-algorithms like RSA and ECDH. Separate objects are used for storing the public and private key, thus a user may have permission to access one but not the other.  Related objects usually contain Link attributes containing the other object's unique identifier.\nCertificates and PGP Keys.\nSplit Keys, with each split being a distinct object that can be managed independently from the other splits.\nSecret Data, such as passwords.\nOpaque Data for client and server defined extensions.\nCertificate Signing Requests.\n\n\n*** Operations ***\nThe operations provided by KMIP include:\n\nCreate, creating a new managed object such as a symmetric key, and return the identifier.\nCreate Key Pair, creating two objects that represent asymmetric keys.\nGet, retrieving an object's value given its unique identifier.  The returned value may be wrapped (encrypted) with another key that is on the server for additional security.\nRegister, storing an externally generated key value.\nAdd Attributes, Get Attributes, Modify Attributes and Set Attribute.  These can be used to manipulate mutable attributes of a managed object.\nLocate, retrieving a list of objects based on a predicates.\nRe-Key, creating a new key that can replace an existing key.  There are also attributes that can be used to have the server automatically rotate keys after a given period or number of uses.  The Name is moved to the new key and is normally used to retrieve a key for protection operations such as encrypt and sign.  The old key can also be retrieved using the Unique Identifier for process operations such as decryption and signature verification.\n(Re-)Certify - certifies a certificate.\nSplit and Join N of M keys.\nEncrypt, Decrypt, MAC etc. Cryptographic operations performed on the key management server. A key itself could be marked being not-Extractable, in which case its value never leaves the server.\nExport and Import keys to and from other KMIP servers.\nOperations to implement the NIST key life cycle.\n\n\n*** Key life cycle ***\nEach key has a cryptographic state defined by the National Institute of Standards and Technology (NIST). Keys are created in an Initial state, and must be Activated before they can be used. Keys may then be Deactivated and eventually Destroyed. A key may also be marked being Compromised.\nOperations are provided for manipulating Key-state in conformance with the NIST life-cycle guidelines. A Key-state may be interrogated using the State attribute or the attributes that record dates of each transformation such as Activation Date. Dates can be specified into the future thus keys automatically become unavailable for specified operations when they expire.\n\n\n*** Message structure ***\nKMIP is a stateless protocol in which messages are sent from a client to a server and then the client normally awaits on a reply. Each request may contain many operations thus enables the protocol to efficiently handle large numbers of keys.  There are also advanced features for processing requests asynchronously.\nThe KMIP protocol specifies several different types of encodings.  The main one is a type\u2013length\u2013value encoding of messages, called TTLV (tag, type, length, value). Nested TTLV structures allow for encoding of complex, multi-operation messages in a single binary message.\nThere are also well defined XML and JSON encodings of the protocol for environments where binary is not appropriate.  A very compact CBOR encoding is also provided for applications that require it.\nAll of these protocols are expected to be transmitted using TLS protocol in order to ensure integrity and security.  However, it is also possible to register and retrieve keys that are wrapped (encrypted) using another key on the server, which provides an additional level of security.\n\n\n*** System management ***\nKMIP provides standardized mechanisms to manage a KMIP server by suitably authorized administrative clients using System Objects.  \nUser objects can be created and authorized to perform specific operations on specific managed objects.  Both Managed Objects and Users can be assigned to groups, and those groups can form a hierarchy which facilitates efficient management of complex operating environments.\nKMIP also provides a provisioning system that facilitates providing end points with credentials using simple one time passwords.\nDefault values of attributes can be provided, so that simple clients need not specify cryptographic and other parameters.  For example, an administrative user might specify that all \"SecretAgent\" keys should be 192 bit  AES keys with  CBC block chaining.  A client then only needs to specify that they wish to create a \"SecretAgent\" key to have those defaults provided.  It is also possible to enforce constraints on key parameters that implement security policy.\n\n\n*** KMIP profiles ***\nKMIP also defines a set of profiles, which are subsets of the KMIP specification showing common usage for a particular context. A particular KMIP implementation is said to be conformant to a profile when it fulfills all the requirements set forth in a profile specification document. OASIS has put forth various profiles describing the requirements for compliance towards storage arrays and tape libraries, but any organization can create a profile.\n\n\n*** Relationship to PKCS#11 ***\nPKCS#11 is a C API used to control a hardware security module. PKCS#11 provides cryptographic operations to encrypt and decrypt, as well as operations for simple key management. There is considerable amount of overlap between the PKCS#11 API and the KMIP protocol.\nThe two standards were originally developed independently. PKCS#11 was created by RSA Security, but the standard is now also governed by an OASIS technical committee. It is the stated objective of both the PKCS#11 and KMIP committees to align the standards where practical. For example, the PKCS#11 Sensitive and Extractable attributes are being added to KMIP version 1.4. Many of the same people are on the technical committees of both KMIP and PKCS#11.\nKMIP 2.0 provides a standardized mechanism to transport PKCS#11 messages from clients to servers.  This can be used to target different PKCS#11 implementations without the need to recompile the programs that use it.\n\n== KMIP implementations ==\nThe OASIS KMIP Technical Committee maintains a list of known KMIP implementations, which can be found on the OASIS website. As of March 2017, there are 28 implementations and 61 KMIP products in this list.\n\n\n*** Interoperability between implementations ***\nThe KMIP standard is defined using a formal specification document, testcases, and profiles put forth by the OASIS KMIP technical committee. These documents are publicly available on the OASIS website.\n\nVendors demonstrate interoperability during a process organized by the OASIS KMIP technical committee in the months before each RSA security conference. These demonstrations are informally known as interops. KMIP interops have been held every year since 2010. The following chart shows the number of individual tests performed by each client and server vendor combination since 2012.\n\n== Example ==\nThe following shows the XML encoding of a request to Locate a key named \"MyKeyName\" and return its value wrapped in a different key with ID \"c6d14516-4d38-0644-b810-1913b9aef4da\".  (TTLV is a more common wire protocol, but XML is more human readable.)\n\n== Documentation ==\nDocumentation is freely available from the OASIS website. This includes the formal technical specification and a usage guide to assist people that are unfamiliar with the specification. A substantial library of test cases is also provided. These are used to test the interoperability of clients and servers, but they also provide concrete examples of the usage of each standard KMIP feature.\n\n== Version history =="
    }
  },
  {
    "instruction": "Context: IEEE P1363\n\n==Introduction==\nIEEE P1363 is an Institute of Electrical and Electronics Engineers (IEEE) standardization project for public-key cryptography. It includes specifications for:\n\nTraditional public-key cryptography (IEEE Std 1363-2000 and 1363a-2004)\nLattice-based public-key cryptography (IEEE Std 1363.1-2008)\nPassword-based public-key cryptography (IEEE Std 1363.2-2008)\nIdentity-based public-key cryptography using pairings (IEEE Std 1363.3-2013)The chair of the working group as of October 2008 is William Whyte of NTRU Cryptosystems, Inc., who has served since August 2001. Former chairs were Ari Singer, also of NTRU (1999\u20132001), and Burt Kaliski of RSA Security (1994\u20131999).\nThe IEEE Standard Association withdrew all of the 1363 standards except 1363.3-2013 on 7 November 2019.\n\n\n\n== Traditional public-key cryptography (IEEE Std 1363-2000 and 1363a-2004) ==\nThis specification includes key agreement, signature, and encryption\nschemes using several mathematical approaches: integer factorization,\ndiscrete logarithm, and elliptic curve discrete logarithm.\n\n\n*** Key agreement schemes ***\nDL/ECKAS-DH1 and DL/ECKAS-DH2 (Discrete Logarithm/Elliptic Curve Key Agreement Scheme, Diffie\u2013Hellman version): This includes both traditional Diffie\u2013Hellman and elliptic curve Diffie\u2013Hellman.\nDL/ECKAS-MQV (Discrete Logarithm/Elliptic Curve Key Agreement Scheme, Menezes\u2013Qu\u2013Vanstone version)\n\n\n*** Signature schemes ***\nDL/ECSSA (Discrete Logarithm/Elliptic Curve Signature Scheme with Appendix): Includes four main variants:  DSA, ECDSA, Nyberg-Rueppel, and Elliptic Curve Nyberg-Rueppel.\nIFSSA (Integer Factorization Signature Scheme with Appendix): Includes two variants of RSA, Rabin-Williams, and ESIGN, with several message encoding methods.  \"RSA1 with EMSA3\" is essentially PKCS#1 v1.5 RSA signature; \"RSA1 with EMSA4 encoding\" is essentially RSA-PSS; \"RSA1 with EMSA2 encoding\" is essentially ANSI X9.31 RSA signature.\nDL/ECSSR (Discrete Logarithm/Elliptic Curve Signature Scheme with Recovery)\nDL/ECSSR-PV (Discrete Logarithm/Elliptic Curve Signature Scheme with Recovery, Pintsov-Vanstone version)\nIFSSR (Integer Factorization Signature Scheme with Recovery)\n\n\n*** Encryption schemes ***\nIFES (Integer Factorization Encryption Scheme): Essentially RSA encryption with Optimal Asymmetric Encryption Padding (OAEP).\nDL/ECIES (Discrete Logarithm/Elliptic Curve Integrated Encryption Scheme): Essentially the \"DHAES\" variant of ElGamal encryption.\nIFES-EPOC (Integer Factorization Encryption Scheme, EPOC version)\n\n== Lattice-based public key cryptography (IEEE Std 1363.1-2008) ==\nNTRU encryption scheme\n\n== Password-based public-key cryptography (IEEE Std 1363.2-2008) ==\nThis document includes a number of password-authenticated key agreement schemes, and a password-authenticated key retrieval scheme.\n\nBPKAS-PAK (Balanced Password-Authenticated Key Agreement Scheme, version PAK)\nBPKAS-PPK (version PPK)\nBPKAS-SPEKE (version SPEKE)\nAPKAS-AMP (Augmented Password-Authenticated Key Agreement Scheme, version AMP)\nAPKAS-BSPEKE2 (version BSPEKE2)\nAPKAS-PAKZ (version PAKZ)\nAPKAS-SRP3 and SRP6 (version Secure Remote Password (SRP) 3 and 6)\nAPKAS-SRP5 (version Secure Remote Password (SRP) 5)\nAPKAS-WSPEKE (version WSPEKE)\nPKRS-1 (Password Authenticated Key Retrieval Scheme, version 1)\n\n== Identity-based public key cryptography based on pairings (IEEE Std 1363.3-2013) ==\nThis standard was published on 15 November 2013. It includes techniques for identity-based encryption, signatures, signcryption, key agreement, and proxy re-encryption, all based on bilinear pairings.\nAnswer this question: Which mathematical approaches are used in traditional public-key cryptography as per IEEE P1363?",
    "context": "",
    "output": "The mathematical approaches used in traditional public-key cryptography as per IEEE P1363 are integer factorization, discrete logarithm, and elliptic curve discrete logarithm.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which mathematical approaches are used in traditional public-key cryptography as per IEEE P1363?",
      "answer": "The mathematical approaches used in traditional public-key cryptography as per IEEE P1363 are integer factorization, discrete logarithm, and elliptic curve discrete logarithm.",
      "context": "IEEE P1363\n\n==Introduction==\nIEEE P1363 is an Institute of Electrical and Electronics Engineers (IEEE) standardization project for public-key cryptography. It includes specifications for:\n\nTraditional public-key cryptography (IEEE Std 1363-2000 and 1363a-2004)\nLattice-based public-key cryptography (IEEE Std 1363.1-2008)\nPassword-based public-key cryptography (IEEE Std 1363.2-2008)\nIdentity-based public-key cryptography using pairings (IEEE Std 1363.3-2013)The chair of the working group as of October 2008 is William Whyte of NTRU Cryptosystems, Inc., who has served since August 2001. Former chairs were Ari Singer, also of NTRU (1999\u20132001), and Burt Kaliski of RSA Security (1994\u20131999).\nThe IEEE Standard Association withdrew all of the 1363 standards except 1363.3-2013 on 7 November 2019.\n\n\n\n== Traditional public-key cryptography (IEEE Std 1363-2000 and 1363a-2004) ==\nThis specification includes key agreement, signature, and encryption\nschemes using several mathematical approaches: integer factorization,\ndiscrete logarithm, and elliptic curve discrete logarithm.\n\n\n*** Key agreement schemes ***\nDL/ECKAS-DH1 and DL/ECKAS-DH2 (Discrete Logarithm/Elliptic Curve Key Agreement Scheme, Diffie\u2013Hellman version): This includes both traditional Diffie\u2013Hellman and elliptic curve Diffie\u2013Hellman.\nDL/ECKAS-MQV (Discrete Logarithm/Elliptic Curve Key Agreement Scheme, Menezes\u2013Qu\u2013Vanstone version)\n\n\n*** Signature schemes ***\nDL/ECSSA (Discrete Logarithm/Elliptic Curve Signature Scheme with Appendix): Includes four main variants:  DSA, ECDSA, Nyberg-Rueppel, and Elliptic Curve Nyberg-Rueppel.\nIFSSA (Integer Factorization Signature Scheme with Appendix): Includes two variants of RSA, Rabin-Williams, and ESIGN, with several message encoding methods.  \"RSA1 with EMSA3\" is essentially PKCS#1 v1.5 RSA signature; \"RSA1 with EMSA4 encoding\" is essentially RSA-PSS; \"RSA1 with EMSA2 encoding\" is essentially ANSI X9.31 RSA signature.\nDL/ECSSR (Discrete Logarithm/Elliptic Curve Signature Scheme with Recovery)\nDL/ECSSR-PV (Discrete Logarithm/Elliptic Curve Signature Scheme with Recovery, Pintsov-Vanstone version)\nIFSSR (Integer Factorization Signature Scheme with Recovery)\n\n\n*** Encryption schemes ***\nIFES (Integer Factorization Encryption Scheme): Essentially RSA encryption with Optimal Asymmetric Encryption Padding (OAEP).\nDL/ECIES (Discrete Logarithm/Elliptic Curve Integrated Encryption Scheme): Essentially the \"DHAES\" variant of ElGamal encryption.\nIFES-EPOC (Integer Factorization Encryption Scheme, EPOC version)\n\n== Lattice-based public key cryptography (IEEE Std 1363.1-2008) ==\nNTRU encryption scheme\n\n== Password-based public-key cryptography (IEEE Std 1363.2-2008) ==\nThis document includes a number of password-authenticated key agreement schemes, and a password-authenticated key retrieval scheme.\n\nBPKAS-PAK (Balanced Password-Authenticated Key Agreement Scheme, version PAK)\nBPKAS-PPK (version PPK)\nBPKAS-SPEKE (version SPEKE)\nAPKAS-AMP (Augmented Password-Authenticated Key Agreement Scheme, version AMP)\nAPKAS-BSPEKE2 (version BSPEKE2)\nAPKAS-PAKZ (version PAKZ)\nAPKAS-SRP3 and SRP6 (version Secure Remote Password (SRP) 3 and 6)\nAPKAS-SRP5 (version Secure Remote Password (SRP) 5)\nAPKAS-WSPEKE (version WSPEKE)\nPKRS-1 (Password Authenticated Key Retrieval Scheme, version 1)\n\n== Identity-based public key cryptography based on pairings (IEEE Std 1363.3-2013) ==\nThis standard was published on 15 November 2013. It includes techniques for identity-based encryption, signatures, signcryption, key agreement, and proxy re-encryption, all based on bilinear pairings."
    }
  },
  {
    "instruction": "Write an answer to the following question: How are weak ETags used in cases where strong ETags are impractical?",
    "context": "",
    "output": "Weak ETags may be useful for cases in which strong ETags are impractical for a Web server to generate, such as with dynamically generated content.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are weak ETags used in cases where strong ETags are impractical?",
      "answer": "Weak ETags may be useful for cases in which strong ETags are impractical for a Web server to generate, such as with dynamically generated content."
    }
  },
  {
    "instruction": "Answer based on context:\n\nBolgimo\n\n==Introduction==\nBolgimo is a Win32 computer worm, a self-replicating computer program similar to a computer virus, which propagates by attempting to exploit unpatched Windows computers vulnerable to the  DCOM RPC Interface Buffer Overrun Vulnerability using TCP port 445 on a network.  The worm was discovered on November 10, 2003, and targets Windows NT, 2000 and XP Operating Systems.\nIf a target computer is successfully infected, the worm will call the user's attention to the fact that the machine is vulnerable, download the patch to the user's desktop and run the patch installer. The worm also attempts to shut down processes linked to other malware known to exploit the same vulnerability, like MSBlaster.\n\n\n\n== Aliases ==\nWorm.Win32.Bolgi      (Kaspersky)\nW32/Bolgimo.worm      (McAfee)\nW32.Bogi.Worm         (Symantec)\nWorm/Bolgi.A          (Avira)\nW32/Bolgi-A           (Sophos)\nWorm:Win32/Bolgimo.A  (Microsoft)\n\nIs Bolgimo still a threat to modern Windows operating systems?",
    "context": "",
    "output": "Bolgimo is not currently considered a threat to modern Windows operating systems, as it specifically targets Windows NT, 2000, and XP, which are no longer supported.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is Bolgimo still a threat to modern Windows operating systems?",
      "answer": "Bolgimo is not currently considered a threat to modern Windows operating systems, as it specifically targets Windows NT, 2000, and XP, which are no longer supported.",
      "context": "Bolgimo\n\n==Introduction==\nBolgimo is a Win32 computer worm, a self-replicating computer program similar to a computer virus, which propagates by attempting to exploit unpatched Windows computers vulnerable to the  DCOM RPC Interface Buffer Overrun Vulnerability using TCP port 445 on a network.  The worm was discovered on November 10, 2003, and targets Windows NT, 2000 and XP Operating Systems.\nIf a target computer is successfully infected, the worm will call the user's attention to the fact that the machine is vulnerable, download the patch to the user's desktop and run the patch installer. The worm also attempts to shut down processes linked to other malware known to exploit the same vulnerability, like MSBlaster.\n\n\n\n== Aliases ==\nWorm.Win32.Bolgi      (Kaspersky)\nW32/Bolgimo.worm      (McAfee)\nW32.Bogi.Worm         (Symantec)\nWorm/Bolgi.A          (Avira)\nW32/Bolgi-A           (Sophos)\nWorm:Win32/Bolgimo.A  (Microsoft)"
    }
  },
  {
    "instruction": "Write an answer to the following question: How much did the Onyx system cost and when was it launched?",
    "context": "",
    "output": "The costs of the Onyx system are not public, but it has been estimated to have cost around 400 million CHF. The system was launched in 2000.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How much did the Onyx system cost and when was it launched?",
      "answer": "The costs of the Onyx system are not public, but it has been estimated to have cost around 400 million CHF. The system was launched in 2000."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is one example of a verifiable computation scheme based on fully homomorphic encryption?",
    "context": "",
    "output": "One example of a verifiable computation scheme based on fully homomorphic encryption is the scheme defined by Gennaro et al. using Yao's garbled circuit combined with a fully homomorphic encryption system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is one example of a verifiable computation scheme based on fully homomorphic encryption?",
      "answer": "One example of a verifiable computation scheme based on fully homomorphic encryption is the scheme defined by Gennaro et al. using Yao's garbled circuit combined with a fully homomorphic encryption system."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can black-bag cryptanalysis be used to capture unencrypted plaintext?",
    "context": "",
    "output": "Black-bag cryptanalysis can be used to capture unencrypted plaintext by monitoring the electromagnetic emissions of computer displays or keyboards from a distance. This can allow an attacker to decode what has been typed and obtain the unencrypted plaintext.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can black-bag cryptanalysis be used to capture unencrypted plaintext?",
      "answer": "Black-bag cryptanalysis can be used to capture unencrypted plaintext by monitoring the electromagnetic emissions of computer displays or keyboards from a distance. This can allow an attacker to decode what has been typed and obtain the unencrypted plaintext."
    }
  },
  {
    "instruction": "Write an answer to the following question: What modifications does Slenfbot make to the hosts file?",
    "context": "",
    "output": "Slenfbot modifies the hosts file by replacing %SYSTEM%\\drivers\\etc.\\hosts with a file of its own, which contains several entries to point various anti-virus and security related domains to localhost (i.e. 127.0.0.1) or to a random IP address.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What modifications does Slenfbot make to the hosts file?",
      "answer": "Slenfbot modifies the hosts file by replacing %SYSTEM%\\drivers\\etc.\\hosts with a file of its own, which contains several entries to point various anti-virus and security related domains to localhost (i.e. 127.0.0.1) or to a random IP address."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the PGP Virtual Disk system provide secure storage for confidential data, and what are the advantages of using it compared to other disk encryption methods?",
    "context": "",
    "output": "The PGP Virtual Disk system provides secure storage for confidential data by encrypting the disk within a file, making it difficult for unauthorized users to access the data. Compared to other disk encryption methods, PGP Virtual Disk offers the advantage of being able to store encrypted data within a single file, making it easier to manage and transport. Additionally, PGP Virtual Disk is part of the PGP Desktop product family, which provides users with enhanced security features, regular updates, and compatibility with modern operating systems.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the PGP Virtual Disk system provide secure storage for confidential data, and what are the advantages of using it compared to other disk encryption methods?",
      "answer": "The PGP Virtual Disk system provides secure storage for confidential data by encrypting the disk within a file, making it difficult for unauthorized users to access the data. Compared to other disk encryption methods, PGP Virtual Disk offers the advantage of being able to store encrypted data within a single file, making it easier to manage and transport. Additionally, PGP Virtual Disk is part of the PGP Desktop product family, which provides users with enhanced security features, regular updates, and compatibility with modern operating systems."
    }
  },
  {
    "instruction": "Strengthening State and Local Cyber Crime Fighting Act of 2017\n\n==Introduction==\nThe Strengthening State and Local Cyber Crime Fighting Act of 2017 (H.R. 1616) is a bill introduced in the United States House of Representatives by U.S. Representative John Ratcliffe (R-Texas). The bill would amend the Homeland Security Act of 2002 to authorize the National Computer Forensics Institute, with the intent of providing local and state officials with resources to better handle cybercrime threats. Ratcliffe serves as the current chairman of the House Homeland Security Subcommittee on Cybersecurity and Infrastructure Protection.The bill was passed by the House with a roll call vote of 408-3 after forty minutes of debate. Between its introduction and approval, the bill was referred to the Committee on the Judiciary, the Committee on Homeland Security, the Subcommittee on Transportation and Protective Security, and the Subcommittee on Crime, Terrorism, Homeland Security, and Investigations.The bill has a total of 18 cosponsors, including 17 Republicans and one Democrat.Ratcliffe introduced the bill because he believes that local and state level law enforcement entities should be better equipped to handle emerging cyber threats in order to protect communities. He expressed concern that in today's world, traditional evidence of crimes, like DNA samples, might not be enough to solve cases, because criminals are more frequently breaking the law and leaving behind traces on the internet. In March 2017, Ratcliffe said, \"Cyber elements add layers of complexity to the crimes our local law enforcement officers face every day \u2012 and we've got to make sure they have access to the training they need to address this trend.\"As of July 2017, the Senate has not yet considered the bill, although Senators Chuck Grassley (R-Iowa), Dianne Feinstein (D-California), Richard Shelby (R-Alabama), Sheldon Whitehouse (D-Rhode Island), and Luther Strange (R-Alabama) introduced a companion bill.Senator Grassley, current Senate Judiciary Committee Chairman, supported the role of the National Computer Forensics Institute and the purpose of Ratcliffe's bill, saying the center gives officials the capacity to \"dust for 'digital fingerprints' and utilize forensics to gather evidence and solve cases.\"\n\n\n\n== Background ==\n\nAs the internet has grown increasingly dominant in communications, business, and daily life, cybercrime has become a more dangerous threat to privacy and safety of both public and private entities. Americans recognize this issue, as they identified cyberattacks as the second most concerning global threat to the nation in a May 2016 survey conducted by Pew Research.\nThe federal government has fallen victim to cyber attacks numerous times, especially in recent years. A 2016 report from the Government Accountability Office that included a survey of two dozen federal agencies found that cyberattacks exploded in frequency by 1,300 percent over the course of a decade, with 5,500 in 2006 to as many as 77,000 in 2015. The report listed eighteen of the agencies as operators of \"high-impact systems\", meaning that leaks could cause \"catastrophic harm\" to particular individuals, the government, or the general public.In May 2015, hackers accessed tax returns of over 300,000 people during an attack on the Internal Revenue Service, which led to the distribution of over $50 million in fraudulent refunds. Since 2007, federal agencies have dealt with at least a dozen attacks on their systems. Social Security information, home addresses, health records, and other personal data has been stolen from millions of people, including elected officials.Hackers from foreign countries have played a significant role in cyber attacks against the United States. The FBI, CIA, NSA and the Office of the Director of National Intelligence agreed that Russian hackers were behind an infiltration of the Democratic National Committee's data during the 2016 United States presidential election.NBC News obtained a document from the National Security Agency that detailed a five-year period of Chinese hacking of government information, which ended in 2014.Private groups and businesses have also been damaged by cybercrime. Cyberattacks cost American companies more than $15 million per year. The United States loses 500,000 jobs on an annual basis due to cyberattacks. More than 50 percent of all cyberattacks are launched against American companies, leading to a loss of $100 billion in the economy each year. A Citibank ATM server attack in 2008 lead to the loss of $2 million, and a Sony hack in 2014 lead to the loss of $15 million. In 2014 alone, 44% of all small businesses in the United States were attacked, which resulted in affected companies losing an average of $8,700 each.Ratcliffe and supporters of the bill aim to better equip all levels of the government to handle the increasing cyber threats that challenge both the government and American businesses and private citizens. U.S. Representative Dan Donovan (R-NY), who voted in favor of the bill, said, \"It's critical that our law enforcement agencies have the information and training they need to respond to threats. This legislation will help increase coordination between the brave men and women who defend us on the local, state, and federal level and ensure that they have the tools needed to protect the homeland.\"The National Computer Forensics Institute has proven vital in this effort, having already worked with over 6,250 officials coming from all 50 states and even three United States territories.Representative Bob Goodlatte (R-VA), House Judiciary Committee chairman, said the NCFI would benefit from a clear congressional mandate. \"Authorizing the existing National Computer Forensics Institute in federal law will cement its position as our nation's premier hi-tech cyber crime training facility.\"\n\n== Major provisions ==\nThe objective of the bill is to authorize the National Computer Forensics Institute so that the center can \"disseminate homeland security information related to the investigation and prevention of cyber and electronic crime and related threats, and educate, train, and equip State, local, tribal, and territorial law enforcement officers, prosecutors, and judges.\" The bill aims to achieve this through amending the Homeland Security Act of 2002.While the National Computer Forensics Institute, based in Hoover, Alabama, has been open since 2008, the bill would ensure proper oversight and accountability, solidifying the center's position as the optimal site for training law enforcement to mitigate cyber threats.The bill establishes that the operations of the National Computer Forensics Institute are to:\nEducate law enforcement officers at all levels of government, including local, state, territorial, and tribal forces on threats related to cybercrime.\nInstruct law enforcement personnel, about proper investigation methods, device examination techniques, and potential prosecutorial and judicial challenges.\nTrain law enforcement officers to carry out investigations and respond in a necessary manner to reported incidents of cybercrime.\nFacilitate the sharing of information between State, local, tribal and territorial officers and prosecutors.\nProvide materials like hardware, software, manuals, tools, and other items to law enforcement to conduct investigations.\nExpand the Electronic Crime Task Forces of the United States Secret Service through continuous training of officers.The NCFI would continue to be operated by the U.S. Secret Service, within the Department of Homeland Security. The network of Electronic Crime Task Forces would include stakeholders from academic institutions and the private sector under the expansion sanctioned by the authorization of the NCFI.\n\n== Legislative history ==\nDuring the 114th Congress, an earlier version of the bill was passed in the U.S. House on November 30, 2015. On December 1, 2015, the bill was received in the Senate and referred to the Committee on the Judiciary. No further action was taken.\nOn March 17, 2017, Ratcliffe introduced the bill in the House. After introduction:\n3/17/17 - Referred to the Committee on the Judiciary and Committee on Homeland Security.\n3/29/17 - Referred to the Subcommittee on Transportation and Protective Security by the Committee on Homeland Security.\n3/31/17 - Referred to the Subcommittee on Crime, Terrorism, Homeland Security, and Investigations by the Committee on the Judiciary.\n5/16/17 - The House passed the bill on motion to suspend the rules and pass the bill as amended with a vote of 403 Yeas and 8 Nays.\n5/17/17 - The Senate received the bill, read it twice, and referred it to the Committee on the Judiciary.\n\nAnswer this question based on the above context: How does the Strengthening State and Local Cyber Crime Fighting Act of 2017 aim to help local and state law enforcement entities handle emerging cyber threats?",
    "context": "",
    "output": "The Strengthening State and Local Cyber Crime Fighting Act of 2017 aims to help local and state law enforcement entities handle emerging cyber threats by amending the Homeland Security Act of 2002 to authorize the National Computer Forensics Institute. The Institute would provide resources, training, and education to officials to better equip them in dealing with cybercrime threats.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Strengthening State and Local Cyber Crime Fighting Act of 2017 aim to help local and state law enforcement entities handle emerging cyber threats?",
      "answer": "The Strengthening State and Local Cyber Crime Fighting Act of 2017 aims to help local and state law enforcement entities handle emerging cyber threats by amending the Homeland Security Act of 2002 to authorize the National Computer Forensics Institute. The Institute would provide resources, training, and education to officials to better equip them in dealing with cybercrime threats.",
      "context": "Strengthening State and Local Cyber Crime Fighting Act of 2017\n\n==Introduction==\nThe Strengthening State and Local Cyber Crime Fighting Act of 2017 (H.R. 1616) is a bill introduced in the United States House of Representatives by U.S. Representative John Ratcliffe (R-Texas). The bill would amend the Homeland Security Act of 2002 to authorize the National Computer Forensics Institute, with the intent of providing local and state officials with resources to better handle cybercrime threats. Ratcliffe serves as the current chairman of the House Homeland Security Subcommittee on Cybersecurity and Infrastructure Protection.The bill was passed by the House with a roll call vote of 408-3 after forty minutes of debate. Between its introduction and approval, the bill was referred to the Committee on the Judiciary, the Committee on Homeland Security, the Subcommittee on Transportation and Protective Security, and the Subcommittee on Crime, Terrorism, Homeland Security, and Investigations.The bill has a total of 18 cosponsors, including 17 Republicans and one Democrat.Ratcliffe introduced the bill because he believes that local and state level law enforcement entities should be better equipped to handle emerging cyber threats in order to protect communities. He expressed concern that in today's world, traditional evidence of crimes, like DNA samples, might not be enough to solve cases, because criminals are more frequently breaking the law and leaving behind traces on the internet. In March 2017, Ratcliffe said, \"Cyber elements add layers of complexity to the crimes our local law enforcement officers face every day \u2012 and we've got to make sure they have access to the training they need to address this trend.\"As of July 2017, the Senate has not yet considered the bill, although Senators Chuck Grassley (R-Iowa), Dianne Feinstein (D-California), Richard Shelby (R-Alabama), Sheldon Whitehouse (D-Rhode Island), and Luther Strange (R-Alabama) introduced a companion bill.Senator Grassley, current Senate Judiciary Committee Chairman, supported the role of the National Computer Forensics Institute and the purpose of Ratcliffe's bill, saying the center gives officials the capacity to \"dust for 'digital fingerprints' and utilize forensics to gather evidence and solve cases.\"\n\n\n\n== Background ==\n\nAs the internet has grown increasingly dominant in communications, business, and daily life, cybercrime has become a more dangerous threat to privacy and safety of both public and private entities. Americans recognize this issue, as they identified cyberattacks as the second most concerning global threat to the nation in a May 2016 survey conducted by Pew Research.\nThe federal government has fallen victim to cyber attacks numerous times, especially in recent years. A 2016 report from the Government Accountability Office that included a survey of two dozen federal agencies found that cyberattacks exploded in frequency by 1,300 percent over the course of a decade, with 5,500 in 2006 to as many as 77,000 in 2015. The report listed eighteen of the agencies as operators of \"high-impact systems\", meaning that leaks could cause \"catastrophic harm\" to particular individuals, the government, or the general public.In May 2015, hackers accessed tax returns of over 300,000 people during an attack on the Internal Revenue Service, which led to the distribution of over $50 million in fraudulent refunds. Since 2007, federal agencies have dealt with at least a dozen attacks on their systems. Social Security information, home addresses, health records, and other personal data has been stolen from millions of people, including elected officials.Hackers from foreign countries have played a significant role in cyber attacks against the United States. The FBI, CIA, NSA and the Office of the Director of National Intelligence agreed that Russian hackers were behind an infiltration of the Democratic National Committee's data during the 2016 United States presidential election.NBC News obtained a document from the National Security Agency that detailed a five-year period of Chinese hacking of government information, which ended in 2014.Private groups and businesses have also been damaged by cybercrime. Cyberattacks cost American companies more than $15 million per year. The United States loses 500,000 jobs on an annual basis due to cyberattacks. More than 50 percent of all cyberattacks are launched against American companies, leading to a loss of $100 billion in the economy each year. A Citibank ATM server attack in 2008 lead to the loss of $2 million, and a Sony hack in 2014 lead to the loss of $15 million. In 2014 alone, 44% of all small businesses in the United States were attacked, which resulted in affected companies losing an average of $8,700 each.Ratcliffe and supporters of the bill aim to better equip all levels of the government to handle the increasing cyber threats that challenge both the government and American businesses and private citizens. U.S. Representative Dan Donovan (R-NY), who voted in favor of the bill, said, \"It's critical that our law enforcement agencies have the information and training they need to respond to threats. This legislation will help increase coordination between the brave men and women who defend us on the local, state, and federal level and ensure that they have the tools needed to protect the homeland.\"The National Computer Forensics Institute has proven vital in this effort, having already worked with over 6,250 officials coming from all 50 states and even three United States territories.Representative Bob Goodlatte (R-VA), House Judiciary Committee chairman, said the NCFI would benefit from a clear congressional mandate. \"Authorizing the existing National Computer Forensics Institute in federal law will cement its position as our nation's premier hi-tech cyber crime training facility.\"\n\n== Major provisions ==\nThe objective of the bill is to authorize the National Computer Forensics Institute so that the center can \"disseminate homeland security information related to the investigation and prevention of cyber and electronic crime and related threats, and educate, train, and equip State, local, tribal, and territorial law enforcement officers, prosecutors, and judges.\" The bill aims to achieve this through amending the Homeland Security Act of 2002.While the National Computer Forensics Institute, based in Hoover, Alabama, has been open since 2008, the bill would ensure proper oversight and accountability, solidifying the center's position as the optimal site for training law enforcement to mitigate cyber threats.The bill establishes that the operations of the National Computer Forensics Institute are to:\nEducate law enforcement officers at all levels of government, including local, state, territorial, and tribal forces on threats related to cybercrime.\nInstruct law enforcement personnel, about proper investigation methods, device examination techniques, and potential prosecutorial and judicial challenges.\nTrain law enforcement officers to carry out investigations and respond in a necessary manner to reported incidents of cybercrime.\nFacilitate the sharing of information between State, local, tribal and territorial officers and prosecutors.\nProvide materials like hardware, software, manuals, tools, and other items to law enforcement to conduct investigations.\nExpand the Electronic Crime Task Forces of the United States Secret Service through continuous training of officers.The NCFI would continue to be operated by the U.S. Secret Service, within the Department of Homeland Security. The network of Electronic Crime Task Forces would include stakeholders from academic institutions and the private sector under the expansion sanctioned by the authorization of the NCFI.\n\n== Legislative history ==\nDuring the 114th Congress, an earlier version of the bill was passed in the U.S. House on November 30, 2015. On December 1, 2015, the bill was received in the Senate and referred to the Committee on the Judiciary. No further action was taken.\nOn March 17, 2017, Ratcliffe introduced the bill in the House. After introduction:\n3/17/17 - Referred to the Committee on the Judiciary and Committee on Homeland Security.\n3/29/17 - Referred to the Subcommittee on Transportation and Protective Security by the Committee on Homeland Security.\n3/31/17 - Referred to the Subcommittee on Crime, Terrorism, Homeland Security, and Investigations by the Committee on the Judiciary.\n5/16/17 - The House passed the bill on motion to suspend the rules and pass the bill as amended with a vote of 403 Yeas and 8 Nays.\n5/17/17 - The Senate received the bill, read it twice, and referred it to the Committee on the Judiciary."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does P2PRIV ensure high-speed anonymous data transfer?",
    "context": "",
    "output": "P2PRIV ensures high-speed anonymous data transfer by allowing user data to be sent directly and independently in the distributed network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does P2PRIV ensure high-speed anonymous data transfer?",
      "answer": "P2PRIV ensures high-speed anonymous data transfer by allowing user data to be sent directly and independently in the distributed network."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of the National Cyber Defence Centre in Germany's cyber-security?",
    "context": "",
    "output": "The National Cyber Defence Centre is a cooperation, communication, and coordination platform for German (security) authorities and institutions that deals with cyber-related matters of nationwide relevance. It is responsible for preparing and updating a joint cyber-security situation report for Germany, coordinating protective measures and countermeasures against IT security incidents, and facilitating information exchange between participating authorities and institutions.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the National Cyber Defence Centre in Germany's cyber-security?",
      "answer": "The National Cyber Defence Centre is a cooperation, communication, and coordination platform for German (security) authorities and institutions that deals with cyber-related matters of nationwide relevance. It is responsible for preparing and updating a joint cyber-security situation report for Germany, coordinating protective measures and countermeasures against IT security incidents, and facilitating information exchange between participating authorities and institutions."
    }
  },
  {
    "instruction": "context: The OFT received numerous complaints from consumers who said they had not realized they were agreeing to be billed. However, it had no legal jurisdiction to deal with the issue of software being downloaded without consent. The OFT acted in the interests of those consumers whose access to MBS sites was confirmed but did not have the authority to address unauthorized downloads.\n\nAsk a question about this context.",
    "context": "",
    "output": "How did the UK's Office of Fair Trading (OFT) respond to consumer complaints about MBS?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the UK's Office of Fair Trading (OFT) respond to consumer complaints about MBS?",
      "answer": "The OFT received numerous complaints from consumers who said they had not realized they were agreeing to be billed. However, it had no legal jurisdiction to deal with the issue of software being downloaded without consent. The OFT acted in the interests of those consumers whose access to MBS sites was confirmed but did not have the authority to address unauthorized downloads."
    }
  },
  {
    "instruction": "context: Winlogon creates and opens an interactive windows station, WinSta0, and creates three desktops - Winlogon, Default and ScreenSaver.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does Winlogon handle the creation of the desktops for the window station?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Winlogon handle the creation of the desktops for the window station?",
      "answer": "Winlogon creates and opens an interactive windows station, WinSta0, and creates three desktops - Winlogon, Default and ScreenSaver."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did Kimberley Vanvaeck, also known as Gigabyte, respond to Graham Cluley's comments about the gender of virus writers?",
    "context": "",
    "output": "Gigabyte, in response to Graham Cluley's comments, wrote several viruses specifically targeting Cluley. However, she stated that these viruses were created as proof-of-concept rather than being released in the wild.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Kimberley Vanvaeck, also known as Gigabyte, respond to Graham Cluley's comments about the gender of virus writers?",
      "answer": "Gigabyte, in response to Graham Cluley's comments, wrote several viruses specifically targeting Cluley. However, she stated that these viruses were created as proof-of-concept rather than being released in the wild."
    }
  },
  {
    "instruction": "context: The DICOM medical imaging format was designed to allow polyglotting with TIFF files, allowing efficient storage of the same image data in a file that can be interpreted by either DICOM or TIFF viewers.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can the DICOM medical imaging format be used for polyglotting with TIFF files?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can the DICOM medical imaging format be used for polyglotting with TIFF files?",
      "answer": "The DICOM medical imaging format was designed to allow polyglotting with TIFF files, allowing efficient storage of the same image data in a file that can be interpreted by either DICOM or TIFF viewers."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are some of the methodologies used to define and design data validation rules?",
    "context": "",
    "output": "Data validation rules can be defined and designed using various methodologies, such as declarative data integrity rules, or procedure-based business rules.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some of the methodologies used to define and design data validation rules?",
      "answer": "Data validation rules can be defined and designed using various methodologies, such as declarative data integrity rules, or procedure-based business rules."
    }
  },
  {
    "instruction": "context: Dell BSAFE is a FIPS 140-2 validated cryptography library that is available in both C and Java. It was initially created by RSA Security and was later acquired by Dell, who retained the product line even after selling the RSA business to Symphony Technology Group in 2020.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is Dell BSAFE and in what programming languages is it available?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is Dell BSAFE and in what programming languages is it available?",
      "answer": "Dell BSAFE is a FIPS 140-2 validated cryptography library that is available in both C and Java. It was initially created by RSA Security and was later acquired by Dell, who retained the product line even after selling the RSA business to Symphony Technology Group in 2020."
    }
  },
  {
    "instruction": "Neural cryptography\n\n==Introduction==\nNeural cryptography is a branch of cryptography dedicated to analyzing the application of stochastic algorithms, especially artificial neural network algorithms, for use in encryption and cryptanalysis.\n\n\n\n== Definition ==\nArtificial neural networks are well known for their ability to selectively explore the solution space of a given problem.  This feature finds a natural niche of application in the field of cryptanalysis. At the same time, neural networks offer a new approach to attack ciphering algorithms based on the principle that any function could be reproduced by a neural network, which is a powerful proven computational tool that can be used to find the inverse-function of any cryptographic algorithm.\nThe ideas of mutual learning, self learning, and stochastic behavior of neural networks and similar algorithms can be used for different aspects of cryptography, like public-key cryptography, solving the key distribution problem using neural network mutual synchronization, hashing or generation of pseudo-random numbers.\nAnother idea is the ability of a neural network to separate space in non-linear pieces using \"bias\". It gives different probabilities of activating the neural network or not. This is very useful in the case of Cryptanalysis.\nTwo names are used to design the same domain of research: Neuro-Cryptography and Neural Cryptography.\nThe first work that it is known on this topic can be traced back to 1995 in an IT Master Thesis.\n\n== Applications ==\nIn 1995, Sebastien Dourlens applied neural networks to cryptanalyze DES by allowing the networks to learn how to invert the S-tables of the DES. The bias in DES studied through Differential Cryptanalysis by Adi Shamir is highlighted. The experiment shows about 50% of the key bits can be found, allowing the complete key to be found in a short time. Hardware application with multi micro-controllers have been proposed due to the easy implementation of multilayer neural networks in hardware.\nOne example of a public-key protocol is given by Khalil Shihab. He describes the decryption scheme and the public key creation that are based on a backpropagation neural network. The encryption scheme and the private key creation process are based on Boolean algebra. This technique has the advantage of small time and memory complexities. A disadvantage is the property of backpropagation algorithms: because of huge training sets, the learning phase of a neural network is very long. Therefore, the use of this protocol is only theoretical so far.\n\n== Neural key exchange protocol ==\nThe most used protocol for key exchange between two parties A and B in the practice is Diffie\u2013Hellman key exchange protocol. Neural key exchange, which is based on the synchronization of two tree parity machines, should be a secure replacement for this method.\nSynchronizing these two machines is similar to synchronizing two chaotic oscillators in chaos communications.\n\n\n*** Tree parity machine ***\nThe tree parity machine is a special type of multi-layer feedforward neural network.\nIt consists of one output neuron, K hidden neurons and K\u00d7N input neurons. Inputs to the network take three values: \n\n  \n    \n      \n        \n          x\n          \n            i\n            j\n          \n        \n        \u2208\n        \n          {\n          \n            \u2212\n            1\n            ,\n            0\n            ,\n            +\n            1\n          \n          }\n        \n      \n    \n    {\\displaystyle x_{ij}\\in \\left\\{-1,0,+1\\right\\}}\n  The weights between input and hidden neurons take the values: \n\n  \n    \n      \n        \n          w\n          \n            i\n            j\n          \n        \n        \u2208\n        \n          {\n          \n            \u2212\n            L\n            ,\n            .\n            .\n            .\n            ,\n            0\n            ,\n            .\n            .\n            .\n            ,\n            +\n            L\n          \n          }\n        \n      \n    \n    {\\displaystyle w_{ij}\\in \\left\\{-L,...,0,...,+L\\right\\}}\n  Output value of each hidden neuron is calculated as a sum of all multiplications of input neurons and these weights: \n\n  \n    \n      \n        \n          \u03c3\n          \n            i\nQ: How does the \"bias\" in artificial neural networks help in cryptanalysis?",
    "context": "",
    "output": "The \"bias\" in artificial neural networks gives different probabilities of activating the neural network, which is useful in cryptanalysis as it can help separate the solution space into non-linear pieces.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the \"bias\" in artificial neural networks help in cryptanalysis?",
      "answer": "The \"bias\" in artificial neural networks gives different probabilities of activating the neural network, which is useful in cryptanalysis as it can help separate the solution space into non-linear pieces.",
      "context": "Neural cryptography\n\n==Introduction==\nNeural cryptography is a branch of cryptography dedicated to analyzing the application of stochastic algorithms, especially artificial neural network algorithms, for use in encryption and cryptanalysis.\n\n\n\n== Definition ==\nArtificial neural networks are well known for their ability to selectively explore the solution space of a given problem.  This feature finds a natural niche of application in the field of cryptanalysis. At the same time, neural networks offer a new approach to attack ciphering algorithms based on the principle that any function could be reproduced by a neural network, which is a powerful proven computational tool that can be used to find the inverse-function of any cryptographic algorithm.\nThe ideas of mutual learning, self learning, and stochastic behavior of neural networks and similar algorithms can be used for different aspects of cryptography, like public-key cryptography, solving the key distribution problem using neural network mutual synchronization, hashing or generation of pseudo-random numbers.\nAnother idea is the ability of a neural network to separate space in non-linear pieces using \"bias\". It gives different probabilities of activating the neural network or not. This is very useful in the case of Cryptanalysis.\nTwo names are used to design the same domain of research: Neuro-Cryptography and Neural Cryptography.\nThe first work that it is known on this topic can be traced back to 1995 in an IT Master Thesis.\n\n== Applications ==\nIn 1995, Sebastien Dourlens applied neural networks to cryptanalyze DES by allowing the networks to learn how to invert the S-tables of the DES. The bias in DES studied through Differential Cryptanalysis by Adi Shamir is highlighted. The experiment shows about 50% of the key bits can be found, allowing the complete key to be found in a short time. Hardware application with multi micro-controllers have been proposed due to the easy implementation of multilayer neural networks in hardware.\nOne example of a public-key protocol is given by Khalil Shihab. He describes the decryption scheme and the public key creation that are based on a backpropagation neural network. The encryption scheme and the private key creation process are based on Boolean algebra. This technique has the advantage of small time and memory complexities. A disadvantage is the property of backpropagation algorithms: because of huge training sets, the learning phase of a neural network is very long. Therefore, the use of this protocol is only theoretical so far.\n\n== Neural key exchange protocol ==\nThe most used protocol for key exchange between two parties A and B in the practice is Diffie\u2013Hellman key exchange protocol. Neural key exchange, which is based on the synchronization of two tree parity machines, should be a secure replacement for this method.\nSynchronizing these two machines is similar to synchronizing two chaotic oscillators in chaos communications.\n\n\n*** Tree parity machine ***\nThe tree parity machine is a special type of multi-layer feedforward neural network.\nIt consists of one output neuron, K hidden neurons and K\u00d7N input neurons. Inputs to the network take three values: \n\n  \n    \n      \n        \n          x\n          \n            i\n            j\n          \n        \n        \u2208\n        \n          {\n          \n            \u2212\n            1\n            ,\n            0\n            ,\n            +\n            1\n          \n          }\n        \n      \n    \n    {\\displaystyle x_{ij}\\in \\left\\{-1,0,+1\\right\\}}\n  The weights between input and hidden neurons take the values: \n\n  \n    \n      \n        \n          w\n          \n            i\n            j\n          \n        \n        \u2208\n        \n          {\n          \n            \u2212\n            L\n            ,\n            .\n            .\n            .\n            ,\n            0\n            ,\n            .\n            .\n            .\n            ,\n            +\n            L\n          \n          }\n        \n      \n    \n    {\\displaystyle w_{ij}\\in \\left\\{-L,...,0,...,+L\\right\\}}\n  Output value of each hidden neuron is calculated as a sum of all multiplications of input neurons and these weights: \n\n  \n    \n      \n        \n          \u03c3\n          \n            i"
    }
  },
  {
    "instruction": "context: FRISK Software International was established in 1993 and was acquired by Cyren in 2012.\n\nAsk a question about this context.",
    "context": "",
    "output": "When did FRISK Software International start its operations and when was it acquired by Cyren?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "When did FRISK Software International start its operations and when was it acquired by Cyren?",
      "answer": "FRISK Software International was established in 1993 and was acquired by Cyren in 2012."
    }
  },
  {
    "instruction": "context: The Donbot botnet is estimated to consist of roughly 125,000 individual computers, which combined send 800 million spam messages a day. This amount equals about 1.3% of the estimated total global spam volume of 230 billion messages a day.\n\nAsk a question about this context.",
    "context": "",
    "output": "How many individual computers are estimated to be part of the Donbot botnet, and what percentage of the total global spam volume does it account for on a daily basis?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How many individual computers are estimated to be part of the Donbot botnet, and what percentage of the total global spam volume does it account for on a daily basis?",
      "answer": "The Donbot botnet is estimated to consist of roughly 125,000 individual computers, which combined send 800 million spam messages a day. This amount equals about 1.3% of the estimated total global spam volume of 230 billion messages a day."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of visualization in a SIEM system?",
    "context": "",
    "output": "Visualization in a SIEM system involves using security events and log failures to create visual aids, such as charts and graphs, to assist in pattern detection. This helps security analysts identify anomalous activity and respond to security incidents more effectively.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of visualization in a SIEM system?",
      "answer": "Visualization in a SIEM system involves using security events and log failures to create visual aids, such as charts and graphs, to assist in pattern detection. This helps security analysts identify anomalous activity and respond to security incidents more effectively."
    }
  },
  {
    "instruction": "Wi-Fi Protected Access\n\n==Introduction==\nWi-Fi Protected Access (WPA), Wi-Fi Protected Access 2 (WPA2), and Wi-Fi Protected Access 3 (WPA3) are the three security certification programs developed after 2000 by the Wi-Fi Alliance to secure wireless computer networks. The Alliance defined these in response to serious weaknesses researchers had found in the previous system, Wired Equivalent Privacy (WEP).WPA (sometimes referred to as the TKIP standard) became available in 2003. The Wi-Fi Alliance intended it as an intermediate measure in anticipation of the availability of the more secure and complex WPA2, which became available in 2004 and is a common shorthand for the full IEEE 802.11i (or IEEE 802.11i-2004) standard.\nIn January 2018, the Wi-Fi Alliance announced the release of WPA3, which has several security improvements over WPA2.\n\n\n\n== Versions ==\n\n\n*** WPA ***\nThe Wi-Fi Alliance intended WPA as an intermediate measure to take the place of WEP pending the availability of the full IEEE 802.11i standard. WPA could be implemented through firmware upgrades on wireless network interface cards designed for WEP that began shipping as far back as 1999. However, since the changes required in the wireless access points (APs) were more extensive than those needed on the network cards, most pre-2003 APs could not be upgraded to support WPA.\nThe WPA protocol implements the Temporal Key Integrity Protocol (TKIP). WEP used a 64-bit or 128-bit encryption key that must be manually entered on wireless access points and devices and does not change. TKIP employs a per-packet key, meaning that it dynamically generates a new 128-bit key for each packet and thus prevents the types of attacks that compromised WEP.WPA also includes a Message Integrity Check, which is designed to prevent an attacker from altering and resending data packets. This replaces the cyclic redundancy check (CRC) that was used by the WEP standard. CRC's main flaw was that it did not provide a sufficiently strong data integrity guarantee for the packets it handled. Well-tested message authentication codes existed to solve these problems, but they required too much computation to be used on old network cards. WPA uses a message integrity check algorithm called TKIP to verify the integrity of the packets. TKIP is much stronger than a CRC, but not as strong as the algorithm used in WPA2. Researchers have since discovered a flaw in WPA that relied on older weaknesses in WEP and the limitations of the message integrity code hash function, named Michael, to retrieve the keystream from short packets to use for re-injection and spoofing.\n\n\n*** WPA2 ***\n\nRatified in 2004, WPA2 replaced WPA. WPA2, which requires testing and certification by the Wi-Fi Alliance, implements the mandatory elements of IEEE 802.11i. In particular, it includes mandatory support for CCMP, an AES-based encryption mode. Certification began in September, 2004. From March 13, 2006, to June 30, 2020, WPA2 certification was mandatory for all new devices to bear the Wi-Fi trademark. As of July 1, 2020, support for WPA3 is mandatory.\n\n\n*** WPA3 ***\nIn January 2018, the Wi-Fi Alliance announced WPA3 as a replacement to WPA2. Certification began in June 2018, and WPA3 support has been mandatory for devices which bear the \"Wi-Fi CERTIFIED\u2122\" logo since July 2020.The new standard uses an equivalent 192-bit cryptographic strength in WPA3-Enterprise mode (AES-256 in GCM mode with SHA-384 as HMAC), and still mandates the use of CCMP-128 (AES-128 in CCM mode) as the minimum encryption algorithm in WPA3-Personal mode.\nThe WPA3 standard also replaces the pre-shared key (PSK) exchange with Simultaneous Authentication of Equals (SAE) exchange, a method originally introduced with IEEE 802.11s, resulting in a more secure initial key exchange in personal mode and forward secrecy. The Wi-Fi Alliance also says that WPA3 will mitigate security issues posed by weak passwords and simplify the process of setting up devices with no display interface.Protection of management frames as specified in the IEEE 802.11w amendment is also enforced by the WPA3 specifications.\n\n== Hardware support ==\nWPA has been designed specifically to work with wireless hardware produced prior to the introduction of WPA protocol, which provides inadequate security through WEP. Some of these devices support WPA only after applying firmware upgrades, which are not available for some legacy devices.Wi-Fi devices certified since 2006 support both the WPA and WPA2 security protocols. WPA3 is required since July 1, 2020.\n\n== WPA terminology ==\nDifferent WPA versions and protection mechanisms can be distinguished based on the target end-user(such as wep, wpa, wpa2, wpa3) (according to the method of authentication key distribution), and the encryption protocol used.\n\n\n*** Target users (authentication key distribution) ***\nWPA-Personal\nAlso referred to as WPA-PSK (pre-shared key) mode, this is designed for home, small office and basic uses these networks and does not require an authentication server. Each wireless network device encrypts the network traffic by deriving its 128-bit encryption key from a 256-bit shared key. This key may be entered either as a string of 64 hexadecimal digits, or as a passphrase of 8 to 63 printable ASCII characters. This pass-phrase-to-PSK mapping is nevertheless not binding, as Annex J is informative in the latest 802.11 standard. If ASCII characters are used, the 256-bit key is calculated by applying the PBKDF2 key derivation function to the passphrase, using the SSID as the salt and 4096 iterations of HMAC-SHA1. WPA-Personal mode is available on all three WPA versions.\nWPA-Enterprise\nAlso referred to as WPA-802.1X mode, and sometimes just WPA (as opposed to WPA-PSK), this is designed for enterprise networks and requires a RADIUS authentication server. This requires a more complicated setup, but provides additional security (e.g. protection against dictionary attacks on short passwords). Various kinds of the Extensible Authentication Protocol (EAP) are used for authentication. WPA-Enterprise mode is available on all three WPA versions.\nWi-Fi Protected Setup (WPS)\nThis is an alternative authentication key distribution method intended to simplify and strengthen the process, but which, as widely implemented, creates a major security hole via WPS PIN recovery.\n\n\n*** Encryption protocol ***\nTKIP (Temporal Key Integrity Protocol)\nThe RC4 stream cipher is used with a 128-bit per-packet key, meaning that it dynamically generates a new key for each packet. This is used by WPA.\nCCMP (CTR mode with CBC-MAC Protocol)\nThe protocol used by WPA2, based on the Advanced Encryption Standard (AES) cipher along with strong message authenticity and integrity checking is significantly stronger in protection for both privacy and integrity than the RC4-based TKIP that is used by WPA. Among informal names are AES and AES-CCMP. According to the 802.11n specification, this encryption protocol must be used to achieve fast 802.11n high bitrate schemes, though not all implementations enforce this. Otherwise, the data rate will not exceed 54 Mbit/s.\n\n== EAP extensions under WPA and WPA2 Enterprise ==\nOriginally, only EAP-TLS (Extensible Authentication Protocol - Transport Layer Security) was certified by the Wi-Fi alliance. In April 2010, the Wi-Fi Alliance announced the inclusion of additional EAP types to its WPA- and WPA2-Enterprise certification programs. This was to ensure that WPA-Enterprise certified products can interoperate with one another.\nAs of 2010 the certification program includes the following EAP types:\n\nEAP-TLS (previously tested)\nEAP-TTLS/MSCHAPv2 (April 2005)\nPEAPv0/EAP-MSCHAPv2 (April 2005)\nPEAPv1/EAP-GTC (April 2005)\nPEAP-TLS\nEAP-SIM (April 2005)\nEAP-AKA (April 2009)\nEAP-FAST (April 2009)802.1X clients and servers developed by specific firms may support other EAP types. This certification is an attempt for popular EAP types to interoperate; their failure to do so as of 2013 is one of the major issues preventing rollout of 802.1X on heterogeneous networks.\nCommercial 802.1X servers include Microsoft Internet Authentication Service and Juniper Networks Steelbelted RADIUS as well as Aradial Radius server. FreeRADIUS is an open source 802.1X server.\n\n== Security issues ==\n\n\n*** Weak password ***\nPre-shared key WPA and WPA2 remain vulnerable to password cracking attacks if users rely on a weak password or passphrase. WPA passphrase hashes are seeded from the SSID name and its length; rainbow tables exist for the top 1,000 network SSIDs and a multitude of common passwords, requiring only a quick lookup to speed up cracking WPA-PSK.Brute forcing of simple passwords can be attempted using the Aircrack Suite starting from the four-way authentication handshake exchanged during association or periodic re-authentication.WPA3 replaces cryptographic protocols susceptible to off-line analysis with protocols that require interaction with the infrastructure for each guessed password, supposedly placing temporal limits on the number of guesses. However, design flaws in WPA3 enable attackers to plausibly launch brute-force attacks (see Dragonblood attack).\n\n\n*** Lack of forward secrecy ***\nWPA and WPA2 do not provide forward secrecy, meaning that once an adverse person discovers the pre-shared key, they can potentially decrypt all packets encrypted using that PSK transmitted in the future and even past, which could be passively and silently collected by the attacker. This also means an attacker can silently capture and decrypt others' packets if a WPA-protected access point is provided free of charge at a public place, because its password is usually shared to anyone in that place. In other words, WPA only protects from attackers who do not have access to the password. Because of that, it's safer to use Transport Layer Security (TLS) or similar on top of that for the transfer of any sensitive data. However starting from WPA3, this issue has been addressed.\n\n\n*** WPA packet spoofing and decryption ***\nIn 2013, Mathy Vanhoef and Frank Piessens significantly improved upon the WPA-TKIP attacks of Erik Tews and Martin Beck. They demonstrated how to inject an arbitrary number of packets, with each packet containing at most 112 bytes of payload. This was demonstrated by implementing a port scanner, which can be executed against any client using WPA-TKIP. Additionally, they showed how to decrypt arbitrary packets sent to a client. They mentioned this can be used to hijack a TCP connection, allowing an attacker to inject malicious JavaScript when the victim visits a website.\nIn contrast, the Beck-Tews attack could only decrypt short packets with mostly known content, such as ARP messages, and only allowed injection of 3 to 7 packets of at most 28 bytes. The Beck-Tews attack also requires quality of service (as defined in 802.11e) to be enabled, while the Vanhoef-Piessens attack does not. Neither attack leads to recovery of the shared session key between the client and Access Point. The authors say using a short rekeying interval can prevent some attacks but not all, and strongly recommend switching from TKIP to AES-based CCMP.\nHalvorsen and others show how to modify the Beck-Tews attack to allow injection of 3 to 7 packets having a size of at most 596 bytes. The downside is that their attack requires substantially more time to execute: approximately 18 minutes and 25 seconds. In other work Vanhoef and Piessens showed that, when WPA is used to encrypt broadcast packets, their original attack can also be executed. This is an important extension, as substantially more networks use WPA to protect broadcast packets, than to protect unicast packets. The execution time of this attack is on average around 7 minutes, compared to the 14 minutes of the original Vanhoef-Piessens and Beck-Tews attack.\nThe vulnerabilities of TKIP are significant because WPA-TKIP had been held before to be an extremely safe combination; indeed, WPA-TKIP is still a configuration option upon a wide variety of wireless routing devices provided by many hardware vendors. A survey in 2013 showed that 71% still allow usage of TKIP, and 19% exclusively support TKIP.\n\n\n*** WPS PIN recovery ***\nA more serious security flaw was revealed in December 2011 by Stefan Viehb\u00f6ck that affects wireless routers with the Wi-Fi Protected Setup (WPS) feature, regardless of which encryption method they use. Most recent models have this feature and enable it by default. Many consumer Wi-Fi device manufacturers had taken steps to eliminate the potential of weak passphrase choices by promoting alternative methods of automatically generating and distributing strong keys when users add a new wireless adapter or appliance to a network. These methods include pushing buttons on the devices or entering an 8-digit PIN.\nThe Wi-Fi Alliance standardized these methods as Wi-Fi Protected Setup; however, the PIN feature as widely implemented introduced a major new security flaw. The flaw allows a remote attacker to recover the WPS PIN and, with it, the router's WPA/WPA2 password in a few hours. Users have been urged to turn off the WPS feature, although this may not be possible on some router models. Also, the PIN is written on a label on most Wi-Fi routers with WPS, and cannot be changed if compromised.\nWPA3 introduces a new alternative for the configuration of devices that lack sufficient user interface capabilities by allowing nearby devices to serve as an adequate UI for network provisioning purposes, thus mitigating the need for WPS.\n\n\n*** MS-CHAPv2 and lack of AAA server CN validation ***\nSeveral weaknesses have been found in MS-CHAPv2, some of which severely reduce the complexity of brute-force attacks, making them feasible with modern hardware. In 2012 the complexity of breaking MS-CHAPv2 was reduced to that of breaking a single DES key (work by Moxie Marlinspike and Marsh Ray). Moxie advised: \"Enterprises who are depending on the mutual authentication properties of MS-CHAPv2 for connection to their WPA2 Radius servers should immediately start migrating to something else.\"Tunneled EAP methods using TTLS or PEAP which encrypt the MSCHAPv2 exchange are widely deployed to protect against exploitation of this vulnerability.  However, prevalent WPA2 client implementations during the early 2000s were prone to misconfiguration by end users, or in some cases (e.g. Android), lacked any user-accessible way to properly configure validation of AAA server certificate CNs.  This extended the relevance of the original weakness in MSCHAPv2 within MiTM attack scenarios.  Under stricter WPA2 compliance tests announced alongside WPA3, certified client software will be required to conform to certain behaviors surrounding AAA certificate validation.\n\n\n*** Hole196 ***\nHole196 is a vulnerability in the WPA2 protocol that abuses the shared Group Temporal Key (GTK). It can be used to conduct man-in-the-middle and denial-of-service attacks. However, it assumes that the attacker is already authenticated against Access Point and thus in possession of the GTK.\n\n\n*** Predictable Group Temporal Key (GTK) ***\nIn 2016 it was shown that the WPA and WPA2 standards contain an insecure expository random number generator (RNG). Researchers showed that, if vendors implement the proposed RNG, an attacker is able to predict the group key (GTK) that is supposed to be randomly generated by the access point (AP). Additionally, they showed that possession of the GTK enables the attacker to inject any traffic into the network, and allowed the attacker to decrypt unicast internet traffic transmitted over the wireless network. They demonstrated their attack against an Asus RT-AC51U router that uses the MediaTek out-of-tree drivers, which generate the GTK themselves, and showed the GTK can be recovered within two minutes or less. Similarly, they demonstrated the keys generated by Broadcom access daemons running on VxWorks 5 and later can be recovered in four minutes or less, which affects, for example, certain versions of Linksys WRT54G and certain Apple AirPort Extreme models. Vendors can defend against this attack by using a secure RNG. By doing so, Hostapd running on Linux kernels is not vulnerable against this attack and thus routers running typical OpenWrt or LEDE installations do not exhibit this issue.\n\n\n*** KRACK attack ***\n\nIn October 2017, details of the KRACK (Key Reinstallation Attack) attack on WPA2 were published. The KRACK attack is believed to affect all variants of WPA and WPA2; however, the security implications vary between implementations, depending upon how individual developers interpreted a poorly specified part of the standard. Software patches can resolve the vulnerability but are not available for all devices.\n\n\n*** Dragonblood attack ***\nIn April 2019, serious design flaws in WPA3 were found which allow attackers to perform downgrade attacks and side-channel attacks, enabling brute-forcing the passphrase, as well as launching denial-of-service attacks on Wi-Fi base stations.\nQ: How do weaknesses in MS-CHAPv2 impact WPA2 security?",
    "context": "",
    "output": "Several weaknesses in MS-CHAPv2, including the reduction of brute-force attack complexity to that of breaking a single DES key, make it feasible to exploit this vulnerability within MiTM attack scenarios, particularly in WPA2 client implementations prone to misconfiguration or lacking user-accessible ways to properly configure AAA server certificate CNs validation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do weaknesses in MS-CHAPv2 impact WPA2 security?",
      "answer": "Several weaknesses in MS-CHAPv2, including the reduction of brute-force attack complexity to that of breaking a single DES key, make it feasible to exploit this vulnerability within MiTM attack scenarios, particularly in WPA2 client implementations prone to misconfiguration or lacking user-accessible ways to properly configure AAA server certificate CNs validation.",
      "context": "Wi-Fi Protected Access\n\n==Introduction==\nWi-Fi Protected Access (WPA), Wi-Fi Protected Access 2 (WPA2), and Wi-Fi Protected Access 3 (WPA3) are the three security certification programs developed after 2000 by the Wi-Fi Alliance to secure wireless computer networks. The Alliance defined these in response to serious weaknesses researchers had found in the previous system, Wired Equivalent Privacy (WEP).WPA (sometimes referred to as the TKIP standard) became available in 2003. The Wi-Fi Alliance intended it as an intermediate measure in anticipation of the availability of the more secure and complex WPA2, which became available in 2004 and is a common shorthand for the full IEEE 802.11i (or IEEE 802.11i-2004) standard.\nIn January 2018, the Wi-Fi Alliance announced the release of WPA3, which has several security improvements over WPA2.\n\n\n\n== Versions ==\n\n\n*** WPA ***\nThe Wi-Fi Alliance intended WPA as an intermediate measure to take the place of WEP pending the availability of the full IEEE 802.11i standard. WPA could be implemented through firmware upgrades on wireless network interface cards designed for WEP that began shipping as far back as 1999. However, since the changes required in the wireless access points (APs) were more extensive than those needed on the network cards, most pre-2003 APs could not be upgraded to support WPA.\nThe WPA protocol implements the Temporal Key Integrity Protocol (TKIP). WEP used a 64-bit or 128-bit encryption key that must be manually entered on wireless access points and devices and does not change. TKIP employs a per-packet key, meaning that it dynamically generates a new 128-bit key for each packet and thus prevents the types of attacks that compromised WEP.WPA also includes a Message Integrity Check, which is designed to prevent an attacker from altering and resending data packets. This replaces the cyclic redundancy check (CRC) that was used by the WEP standard. CRC's main flaw was that it did not provide a sufficiently strong data integrity guarantee for the packets it handled. Well-tested message authentication codes existed to solve these problems, but they required too much computation to be used on old network cards. WPA uses a message integrity check algorithm called TKIP to verify the integrity of the packets. TKIP is much stronger than a CRC, but not as strong as the algorithm used in WPA2. Researchers have since discovered a flaw in WPA that relied on older weaknesses in WEP and the limitations of the message integrity code hash function, named Michael, to retrieve the keystream from short packets to use for re-injection and spoofing.\n\n\n*** WPA2 ***\n\nRatified in 2004, WPA2 replaced WPA. WPA2, which requires testing and certification by the Wi-Fi Alliance, implements the mandatory elements of IEEE 802.11i. In particular, it includes mandatory support for CCMP, an AES-based encryption mode. Certification began in September, 2004. From March 13, 2006, to June 30, 2020, WPA2 certification was mandatory for all new devices to bear the Wi-Fi trademark. As of July 1, 2020, support for WPA3 is mandatory.\n\n\n*** WPA3 ***\nIn January 2018, the Wi-Fi Alliance announced WPA3 as a replacement to WPA2. Certification began in June 2018, and WPA3 support has been mandatory for devices which bear the \"Wi-Fi CERTIFIED\u2122\" logo since July 2020.The new standard uses an equivalent 192-bit cryptographic strength in WPA3-Enterprise mode (AES-256 in GCM mode with SHA-384 as HMAC), and still mandates the use of CCMP-128 (AES-128 in CCM mode) as the minimum encryption algorithm in WPA3-Personal mode.\nThe WPA3 standard also replaces the pre-shared key (PSK) exchange with Simultaneous Authentication of Equals (SAE) exchange, a method originally introduced with IEEE 802.11s, resulting in a more secure initial key exchange in personal mode and forward secrecy. The Wi-Fi Alliance also says that WPA3 will mitigate security issues posed by weak passwords and simplify the process of setting up devices with no display interface.Protection of management frames as specified in the IEEE 802.11w amendment is also enforced by the WPA3 specifications.\n\n== Hardware support ==\nWPA has been designed specifically to work with wireless hardware produced prior to the introduction of WPA protocol, which provides inadequate security through WEP. Some of these devices support WPA only after applying firmware upgrades, which are not available for some legacy devices.Wi-Fi devices certified since 2006 support both the WPA and WPA2 security protocols. WPA3 is required since July 1, 2020.\n\n== WPA terminology ==\nDifferent WPA versions and protection mechanisms can be distinguished based on the target end-user(such as wep, wpa, wpa2, wpa3) (according to the method of authentication key distribution), and the encryption protocol used.\n\n\n*** Target users (authentication key distribution) ***\nWPA-Personal\nAlso referred to as WPA-PSK (pre-shared key) mode, this is designed for home, small office and basic uses these networks and does not require an authentication server. Each wireless network device encrypts the network traffic by deriving its 128-bit encryption key from a 256-bit shared key. This key may be entered either as a string of 64 hexadecimal digits, or as a passphrase of 8 to 63 printable ASCII characters. This pass-phrase-to-PSK mapping is nevertheless not binding, as Annex J is informative in the latest 802.11 standard. If ASCII characters are used, the 256-bit key is calculated by applying the PBKDF2 key derivation function to the passphrase, using the SSID as the salt and 4096 iterations of HMAC-SHA1. WPA-Personal mode is available on all three WPA versions.\nWPA-Enterprise\nAlso referred to as WPA-802.1X mode, and sometimes just WPA (as opposed to WPA-PSK), this is designed for enterprise networks and requires a RADIUS authentication server. This requires a more complicated setup, but provides additional security (e.g. protection against dictionary attacks on short passwords). Various kinds of the Extensible Authentication Protocol (EAP) are used for authentication. WPA-Enterprise mode is available on all three WPA versions.\nWi-Fi Protected Setup (WPS)\nThis is an alternative authentication key distribution method intended to simplify and strengthen the process, but which, as widely implemented, creates a major security hole via WPS PIN recovery.\n\n\n*** Encryption protocol ***\nTKIP (Temporal Key Integrity Protocol)\nThe RC4 stream cipher is used with a 128-bit per-packet key, meaning that it dynamically generates a new key for each packet. This is used by WPA.\nCCMP (CTR mode with CBC-MAC Protocol)\nThe protocol used by WPA2, based on the Advanced Encryption Standard (AES) cipher along with strong message authenticity and integrity checking is significantly stronger in protection for both privacy and integrity than the RC4-based TKIP that is used by WPA. Among informal names are AES and AES-CCMP. According to the 802.11n specification, this encryption protocol must be used to achieve fast 802.11n high bitrate schemes, though not all implementations enforce this. Otherwise, the data rate will not exceed 54 Mbit/s.\n\n== EAP extensions under WPA and WPA2 Enterprise ==\nOriginally, only EAP-TLS (Extensible Authentication Protocol - Transport Layer Security) was certified by the Wi-Fi alliance. In April 2010, the Wi-Fi Alliance announced the inclusion of additional EAP types to its WPA- and WPA2-Enterprise certification programs. This was to ensure that WPA-Enterprise certified products can interoperate with one another.\nAs of 2010 the certification program includes the following EAP types:\n\nEAP-TLS (previously tested)\nEAP-TTLS/MSCHAPv2 (April 2005)\nPEAPv0/EAP-MSCHAPv2 (April 2005)\nPEAPv1/EAP-GTC (April 2005)\nPEAP-TLS\nEAP-SIM (April 2005)\nEAP-AKA (April 2009)\nEAP-FAST (April 2009)802.1X clients and servers developed by specific firms may support other EAP types. This certification is an attempt for popular EAP types to interoperate; their failure to do so as of 2013 is one of the major issues preventing rollout of 802.1X on heterogeneous networks.\nCommercial 802.1X servers include Microsoft Internet Authentication Service and Juniper Networks Steelbelted RADIUS as well as Aradial Radius server. FreeRADIUS is an open source 802.1X server.\n\n== Security issues ==\n\n\n*** Weak password ***\nPre-shared key WPA and WPA2 remain vulnerable to password cracking attacks if users rely on a weak password or passphrase. WPA passphrase hashes are seeded from the SSID name and its length; rainbow tables exist for the top 1,000 network SSIDs and a multitude of common passwords, requiring only a quick lookup to speed up cracking WPA-PSK.Brute forcing of simple passwords can be attempted using the Aircrack Suite starting from the four-way authentication handshake exchanged during association or periodic re-authentication.WPA3 replaces cryptographic protocols susceptible to off-line analysis with protocols that require interaction with the infrastructure for each guessed password, supposedly placing temporal limits on the number of guesses. However, design flaws in WPA3 enable attackers to plausibly launch brute-force attacks (see Dragonblood attack).\n\n\n*** Lack of forward secrecy ***\nWPA and WPA2 do not provide forward secrecy, meaning that once an adverse person discovers the pre-shared key, they can potentially decrypt all packets encrypted using that PSK transmitted in the future and even past, which could be passively and silently collected by the attacker. This also means an attacker can silently capture and decrypt others' packets if a WPA-protected access point is provided free of charge at a public place, because its password is usually shared to anyone in that place. In other words, WPA only protects from attackers who do not have access to the password. Because of that, it's safer to use Transport Layer Security (TLS) or similar on top of that for the transfer of any sensitive data. However starting from WPA3, this issue has been addressed.\n\n\n*** WPA packet spoofing and decryption ***\nIn 2013, Mathy Vanhoef and Frank Piessens significantly improved upon the WPA-TKIP attacks of Erik Tews and Martin Beck. They demonstrated how to inject an arbitrary number of packets, with each packet containing at most 112 bytes of payload. This was demonstrated by implementing a port scanner, which can be executed against any client using WPA-TKIP. Additionally, they showed how to decrypt arbitrary packets sent to a client. They mentioned this can be used to hijack a TCP connection, allowing an attacker to inject malicious JavaScript when the victim visits a website.\nIn contrast, the Beck-Tews attack could only decrypt short packets with mostly known content, such as ARP messages, and only allowed injection of 3 to 7 packets of at most 28 bytes. The Beck-Tews attack also requires quality of service (as defined in 802.11e) to be enabled, while the Vanhoef-Piessens attack does not. Neither attack leads to recovery of the shared session key between the client and Access Point. The authors say using a short rekeying interval can prevent some attacks but not all, and strongly recommend switching from TKIP to AES-based CCMP.\nHalvorsen and others show how to modify the Beck-Tews attack to allow injection of 3 to 7 packets having a size of at most 596 bytes. The downside is that their attack requires substantially more time to execute: approximately 18 minutes and 25 seconds. In other work Vanhoef and Piessens showed that, when WPA is used to encrypt broadcast packets, their original attack can also be executed. This is an important extension, as substantially more networks use WPA to protect broadcast packets, than to protect unicast packets. The execution time of this attack is on average around 7 minutes, compared to the 14 minutes of the original Vanhoef-Piessens and Beck-Tews attack.\nThe vulnerabilities of TKIP are significant because WPA-TKIP had been held before to be an extremely safe combination; indeed, WPA-TKIP is still a configuration option upon a wide variety of wireless routing devices provided by many hardware vendors. A survey in 2013 showed that 71% still allow usage of TKIP, and 19% exclusively support TKIP.\n\n\n*** WPS PIN recovery ***\nA more serious security flaw was revealed in December 2011 by Stefan Viehb\u00f6ck that affects wireless routers with the Wi-Fi Protected Setup (WPS) feature, regardless of which encryption method they use. Most recent models have this feature and enable it by default. Many consumer Wi-Fi device manufacturers had taken steps to eliminate the potential of weak passphrase choices by promoting alternative methods of automatically generating and distributing strong keys when users add a new wireless adapter or appliance to a network. These methods include pushing buttons on the devices or entering an 8-digit PIN.\nThe Wi-Fi Alliance standardized these methods as Wi-Fi Protected Setup; however, the PIN feature as widely implemented introduced a major new security flaw. The flaw allows a remote attacker to recover the WPS PIN and, with it, the router's WPA/WPA2 password in a few hours. Users have been urged to turn off the WPS feature, although this may not be possible on some router models. Also, the PIN is written on a label on most Wi-Fi routers with WPS, and cannot be changed if compromised.\nWPA3 introduces a new alternative for the configuration of devices that lack sufficient user interface capabilities by allowing nearby devices to serve as an adequate UI for network provisioning purposes, thus mitigating the need for WPS.\n\n\n*** MS-CHAPv2 and lack of AAA server CN validation ***\nSeveral weaknesses have been found in MS-CHAPv2, some of which severely reduce the complexity of brute-force attacks, making them feasible with modern hardware. In 2012 the complexity of breaking MS-CHAPv2 was reduced to that of breaking a single DES key (work by Moxie Marlinspike and Marsh Ray). Moxie advised: \"Enterprises who are depending on the mutual authentication properties of MS-CHAPv2 for connection to their WPA2 Radius servers should immediately start migrating to something else.\"Tunneled EAP methods using TTLS or PEAP which encrypt the MSCHAPv2 exchange are widely deployed to protect against exploitation of this vulnerability.  However, prevalent WPA2 client implementations during the early 2000s were prone to misconfiguration by end users, or in some cases (e.g. Android), lacked any user-accessible way to properly configure validation of AAA server certificate CNs.  This extended the relevance of the original weakness in MSCHAPv2 within MiTM attack scenarios.  Under stricter WPA2 compliance tests announced alongside WPA3, certified client software will be required to conform to certain behaviors surrounding AAA certificate validation.\n\n\n*** Hole196 ***\nHole196 is a vulnerability in the WPA2 protocol that abuses the shared Group Temporal Key (GTK). It can be used to conduct man-in-the-middle and denial-of-service attacks. However, it assumes that the attacker is already authenticated against Access Point and thus in possession of the GTK.\n\n\n*** Predictable Group Temporal Key (GTK) ***\nIn 2016 it was shown that the WPA and WPA2 standards contain an insecure expository random number generator (RNG). Researchers showed that, if vendors implement the proposed RNG, an attacker is able to predict the group key (GTK) that is supposed to be randomly generated by the access point (AP). Additionally, they showed that possession of the GTK enables the attacker to inject any traffic into the network, and allowed the attacker to decrypt unicast internet traffic transmitted over the wireless network. They demonstrated their attack against an Asus RT-AC51U router that uses the MediaTek out-of-tree drivers, which generate the GTK themselves, and showed the GTK can be recovered within two minutes or less. Similarly, they demonstrated the keys generated by Broadcom access daemons running on VxWorks 5 and later can be recovered in four minutes or less, which affects, for example, certain versions of Linksys WRT54G and certain Apple AirPort Extreme models. Vendors can defend against this attack by using a secure RNG. By doing so, Hostapd running on Linux kernels is not vulnerable against this attack and thus routers running typical OpenWrt or LEDE installations do not exhibit this issue.\n\n\n*** KRACK attack ***\n\nIn October 2017, details of the KRACK (Key Reinstallation Attack) attack on WPA2 were published. The KRACK attack is believed to affect all variants of WPA and WPA2; however, the security implications vary between implementations, depending upon how individual developers interpreted a poorly specified part of the standard. Software patches can resolve the vulnerability but are not available for all devices.\n\n\n*** Dragonblood attack ***\nIn April 2019, serious design flaws in WPA3 were found which allow attackers to perform downgrade attacks and side-channel attacks, enabling brute-forcing the passphrase, as well as launching denial-of-service attacks on Wi-Fi base stations."
    }
  },
  {
    "instruction": "Onion routing\n\n==Introduction==\nOnion routing is a technique for anonymous communication over a computer network. In an onion network, messages are encapsulated in layers of encryption, analogous to the layers of an onion. The encrypted data is transmitted through a series of network nodes called \"onion routers,\" each of which \"peels\" away a single layer, revealing the data's next destination. When the final layer is decrypted, the message arrives at its destination. The sender remains anonymous because each intermediary knows only the location of the immediately preceding and following nodes. While onion routing provides a high level of security and anonymity, there are methods to break the anonymity of this technique, such as timing analysis.\n\n== Data structure ==\nMetaphorically, an onion is the data structure formed by \"wrapping\" a message with successive layers of encryption to be decrypted (\"peeled\" or \"unwrapped\") by as many intermediary computers as there are layers before arriving at its destination. The original message remains hidden as it is transferred from one node to the next, and no intermediary knows both the origin and final destination of the data, allowing the sender to remain anonymous.\n\n\n*** Onion creation and transmission ***\nTo create and transmit an onion, the originator selects a set of nodes from a list provided by a \"directory node\". The chosen nodes are arranged into a path, called a \"chain\" or \"circuit\", through which the message will be transmitted. To preserve the anonymity of the sender, no node in the circuit is able to tell whether the node before it is the originator or another intermediary like itself. Likewise, no node in the circuit is able to tell how many other nodes are in the circuit and only the final node, the \"exit node\", is able to determine its own location in the chain.Using asymmetric key cryptography, the originator obtains a public key from the directory node to send an encrypted message to the first (\"entry\") node, establishing a connection and a shared secret (\"session key\"). Using the established encrypted link to the entry node, the originator can then relay a message through the first node to a second node in the chain using encryption that only the second node, and not the first, can decrypt. When the second node receives the message, it establishes a connection with the first node. While this extends the encrypted link from the originator, the second node cannot determine whether the first node is the originator or just another node in the circuit. The originator can then send a message through the first and second nodes to a third node, encrypted such that only the third node is able to decrypt it. The third, as with the second, becomes linked to the originator but connects only with the second. This process can be repeated to build larger and larger chains but is typically limited to preserve performance.When the chain is complete, the originator can send data over the Internet anonymously. When the final recipient of the data sends data back, the intermediary nodes maintain the same link back to the originator, with data again layered, but in reverse such that the final node this time adds the first layer of encryption and the first node adds the last layer of encryption before sending the data, for example a web page, to the originator, who is able to decrypt all layers.\n\n== Weaknesses ==\n\n\n*** Timing analysis ***\n\nOne of the reasons why the typical Internet connections are not considered anonymous is the ability of Internet service providers to trace and log connections between computers. For example, when a person accesses a particular website, the data itself may be secured through a connection like HTTPS such that the user's password, emails, or other content is not visible to an outside party, but there is a record of the connection itself, what time it occurred, and the amount of data transferred. Onion routing creates and obscures a path between two computers such that there is no discernible connection directly from a person to a website, but there still exist records of connections between computers. Traffic analysis searches those records of connections made by a potential originator and tries to match timing and data transfers to connections made to a potential recipient. If an attacker has compromised both ends of a route, a sender may be seen to have transferred an amount of data to an unknown computer a specified amount of seconds before a different unknown computer transferred data of the same exact size to a particular destination. Factors that may facilitate traffic analysis include nodes failing or leaving the network and a compromised node keeping track of a session as it occurs when chains are periodically rebuilt.Garlic routing is a variant of onion routing associated with the I2P network that encrypts multiple messages together, which both increases the speed of data transfer and makes it more difficult for attackers to perform traffic analysis.\n\n\n*** Exit node vulnerability ***\nAlthough the message being sent is transmitted inside several layers of encryption, the job of the exit node, as the final node in the chain, is to decrypt the final layer and deliver the message to the recipient. A compromised exit node is thus able to acquire the raw data being transmitted, potentially including passwords, private messages, bank account numbers, and other forms of personal information. Dan Egerstad, a Swedish researcher, used such an attack to collect the passwords of over 100 email accounts related to foreign embassies.Exit node vulnerabilities are similar to those on unsecured wireless networks, where the data being transmitted by a user on the network may be intercepted by another user or by the router operator. Both issues are solved by using a secure end-to-end connection like SSL/TLS or secure HTTP (S-HTTP). If there is end-to-end encryption between the sender and the recipient, and the sender isn't lured into trusting a false SSL certificate offered by the exit node, then not even the last intermediary can view the original message.\n\nAnswer this question based on the above context: How can timing analysis be used to compromise the anonymity of onion routing?",
    "context": "",
    "output": "Timing analysis can be used to compromise the anonymity of onion routing by examining records of connections made by a potential originator and trying to match timing and data transfers to connections made to a potential recipient. If an attacker has compromised both ends of a route, they may be able to identify the sender by observing the timing and size of data transfers.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can timing analysis be used to compromise the anonymity of onion routing?",
      "answer": "Timing analysis can be used to compromise the anonymity of onion routing by examining records of connections made by a potential originator and trying to match timing and data transfers to connections made to a potential recipient. If an attacker has compromised both ends of a route, they may be able to identify the sender by observing the timing and size of data transfers.",
      "context": "Onion routing\n\n==Introduction==\nOnion routing is a technique for anonymous communication over a computer network. In an onion network, messages are encapsulated in layers of encryption, analogous to the layers of an onion. The encrypted data is transmitted through a series of network nodes called \"onion routers,\" each of which \"peels\" away a single layer, revealing the data's next destination. When the final layer is decrypted, the message arrives at its destination. The sender remains anonymous because each intermediary knows only the location of the immediately preceding and following nodes. While onion routing provides a high level of security and anonymity, there are methods to break the anonymity of this technique, such as timing analysis.\n\n== Data structure ==\nMetaphorically, an onion is the data structure formed by \"wrapping\" a message with successive layers of encryption to be decrypted (\"peeled\" or \"unwrapped\") by as many intermediary computers as there are layers before arriving at its destination. The original message remains hidden as it is transferred from one node to the next, and no intermediary knows both the origin and final destination of the data, allowing the sender to remain anonymous.\n\n\n*** Onion creation and transmission ***\nTo create and transmit an onion, the originator selects a set of nodes from a list provided by a \"directory node\". The chosen nodes are arranged into a path, called a \"chain\" or \"circuit\", through which the message will be transmitted. To preserve the anonymity of the sender, no node in the circuit is able to tell whether the node before it is the originator or another intermediary like itself. Likewise, no node in the circuit is able to tell how many other nodes are in the circuit and only the final node, the \"exit node\", is able to determine its own location in the chain.Using asymmetric key cryptography, the originator obtains a public key from the directory node to send an encrypted message to the first (\"entry\") node, establishing a connection and a shared secret (\"session key\"). Using the established encrypted link to the entry node, the originator can then relay a message through the first node to a second node in the chain using encryption that only the second node, and not the first, can decrypt. When the second node receives the message, it establishes a connection with the first node. While this extends the encrypted link from the originator, the second node cannot determine whether the first node is the originator or just another node in the circuit. The originator can then send a message through the first and second nodes to a third node, encrypted such that only the third node is able to decrypt it. The third, as with the second, becomes linked to the originator but connects only with the second. This process can be repeated to build larger and larger chains but is typically limited to preserve performance.When the chain is complete, the originator can send data over the Internet anonymously. When the final recipient of the data sends data back, the intermediary nodes maintain the same link back to the originator, with data again layered, but in reverse such that the final node this time adds the first layer of encryption and the first node adds the last layer of encryption before sending the data, for example a web page, to the originator, who is able to decrypt all layers.\n\n== Weaknesses ==\n\n\n*** Timing analysis ***\n\nOne of the reasons why the typical Internet connections are not considered anonymous is the ability of Internet service providers to trace and log connections between computers. For example, when a person accesses a particular website, the data itself may be secured through a connection like HTTPS such that the user's password, emails, or other content is not visible to an outside party, but there is a record of the connection itself, what time it occurred, and the amount of data transferred. Onion routing creates and obscures a path between two computers such that there is no discernible connection directly from a person to a website, but there still exist records of connections between computers. Traffic analysis searches those records of connections made by a potential originator and tries to match timing and data transfers to connections made to a potential recipient. If an attacker has compromised both ends of a route, a sender may be seen to have transferred an amount of data to an unknown computer a specified amount of seconds before a different unknown computer transferred data of the same exact size to a particular destination. Factors that may facilitate traffic analysis include nodes failing or leaving the network and a compromised node keeping track of a session as it occurs when chains are periodically rebuilt.Garlic routing is a variant of onion routing associated with the I2P network that encrypts multiple messages together, which both increases the speed of data transfer and makes it more difficult for attackers to perform traffic analysis.\n\n\n*** Exit node vulnerability ***\nAlthough the message being sent is transmitted inside several layers of encryption, the job of the exit node, as the final node in the chain, is to decrypt the final layer and deliver the message to the recipient. A compromised exit node is thus able to acquire the raw data being transmitted, potentially including passwords, private messages, bank account numbers, and other forms of personal information. Dan Egerstad, a Swedish researcher, used such an attack to collect the passwords of over 100 email accounts related to foreign embassies.Exit node vulnerabilities are similar to those on unsecured wireless networks, where the data being transmitted by a user on the network may be intercepted by another user or by the router operator. Both issues are solved by using a secure end-to-end connection like SSL/TLS or secure HTTP (S-HTTP). If there is end-to-end encryption between the sender and the recipient, and the sender isn't lured into trusting a false SSL certificate offered by the exit node, then not even the last intermediary can view the original message."
    }
  },
  {
    "instruction": "Write an answer to the following question: How were individuals financially rewarded for their contributions to the development of the 5-UCO system in the UK?",
    "context": "",
    "output": "In the UK, Colonel G. ff Bellairs was awarded sums totaling \u00a32250 for the development of the 5-UCO system, with \u00a3750 awarded in 1943 and \u00a31,500 awarded in 1960. Additionally, Dr G. Timms and Mr D. C. Harwood were awarded \u00a31,000 for their work on random tape for the 5-UCO system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How were individuals financially rewarded for their contributions to the development of the 5-UCO system in the UK?",
      "answer": "In the UK, Colonel G. ff Bellairs was awarded sums totaling \u00a32250 for the development of the 5-UCO system, with \u00a3750 awarded in 1943 and \u00a31,500 awarded in 1960. Additionally, Dr G. Timms and Mr D. C. Harwood were awarded \u00a31,000 for their work on random tape for the 5-UCO system."
    }
  },
  {
    "instruction": "context: The Google Hacking Database is a project created by Johnny Long and hosted by Offensive Security. It is used to help security professionals determine whether a given application or website is compromised by using Google search to establish whether usernames and passwords had been compromised.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the Google Hacking Database and how is it used in security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Google Hacking Database and how is it used in security?",
      "answer": "The Google Hacking Database is a project created by Johnny Long and hosted by Offensive Security. It is used to help security professionals determine whether a given application or website is compromised by using Google search to establish whether usernames and passwords had been compromised."
    }
  },
  {
    "instruction": "JSON Web Token\n\n==Introduction==\nJSON Web Token (JWT, pronounced , same as the word \"jot\") is a proposed Internet standard for creating data with optional signature and/or optional encryption whose payload holds JSON that asserts some number of claims. The tokens are signed either using a private secret or a public/private key.\nFor example, a server could generate a token that has the claim \"logged in as administrator\" and provide that to a client. The client could then use that token to prove that it is logged in as admin. The tokens can be signed by one party's private key (usually the server's) so that any party can subsequently verify whether or not the token is legitimate. If the other party, by some suitable and trustworthy means, is in possession of the corresponding public key, they too are able to verify the token's legitimacy. The tokens are designed to be compact, URL-safe, and usable especially in a web-browser single-sign-on (SSO) context. JWT claims can typically be used to pass identity of authenticated users between an identity provider and a service provider, or any other type of claims as required by business processes.JWT relies on other JSON-based standards: JSON Web Signature and JSON Web Encryption.\n\n== Structure ==\nHeader\nIdentifies which algorithm is used to generate the signature\nHS256 indicates that this token is signed using HMAC-SHA256.\nTypical cryptographic algorithms used are HMAC with SHA-256 (HS256) and RSA signature with SHA-256 (RS256). JWA (JSON Web Algorithms) RFC 7518 introduces many more for both authentication and encryption.\n\nPayload\nContains a set of claims. The JWT specification defines seven Registered Claim Names which are the standard fields commonly included in tokens. Custom claims are usually also included, depending on the purpose of the token.\nThis example has the standard Issued At Time claim (iat) and a custom claim (loggedInAs).\n\nSignature\nSecurely validates the token. The signature is calculated by encoding the header and payload using Base64url Encoding RFC 4648 and concatenating the two together with a period separator. That string is then run through the cryptographic algorithm specified in the header. This example uses HMAC-SHA256 with a shared secret (public key algorithms are also defined). The Base64url Encoding is similar to base64, but uses different non-alphanumeric characters and omits padding.\nThe three parts are encoded separately using Base64url Encoding RFC 4648, and concatenated using periods to produce the JWT:\n\nThe above data and the secret of \"secretkey\" creates the token:\n\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJsb2dnZWRJbkFzIjoiYWRtaW4iLCJpYXQiOjE0MjI3Nzk2Mzh9.gzSraSYS8EXBxLN_oWnFSRgCzcmJmMjLiuyu5CSpyHI\nThis resulting token can be easily passed into HTML and HTTP.\n\n== Use ==\nIn authentication, when the user successfully logs in using their credentials, a JSON Web Token will be returned and must be saved locally (typically in local or session storage, but cookies can also be used), instead of the traditional approach of creating a session in the server and returning a cookie. For unattended processes the client may also authenticate directly by generating and signing its own JWT with a pre-shared secret and pass it to a OAuth compliant service like so:If the client passes a valid JWT assertion the server will generate an access_token valid for making calls to the application and pass it back to the client:When the client wants to access a protected route or resource, the user agent should send the JWT, typically in the Authorization HTTP header using the Bearer schema. The content of the header might look like the following:\nAuthorization: Bearer eyJhbGci...<snip>...yu5CSpyHI\n\nThis is a stateless authentication mechanism as the user state is never saved in server memory. The server's protected routes will check for a valid JWT in the Authorization header, and if it is present, the user will be allowed to access protected resources. As JWTs are self-contained, all the necessary information is there, reducing the need to query the database multiple times.\n\n== Standard fields ==\n\n== Implementations ==\nJWT implementations exist for many languages and frameworks, including but not limited to:\n\n== Vulnerabilities ==\nJSON web tokens may contain session state. But if project requirements allow session invalidation before JWT expiration, services can no longer trust token assertions by the token alone. To validate that the session stored in the token is not revoked, token assertions must be checked against a data store. This renders the tokens no longer stateless, undermining the primary advantage of JWTs.Security consultant Tim McLean reported vulnerabilities in some JWT libraries that used the alg field to incorrectly validate tokens, most commonly by accepting a alg\n\nAnswer this question based on the above context: What are Registered Claim Names in a JWT?",
    "context": "",
    "output": "Registered Claim Names are standard fields commonly included in JWTs, such as the standard Issued At Time claim (iat).",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are Registered Claim Names in a JWT?",
      "answer": "Registered Claim Names are standard fields commonly included in JWTs, such as the standard Issued At Time claim (iat).",
      "context": "JSON Web Token\n\n==Introduction==\nJSON Web Token (JWT, pronounced , same as the word \"jot\") is a proposed Internet standard for creating data with optional signature and/or optional encryption whose payload holds JSON that asserts some number of claims. The tokens are signed either using a private secret or a public/private key.\nFor example, a server could generate a token that has the claim \"logged in as administrator\" and provide that to a client. The client could then use that token to prove that it is logged in as admin. The tokens can be signed by one party's private key (usually the server's) so that any party can subsequently verify whether or not the token is legitimate. If the other party, by some suitable and trustworthy means, is in possession of the corresponding public key, they too are able to verify the token's legitimacy. The tokens are designed to be compact, URL-safe, and usable especially in a web-browser single-sign-on (SSO) context. JWT claims can typically be used to pass identity of authenticated users between an identity provider and a service provider, or any other type of claims as required by business processes.JWT relies on other JSON-based standards: JSON Web Signature and JSON Web Encryption.\n\n== Structure ==\nHeader\nIdentifies which algorithm is used to generate the signature\nHS256 indicates that this token is signed using HMAC-SHA256.\nTypical cryptographic algorithms used are HMAC with SHA-256 (HS256) and RSA signature with SHA-256 (RS256). JWA (JSON Web Algorithms) RFC 7518 introduces many more for both authentication and encryption.\n\nPayload\nContains a set of claims. The JWT specification defines seven Registered Claim Names which are the standard fields commonly included in tokens. Custom claims are usually also included, depending on the purpose of the token.\nThis example has the standard Issued At Time claim (iat) and a custom claim (loggedInAs).\n\nSignature\nSecurely validates the token. The signature is calculated by encoding the header and payload using Base64url Encoding RFC 4648 and concatenating the two together with a period separator. That string is then run through the cryptographic algorithm specified in the header. This example uses HMAC-SHA256 with a shared secret (public key algorithms are also defined). The Base64url Encoding is similar to base64, but uses different non-alphanumeric characters and omits padding.\nThe three parts are encoded separately using Base64url Encoding RFC 4648, and concatenated using periods to produce the JWT:\n\nThe above data and the secret of \"secretkey\" creates the token:\n\neyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJsb2dnZWRJbkFzIjoiYWRtaW4iLCJpYXQiOjE0MjI3Nzk2Mzh9.gzSraSYS8EXBxLN_oWnFSRgCzcmJmMjLiuyu5CSpyHI\nThis resulting token can be easily passed into HTML and HTTP.\n\n== Use ==\nIn authentication, when the user successfully logs in using their credentials, a JSON Web Token will be returned and must be saved locally (typically in local or session storage, but cookies can also be used), instead of the traditional approach of creating a session in the server and returning a cookie. For unattended processes the client may also authenticate directly by generating and signing its own JWT with a pre-shared secret and pass it to a OAuth compliant service like so:If the client passes a valid JWT assertion the server will generate an access_token valid for making calls to the application and pass it back to the client:When the client wants to access a protected route or resource, the user agent should send the JWT, typically in the Authorization HTTP header using the Bearer schema. The content of the header might look like the following:\nAuthorization: Bearer eyJhbGci...<snip>...yu5CSpyHI\n\nThis is a stateless authentication mechanism as the user state is never saved in server memory. The server's protected routes will check for a valid JWT in the Authorization header, and if it is present, the user will be allowed to access protected resources. As JWTs are self-contained, all the necessary information is there, reducing the need to query the database multiple times.\n\n== Standard fields ==\n\n== Implementations ==\nJWT implementations exist for many languages and frameworks, including but not limited to:\n\n== Vulnerabilities ==\nJSON web tokens may contain session state. But if project requirements allow session invalidation before JWT expiration, services can no longer trust token assertions by the token alone. To validate that the session stored in the token is not revoked, token assertions must be checked against a data store. This renders the tokens no longer stateless, undermining the primary advantage of JWTs.Security consultant Tim McLean reported vulnerabilities in some JWT libraries that used the alg field to incorrectly validate tokens, most commonly by accepting a alg"
    }
  },
  {
    "instruction": "Write an answer to the following question: Who were the founders of PHIRM that co-authored a report on Cleveland's Free-net in 1987 and were also responsible for bringing the group into the public eye in 1985 with a Phrack magazine article?",
    "context": "",
    "output": "Archangel and The Stingray, two of PHIRM's founders, co-authored a report on Cleveland's Free-net in 1987 and were also responsible for bringing the group into the public eye in 1985 with a Phrack magazine article.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who were the founders of PHIRM that co-authored a report on Cleveland's Free-net in 1987 and were also responsible for bringing the group into the public eye in 1985 with a Phrack magazine article?",
      "answer": "Archangel and The Stingray, two of PHIRM's founders, co-authored a report on Cleveland's Free-net in 1987 and were also responsible for bringing the group into the public eye in 1985 with a Phrack magazine article."
    }
  },
  {
    "instruction": "context: The Minister acknowledged similarities between the MTU attack and the 2021 HSE cyberattack, both involving threats to delete and publish data.\n\nAsk a question about this context.",
    "context": "",
    "output": "What was the response of the Minister of State for Public Procurement and eGovernment to the Munster Technological University ransomware attack?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the response of the Minister of State for Public Procurement and eGovernment to the Munster Technological University ransomware attack?",
      "answer": "The Minister acknowledged similarities between the MTU attack and the 2021 HSE cyberattack, both involving threats to delete and publish data."
    }
  },
  {
    "instruction": "context: The \"Data Protection Review Court\" is a new mechanism in the Trans-Atlantic Data Privacy Framework that allows EU citizens to pursue data privacy violations.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the role of the \"Data Protection Review Court\" in the new Trans-Atlantic Data Privacy Framework?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the \"Data Protection Review Court\" in the new Trans-Atlantic Data Privacy Framework?",
      "answer": "The \"Data Protection Review Court\" is a new mechanism in the Trans-Atlantic Data Privacy Framework that allows EU citizens to pursue data privacy violations."
    }
  },
  {
    "instruction": "context: The different types of internal risks include strategic risks such as R&D, operational risks such as systems and processes, financial risks such as liquidity and cash flow, hazard risks such as safety and security, and compliance risks such as changes in an organization's systems, processes, suppliers, etc.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are the different types of internal risks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the different types of internal risks?",
      "answer": "The different types of internal risks include strategic risks such as R&D, operational risks such as systems and processes, financial risks such as liquidity and cash flow, hazard risks such as safety and security, and compliance risks such as changes in an organization's systems, processes, suppliers, etc."
    }
  },
  {
    "instruction": "Context: Octopussy (software)\n\n==Introduction==\nOctopussy, also known as 8Pussy, is a  free and open-source computer-software which monitors  systems, by constantly analyzing the syslog data they generate and transmit to such a central Octopussy server (thus often called a SIEM solution). Therefore, software like Octopussy plays an important role in maintaining an information security management system within ISO/IEC 27001-compliant environments.\nOctopussy has the ability to monitor any device that supports the syslog protocol, such as servers, routers, switches, firewalls, load balancers, and its important applications and services. The main purpose of the software is to alert its administrators and users to different kinds of events, like system outages, attacks on systems or errors in applications. However, unlike Nagios or Icinga, Octopussy is not a state-checker and therefore problems cannot be resolved within the application. The software also makes no prescription whatsoever on which messages must be/must not be analyzed. As such, Octopussy can be seen as less powerful than other popular commercial software in the same category (event monitoring and log analysis).Octopussy is compatible with many Linux system distributions like Debian, Ubuntu, OpenSUSE, CentOS, RHEL and even meta-distributions as Gentoo or Arch Linux. Although Octopussy was originally designed to run on Linux, it could be ported to other Unix variants like FreeBSD with minimal effort. Octopussy has extensive report generating features and also various interfaces to other software, like e.g. NSCA (Nagios), Jabber/XMPP and Zabbix. With the help of software like Snare even Windows EventLogs can be processed.Octopussy is licensed under the terms of the GNU General Public License.\n\n\n\n== Characteristics ==\nAlthough Octopussy is free and open-source software it has a variety of characteristics also found in some professional enterprise applications like Splunk, SAWMILL or Kiwi Syslog.\n\n\n*** Octopussy features ***\nAt the time of writing, Octopussy comes with the following set of features:\n\nBasic LDAP support (v1.0+) for Octopussy users and contacts with filter mechanism\nAlert sending by email, IM (Jabber), NSCA (Nagios) and Zabbix\nMap functionality to show the system infrastructure known to Octopussy\nExportable reports by email, FTP and SCP\nInput & output plugins for manual and automatic reports\nReport scheduling and automated report generation based on parameters\nA log viewer to search for syslog messages received by Octopussy\nAn RRDtool to provide data graphing of syslog activity for enabled services\nComprehensive service definitions (Apache 2, BIND, BSD Kernel ...)\nA wizard to easily create new services and/or message patterns for existing services\nAn option to enable or disable services and alerts for every system under surveillance\nOnline updates for services, tables and l18n (language support)\nMulti-language support: English French German Italian Spanish Portuguese Russian\nA web-interface for viewing current devices status, alerts, log messages, etc.\nA themable interface and report documents\nManageability of Octopussy core services from the operating system shell\nFlat-text formatted configuration files (integrates with many configuration editors)\nAn option to timely rotate and store received syslog messages in various locations\nUser management with the ability of granular permission configuration\nSimple outline of styles and GUI components in ASP for easy modification\n\n\n*** Supported services ***\nSome of the (meta-)services supported by/known by Octopussy are:\nApache 2, BIND, BSD Kernel, BSD PAM, BSD System, Cisco Routers (ASR), Cisco Switches, ClamAV, DenyAll Reverse Proxy, DRBD, F5 BigIP, Fortinet FW, HP-Tools, Ironport MailServer, Juniper Netscreen FW, Juniper Netscreen NSM, LDAP, Linux AppArmor, Linux Auditd, Linux IPTables, Linux Kernel, Linux PAM, Linux System, Monit, MySQL, Nagios, Neoteris/Juniper FW, NetApp NetCache, Postfix, PostgreSQL, Samba, Samhain, SNMPd, Squid, SSHd, Syslog-ng, TACACS, VMware ESX(i), Windows Snare Agent, Windows System, Xen ...\n\n\n*** Processible events ***\nEvents receivable from services and thus processible by Octopussy include:\n\nFailed and/or successful logins, especially of higher privileged users\nViolation of access permissions or policies in applications and operating systems\nWrite and/or read access in critical environments, e.g. with AppArmor or SELinux\nEstablished or terminated VPN tunnels in systems, like e.g. Juniper Netscreen\nObjects like processes or files which security context or configuration changed\nStarted or stopped processes on an operating system level\nCritical system states like (unrecoverable) hardware or software failure\nChange in operating system state due to boot, reboot or shutdown\nInformation regarding network connections/traffic, including ICMP messages, etc.\nDetection or otherwise handling of malware (i.e. worms, viruses, trojans)\n\n== Dependencies ==\nThe software requires RSYSLOG installed on the syslog-server and expects systems that are monitored to run one of the numerous available syslog services, like e.g. syslogd/klogd, RSYSLOG or syslog-ng.The software further depends on the Apache 2 HTTP Server installed, with Apache::ASP, Mod_Perl and Mod_SSL. Octopussy also requires a MySQL DBMS (actual database is installed/copied during Octopussy setup) as well as a recent Perl interpreter installed on the operating system, with a variety of Perl modules from CPAN (e.g. Crypt::PasswdMD5, DBD::mysql, JSON, Unix::Syslog, XML::Simple). A comprehensive list of those modules can be found within the software packages/archives README.txt file. In addition to that NSCD and RRDtool are a requirement. RRDtool aids in the creation of graphs that will be displayed on the Octopussy dashboard or shown on a per-device/per-service level.\n\n== Architecture ==\n\nOctopussy receives syslog messages via syslog protocol and therefore behaves passively, not running any type of network agent on the remote machines under monitoring/surveillance. Octopussy completely conforms to RfC 3164 and RfC 3195 of the IETF, describing syslog as the logging mechanism in Unix-like/BSD operating systems. That especially includes the internal representation of the facility and severity-principle where applicable.\nThe software is driven by a semi-stateful event correlation engine. This means that the engine records and thus knows its internal state, but only uses it to some extent to link together logically related elements for the same device, in order to draw a conclusion (i.e. to generate an alert). In Octopussy the semi-stateful correlation engine, with its so called sliding window (a shifting window being the logical boundary of a number of events during a certain period of time), is capable of comparing known past events with present ones based on a limited number of comparative values.\n\n\n*** Octopussy Dispatcher ***\nThe Octo-Dispatcher is the component used by the Octopussy software to receive syslog lines from RSYSLOG and dispatch them into device directories. Every device registered and activated within Octopussy gets its syslog messages assigned to it depending on the device name. Noteworthy is also the adjacent Octo-Replay component, which is the program used by the Octopussy software to replay log messages for some device or service (it receives and processes recognized logs and puts them back into the incoming directory).\n\n\n*** Octopussy Parser ***\nThe Octo-Parser and Octo-Uparser are two of Octopussy's most important core components. The Octo-Parser is the program used by the Octopussy software to parse logs in syslog format for each device registered within Octopussy. It basically uses a regex-engine and commences pattern matching on incoming syslog messages. The Octo-Uparser is restarted every time device's services are changed, to check if previously received \"unknown\" log messages can be associated with a service.\nIn some cases Octo-Pusher is also called in advance to process non-syslog messages incoming from some devices. In that regard, the device setting \"asynchronous\" is helpful to process such log messages, after they were sent to an Octopussy server using e.g. FTP, rsync or SSH/SCP.\n\n\n*** Octopussy Interface ***\nThe Octopussy interface (GUI) is the default user-interface and provides configuration management, device and service management as well as alert definition and therefore extends the Octopussy core components. Devices are displayed in tabular form on the Devices page, with the following descriptors as a minimum: hostname, IP address, log type, device model/type, FQDN and OS.\nHence, the interface (Octo-Web) mainly provides access to other Octopussy core components like Octo-Commander, Octo-Message-Finder, Octo-Reporter and Octo-Statistic-Reporter. The Octopussy front-end/GUI is written in Perl 5, employing Apache::ASP to structure and display content.In addition to that, Octopussy core services can also be accessed from the operating system shell. That represents a convenient way for administrators to start/stop services or make fundamental configuration changes.\n\n\n*** Octopussy RRD ***\nThe Octopussy RRD graph generator is a core component of the software and installed by default. Since the generation of such graphs is very resource intensive administrators may opt to disable it on an Octopussy syslog server with a less powerful CPU and a low amount of RAM. The generated RRD graphs displays the activity of all active services for monitored devices, highly depending on the specific service. After a restart of the Octopussy software or during operation, Octo-Dispatcher and Octo-Parser will always process syslog messages in their buffer and queue first and RRD graph generation is delayed. Octo-RRD further depends on Octo-Scheduler, to execute the Octopussy::Report function in order to generate syslog activity RRD graphs, that have been scheduled previously. Finally Octo-Sender has the capability to send report data to arbitrary recipients.\n\n== Extensions ==\nThere is a plug-in/module system in Octopussy, which is mainly geared towards the modification of Octopussy reports. Such a plug-in consists out of a description file, which defines the plug-in name and functions, and a code file with perl code to process the actual data.There are also extensions for software related to Octopussy, like e.g. a Nagios plug-in that checks the Octopussy core services (i.e. Octo-Dispatcher, Octo-Scheduler, etc.) as well as the Octopussy parser states and log partitions.\n\n== Services & Patterns ==\nThe creation of new services and service patterns presents the most important way to extend Octopussy without making changes to the source code. However, since patterns are outlined as simplified regular expressions, administrators should have at least some basic knowledge about regex in general. It is further strongly recommended to build on already existing services and also understand the meaning of a message objects' basic fields, which are message ID, pattern, log level, taxonomy, table and rank.Usually the logs wizard is used to search the system for unrecognized syslog messages per device to generate new service patterns. During the process the creation of patterns should be in a way that enables Octopussy to distinguish messages based on their severity and taxonomy.\nAnswer this question: What is the primary function of Octopussy software in an ISO/IEC 27001-compliant environment?",
    "context": "",
    "output": "Octopussy software plays a critical role in maintaining an information security management system within ISO/IEC 27001-compliant environments by constantly analyzing syslog data generated by various devices. It monitors systems, alerts administrators and users to events like system outages, attacks on systems, or errors in applications, and can be used with many Linux system distributions and some Unix variants.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the primary function of Octopussy software in an ISO/IEC 27001-compliant environment?",
      "answer": "Octopussy software plays a critical role in maintaining an information security management system within ISO/IEC 27001-compliant environments by constantly analyzing syslog data generated by various devices. It monitors systems, alerts administrators and users to events like system outages, attacks on systems, or errors in applications, and can be used with many Linux system distributions and some Unix variants.",
      "context": "Octopussy (software)\n\n==Introduction==\nOctopussy, also known as 8Pussy, is a  free and open-source computer-software which monitors  systems, by constantly analyzing the syslog data they generate and transmit to such a central Octopussy server (thus often called a SIEM solution). Therefore, software like Octopussy plays an important role in maintaining an information security management system within ISO/IEC 27001-compliant environments.\nOctopussy has the ability to monitor any device that supports the syslog protocol, such as servers, routers, switches, firewalls, load balancers, and its important applications and services. The main purpose of the software is to alert its administrators and users to different kinds of events, like system outages, attacks on systems or errors in applications. However, unlike Nagios or Icinga, Octopussy is not a state-checker and therefore problems cannot be resolved within the application. The software also makes no prescription whatsoever on which messages must be/must not be analyzed. As such, Octopussy can be seen as less powerful than other popular commercial software in the same category (event monitoring and log analysis).Octopussy is compatible with many Linux system distributions like Debian, Ubuntu, OpenSUSE, CentOS, RHEL and even meta-distributions as Gentoo or Arch Linux. Although Octopussy was originally designed to run on Linux, it could be ported to other Unix variants like FreeBSD with minimal effort. Octopussy has extensive report generating features and also various interfaces to other software, like e.g. NSCA (Nagios), Jabber/XMPP and Zabbix. With the help of software like Snare even Windows EventLogs can be processed.Octopussy is licensed under the terms of the GNU General Public License.\n\n\n\n== Characteristics ==\nAlthough Octopussy is free and open-source software it has a variety of characteristics also found in some professional enterprise applications like Splunk, SAWMILL or Kiwi Syslog.\n\n\n*** Octopussy features ***\nAt the time of writing, Octopussy comes with the following set of features:\n\nBasic LDAP support (v1.0+) for Octopussy users and contacts with filter mechanism\nAlert sending by email, IM (Jabber), NSCA (Nagios) and Zabbix\nMap functionality to show the system infrastructure known to Octopussy\nExportable reports by email, FTP and SCP\nInput & output plugins for manual and automatic reports\nReport scheduling and automated report generation based on parameters\nA log viewer to search for syslog messages received by Octopussy\nAn RRDtool to provide data graphing of syslog activity for enabled services\nComprehensive service definitions (Apache 2, BIND, BSD Kernel ...)\nA wizard to easily create new services and/or message patterns for existing services\nAn option to enable or disable services and alerts for every system under surveillance\nOnline updates for services, tables and l18n (language support)\nMulti-language support: English French German Italian Spanish Portuguese Russian\nA web-interface for viewing current devices status, alerts, log messages, etc.\nA themable interface and report documents\nManageability of Octopussy core services from the operating system shell\nFlat-text formatted configuration files (integrates with many configuration editors)\nAn option to timely rotate and store received syslog messages in various locations\nUser management with the ability of granular permission configuration\nSimple outline of styles and GUI components in ASP for easy modification\n\n\n*** Supported services ***\nSome of the (meta-)services supported by/known by Octopussy are:\nApache 2, BIND, BSD Kernel, BSD PAM, BSD System, Cisco Routers (ASR), Cisco Switches, ClamAV, DenyAll Reverse Proxy, DRBD, F5 BigIP, Fortinet FW, HP-Tools, Ironport MailServer, Juniper Netscreen FW, Juniper Netscreen NSM, LDAP, Linux AppArmor, Linux Auditd, Linux IPTables, Linux Kernel, Linux PAM, Linux System, Monit, MySQL, Nagios, Neoteris/Juniper FW, NetApp NetCache, Postfix, PostgreSQL, Samba, Samhain, SNMPd, Squid, SSHd, Syslog-ng, TACACS, VMware ESX(i), Windows Snare Agent, Windows System, Xen ...\n\n\n*** Processible events ***\nEvents receivable from services and thus processible by Octopussy include:\n\nFailed and/or successful logins, especially of higher privileged users\nViolation of access permissions or policies in applications and operating systems\nWrite and/or read access in critical environments, e.g. with AppArmor or SELinux\nEstablished or terminated VPN tunnels in systems, like e.g. Juniper Netscreen\nObjects like processes or files which security context or configuration changed\nStarted or stopped processes on an operating system level\nCritical system states like (unrecoverable) hardware or software failure\nChange in operating system state due to boot, reboot or shutdown\nInformation regarding network connections/traffic, including ICMP messages, etc.\nDetection or otherwise handling of malware (i.e. worms, viruses, trojans)\n\n== Dependencies ==\nThe software requires RSYSLOG installed on the syslog-server and expects systems that are monitored to run one of the numerous available syslog services, like e.g. syslogd/klogd, RSYSLOG or syslog-ng.The software further depends on the Apache 2 HTTP Server installed, with Apache::ASP, Mod_Perl and Mod_SSL. Octopussy also requires a MySQL DBMS (actual database is installed/copied during Octopussy setup) as well as a recent Perl interpreter installed on the operating system, with a variety of Perl modules from CPAN (e.g. Crypt::PasswdMD5, DBD::mysql, JSON, Unix::Syslog, XML::Simple). A comprehensive list of those modules can be found within the software packages/archives README.txt file. In addition to that NSCD and RRDtool are a requirement. RRDtool aids in the creation of graphs that will be displayed on the Octopussy dashboard or shown on a per-device/per-service level.\n\n== Architecture ==\n\nOctopussy receives syslog messages via syslog protocol and therefore behaves passively, not running any type of network agent on the remote machines under monitoring/surveillance. Octopussy completely conforms to RfC 3164 and RfC 3195 of the IETF, describing syslog as the logging mechanism in Unix-like/BSD operating systems. That especially includes the internal representation of the facility and severity-principle where applicable.\nThe software is driven by a semi-stateful event correlation engine. This means that the engine records and thus knows its internal state, but only uses it to some extent to link together logically related elements for the same device, in order to draw a conclusion (i.e. to generate an alert). In Octopussy the semi-stateful correlation engine, with its so called sliding window (a shifting window being the logical boundary of a number of events during a certain period of time), is capable of comparing known past events with present ones based on a limited number of comparative values.\n\n\n*** Octopussy Dispatcher ***\nThe Octo-Dispatcher is the component used by the Octopussy software to receive syslog lines from RSYSLOG and dispatch them into device directories. Every device registered and activated within Octopussy gets its syslog messages assigned to it depending on the device name. Noteworthy is also the adjacent Octo-Replay component, which is the program used by the Octopussy software to replay log messages for some device or service (it receives and processes recognized logs and puts them back into the incoming directory).\n\n\n*** Octopussy Parser ***\nThe Octo-Parser and Octo-Uparser are two of Octopussy's most important core components. The Octo-Parser is the program used by the Octopussy software to parse logs in syslog format for each device registered within Octopussy. It basically uses a regex-engine and commences pattern matching on incoming syslog messages. The Octo-Uparser is restarted every time device's services are changed, to check if previously received \"unknown\" log messages can be associated with a service.\nIn some cases Octo-Pusher is also called in advance to process non-syslog messages incoming from some devices. In that regard, the device setting \"asynchronous\" is helpful to process such log messages, after they were sent to an Octopussy server using e.g. FTP, rsync or SSH/SCP.\n\n\n*** Octopussy Interface ***\nThe Octopussy interface (GUI) is the default user-interface and provides configuration management, device and service management as well as alert definition and therefore extends the Octopussy core components. Devices are displayed in tabular form on the Devices page, with the following descriptors as a minimum: hostname, IP address, log type, device model/type, FQDN and OS.\nHence, the interface (Octo-Web) mainly provides access to other Octopussy core components like Octo-Commander, Octo-Message-Finder, Octo-Reporter and Octo-Statistic-Reporter. The Octopussy front-end/GUI is written in Perl 5, employing Apache::ASP to structure and display content.In addition to that, Octopussy core services can also be accessed from the operating system shell. That represents a convenient way for administrators to start/stop services or make fundamental configuration changes.\n\n\n*** Octopussy RRD ***\nThe Octopussy RRD graph generator is a core component of the software and installed by default. Since the generation of such graphs is very resource intensive administrators may opt to disable it on an Octopussy syslog server with a less powerful CPU and a low amount of RAM. The generated RRD graphs displays the activity of all active services for monitored devices, highly depending on the specific service. After a restart of the Octopussy software or during operation, Octo-Dispatcher and Octo-Parser will always process syslog messages in their buffer and queue first and RRD graph generation is delayed. Octo-RRD further depends on Octo-Scheduler, to execute the Octopussy::Report function in order to generate syslog activity RRD graphs, that have been scheduled previously. Finally Octo-Sender has the capability to send report data to arbitrary recipients.\n\n== Extensions ==\nThere is a plug-in/module system in Octopussy, which is mainly geared towards the modification of Octopussy reports. Such a plug-in consists out of a description file, which defines the plug-in name and functions, and a code file with perl code to process the actual data.There are also extensions for software related to Octopussy, like e.g. a Nagios plug-in that checks the Octopussy core services (i.e. Octo-Dispatcher, Octo-Scheduler, etc.) as well as the Octopussy parser states and log partitions.\n\n== Services & Patterns ==\nThe creation of new services and service patterns presents the most important way to extend Octopussy without making changes to the source code. However, since patterns are outlined as simplified regular expressions, administrators should have at least some basic knowledge about regex in general. It is further strongly recommended to build on already existing services and also understand the meaning of a message objects' basic fields, which are message ID, pattern, log level, taxonomy, table and rank.Usually the logs wizard is used to search the system for unrecognized syslog messages per device to generate new service patterns. During the process the creation of patterns should be in a way that enables Octopussy to distinguish messages based on their severity and taxonomy."
    }
  },
  {
    "instruction": "context: China Daily\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the name of the Chinese Communist Party-owned newspaper that published an article and a video criticizing IPVM in January 2022?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the name of the Chinese Communist Party-owned newspaper that published an article and a video criticizing IPVM in January 2022?",
      "answer": "China Daily"
    }
  },
  {
    "instruction": "Write an answer to the following question: How has Russia used international institutions as platforms for accusations of discrimination against minorities in Estonia, according to the Estonian Internal Security Service yearbook published in April 2009?",
    "context": "",
    "output": "Russia has used disinformation campaigns and international institutions as platforms for accusations of discrimination against minorities in Estonia, aggravating inter-ethnic tensions in a way that has worked against the country's integration policies.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has Russia used international institutions as platforms for accusations of discrimination against minorities in Estonia, according to the Estonian Internal Security Service yearbook published in April 2009?",
      "answer": "Russia has used disinformation campaigns and international institutions as platforms for accusations of discrimination against minorities in Estonia, aggravating inter-ethnic tensions in a way that has worked against the country's integration policies."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the purpose of the NSA's infiltration of smartphones?",
    "context": "",
    "output": "The NSA infiltrates smartphones to gain access to a variety of data sets that would interest an intelligence agency, such as social contacts, user behaviour, interests, location, photos and credit card numbers and passwords.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the NSA's infiltration of smartphones?",
      "answer": "The NSA infiltrates smartphones to gain access to a variety of data sets that would interest an intelligence agency, such as social contacts, user behaviour, interests, location, photos and credit card numbers and passwords."
    }
  },
  {
    "instruction": "Russian interference in the 2020 United States elections\n\n==Introduction==\nRussian interference in the 2020 United States elections was a matter of concern at the highest level of national security within the United States government, in addition to the computer and social media industries. In 2020, the RAND Corporation was one of the first to release research describing Russia's playbook for interfering in U.S. elections, developed machine-learning tools to detect the interference, and tested strategies to counter Russian interference. In February and August 2020, United States Intelligence Community (USIC) experts warned members of Congress that Russia was interfering in the 2020 presidential election in then-President Donald Trump's favor. USIC analysis released by the Office of the Director of National Intelligence (DNI) in March 2021 found that proxies of Russian intelligence promoted and laundered misleading or unsubstantiated narratives about Joe Biden \"to US media organizations, US officials, and prominent US individuals, including some close to former President Trump and his administration.\" The New York Times reported in May 2021 that federal investigators in Brooklyn began a criminal investigation late in the Trump administration into possible efforts by several current and former Ukrainian officials to spread unsubstantiated allegations about corruption by Joe Biden, including whether they had used Trump personal attorney Rudy Giuliani as a channel.\n\n== Reports of attempted interference ==\n\n\n*** Overview ***\nIn response to Russian interference in the 2016 United States elections, special counsel Robert Mueller conducted a two-year-long investigation. The resulting report concluded that Russia interfered in \"sweeping and systematic fashion\". In his July 2019 congressional testimony, Mueller stated that the Russians continue to interfere in U.S. elections \"as we sit here\", and that \"many more countries\" have developed disinformation campaigns targeting U.S. elections, based partly on the Russian model.Also in July 2019, the Senate Intelligence Committee released the first volume of a bipartisan report on Russian interference in the 2016 United States elections, a report that included recommendations for securing the 2020 elections. The second volume of that report noted, based on social-media data from October 2018, that \"Russian disinformation efforts may be focused on gathering information and data points in support of an active measures campaign targeted at the 2020 U.S. presidential election.\"In a highly classified report, the Central Intelligence Agency stated: \"We assess that President Vladimir Putin and the senior most Russian officials are aware of and probably directing Russia's influence operations aimed at denigrating the former U.S. Vice President, supporting the U.S. president and fueling public discord ahead of the U.S. election in November.\" The existence of this report, published at the end of August 2020, was made public knowledge on September 22 in reports from The Washington Post and The New York Times.U.S. officials have accused Russia, China and Iran of trying to influence the 2020 elections. Between January and late July 2017, Twitter identified and shut down over 7,000 phony accounts created by Iranian influence operations. According to Christopher A. Wray, the Director of the Federal Bureau of Investigation, Russia is attempting to interfere with the 2020 United States elections. Speaking to the Council on Foreign Relations in July 2019, Wray stated, \"We are very much viewing 2018 as just kind of a dress rehearsal for the big show in 2020.\" Dan Coats, the former Director of National Intelligence, believes that Russia and China will both attempt to influence the elections. As of September 2020, intelligence officials point to Russia as the more \"acute threat\" to the election, saying that China has been expressing its preferences by public rhetoric rather than engaging in covert operations to denigrate a candidate or otherwise interfere in the election itself. Wray testified to the House Committee on Homeland Security on September 17, 2020, that Russian efforts to damage the Biden campaign were \"very active\".According to United States intelligence officials interviewed by The New York Times, Russian \"operations would be intended to help President Trump, potentially by exacerbating disputes around the results, especially if the race is too close to call.\" The FBI and the Cybersecurity and Infrastructure Security Agency have stated that Russian cyberattacks have targeted \"U.S. state, local, territorial, and tribal government networks, as well as aviation networks\".\n\n\n*** Social-media disinformation and voting infrastructure ***\nVarious disinformation campaigns on social media have targeted the Democratic Party candidates running in the 2020 Democratic Party presidential primaries. This has prompted considerable concern regarding the ability of social media companies to cope with disinformation and manipulation. By August 2019, Facebook and Twitter had banned advertisements that use misinformation to attempt the suppression of voter turnout.Microsoft developed an open source software called ElectionGuard to help safeguard the 2020 elections. In mid-July 2019, Microsoft announced that it had, over the prior year, \"notified nearly 10,000 customers they've been targeted or compromised by nation-state attacks\". Based on attacks that had targeted political organizations, and on experience from 2016 and 2018, Microsoft anticipated \"attacks targeting U.S. election systems, political campaigns or NGOs that work closely with campaigns\". Of the \"nation-state attacks\" that had originated from Russia, Microsoft claimed that they followed the \"same pattern of engagement\" as Russian operations in 2016 and 2018. On September 20, 2019, Microsoft announced that it would provide free security updates for Windows 7, which reached its end-of-life on January 14, 2020, on federally-certified voting machines through the 2020 United States elections. On October 4, 2019, Microsoft announced that \"Phosphorus\", a group of hackers linked to the Iranian government, had attempted to compromise e-mail accounts belonging to journalists, prominent Iranian expatriates, U.S. government officials and the campaign of a U.S. presidential candidate. While Microsoft did not disclose which campaign had been the target of the cyber attack, unnamed sources informed Reuters that it had been that of Donald Trump.On October 21, 2019, Facebook CEO Mark Zuckerberg announced that his company has detected a \"highly sophisticated\" set of campaigns to interfere with the 2020 elections. These campaigns originated from Russia and from Iran. Fake accounts based in Russia posed as Americans of varied political backgrounds and worked to undermine the campaign of Joe Biden, aiming to sow discontent with Biden from both the left and the right.A September 2019 report from The Washington Post demonstrated that due to bad default passwords and weak encryption, hackers with physical access can easily get into voting machines designed for use in the 2020 United States elections, and remote hacking was possible if the machines were accidentally misconfigured.On February 21, 2020, The Washington Post reported that, according to unnamed US officials, Russia was interfering in the Democratic primary in an effort to support the nomination of Senator Bernie Sanders. Sanders issued a statement after the news report, saying in part, \"I don't care, frankly, who Putin wants to be president. My message to Putin is clear: stay out of American elections, and as president I will make sure that you do.\" Sanders acknowledged that his campaign was briefed about Russia's alleged efforts about a month prior. Sanders suggested that Russians were impersonating people claiming to be his supporters online in order to create an atmosphere of toxicity and give \"Bernie Bros\" a bad reputation, a suggestion that Twitter rejected. According to election-security expert Laura Rosenberger, \"Russian attempts to sow discord in the Democratic primary would be consistent with its strategy of undermining Americans' faith in democratic institutions and processes.\"In March 2020, the University of Wisconsin\u2013Madison and the Brennan Center for Justice published a report indicating that Russia-linked social media accounts have been spreading Instagram posts calculated to sow division among American voters. According to the report, Russian operatives were increasingly impersonating real political candidates and groups rather than creating fictional groups. According to Twitter's head of site integrity, Russian agents also attempted in 2018 to create the impression of more election interference than is actually happening to undermine confidence in the process. Shortly thereafter, the New York Times reported that according to American intelligence officials Russian operatives have been stoking via private Facebook groups anger among African Americans, emphasizing allegations of police brutality in the United States, highlighting racism in the United States against African Americans, and promoting and pressuring hate groups, including white and black extremist groups, in order to create strife within American society, though American intelligence officials provided few details about the alleged operations. A CNN investigation found that Russian efforts had partly been outsourced to troll farms in Ghana and Nigeria. In May 2020, Twitter suspended 44 accounts that exhibited behavior plausibly, but not definitively, indicative of Russian election interference tactics, including association with a Ghana troll farm.\nGovernment officials and American corporate security officers braced for a repeat of 2016's election infrastructure hacking and similar twenty-first century attacks and conducted what were characterized as pre-emptive counter-strikes on botnet infrastructure which might be used in a large-scale coordination of hacking. Some incidents earlier in the year appeared to foreshadow such possibilities. Following his dismissal, in a December 2020 interview, Chris Krebs, the Trump administration's director of the Cybersecurity and Infrastructure Security Agency (CISA), described monitoring Election Day from CISA's joint command center along with representatives from the military's United States Cyber Command, the National Security Agency (NSA), the Federal Bureau of Investigation (FBI), the United States Secret Service (USSS), the Election Assistance Commission (EAC), representatives of vendors of voting machine equipment, and representatives of state and local governments, as well as his agency's analysis preceding and subsequent to that day, saying,It was quiet. There was no indication or evidence that there was any sort of hacking or compromise of election systems on, before, or after November third.Responding to spurious claims of foreign outsourcing of vote counting as a rationale behind litigation attempting to stop official vote counting in some areas, Krebs also affirmed that, \"All votes in the United States of America are counted in the United States of America.\"However, acts of foreign interference did include Russian state-directed application of computational propaganda approaches, more conventional state-sponsored Internet propaganda, smaller-scale disinformation efforts, \"information laundering\" and \"trading up the chain\" propaganda tactics employing some government officials, Trump affiliates, and US media outlets, as described below.\n\n\n*** Briefings to Congress ***\nOn February 13, 2020, American intelligence officials advised members of the House Intelligence Committee that Russia was interfering in the 2020 election in an effort to get Trump re-elected. The briefing was delivered by Shelby Pierson, the intelligence community's top election security official and an aide to acting Director of National Intelligence Joseph Maguire. Trump allies on the committee challenged the findings, and Trump was angered to learn of the briefing as he believed Democrats might \"weaponize\" the information against him. He chastised Maguire for allowing the briefing to occur, and days later he appointed Richard Grenell to replace Maguire.William Evanina, director of the National Counterintelligence and Security Center told members of Congress during a classified briefing on July 31, 2020, that Russia was working to boost the campaign of Trump and undermine that of Biden. Details of Evanina's report were not made public. The Biden campaign confirmed to the Associated Press that they had \"faced multiple related threats\" but were \"reluctant to reveal specifics for fear of giving adversaries useful intelligence\". Evanina later stated in a press release, \"We assess that Russia is using a range of measures to primarily denigrate former Vice President Biden and what it sees as an anti-Russia 'establishment.'\" On August 7, 2020, CNN reported that intelligence officials had provided senators, representatives and both the Biden and Trump campaigns with information \"indicating Russia is behind an ongoing disinformation push targeting\" Biden. That same day, Democratic congressman Eric Swalwell, a member of the House Intelligence Committee, asserted that Republican senators investigating Biden and his son were \"acting as Russian launderers of this information.\"\n\n\n*** Giuliani, Derkach, and Johnson ***\n\nAccording to the Treasury Department, Trump's personal attorney Rudy Giuliani collaborated with active Russian agent Andrii Derkach, a Ukrainian lawmaker, to spread anti-Biden material during Trump's impeachment. The Treasury Department said that Derkach \"waged a covert influence campaign centered on cultivating false and unsubstantiated narratives concerning U.S. officials in the upcoming 2020 Presidential Election,\" including by the release of \"edited audio tapes and other unsupported information with the intent to discredit U.S. officials.\"Their efforts were aided by journalists like John Solomon, a contributor to Fox News, who, according to Jane Mayer, was pivotal for the dissemination of disinformation about Biden. She stated \"No journalist played a bigger part in fueling the Biden corruption narrative than John Solomon.\"In late 2019, the chairman of the Senate committee investigating the matter, Ron Johnson, was warned by American intelligence officials of a risk he could be playing into the hands of Russian intelligence to spread disinformation. During this period, Richard Burr (R-NC), chair of the Senate Intelligence Committee, also warned Johnson that Johnson's investigation could aid Russian efforts to promote distrust in the United States' political system. Senators had also been briefed in late 2019 about Russian efforts to frame Ukraine for 2016 election interference. Johnson initially said he would release findings in spring 2020, as Democrats would be selecting their 2020 presidential nominee, but instead ramped up the investigation at Trump's urging in May 2020, after it became clear Biden would be the nominee. In March 2020, Johnson decided to postpone the issuing of a subpoena for former Ukrainian official and employee of a Democratic lobby firm Blue Star Strategies Andrii Telizhenko, a close ally of Rudy Giuliani who had made appearances on the pro-Trump cable channel One America News, after Senator Mitt Romney backed away on voting for Mr. Telizhenko, as the Senators from the Democratic Party pressured Senator Romney on Mr. Telizhenko's vote. Trump tweeted a press report about the investigations, later stating that he would make allegations of corruption by the Bidens a central theme of his re-election campaign. The State Department revoked Telizhenko's visa in October 2020, and CNN reported the American government was considering sanctioning him as a Russian agent.In May 2020, Andrii Derkach, a Giuliani associate whom Evanina had named as a key participant in Russian interference, released snippets of alleged recordings of Joe Biden speaking with Petro Poroshenko, the Ukrainian president during the years Biden's son, Hunter, worked for Burisma Holdings. The Bidens had been accused without evidence of malfeasance relating to Burisma. The recordings, which were not verified as authentic and appeared heavily edited, depicted Biden linking loan guarantees for Ukraine to the ouster of the country's prosecutor general. The recordings did not provide evidence to support the ongoing conspiracy theory that Biden wanted the prosecutor fired to protect his son. Poroshenko denied In June 2020 that Joe Biden ever approached him about Burisma. In September 2020, the United States Department of the Treasury sanctioned Derkach, stating he \"has been an active Russian agent for over a decade, maintaining close connections with the Russian Intelligence Services.\"Giuliani, Trump's personal attorney, had spent significant time working in Ukraine during 2019 to gather information about the Bidens, making frequent American television appearances to discuss it. Attorney general Bill Barr confirmed in February 2020 that the Justice Department had created an \"intake process\" to analyze Giuliani's information. This information included a September 2019 statement by former Ukrainian prosecutor general Viktor Shokin falsely claiming he had been fired at Biden's insistence because Shokin was investigating Biden's son. The statement disclosed that it had been prepared at the request of attorneys for Ukrainian oligarch Dmitry Firtash, which since July 2019 included Joseph diGenova and his wife Victoria Toensing \u2014 both close associates of Trump and Giuliani. Firtash, fighting extradition to the United States where he was under federal indictment, is believed by the Justice Department to be connected to high levels of Russian organized crime, which allegedly installed him as a broker for Ukrainian imports of Russian natural gas. He is also reportedly close to the Kremlin to support Russian interests in Ukraine.According to officials interviewed by The Daily Beast, then-National Security Advisor John Bolton told his staff not to meet with Giuliani, as did his successor Robert C. O'Brien, because Bolton had been informed that Giuliani was spreading conspiracy theories that aligned with Russian interests in disrupting the 2020 election. These officials were also concerned that Giuliani would be used as a conduit for disinformation, including \"leaks\" of emails that would mix genuine with forged material in order to implicate Hunter Biden in corrupt dealings.The New York Times reported in November 2019 that Giuliani had directed associate Lev Parnas to approach Firtash about hiring the couple, with the proposition that Firtash could help to provide compromising information on Biden, which Parnas's attorney described was \"part of any potential resolution to [Firtash's] extradition matter.\" Giuliani denied any association with Firtash, though he told CNN he met with a Firtash attorney for two hours in New York City at the time he was seeking information about the Bidens. As vice president, Biden had urged the Ukrainian government to eliminate brokers such as Firtash to reduce the country's reliance on Russian gas. After his October 2019  indictment, Parnas asserted that he, Giuliani, diGenova and Toensing had a deal with Firtash in which the oligarch would provide information to discredit Biden in exchange for Giuliani persuading the Justice Department to drop its efforts to extradite Firtash.The Washington Post reported in October 2019 that after they began representing Firtash, Toensing and diGenova secured a rare face-to-face meeting with Barr to argue the Firtash charges should be dropped. Prior to that mid-August meeting, Barr had been briefed in detail on the initial Trump\u2013Ukraine whistleblower complaint within the CIA that had been forwarded to the Justice Department, as well as on Giuliani's activities in Ukraine. Bloomberg News reported that its sources told them Giuliani's high-profile publicity of the Shokin statement had greatly reduced the chances of the Justice Department dropping the charges against Firtash, as it would appear to be a political quid pro quo. Barr declined to intervene in the Firtash case. Firtash denied involvement in collecting or financing damaging information on the Bidens.\n\n\n*** Developments in summer and fall 2020 ***\nBy the summer of 2020, Russian intelligence had advanced to \"information laundering\" in which divisive propaganda was reported on Russia-affiliated news websites with the expectation the stories would be picked-up and spread by more legitimate news outlets. In August 2020, The New York Times reported that a video published by RT's Ruptly video platform, of Black Lives Matter protesters apparently burning a bible in Portland, Oregon, edited in a misleading way, \"went viral\" after it being shared with an inaccurate caption on social media by a far-right personality and then conservative politicians. The Times said the clip \"appear[ed] to be one of the first viral Russian disinformation hits of the 2020 presidential campaign\u201d. An NBC report in the wake of this incident found that Ruptly edited user-generated protest videos to highlight violence over peaceful protest.In September 2020, Facebook and Twitter announced that they had been alerted to the existence of Peace Data, a website set up by Russia's Internet Research Agency to interfere with the 2020 election. The social-media companies deleted accounts that had been used in an operation to recruit American journalists to write articles critical of Joe Biden and his running mate Kamala Harris. On September 3, the intelligence branch of the Department of Homeland Security issued a warning to state and federal law enforcement that Russia was \"amplifying\" concerns about postal voting and other measures taken to protect voters during the COVID-19 pandemic. According to DHS analysts, \"Russian malign influence actors\" had been spreading misinformation since at least March. Trump had repeatedly asserted without evidence that voting by mail would result in widespread fraud.ABC News reported in September 2020 that the Homeland Security Department had withheld the July release of an intelligence bulletin to law enforcement that warned of Russian efforts to promote \u201callegations about the poor mental health\u201d of Joe Biden. DHS chief of staff John Gountanis halted the release pending review by secretary Chad Wolf. The bulletin stated that analysts had \u201chigh confidence\u201d of the Russian efforts, which were similar to efforts by Trump and his campaign to depict Biden as mentally unfit. A DHS spokesperson said the bulletin was \u201cdelayed\u201d because it did not meet the department's standards. The bulletin had not been released as of the date of the ABC News report. Later in September, Brian Murphy \u2014 a former DHS undersecretary for intelligence and analysis \u2014 asserted in a whistleblower complaint that Wolf told him \u201cthe intelligence notification should be \u2018held\u2019 because it \u2018made the President look bad.\u2019\u201d Murphy also claimed Wolf told him to \"cease providing intelligence assessments on the threat of Russian interference in the US, and instead start reporting on interference activities by China and Iran.\u201d Murphy said Wolf told him this directive came from White House national security advisor Robert O'Brien. The DHS inspector general released findings in May 2022 that affirmed the accounts of ABC News and Murphy. The intelligence report on Russian interference appeared to have been \"delayed and altered...changes that 'appear to be based in part on political considerations'\".On September 10, 2020, Reuters reported that hackers had tried and failed to breach the systems of SKDKnickerbocker, a political consulting firm that specializes in working for Democratic Party politicians and that had been working with the Biden campaign for two months. Microsoft, who detected the cyberattack, informed SKDKnickerbocker that Russian state-backed hackers were the likely perpetrators.Analysts and officials interviewed by The New York Times in September 2020 indicated that a primary tactic of Russian disinformation campaigns was to amplify misleading statements from Trump, chiefly about postal voting. Russia's Internet Research Agency also created a fictitious press organization, the \"Newsroom for American and European Based Citizens\", in order to feed propaganda to right-wing social media users. NAEBC accounts were blocked or suspended by Facebook, Twitter, and LinkedIn, but their content \"got more traction\" on alt-tech platforms Gab and Parler, according to a Reuters report.H.R. McMaster, Trump's former national security advisor, said on October 1 that Trump was \"aiding and abetting Putin\u2019s efforts by not being direct about this. This sustained campaign of disruption, disinformation and denial is aided by any leader who doesn\u2019t acknowledge it.\"On October 5, The Washington Post reported that the State Department had revoked the travel visa of Giuliani associate Andrii Telizhenko.On October 21, threatening emails were sent to Democrats in at least four states. The emails warned that \"You will vote for Trump on Election Day or we will come after you.\" Director of National Intelligence John Ratcliffe announced that evening that the emails, using a spoofed return address, had been sent by Iran. He added that both Iran and Russia are known to have obtained American voter registration data, possibly from publicly available information, and that \"This data can be used by foreign actors to attempt to communicate false information to registered voters that they hope will cause confusion, sow chaos and undermine your confidence in American democracy.\" A spokesman for Iran denied the allegation. In his announcement Ratcliffe said that Iran's intent had been \"to intimidate voters, incite social unrest, and damage President Trump\", raising questions as to how ordering Democrats to vote for Trump would be damaging to Trump. It was later reported that the reference to Trump had not been in Ratcliffe's prepared remarks as signed off by the other officials on the stage, but that he added it on his own.\n\n\n**** New York Post story ****\n\nIn October 2020, the FBI reportedly launched an investigation into whether a story published in the tabloid journal New York Post on October 14 might be part of a Russian disinformation effort targeting Biden. The story, titled \"Biden Secret Emails\", displayed an email supposedly showing that Hunter Biden had arranged for his father, then-vice-president Joe Biden, to meet with a top advisor to Burisma. The Biden campaign said that no such meeting ever happened. The Post's source for the data was Giuliani, who says he got it from the hard drive of a laptop that was allegedly dropped off at a Delaware repair shop in April 2019 and never picked up. The shop owner told reporters that he thought the person who dropped it off was Hunter Biden but wasn't sure. He said he eventually gave the laptop to the FBI, keeping a copy of the hard drive for himself that he later gave to Giuliani. A year and a half earlier, in early 2019, White House officials had been warned that the Russians were planning to leak forged emails in the weeks before the election, and that Giuliani could be the conduit for such a leak.Most of the New York Post story was written by a staff reporter who did not allow his name to be used on it because he doubted the story's credibility. According to an investigation by The New York Times, editors at the New York Post \"pressed staff members to add their bylines to the story\", and at least one refused, in addition to the original author. Of the two writers eventually credited on the article, the second did not know her name was attached to it until after it was published. Giuliani was later quoted as saying he had given the hard drive to the New York Post because  \"either nobody else would take it, or if they took it, they would spend all the time they could to try to contradict it before they put it out.\" Several days after the story was published, more than 50 former senior intelligence officials signed a letter saying that while they have no evidence, the story \"has all the classic earmarks of a Russian information operation.\" The New York Times reported that no solid evidence has emerged that the laptop contained Russian disinformation.\n\n\n**** Hall County, Georgia ****\nOn October 7, 2020, the government of Hall County, Georgia had all its election-related information released by Russian hackers using DoppelPaymer ransomware.\n\n\n*** 2021 DNI report ***\n\nAccording to a declassified DNI report released on March 16, 2021, there was evidence of broad efforts by both Russia and Iran to shape the election's outcome. However, there was no evidence that any votes, ballots, or voter registrations were directly changed. While Iran sought to undermine confidence in the vote and harm Trump's reelection prospects, the report found that Russia's efforts had been aimed at \"denigrating President Biden's candidacy and the Democratic Party, supporting former President Trump, undermining public confidence in the electoral process, and exacerbating sociopolitical divisions in the US\", central to Moscow's interference effort having been reliance on Russian intelligence agencies\u2032 proxies \u201cto launder influence narratives\u201d by using media organizations, U.S. officials and people close to Trump to push \u201cmisleading or unsubstantiated\u201d allegations against Biden. As an example of such activity by Russia the report cited a documentary aired on One America News Network in January 2020, which was identified by news media as The Ukraine Hoax: Impeachment, Biden Cash, and Mass Murder.The report specifically identified individuals controlled by the Russian government as having been involved in Russia's interference efforts, such as Konstantin Kilimnik and Andrii Derkach. The report said that Putin was likely to have had \"purview\" over the activities of Andrii Derkach.  According to the report, Putin had authorized the Russian influence operations. Following the publication of the DNI report, House Intelligence Committee Chairman Adam Schiff issued a statement that said, \"Through proxies, Russia ran a successful intelligence operation that penetrated the former president\u2019s inner circle.\"\n\n== Government reaction ==\nDan Coats appointed Shelby Pierson as the U.S. election security czar in July 2019, creating a new position in a move seen as an acknowledgment that foreign influence operations against U.S. elections will be ongoing indefinitely. Election-security task forces established before the 2018 midterm elections at the FBI, the Department of Homeland Security, the National Security Agency and the United States Cyber Command have been expanded and \"made permanent\". The Department of Homeland Security indicated that the threat of ransomware attacks upon voter registration databases was a particular concern.Prior to resigning as U.S. Secretary of Homeland Security, Kirstjen Nielsen attempted to organize a meeting of the U.S. Cabinet to discuss how to address potential foreign interference in the 2020 elections. Mick Mulvaney, the White House Chief of Staff, reportedly warned her to keep the subject away from Trump, who views the discussion as questioning the legitimacy of his victory in 2016. Mitch McConnell, the Senate Majority Leader, has blocked various bills intended to improve election security from being considered, including some measures that have had bipartisan support. Election-security legislation remains stalled in the Senate as of February 2020. However, various states have implemented changes, such as paper ballots. Florida has expanded its paper-ballot backup system since 2016, but experts warn that its voting systems are still vulnerable to manipulation, a particular concern being the electronic poll books that store lists of registered voters. All 67 election supervisors in Florida have been required to sign nondisclosure agreements, and consequently, information such as the identity of which four counties had been hacked by Russian intelligence in 2016 remains unknown to the public. Democratic members of Congress cited the lack of effort to secure U.S. elections against foreign interference, particularly from Russia, as among grounds to begin an impeachment inquiry.On September 30, 2019, the United States issued economic sanctions against seven Russians affiliated with the Internet Research Agency, an organization that manipulates social media for misinformation purposes. The sanctions were described as a warning against foreign interference in United States elections.On December 9, 2019, FBI Director Christopher A. Wray told ABC News: \"as far as the [2020] election itself goes, we think Russia represents the most significant threat.\" According to William Evanina, director of the National Counterintelligence and Security Center, Russia is \"using social media and many other tools to inflame social divisions, promote conspiracy theories and sow distrust in our democracy and elections.\"Bloomberg News reported in January 2020 that American intelligence and law enforcement were examining whether Russia was involved in promoting disinformation to undermine Joe Biden as part of a campaign to disrupt the 2020 election. The following month, the Estonian Foreign Intelligence Service warned that Russia would attempt to interfere in the Georgian parliamentary election in October 2020 as well as the US election in November.On July 13, 2020, House Speaker Nancy Pelosi and Senate Minority Leader Chuck Schumer wrote to FBI Director Wray, requesting a briefing on a \"concerted foreign interference campaign\" targeting the United States Congress. The request for an all-Congress briefing, also signed by Rep. Adam Schiff and Sen. Mark Warner, was made public one week later, save for a classified addendum that was not released to the media.\n\n\n*** Trump administration reaction ***\nThe Trump administration reacted to the briefing by American intelligence officials to the House Intelligence Committee that Russia was interfering in the 2020 election in an effort to get Trump re-elected  by rejecting the efforts were in favor of Trump and by firing Joseph Maguire, who was involved in those reports.By contrast, Trump and his national security adviser Robert O'Brien accepted reports the Russians were supporting the nomination of Bernie Sanders.Three weeks after Trump loyalist Richard Grenell was appointed acting Director of National Intelligence, intelligence officials briefed members of Congress behind closed doors that they had \"not concluded that the Kremlin is directly aiding any candidate\u2019s re-election or any other candidates\u2019 election,\" which differed from testimony they had provided the previous month indicating that Russia was working to aid Trump's candidacy. Two intelligence officials pushed back on suggestions the new testimony was politically motivated. One intelligence official asserted the earlier testimony had overreached and that Democrats had mischaracterized it. Kash Patel, a former aide to congressman Devin Nunes who joined Grenell at the ODNI, imposed limits on what intelligence officials could tell Congress about foreign influence operations. The briefers reportedly did not intend to contradict their previous testimony, though they avoided repeating it.Trump and his surrogates asserted that China, rather than Russia, posed the greater risk to election security and was trying to help Biden win. In August 2020, Trump tweeted that \"Chinese State Media and Leaders of CHINA want Biden to win \u2018the U.S. Election.\"\u201d Donald Trump Jr. asserted at the August Republican convention that \"Beijing Biden is so weak on China that the intelligence community recently assessed that the Chinese Communist Party favors Biden.\u201d Director of National Intelligence John Ratcliffe stated during an August Fox News appearance, \"China is using a massive and sophisticated influence campaign that dwarfs anything that any other country is doing.\" Attorney general Bill Barr and national security advisor Robert O'Brien made similar assertions. Intelligence community officials have publicly and privately said that the underlying intelligence indicates that while China would prefer Trump not be reelected, the nation had not been actively interfering and that Russia remained the far greater threat, working to undermine Biden. Trump also asserted that China was trying to stoke race protests in an effort to help Biden, which was also not supported by the intelligence community's assessment. The United States intelligence community released analysis in March 2021 finding that China had considered interfering with the election but decided against it on concerns it would fail or backfire.Following Joe Biden's apparent win\u2014which Trump was actively disputing through numerous lawsuits\u2014Chris Krebs, the director of the Department of Homeland Security's Cybersecurity and Infrastructure Security Agency, issued a statement on November 12: \"There is no evidence that any voting system deleted or lost votes, changed votes, or was in any way compromised.\" Trump tweeted on November 17 that he had fired Krebs as a result of this statement.\n\n\n*** Putin administration reaction ***\nRussian officials denied that it had interfered in the 2016 election or that it was interfering in the 2020 election. On September 25, 2020, Putin released a formal statement seeking mutual \"guarantees of non-interference\" in U.S. and Russian elections and asking the United States \"to approve a comprehensive program of practical measures to reset our relations in the use of information and communication technologies (ICT).\"\n\n== Interference from the administration ==\nIn a June 2019 interview with George Stephanopoulos, Donald Trump said that he would accept information from other nations about his opponents in the 2020 United States presidential election.According to reporting by The Wall Street Journal, The Washington Post and The New York Times, Trump and his personal attorney Rudy Giuliani repeatedly pressed the Ukrainian government to investigate Hunter Biden, the son of Joe Biden, leading to the ongoing Trump\u2013Ukraine scandal. Biden was viewed as a potentially strong Trump challenger in the 2020 presidential election, and the purpose of the requested investigation was alleged to be to damage Biden's election campaign for president. Reports suggested that Trump threatened to withhold military aid from Ukraine unless they investigated Biden. The controversy triggered the commencement of the formal process of impeachment inquiries against Trump on September 24, with House speaker Nancy Pelosi directing six House committee chairmen to proceed \"under that umbrella of impeachment inquiry\".On October 3, 2019, while discussing negotiations on a possible agreement in the ongoing China\u2013United States trade war, he said that \"if they [China] don't do what we want, we have tremendous power.\" He then said that \"China should start an investigation\" into presidential candidate Joe Biden and his son Hunter Biden. Chair of the Federal Election Commission Ellen Weintraub then retweeted a June statement explaining that \"it is illegal for any person to solicit, accept, or receive anything of value from a foreign national in connection with a U.S. election\".As of early October 2019, there is evidence President Trump, Vice President Mike Pence, U.S. Attorney General William Barr, as well as Trump's personal attorney Giuliani solicited help from Ukraine and China for assistance in discrediting Trump's political opponents. Trump also dispatched Barr to meet with Italian officials as part of Trump's efforts to discredit the Mueller investigation into Russian interference in the 2016 election. Trump also pressed Australian Prime Minister Scott Morrison to give Barr information that Trump hoped would discredit the Mueller inquiry, in a call that (like Trump's earlier call with Ukrainian president Volodymyr Zelensky), used diplomatic contacts to advance Trump's \"personal political interests.\" According to a report in the Times of London, Trump also personally contacted British Prime Minister Boris Johnson to seek help to discredit the Mueller investigation.A Department of Homeland Security intelligence bulletin, warning about Russian interference in the 2020 election, was planned for release on July 9 but was blocked by acting Secretary of Homeland Security Chad Wolf's chief of staff. The bulletin, intended to be distributed among law-enforcement agencies, indicated that Russian disinformation operations would denigrate the mental health of Joe Biden.\n\n== Aftermath ==\n\nRussian interference in the 2020 election was significantly less severe than it had been in 2016. Experts suggested a variety of possible explanations, not mutually exclusive. These include a hardening of American cyber defenses, reluctance on Russia's part to risk reprisals, and the fact that misinformation intended to delegitimize the election was already prevalent within the United States thanks to unfounded claims by Trump and others.On April 15, 2021, the Biden administration expelled 10 Russian diplomats and sanctioned six Russian companies that support Russia's cyber activities, in addition to 32 individuals and entities for its role in the interference and the 2020 United States federal government data breach.The New York Times reported in May 2021 that federal investigators in Brooklyn began a criminal investigation late in the Trump administration into possible efforts by several current and former Ukrainian officials to spread unsubstantiated allegations about corruption by Joe Biden. Investigators were examining whether the Ukrainians used Giuliani as a channel for the allegations, though he was not a specific subject of the investigation, in contrast to a long-running investigation of Giuliani by the US attorney's office in Manhattan.\nRead the text above and answer this question: What did the Senate Intelligence Committee warn Senator Ron Johnson about in late 2019?",
    "context": "",
    "output": "The Senate Intelligence Committee warned Senator Ron Johnson in late 2019 of a risk he could be playing into the hands of Russian intelligence to spread disinformation and that his investigation could aid Russian efforts to promote distrust in the United States' political system.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What did the Senate Intelligence Committee warn Senator Ron Johnson about in late 2019?",
      "answer": "The Senate Intelligence Committee warned Senator Ron Johnson in late 2019 of a risk he could be playing into the hands of Russian intelligence to spread disinformation and that his investigation could aid Russian efforts to promote distrust in the United States' political system.",
      "context": "Russian interference in the 2020 United States elections\n\n==Introduction==\nRussian interference in the 2020 United States elections was a matter of concern at the highest level of national security within the United States government, in addition to the computer and social media industries. In 2020, the RAND Corporation was one of the first to release research describing Russia's playbook for interfering in U.S. elections, developed machine-learning tools to detect the interference, and tested strategies to counter Russian interference. In February and August 2020, United States Intelligence Community (USIC) experts warned members of Congress that Russia was interfering in the 2020 presidential election in then-President Donald Trump's favor. USIC analysis released by the Office of the Director of National Intelligence (DNI) in March 2021 found that proxies of Russian intelligence promoted and laundered misleading or unsubstantiated narratives about Joe Biden \"to US media organizations, US officials, and prominent US individuals, including some close to former President Trump and his administration.\" The New York Times reported in May 2021 that federal investigators in Brooklyn began a criminal investigation late in the Trump administration into possible efforts by several current and former Ukrainian officials to spread unsubstantiated allegations about corruption by Joe Biden, including whether they had used Trump personal attorney Rudy Giuliani as a channel.\n\n== Reports of attempted interference ==\n\n\n*** Overview ***\nIn response to Russian interference in the 2016 United States elections, special counsel Robert Mueller conducted a two-year-long investigation. The resulting report concluded that Russia interfered in \"sweeping and systematic fashion\". In his July 2019 congressional testimony, Mueller stated that the Russians continue to interfere in U.S. elections \"as we sit here\", and that \"many more countries\" have developed disinformation campaigns targeting U.S. elections, based partly on the Russian model.Also in July 2019, the Senate Intelligence Committee released the first volume of a bipartisan report on Russian interference in the 2016 United States elections, a report that included recommendations for securing the 2020 elections. The second volume of that report noted, based on social-media data from October 2018, that \"Russian disinformation efforts may be focused on gathering information and data points in support of an active measures campaign targeted at the 2020 U.S. presidential election.\"In a highly classified report, the Central Intelligence Agency stated: \"We assess that President Vladimir Putin and the senior most Russian officials are aware of and probably directing Russia's influence operations aimed at denigrating the former U.S. Vice President, supporting the U.S. president and fueling public discord ahead of the U.S. election in November.\" The existence of this report, published at the end of August 2020, was made public knowledge on September 22 in reports from The Washington Post and The New York Times.U.S. officials have accused Russia, China and Iran of trying to influence the 2020 elections. Between January and late July 2017, Twitter identified and shut down over 7,000 phony accounts created by Iranian influence operations. According to Christopher A. Wray, the Director of the Federal Bureau of Investigation, Russia is attempting to interfere with the 2020 United States elections. Speaking to the Council on Foreign Relations in July 2019, Wray stated, \"We are very much viewing 2018 as just kind of a dress rehearsal for the big show in 2020.\" Dan Coats, the former Director of National Intelligence, believes that Russia and China will both attempt to influence the elections. As of September 2020, intelligence officials point to Russia as the more \"acute threat\" to the election, saying that China has been expressing its preferences by public rhetoric rather than engaging in covert operations to denigrate a candidate or otherwise interfere in the election itself. Wray testified to the House Committee on Homeland Security on September 17, 2020, that Russian efforts to damage the Biden campaign were \"very active\".According to United States intelligence officials interviewed by The New York Times, Russian \"operations would be intended to help President Trump, potentially by exacerbating disputes around the results, especially if the race is too close to call.\" The FBI and the Cybersecurity and Infrastructure Security Agency have stated that Russian cyberattacks have targeted \"U.S. state, local, territorial, and tribal government networks, as well as aviation networks\".\n\n\n*** Social-media disinformation and voting infrastructure ***\nVarious disinformation campaigns on social media have targeted the Democratic Party candidates running in the 2020 Democratic Party presidential primaries. This has prompted considerable concern regarding the ability of social media companies to cope with disinformation and manipulation. By August 2019, Facebook and Twitter had banned advertisements that use misinformation to attempt the suppression of voter turnout.Microsoft developed an open source software called ElectionGuard to help safeguard the 2020 elections. In mid-July 2019, Microsoft announced that it had, over the prior year, \"notified nearly 10,000 customers they've been targeted or compromised by nation-state attacks\". Based on attacks that had targeted political organizations, and on experience from 2016 and 2018, Microsoft anticipated \"attacks targeting U.S. election systems, political campaigns or NGOs that work closely with campaigns\". Of the \"nation-state attacks\" that had originated from Russia, Microsoft claimed that they followed the \"same pattern of engagement\" as Russian operations in 2016 and 2018. On September 20, 2019, Microsoft announced that it would provide free security updates for Windows 7, which reached its end-of-life on January 14, 2020, on federally-certified voting machines through the 2020 United States elections. On October 4, 2019, Microsoft announced that \"Phosphorus\", a group of hackers linked to the Iranian government, had attempted to compromise e-mail accounts belonging to journalists, prominent Iranian expatriates, U.S. government officials and the campaign of a U.S. presidential candidate. While Microsoft did not disclose which campaign had been the target of the cyber attack, unnamed sources informed Reuters that it had been that of Donald Trump.On October 21, 2019, Facebook CEO Mark Zuckerberg announced that his company has detected a \"highly sophisticated\" set of campaigns to interfere with the 2020 elections. These campaigns originated from Russia and from Iran. Fake accounts based in Russia posed as Americans of varied political backgrounds and worked to undermine the campaign of Joe Biden, aiming to sow discontent with Biden from both the left and the right.A September 2019 report from The Washington Post demonstrated that due to bad default passwords and weak encryption, hackers with physical access can easily get into voting machines designed for use in the 2020 United States elections, and remote hacking was possible if the machines were accidentally misconfigured.On February 21, 2020, The Washington Post reported that, according to unnamed US officials, Russia was interfering in the Democratic primary in an effort to support the nomination of Senator Bernie Sanders. Sanders issued a statement after the news report, saying in part, \"I don't care, frankly, who Putin wants to be president. My message to Putin is clear: stay out of American elections, and as president I will make sure that you do.\" Sanders acknowledged that his campaign was briefed about Russia's alleged efforts about a month prior. Sanders suggested that Russians were impersonating people claiming to be his supporters online in order to create an atmosphere of toxicity and give \"Bernie Bros\" a bad reputation, a suggestion that Twitter rejected. According to election-security expert Laura Rosenberger, \"Russian attempts to sow discord in the Democratic primary would be consistent with its strategy of undermining Americans' faith in democratic institutions and processes.\"In March 2020, the University of Wisconsin\u2013Madison and the Brennan Center for Justice published a report indicating that Russia-linked social media accounts have been spreading Instagram posts calculated to sow division among American voters. According to the report, Russian operatives were increasingly impersonating real political candidates and groups rather than creating fictional groups. According to Twitter's head of site integrity, Russian agents also attempted in 2018 to create the impression of more election interference than is actually happening to undermine confidence in the process. Shortly thereafter, the New York Times reported that according to American intelligence officials Russian operatives have been stoking via private Facebook groups anger among African Americans, emphasizing allegations of police brutality in the United States, highlighting racism in the United States against African Americans, and promoting and pressuring hate groups, including white and black extremist groups, in order to create strife within American society, though American intelligence officials provided few details about the alleged operations. A CNN investigation found that Russian efforts had partly been outsourced to troll farms in Ghana and Nigeria. In May 2020, Twitter suspended 44 accounts that exhibited behavior plausibly, but not definitively, indicative of Russian election interference tactics, including association with a Ghana troll farm.\nGovernment officials and American corporate security officers braced for a repeat of 2016's election infrastructure hacking and similar twenty-first century attacks and conducted what were characterized as pre-emptive counter-strikes on botnet infrastructure which might be used in a large-scale coordination of hacking. Some incidents earlier in the year appeared to foreshadow such possibilities. Following his dismissal, in a December 2020 interview, Chris Krebs, the Trump administration's director of the Cybersecurity and Infrastructure Security Agency (CISA), described monitoring Election Day from CISA's joint command center along with representatives from the military's United States Cyber Command, the National Security Agency (NSA), the Federal Bureau of Investigation (FBI), the United States Secret Service (USSS), the Election Assistance Commission (EAC), representatives of vendors of voting machine equipment, and representatives of state and local governments, as well as his agency's analysis preceding and subsequent to that day, saying,It was quiet. There was no indication or evidence that there was any sort of hacking or compromise of election systems on, before, or after November third.Responding to spurious claims of foreign outsourcing of vote counting as a rationale behind litigation attempting to stop official vote counting in some areas, Krebs also affirmed that, \"All votes in the United States of America are counted in the United States of America.\"However, acts of foreign interference did include Russian state-directed application of computational propaganda approaches, more conventional state-sponsored Internet propaganda, smaller-scale disinformation efforts, \"information laundering\" and \"trading up the chain\" propaganda tactics employing some government officials, Trump affiliates, and US media outlets, as described below.\n\n\n*** Briefings to Congress ***\nOn February 13, 2020, American intelligence officials advised members of the House Intelligence Committee that Russia was interfering in the 2020 election in an effort to get Trump re-elected. The briefing was delivered by Shelby Pierson, the intelligence community's top election security official and an aide to acting Director of National Intelligence Joseph Maguire. Trump allies on the committee challenged the findings, and Trump was angered to learn of the briefing as he believed Democrats might \"weaponize\" the information against him. He chastised Maguire for allowing the briefing to occur, and days later he appointed Richard Grenell to replace Maguire.William Evanina, director of the National Counterintelligence and Security Center told members of Congress during a classified briefing on July 31, 2020, that Russia was working to boost the campaign of Trump and undermine that of Biden. Details of Evanina's report were not made public. The Biden campaign confirmed to the Associated Press that they had \"faced multiple related threats\" but were \"reluctant to reveal specifics for fear of giving adversaries useful intelligence\". Evanina later stated in a press release, \"We assess that Russia is using a range of measures to primarily denigrate former Vice President Biden and what it sees as an anti-Russia 'establishment.'\" On August 7, 2020, CNN reported that intelligence officials had provided senators, representatives and both the Biden and Trump campaigns with information \"indicating Russia is behind an ongoing disinformation push targeting\" Biden. That same day, Democratic congressman Eric Swalwell, a member of the House Intelligence Committee, asserted that Republican senators investigating Biden and his son were \"acting as Russian launderers of this information.\"\n\n\n*** Giuliani, Derkach, and Johnson ***\n\nAccording to the Treasury Department, Trump's personal attorney Rudy Giuliani collaborated with active Russian agent Andrii Derkach, a Ukrainian lawmaker, to spread anti-Biden material during Trump's impeachment. The Treasury Department said that Derkach \"waged a covert influence campaign centered on cultivating false and unsubstantiated narratives concerning U.S. officials in the upcoming 2020 Presidential Election,\" including by the release of \"edited audio tapes and other unsupported information with the intent to discredit U.S. officials.\"Their efforts were aided by journalists like John Solomon, a contributor to Fox News, who, according to Jane Mayer, was pivotal for the dissemination of disinformation about Biden. She stated \"No journalist played a bigger part in fueling the Biden corruption narrative than John Solomon.\"In late 2019, the chairman of the Senate committee investigating the matter, Ron Johnson, was warned by American intelligence officials of a risk he could be playing into the hands of Russian intelligence to spread disinformation. During this period, Richard Burr (R-NC), chair of the Senate Intelligence Committee, also warned Johnson that Johnson's investigation could aid Russian efforts to promote distrust in the United States' political system. Senators had also been briefed in late 2019 about Russian efforts to frame Ukraine for 2016 election interference. Johnson initially said he would release findings in spring 2020, as Democrats would be selecting their 2020 presidential nominee, but instead ramped up the investigation at Trump's urging in May 2020, after it became clear Biden would be the nominee. In March 2020, Johnson decided to postpone the issuing of a subpoena for former Ukrainian official and employee of a Democratic lobby firm Blue Star Strategies Andrii Telizhenko, a close ally of Rudy Giuliani who had made appearances on the pro-Trump cable channel One America News, after Senator Mitt Romney backed away on voting for Mr. Telizhenko, as the Senators from the Democratic Party pressured Senator Romney on Mr. Telizhenko's vote. Trump tweeted a press report about the investigations, later stating that he would make allegations of corruption by the Bidens a central theme of his re-election campaign. The State Department revoked Telizhenko's visa in October 2020, and CNN reported the American government was considering sanctioning him as a Russian agent.In May 2020, Andrii Derkach, a Giuliani associate whom Evanina had named as a key participant in Russian interference, released snippets of alleged recordings of Joe Biden speaking with Petro Poroshenko, the Ukrainian president during the years Biden's son, Hunter, worked for Burisma Holdings. The Bidens had been accused without evidence of malfeasance relating to Burisma. The recordings, which were not verified as authentic and appeared heavily edited, depicted Biden linking loan guarantees for Ukraine to the ouster of the country's prosecutor general. The recordings did not provide evidence to support the ongoing conspiracy theory that Biden wanted the prosecutor fired to protect his son. Poroshenko denied In June 2020 that Joe Biden ever approached him about Burisma. In September 2020, the United States Department of the Treasury sanctioned Derkach, stating he \"has been an active Russian agent for over a decade, maintaining close connections with the Russian Intelligence Services.\"Giuliani, Trump's personal attorney, had spent significant time working in Ukraine during 2019 to gather information about the Bidens, making frequent American television appearances to discuss it. Attorney general Bill Barr confirmed in February 2020 that the Justice Department had created an \"intake process\" to analyze Giuliani's information. This information included a September 2019 statement by former Ukrainian prosecutor general Viktor Shokin falsely claiming he had been fired at Biden's insistence because Shokin was investigating Biden's son. The statement disclosed that it had been prepared at the request of attorneys for Ukrainian oligarch Dmitry Firtash, which since July 2019 included Joseph diGenova and his wife Victoria Toensing \u2014 both close associates of Trump and Giuliani. Firtash, fighting extradition to the United States where he was under federal indictment, is believed by the Justice Department to be connected to high levels of Russian organized crime, which allegedly installed him as a broker for Ukrainian imports of Russian natural gas. He is also reportedly close to the Kremlin to support Russian interests in Ukraine.According to officials interviewed by The Daily Beast, then-National Security Advisor John Bolton told his staff not to meet with Giuliani, as did his successor Robert C. O'Brien, because Bolton had been informed that Giuliani was spreading conspiracy theories that aligned with Russian interests in disrupting the 2020 election. These officials were also concerned that Giuliani would be used as a conduit for disinformation, including \"leaks\" of emails that would mix genuine with forged material in order to implicate Hunter Biden in corrupt dealings.The New York Times reported in November 2019 that Giuliani had directed associate Lev Parnas to approach Firtash about hiring the couple, with the proposition that Firtash could help to provide compromising information on Biden, which Parnas's attorney described was \"part of any potential resolution to [Firtash's] extradition matter.\" Giuliani denied any association with Firtash, though he told CNN he met with a Firtash attorney for two hours in New York City at the time he was seeking information about the Bidens. As vice president, Biden had urged the Ukrainian government to eliminate brokers such as Firtash to reduce the country's reliance on Russian gas. After his October 2019  indictment, Parnas asserted that he, Giuliani, diGenova and Toensing had a deal with Firtash in which the oligarch would provide information to discredit Biden in exchange for Giuliani persuading the Justice Department to drop its efforts to extradite Firtash.The Washington Post reported in October 2019 that after they began representing Firtash, Toensing and diGenova secured a rare face-to-face meeting with Barr to argue the Firtash charges should be dropped. Prior to that mid-August meeting, Barr had been briefed in detail on the initial Trump\u2013Ukraine whistleblower complaint within the CIA that had been forwarded to the Justice Department, as well as on Giuliani's activities in Ukraine. Bloomberg News reported that its sources told them Giuliani's high-profile publicity of the Shokin statement had greatly reduced the chances of the Justice Department dropping the charges against Firtash, as it would appear to be a political quid pro quo. Barr declined to intervene in the Firtash case. Firtash denied involvement in collecting or financing damaging information on the Bidens.\n\n\n*** Developments in summer and fall 2020 ***\nBy the summer of 2020, Russian intelligence had advanced to \"information laundering\" in which divisive propaganda was reported on Russia-affiliated news websites with the expectation the stories would be picked-up and spread by more legitimate news outlets. In August 2020, The New York Times reported that a video published by RT's Ruptly video platform, of Black Lives Matter protesters apparently burning a bible in Portland, Oregon, edited in a misleading way, \"went viral\" after it being shared with an inaccurate caption on social media by a far-right personality and then conservative politicians. The Times said the clip \"appear[ed] to be one of the first viral Russian disinformation hits of the 2020 presidential campaign\u201d. An NBC report in the wake of this incident found that Ruptly edited user-generated protest videos to highlight violence over peaceful protest.In September 2020, Facebook and Twitter announced that they had been alerted to the existence of Peace Data, a website set up by Russia's Internet Research Agency to interfere with the 2020 election. The social-media companies deleted accounts that had been used in an operation to recruit American journalists to write articles critical of Joe Biden and his running mate Kamala Harris. On September 3, the intelligence branch of the Department of Homeland Security issued a warning to state and federal law enforcement that Russia was \"amplifying\" concerns about postal voting and other measures taken to protect voters during the COVID-19 pandemic. According to DHS analysts, \"Russian malign influence actors\" had been spreading misinformation since at least March. Trump had repeatedly asserted without evidence that voting by mail would result in widespread fraud.ABC News reported in September 2020 that the Homeland Security Department had withheld the July release of an intelligence bulletin to law enforcement that warned of Russian efforts to promote \u201callegations about the poor mental health\u201d of Joe Biden. DHS chief of staff John Gountanis halted the release pending review by secretary Chad Wolf. The bulletin stated that analysts had \u201chigh confidence\u201d of the Russian efforts, which were similar to efforts by Trump and his campaign to depict Biden as mentally unfit. A DHS spokesperson said the bulletin was \u201cdelayed\u201d because it did not meet the department's standards. The bulletin had not been released as of the date of the ABC News report. Later in September, Brian Murphy \u2014 a former DHS undersecretary for intelligence and analysis \u2014 asserted in a whistleblower complaint that Wolf told him \u201cthe intelligence notification should be \u2018held\u2019 because it \u2018made the President look bad.\u2019\u201d Murphy also claimed Wolf told him to \"cease providing intelligence assessments on the threat of Russian interference in the US, and instead start reporting on interference activities by China and Iran.\u201d Murphy said Wolf told him this directive came from White House national security advisor Robert O'Brien. The DHS inspector general released findings in May 2022 that affirmed the accounts of ABC News and Murphy. The intelligence report on Russian interference appeared to have been \"delayed and altered...changes that 'appear to be based in part on political considerations'\".On September 10, 2020, Reuters reported that hackers had tried and failed to breach the systems of SKDKnickerbocker, a political consulting firm that specializes in working for Democratic Party politicians and that had been working with the Biden campaign for two months. Microsoft, who detected the cyberattack, informed SKDKnickerbocker that Russian state-backed hackers were the likely perpetrators.Analysts and officials interviewed by The New York Times in September 2020 indicated that a primary tactic of Russian disinformation campaigns was to amplify misleading statements from Trump, chiefly about postal voting. Russia's Internet Research Agency also created a fictitious press organization, the \"Newsroom for American and European Based Citizens\", in order to feed propaganda to right-wing social media users. NAEBC accounts were blocked or suspended by Facebook, Twitter, and LinkedIn, but their content \"got more traction\" on alt-tech platforms Gab and Parler, according to a Reuters report.H.R. McMaster, Trump's former national security advisor, said on October 1 that Trump was \"aiding and abetting Putin\u2019s efforts by not being direct about this. This sustained campaign of disruption, disinformation and denial is aided by any leader who doesn\u2019t acknowledge it.\"On October 5, The Washington Post reported that the State Department had revoked the travel visa of Giuliani associate Andrii Telizhenko.On October 21, threatening emails were sent to Democrats in at least four states. The emails warned that \"You will vote for Trump on Election Day or we will come after you.\" Director of National Intelligence John Ratcliffe announced that evening that the emails, using a spoofed return address, had been sent by Iran. He added that both Iran and Russia are known to have obtained American voter registration data, possibly from publicly available information, and that \"This data can be used by foreign actors to attempt to communicate false information to registered voters that they hope will cause confusion, sow chaos and undermine your confidence in American democracy.\" A spokesman for Iran denied the allegation. In his announcement Ratcliffe said that Iran's intent had been \"to intimidate voters, incite social unrest, and damage President Trump\", raising questions as to how ordering Democrats to vote for Trump would be damaging to Trump. It was later reported that the reference to Trump had not been in Ratcliffe's prepared remarks as signed off by the other officials on the stage, but that he added it on his own.\n\n\n**** New York Post story ****\n\nIn October 2020, the FBI reportedly launched an investigation into whether a story published in the tabloid journal New York Post on October 14 might be part of a Russian disinformation effort targeting Biden. The story, titled \"Biden Secret Emails\", displayed an email supposedly showing that Hunter Biden had arranged for his father, then-vice-president Joe Biden, to meet with a top advisor to Burisma. The Biden campaign said that no such meeting ever happened. The Post's source for the data was Giuliani, who says he got it from the hard drive of a laptop that was allegedly dropped off at a Delaware repair shop in April 2019 and never picked up. The shop owner told reporters that he thought the person who dropped it off was Hunter Biden but wasn't sure. He said he eventually gave the laptop to the FBI, keeping a copy of the hard drive for himself that he later gave to Giuliani. A year and a half earlier, in early 2019, White House officials had been warned that the Russians were planning to leak forged emails in the weeks before the election, and that Giuliani could be the conduit for such a leak.Most of the New York Post story was written by a staff reporter who did not allow his name to be used on it because he doubted the story's credibility. According to an investigation by The New York Times, editors at the New York Post \"pressed staff members to add their bylines to the story\", and at least one refused, in addition to the original author. Of the two writers eventually credited on the article, the second did not know her name was attached to it until after it was published. Giuliani was later quoted as saying he had given the hard drive to the New York Post because  \"either nobody else would take it, or if they took it, they would spend all the time they could to try to contradict it before they put it out.\" Several days after the story was published, more than 50 former senior intelligence officials signed a letter saying that while they have no evidence, the story \"has all the classic earmarks of a Russian information operation.\" The New York Times reported that no solid evidence has emerged that the laptop contained Russian disinformation.\n\n\n**** Hall County, Georgia ****\nOn October 7, 2020, the government of Hall County, Georgia had all its election-related information released by Russian hackers using DoppelPaymer ransomware.\n\n\n*** 2021 DNI report ***\n\nAccording to a declassified DNI report released on March 16, 2021, there was evidence of broad efforts by both Russia and Iran to shape the election's outcome. However, there was no evidence that any votes, ballots, or voter registrations were directly changed. While Iran sought to undermine confidence in the vote and harm Trump's reelection prospects, the report found that Russia's efforts had been aimed at \"denigrating President Biden's candidacy and the Democratic Party, supporting former President Trump, undermining public confidence in the electoral process, and exacerbating sociopolitical divisions in the US\", central to Moscow's interference effort having been reliance on Russian intelligence agencies\u2032 proxies \u201cto launder influence narratives\u201d by using media organizations, U.S. officials and people close to Trump to push \u201cmisleading or unsubstantiated\u201d allegations against Biden. As an example of such activity by Russia the report cited a documentary aired on One America News Network in January 2020, which was identified by news media as The Ukraine Hoax: Impeachment, Biden Cash, and Mass Murder.The report specifically identified individuals controlled by the Russian government as having been involved in Russia's interference efforts, such as Konstantin Kilimnik and Andrii Derkach. The report said that Putin was likely to have had \"purview\" over the activities of Andrii Derkach.  According to the report, Putin had authorized the Russian influence operations. Following the publication of the DNI report, House Intelligence Committee Chairman Adam Schiff issued a statement that said, \"Through proxies, Russia ran a successful intelligence operation that penetrated the former president\u2019s inner circle.\"\n\n== Government reaction ==\nDan Coats appointed Shelby Pierson as the U.S. election security czar in July 2019, creating a new position in a move seen as an acknowledgment that foreign influence operations against U.S. elections will be ongoing indefinitely. Election-security task forces established before the 2018 midterm elections at the FBI, the Department of Homeland Security, the National Security Agency and the United States Cyber Command have been expanded and \"made permanent\". The Department of Homeland Security indicated that the threat of ransomware attacks upon voter registration databases was a particular concern.Prior to resigning as U.S. Secretary of Homeland Security, Kirstjen Nielsen attempted to organize a meeting of the U.S. Cabinet to discuss how to address potential foreign interference in the 2020 elections. Mick Mulvaney, the White House Chief of Staff, reportedly warned her to keep the subject away from Trump, who views the discussion as questioning the legitimacy of his victory in 2016. Mitch McConnell, the Senate Majority Leader, has blocked various bills intended to improve election security from being considered, including some measures that have had bipartisan support. Election-security legislation remains stalled in the Senate as of February 2020. However, various states have implemented changes, such as paper ballots. Florida has expanded its paper-ballot backup system since 2016, but experts warn that its voting systems are still vulnerable to manipulation, a particular concern being the electronic poll books that store lists of registered voters. All 67 election supervisors in Florida have been required to sign nondisclosure agreements, and consequently, information such as the identity of which four counties had been hacked by Russian intelligence in 2016 remains unknown to the public. Democratic members of Congress cited the lack of effort to secure U.S. elections against foreign interference, particularly from Russia, as among grounds to begin an impeachment inquiry.On September 30, 2019, the United States issued economic sanctions against seven Russians affiliated with the Internet Research Agency, an organization that manipulates social media for misinformation purposes. The sanctions were described as a warning against foreign interference in United States elections.On December 9, 2019, FBI Director Christopher A. Wray told ABC News: \"as far as the [2020] election itself goes, we think Russia represents the most significant threat.\" According to William Evanina, director of the National Counterintelligence and Security Center, Russia is \"using social media and many other tools to inflame social divisions, promote conspiracy theories and sow distrust in our democracy and elections.\"Bloomberg News reported in January 2020 that American intelligence and law enforcement were examining whether Russia was involved in promoting disinformation to undermine Joe Biden as part of a campaign to disrupt the 2020 election. The following month, the Estonian Foreign Intelligence Service warned that Russia would attempt to interfere in the Georgian parliamentary election in October 2020 as well as the US election in November.On July 13, 2020, House Speaker Nancy Pelosi and Senate Minority Leader Chuck Schumer wrote to FBI Director Wray, requesting a briefing on a \"concerted foreign interference campaign\" targeting the United States Congress. The request for an all-Congress briefing, also signed by Rep. Adam Schiff and Sen. Mark Warner, was made public one week later, save for a classified addendum that was not released to the media.\n\n\n*** Trump administration reaction ***\nThe Trump administration reacted to the briefing by American intelligence officials to the House Intelligence Committee that Russia was interfering in the 2020 election in an effort to get Trump re-elected  by rejecting the efforts were in favor of Trump and by firing Joseph Maguire, who was involved in those reports.By contrast, Trump and his national security adviser Robert O'Brien accepted reports the Russians were supporting the nomination of Bernie Sanders.Three weeks after Trump loyalist Richard Grenell was appointed acting Director of National Intelligence, intelligence officials briefed members of Congress behind closed doors that they had \"not concluded that the Kremlin is directly aiding any candidate\u2019s re-election or any other candidates\u2019 election,\" which differed from testimony they had provided the previous month indicating that Russia was working to aid Trump's candidacy. Two intelligence officials pushed back on suggestions the new testimony was politically motivated. One intelligence official asserted the earlier testimony had overreached and that Democrats had mischaracterized it. Kash Patel, a former aide to congressman Devin Nunes who joined Grenell at the ODNI, imposed limits on what intelligence officials could tell Congress about foreign influence operations. The briefers reportedly did not intend to contradict their previous testimony, though they avoided repeating it.Trump and his surrogates asserted that China, rather than Russia, posed the greater risk to election security and was trying to help Biden win. In August 2020, Trump tweeted that \"Chinese State Media and Leaders of CHINA want Biden to win \u2018the U.S. Election.\"\u201d Donald Trump Jr. asserted at the August Republican convention that \"Beijing Biden is so weak on China that the intelligence community recently assessed that the Chinese Communist Party favors Biden.\u201d Director of National Intelligence John Ratcliffe stated during an August Fox News appearance, \"China is using a massive and sophisticated influence campaign that dwarfs anything that any other country is doing.\" Attorney general Bill Barr and national security advisor Robert O'Brien made similar assertions. Intelligence community officials have publicly and privately said that the underlying intelligence indicates that while China would prefer Trump not be reelected, the nation had not been actively interfering and that Russia remained the far greater threat, working to undermine Biden. Trump also asserted that China was trying to stoke race protests in an effort to help Biden, which was also not supported by the intelligence community's assessment. The United States intelligence community released analysis in March 2021 finding that China had considered interfering with the election but decided against it on concerns it would fail or backfire.Following Joe Biden's apparent win\u2014which Trump was actively disputing through numerous lawsuits\u2014Chris Krebs, the director of the Department of Homeland Security's Cybersecurity and Infrastructure Security Agency, issued a statement on November 12: \"There is no evidence that any voting system deleted or lost votes, changed votes, or was in any way compromised.\" Trump tweeted on November 17 that he had fired Krebs as a result of this statement.\n\n\n*** Putin administration reaction ***\nRussian officials denied that it had interfered in the 2016 election or that it was interfering in the 2020 election. On September 25, 2020, Putin released a formal statement seeking mutual \"guarantees of non-interference\" in U.S. and Russian elections and asking the United States \"to approve a comprehensive program of practical measures to reset our relations in the use of information and communication technologies (ICT).\"\n\n== Interference from the administration ==\nIn a June 2019 interview with George Stephanopoulos, Donald Trump said that he would accept information from other nations about his opponents in the 2020 United States presidential election.According to reporting by The Wall Street Journal, The Washington Post and The New York Times, Trump and his personal attorney Rudy Giuliani repeatedly pressed the Ukrainian government to investigate Hunter Biden, the son of Joe Biden, leading to the ongoing Trump\u2013Ukraine scandal. Biden was viewed as a potentially strong Trump challenger in the 2020 presidential election, and the purpose of the requested investigation was alleged to be to damage Biden's election campaign for president. Reports suggested that Trump threatened to withhold military aid from Ukraine unless they investigated Biden. The controversy triggered the commencement of the formal process of impeachment inquiries against Trump on September 24, with House speaker Nancy Pelosi directing six House committee chairmen to proceed \"under that umbrella of impeachment inquiry\".On October 3, 2019, while discussing negotiations on a possible agreement in the ongoing China\u2013United States trade war, he said that \"if they [China] don't do what we want, we have tremendous power.\" He then said that \"China should start an investigation\" into presidential candidate Joe Biden and his son Hunter Biden. Chair of the Federal Election Commission Ellen Weintraub then retweeted a June statement explaining that \"it is illegal for any person to solicit, accept, or receive anything of value from a foreign national in connection with a U.S. election\".As of early October 2019, there is evidence President Trump, Vice President Mike Pence, U.S. Attorney General William Barr, as well as Trump's personal attorney Giuliani solicited help from Ukraine and China for assistance in discrediting Trump's political opponents. Trump also dispatched Barr to meet with Italian officials as part of Trump's efforts to discredit the Mueller investigation into Russian interference in the 2016 election. Trump also pressed Australian Prime Minister Scott Morrison to give Barr information that Trump hoped would discredit the Mueller inquiry, in a call that (like Trump's earlier call with Ukrainian president Volodymyr Zelensky), used diplomatic contacts to advance Trump's \"personal political interests.\" According to a report in the Times of London, Trump also personally contacted British Prime Minister Boris Johnson to seek help to discredit the Mueller investigation.A Department of Homeland Security intelligence bulletin, warning about Russian interference in the 2020 election, was planned for release on July 9 but was blocked by acting Secretary of Homeland Security Chad Wolf's chief of staff. The bulletin, intended to be distributed among law-enforcement agencies, indicated that Russian disinformation operations would denigrate the mental health of Joe Biden.\n\n== Aftermath ==\n\nRussian interference in the 2020 election was significantly less severe than it had been in 2016. Experts suggested a variety of possible explanations, not mutually exclusive. These include a hardening of American cyber defenses, reluctance on Russia's part to risk reprisals, and the fact that misinformation intended to delegitimize the election was already prevalent within the United States thanks to unfounded claims by Trump and others.On April 15, 2021, the Biden administration expelled 10 Russian diplomats and sanctioned six Russian companies that support Russia's cyber activities, in addition to 32 individuals and entities for its role in the interference and the 2020 United States federal government data breach.The New York Times reported in May 2021 that federal investigators in Brooklyn began a criminal investigation late in the Trump administration into possible efforts by several current and former Ukrainian officials to spread unsubstantiated allegations about corruption by Joe Biden. Investigators were examining whether the Ukrainians used Giuliani as a channel for the allegations, though he was not a specific subject of the investigation, in contrast to a long-running investigation of Giuliani by the US attorney's office in Manhattan."
    }
  },
  {
    "instruction": "context: RAM scrapers use the Luhn algorithm to ensure that the collected card data is valid before exfiltration.\n\nAsk a question about this context.",
    "context": "",
    "output": "How do RAM scrapers ensure that the collected card data is valid before exfiltration?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do RAM scrapers ensure that the collected card data is valid before exfiltration?",
      "answer": "RAM scrapers use the Luhn algorithm to ensure that the collected card data is valid before exfiltration."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the role of information technology security audits in IT risk management?",
    "context": "",
    "output": "Information technology security audits are organizational and procedural controls used to evaluate the security of an organization's IT systems. The audits assess security controls' effectiveness, identify vulnerabilities, and make recommendations for improvement.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of information technology security audits in IT risk management?",
      "answer": "Information technology security audits are organizational and procedural controls used to evaluate the security of an organization's IT systems. The audits assess security controls' effectiveness, identify vulnerabilities, and make recommendations for improvement."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did the Anti-Security Movement's activities reflect on the broader debate about information security and disclosure?",
    "context": "",
    "output": "The Anti-Security Movement's activities sparked a broader debate about information security and disclosure, raising questions about the balance between sharing vulnerabilities to enhance security and the potential misuse of such information by malicious actors and the security industry.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did the Anti-Security Movement's activities reflect on the broader debate about information security and disclosure?",
      "answer": "The Anti-Security Movement's activities sparked a broader debate about information security and disclosure, raising questions about the balance between sharing vulnerabilities to enhance security and the potential misuse of such information by malicious actors and the security industry."
    }
  },
  {
    "instruction": "context: The Personal Eventing Protocol (PEP, XEP-0163) is an open standard used by OMEMO for event notifications and message synchronization.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the Personal Eventing Protocol (PEP, XEP-0163)?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Personal Eventing Protocol (PEP, XEP-0163)?",
      "answer": "The Personal Eventing Protocol (PEP, XEP-0163) is an open standard used by OMEMO for event notifications and message synchronization."
    }
  },
  {
    "instruction": "context: Unidirectional networks can be used in the defense and defense contractors industries to allow export of data from a protected machine while preventing attacks on that machine. This is achieved by using data diodes to connect machines at different security levels, and ensuring that users can only create data at or above their own security level.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can unidirectional networks be used in the defense and defense contractors industries?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can unidirectional networks be used in the defense and defense contractors industries?",
      "answer": "Unidirectional networks can be used in the defense and defense contractors industries to allow export of data from a protected machine while preventing attacks on that machine. This is achieved by using data diodes to connect machines at different security levels, and ensuring that users can only create data at or above their own security level."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the Otway-Rees protocol ensure the detection of modification in a network communication?",
    "context": "",
    "output": "The Otway-Rees protocol uses encryption and nonces to ensure the integrity of messages. Each message is encrypted using a shared key between the sender and the server, and a nonce is included to prevent replay attacks. If any modification is made to the message, the encryption or the nonce will no longer be valid, and the recipient can detect this modification.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Otway-Rees protocol ensure the detection of modification in a network communication?",
      "answer": "The Otway-Rees protocol uses encryption and nonces to ensure the integrity of messages. Each message is encrypted using a shared key between the sender and the server, and a nonce is included to prevent replay attacks. If any modification is made to the message, the encryption or the nonce will no longer be valid, and the recipient can detect this modification."
    }
  },
  {
    "instruction": "context: The three generally accepted factors used to establish a digital identity for electronic authentication are knowledge factor, possession factor, and biometric factor. The knowledge factor is something that the user knows, such as a password or answers to challenge questions. The possession factor is something that the user has, such as a mobile phone or token. The biometric factor is something that the user is, such as his or her fingerprints, eye scan, or voice pattern.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are the three generally accepted factors used to establish a digital identity for electronic authentication?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the three generally accepted factors used to establish a digital identity for electronic authentication?",
      "answer": "The three generally accepted factors used to establish a digital identity for electronic authentication are knowledge factor, possession factor, and biometric factor. The knowledge factor is something that the user knows, such as a password or answers to challenge questions. The possession factor is something that the user has, such as a mobile phone or token. The biometric factor is something that the user is, such as his or her fingerprints, eye scan, or voice pattern."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the use of password managers impact the user's ability to use passwords across different online services, and what measures can be taken to further enhance this ability?",
    "context": "",
    "output": "The use of password managers can make it easier to use passwords across different online services, as users can securely store and organize all of their passwords in one place. To further enhance this ability, users can take advantage of features such as password generation and automatic form filling.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the use of password managers impact the user's ability to use passwords across different online services, and what measures can be taken to further enhance this ability?",
      "answer": "The use of password managers can make it easier to use passwords across different online services, as users can securely store and organize all of their passwords in one place. To further enhance this ability, users can take advantage of features such as password generation and automatic form filling."
    }
  },
  {
    "instruction": "context: Being open-source software, Gpg4win is typically the non-proprietary option for privacy recommended to Windows users, allowing for community involvement in its development and maintenance.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the significance of Gpg4win being open-source software?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of Gpg4win being open-source software?",
      "answer": "Being open-source software, Gpg4win is typically the non-proprietary option for privacy recommended to Windows users, allowing for community involvement in its development and maintenance."
    }
  },
  {
    "instruction": "Write an answer to the following question: How do pulsing zombie attacks differ from regular distributed denial-of-service attacks?",
    "context": "",
    "output": "Pulsing zombie attacks differ from regular distributed denial-of-service attacks in that they are moderated and periodical, rather than intense and continuous. This makes them more difficult to detect and remedy, as the slow-down in website access can go unnoticed for a long time.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How do pulsing zombie attacks differ from regular distributed denial-of-service attacks?",
      "answer": "Pulsing zombie attacks differ from regular distributed denial-of-service attacks in that they are moderated and periodical, rather than intense and continuous. This makes them more difficult to detect and remedy, as the slow-down in website access can go unnoticed for a long time."
    }
  },
  {
    "instruction": "context: The film suggests that learning is a fundamental aspect of the hacking scene, with hackers often engaging in hacking as a form of exploration and self-education.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the film portray the role of learning in the hacking scene?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the film portray the role of learning in the hacking scene?",
      "answer": "The film suggests that learning is a fundamental aspect of the hacking scene, with hackers often engaging in hacking as a form of exploration and self-education."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can improper exception handling lead to security bugs?",
    "context": "",
    "output": "Improper exception handling can lead to security bugs if the software does not handle exceptions properly. This can result in the software behaving in unexpected and insecure ways when an exception is thrown.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can improper exception handling lead to security bugs?",
      "answer": "Improper exception handling can lead to security bugs if the software does not handle exceptions properly. This can result in the software behaving in unexpected and insecure ways when an exception is thrown."
    }
  },
  {
    "instruction": "Write an answer to the following question: How can webmasters detect if their website is being used for cookie stuffing?",
    "context": "",
    "output": "Webmasters can detect if their website is being used for cookie stuffing by monitoring their website traffic, user-generated content, and cookies for suspicious activity.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can webmasters detect if their website is being used for cookie stuffing?",
      "answer": "Webmasters can detect if their website is being used for cookie stuffing by monitoring their website traffic, user-generated content, and cookies for suspicious activity."
    }
  },
  {
    "instruction": "context: Character crowding in NuCaptcha's video CAPTCHAs is easier for humans to detect due to their innate motion-detecting abilities, compared to static image-based CAPTCHAs.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does NuCaptcha incorporate character crowding in its video CAPTCHAs?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does NuCaptcha incorporate character crowding in its video CAPTCHAs?",
      "answer": "Character crowding in NuCaptcha's video CAPTCHAs is easier for humans to detect due to their innate motion-detecting abilities, compared to static image-based CAPTCHAs."
    }
  },
  {
    "instruction": "Write an answer to the following question: Was there a portal for listing compromised data and backdoors on xDedic?",
    "context": "",
    "output": "Yes, xDedic featured a partner portal for the secure and verified listing of compromised data and standardized backdoors to be used.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Was there a portal for listing compromised data and backdoors on xDedic?",
      "answer": "Yes, xDedic featured a partner portal for the secure and verified listing of compromised data and standardized backdoors to be used."
    }
  },
  {
    "instruction": "Write an answer to the following question: Is social jacking a new technique or a variation of an existing one?",
    "context": "",
    "output": "Social jacking is a variation of the existing technique of click jacking, with the added use of social engineering techniques.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is social jacking a new technique or a variation of an existing one?",
      "answer": "Social jacking is a variation of the existing technique of click jacking, with the added use of social engineering techniques."
    }
  },
  {
    "instruction": "context: The Common Computing Security Standards Forum (CCSF) is an industry organization that Comodo helped establish in 2009 to promote industry standards and protect end users.\n\nAsk a question about this context.",
    "context": "",
    "output": "What industry organization did Comodo help establish to promote industry standards and protect end users?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What industry organization did Comodo help establish to promote industry standards and protect end users?",
      "answer": "The Common Computing Security Standards Forum (CCSF) is an industry organization that Comodo helped establish in 2009 to promote industry standards and protect end users."
    }
  },
  {
    "instruction": "context: The Sub-Directorate Expertise (SDE) carries out the overall mission of expertise and technical assistance of the agency, supporting all the other sub-directorates, ministries, industry, and providers of security and vital operators.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the role of the Sub-Directorate Expertise (SDE) at ANSSI?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the Sub-Directorate Expertise (SDE) at ANSSI?",
      "answer": "The Sub-Directorate Expertise (SDE) carries out the overall mission of expertise and technical assistance of the agency, supporting all the other sub-directorates, ministries, industry, and providers of security and vital operators."
    }
  },
  {
    "instruction": "Cryptosystem\n\n==Introduction==\nIn cryptography, a cryptosystem is a suite of cryptographic algorithms needed to implement a particular security service, such as confidentiality (encryption).Typically, a cryptosystem consists of three algorithms: one for key generation, one for encryption, and one for decryption. The term cipher (sometimes cypher) is often used to refer to a pair of algorithms, one for encryption and one for decryption. Therefore, the term cryptosystem is most often used when the key generation algorithm is important.  For this reason, the term cryptosystem is commonly used to refer to public key techniques; however both \"cipher\" and \"cryptosystem\" are used for symmetric key techniques.\n\n\n\n== Formal definition ==\nMathematically, a cryptosystem or encryption scheme can be defined as a tuple \n  \n    \n      \n        (\n        \n          \n            P\n          \n        \n        ,\n        \n          \n            C\n          \n        \n        ,\n        \n          \n            K\n          \n        \n        ,\n        \n          \n            E\n          \n        \n        ,\n        \n          \n            D\n          \n        \n        )\n      \n    \n    {\\displaystyle ({\\mathcal {P}},{\\mathcal {C}},{\\mathcal {K}},{\\mathcal {E}},{\\mathcal {D}})}\n   with the following properties.\n\n  \n    \n      \n        \n          \n            P\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {P}}}\n   is a set called the \"plaintext space\".  Its elements are called plaintexts.\n\n  \n    \n      \n        \n          \n            C\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {C}}}\n   is a set called the \"ciphertext space\". Its elements are called ciphertexts.\n\n  \n    \n      \n        \n          \n            K\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {K}}}\n   is a set called the \"key space\".  Its elements are called keys.\n\n  \n    \n      \n        \n          \n            E\n\n== Examples ==\nA classical example of a cryptosystem is the Caesar cipher.  A more contemporary example is the RSA cryptosystem.\n\nWhat is an example of a contemporary cryptosystem?",
    "context": "",
    "output": "A: A more contemporary example of a cryptosystem is the RSA cryptosystem.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is an example of a contemporary cryptosystem?",
      "answer": "A more contemporary example of a cryptosystem is the RSA cryptosystem.",
      "context": "Cryptosystem\n\n==Introduction==\nIn cryptography, a cryptosystem is a suite of cryptographic algorithms needed to implement a particular security service, such as confidentiality (encryption).Typically, a cryptosystem consists of three algorithms: one for key generation, one for encryption, and one for decryption. The term cipher (sometimes cypher) is often used to refer to a pair of algorithms, one for encryption and one for decryption. Therefore, the term cryptosystem is most often used when the key generation algorithm is important.  For this reason, the term cryptosystem is commonly used to refer to public key techniques; however both \"cipher\" and \"cryptosystem\" are used for symmetric key techniques.\n\n\n\n== Formal definition ==\nMathematically, a cryptosystem or encryption scheme can be defined as a tuple \n  \n    \n      \n        (\n        \n          \n            P\n          \n        \n        ,\n        \n          \n            C\n          \n        \n        ,\n        \n          \n            K\n          \n        \n        ,\n        \n          \n            E\n          \n        \n        ,\n        \n          \n            D\n          \n        \n        )\n      \n    \n    {\\displaystyle ({\\mathcal {P}},{\\mathcal {C}},{\\mathcal {K}},{\\mathcal {E}},{\\mathcal {D}})}\n   with the following properties.\n\n  \n    \n      \n        \n          \n            P\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {P}}}\n   is a set called the \"plaintext space\".  Its elements are called plaintexts.\n\n  \n    \n      \n        \n          \n            C\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {C}}}\n   is a set called the \"ciphertext space\". Its elements are called ciphertexts.\n\n  \n    \n      \n        \n          \n            K\n          \n        \n      \n    \n    {\\displaystyle {\\mathcal {K}}}\n   is a set called the \"key space\".  Its elements are called keys.\n\n  \n    \n      \n        \n          \n            E\n\n== Examples ==\nA classical example of a cryptosystem is the Caesar cipher.  A more contemporary example is the RSA cryptosystem."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which research institute is COSIC a part of, and what is the focus of this institute?",
    "context": "",
    "output": "COSIC is part of the Smart Applications and Innovation Services of imec, which focuses on the development and application of microelectronics and nanotechnology.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which research institute is COSIC a part of, and what is the focus of this institute?",
      "answer": "COSIC is part of the Smart Applications and Innovation Services of imec, which focuses on the development and application of microelectronics and nanotechnology."
    }
  },
  {
    "instruction": "Context: Timeline of computer viruses and worms\n\n==Introduction==\nThis timeline of computer viruses and worms presents a chronological timeline of noteworthy computer viruses, computer worms, Trojan horses, similar malware, related research and events.\n\n\n\n== 1960s ==\nJohn von Neumann's article on the \"Theory of self-reproducing automata\" is published in 1966. The article is based on lectures given by von Neumann at the University of Illinois about the \"Theory and Organization of Complicated Automata\" in 1949.\n\n== 1970s ==\n\n\n*** 1970 ***\nThe first story written about a computer virus is The Scarred Man by Gregory Benford.\n\n\n*** 1971 ***\nThe Creeper system, an experimental self-replicating program, is written by Bob Thomas at BBN Technologies to test John von Neumann's theory. Creeper infected DEC PDP-10 computers running the TENEX operating system. Creeper gained access via the ARPANET and copied itself to the remote system where the message \"I'm the creeper, catch me if you can!\" was displayed. The Reaper program was later created to delete Creeper.\nAt the University of Illinois at Urbana-Champaign, a graduate student named Alan Davis (working for Prof. Donald Gillies) created a process on a PDP-11 that (a) checked to see if an identical copy of itself was currently running as an active process, and if not, created a copy of itself and started it running; (b) checked to see if any disk space (which all users shared) was available, and if so, created a file the size of that space; and (c) looped back to step (a). As a result, the process stole all available disk space. When users tried to save files, the operating system advised them that the disk was full and that they needed to delete some existing files. Of course, if they did delete a file, this process would immediately snatch up the available space. When users called in a system administrator (A. Ian Stocks) to fix the problem, he examined the active processes, discovered the offending process, and deleted it. Of course, before he left the room, the still existing process would create another copy of itself, and the problem wouldn't go away. The only way to make the computer work again was to reboot.\n\n\n*** 1972 ***\nThe science fiction novel, When HARLIE Was One, by David Gerrold, contains one of the first fictional representations of a computer virus, as well as one of the first uses of the word \"virus\" to denote a program that infects a computer.\n\n\n*** 1973 ***\nIn fiction, the 1973 Michael Crichton movie Westworld made an early mention of the concept of a computer virus, being a central plot theme that causes androids to run amok. Alan Oppenheimer's character summarizes the problem by stating that \"...there's a clear pattern here which suggests an analogy to an infectious disease process, spreading from one...area to the next.\"  To which the replies are stated: \"Perhaps there are superficial similarities to disease\" and, \"I must confess I find it difficult to believe in a disease of machinery.\" (Crichton's earlier work, the 1969 novel The Andromeda Strain and 1971 film were about an extraterrestrial biological virus-like disease that threatened the human race.)\n\n\n*** 1974 ***\nThe Rabbit (or Wabbit) virus, more a fork bomb than a virus, is written. The Rabbit virus makes multiple copies of itself on a single computer (and was named \"Rabbit\" for the speed at which it did so) until it clogs the system, reducing system performance, before finally reaching a threshold and crashing the computer.\n\n\n*** 1975 ***\nApril: ANIMAL is written by John Walker for the UNIVAC 1108. ANIMAL asked several questions of the user in an attempt to guess the type of animal the user was thinking of, while the related program PERVADE would create a copy of itself and ANIMAL in every directory to which the current user had access. It spread across the multi-user UNIVACs when users with overlapping permissions discovered the game, and to other computers when tapes were shared. The program was carefully written to avoid damaging existing file or directory structures, and to avoid copying itself if permissions did not exist or if harm would result. Its spread was halted by an OS upgrade that changed the format of the file status tables PERVADE used. Though non-malicious, \"Pervading Animal\" represents the first Trojan \"in the wild\".\nThe novel The Shockwave Rider by John Brunner is published, coining the word \"worm\" to describe a program that propagates itself through a computer network.\n\n\n*** 1977 ***\n\"The Adolescence of P-1\" novel, describes a worm program which propagates through modem-based networks, eventually developing its own strategy-developing AI, which deals with cross-hardware and cross-os issues, eventually infecting hardware manufactures and defense organizations.\n\n== 1980s ==\n\n\n*** 1982 ***\nA program called Elk Cloner, written for Apple II systems, was created by high school student Richard Skrenta, originally as a prank. The Apple II was particularly vulnerable due to the storage of its operating system on a floppy disk. Elk Cloner's design combined with public ignorance about what malware was and how to protect against it led to Elk Cloner being responsible for the first large-scale computer virus outbreak in history.\n\n\n*** 1983 ***\nNovember: The term \"virus\" is re-coined by Frederick B. Cohen in describing self-replicating computer programs. In 1984 Cohen uses the phrase \"computer virus\" (suggested by his teacher Leonard Adleman) to describe the operation of such programs in terms of \"infection\". He defines a \"virus\" as \"a program that can 'infect' other programs by modifying them to include a possibly evolved copy of itself.\" Cohen demonstrates a virus-like program on a VAX11/750 system at Lehigh University. The program could install itself in, or infect, other system objects.\n\n\n*** 1984 ***\nAugust: Ken Thompson publishes his seminal paper, Reflections on Trusting Trust, in which he describes how he modified a C compiler so that when used to compile a specific version of the Unix operating system, it inserts a backdoor into the login command, and when used to compile a new copy of itself, it inserts the backdoor insertion code, even if neither the backdoor nor the backdoor insertion code is present in the source code of this new copy.\n\n\n*** 1986 ***\nJanuary: The Brain boot sector virus is released. Brain is considered the first IBM PC compatible virus, and the program responsible for the first IBM PC compatible virus epidemic. The virus is also known as Lahore, Pakistani, Pakistani Brain, and Pakistani flu as it was created in Lahore, Pakistan by 19-year-old Pakistani programmer, Basit Farooq Alvi, and his brother, Amjad Farooq Alvi.\nDecember: Ralf Burger presented the Virdem model of programs at a meeting of the underground Chaos Computer Club in Germany. The Virdem model represented the first programs that could replicate themselves via addition of their code to executable DOS files in COM format.\n\n\n*** 1987 ***\nAppearance of the Vienna virus, which was subsequently neutralized \u2013 the first time this had happened on the IBM platform.\nAppearance of Lehigh virus (discovered at its namesake university), boot sector viruses such as Yale from the US, Stoned from New Zealand, Ping Pong from Italy, and appearance of the first self-encrypting file virus, Cascade. Lehigh was stopped on campus before it spread to the \"wild\" (to computers beyond the university), and as a result, has never been found elsewhere. A subsequent infection of Cascade in the offices of IBM Belgium led to IBM responding with its own antivirus product development. Prior to this, antivirus solutions developed at IBM were intended for staff use only.\nOctober: The Jerusalem virus, part of the (at that time unknown) Suriv family, is detected in the city of Jerusalem. The virus destroys all executable files on infected machines upon every occurrence of Friday the 13th (except Friday 13 November 1987 making its first trigger date May 13, 1988). Jerusalem caused a worldwide epidemic in 1988.\nNovember: The SCA virus, a boot sector virus for Amiga computers, appears.  It immediately creates a pandemic virus-writer storm. A short time later, SCA releases another, considerably more destructive virus, the Byte Bandit.\nDecember: Christmas Tree EXEC was the first widely disruptive replicating network program, which paralyzed several international computer networks in December 1987. It was written in Rexx on the VM/CMS operating system and originated in what was then West Germany. It re-emerged in 1990.\n\n\n*** 1988 ***\nMarch 1: The Ping-Pong virus (also called Boot, Bouncing Ball, Bouncing Dot, Italian, Italian-A or VeraCruz), an MS-DOS boot sector virus, is discovered at the University of Turin in Italy.\nJune: The CyberAIDS and Festering Hate Apple ProDOS viruses spreads from underground pirate BBS systems and starts infecting mainstream networks. Festering Hate was the last iteration of the CyberAIDS series extending back to 1985 and 1986. Unlike the few Apple viruses that had come before which were essentially annoying, but did no damage, the Festering Hate series of viruses was extremely destructive, spreading to all system files it could find on the host computer (hard drive, floppy, and system memory) and then destroying everything when it could no longer find any uninfected files.\nNovember 2: The Morris worm, created by Robert Tappan Morris, infects DEC VAX and Sun machines running BSD UNIX that are connected to the Internet, and becomes the first worm to spread extensively \"in the wild\", and one of the first well-known programs exploiting buffer overrun vulnerabilities.\nDecember: The Father Christmas worm attacks DEC VAX machines running VMS that are connected to the DECnet Internet (an international scientific research network using DECnet protocols), affecting NASA and other research centers. Its purpose was to deliver a Christmas greeting to all affected users.\n\n\n*** 1989 ***\nOctober: Ghostball, the first multipartite virus, is discovered by Fri\u00f0rik Sk\u00falason. It infects both executable .COM files and boot sectors on MS-DOS systems.\nDecember: Several thousand floppy disks containing the AIDS Trojan, the first known ransomware, are mailed to subscribers of PC Business World magazine and a WHO AIDS conference mailing list. This DOS Trojan lies dormant for 90 boot cycles, then encrypts all filenames on the system, displaying a notice asking for $189 to be sent to a post office box in Panama in order to receive a decryption program.\n\n== 1990s ==\n\n\n*** 1990 ***\nMark Washburn, working on an analysis of the Vienna and Cascade viruses with Ralf Burger, develops the first family of polymorphic viruses, the Chameleon family. Chameleon series debuted with the release of 1260.\nJune: The Form computer virus is isolated in Switzerland. It would remain in the wild for almost 20 years and reappear afterward; during the 1990s it tended to be the most common virus in the wild with 20 to more than 50 percent of reported infections.\n\n\n*** 1992 ***\nMarch: The Michelangelo virus was expected to create a digital apocalypse on March 6, with millions of computers having their information wiped, according to mass media hysteria surrounding the virus. Later assessments of the damage showed the aftermath to be minimal. John McAfee had been quoted by the media as saying that five million computers would be affected. He later said that pressed by the interviewer to come up with a number, he had estimated a range from five thousand to five million, but the media naturally went with just the higher number.\n\n\n*** 1993 ***\n\"Leandro\" or \"Leandro & Kelly\" and \"Freddy Krueger\" spread quickly due to popularity of BBS and shareware distribution.\n\n\n*** 1994 ***\nApril: OneHalf is a DOS-based polymorphic computer virus.\nSeptember: ReBoot first airs, containing another memorable fictional, sentient computer virus, Megabyte.\n\n\n*** 1995 ***\nThe first Macro virus, called \"Concept\", is created. It attacked Microsoft Word documents.\n\n\n*** 1996 ***\n\"Ply\" \u2013 DOS 16-bit based complicated polymorphic virus appeared with a built-in permutation engine.\nBoza, the first virus designed specifically for Windows 95 files arrives.\nLaroux, the first Excel macro virus appears.\nStaog, the first Linux virus attacks Linux machines\n\n\n*** 1998 ***\nJune 2: The first version of the CIH virus appears. It is the first known virus able to erase flash ROM BIOS content.\n\n\n*** 1999 ***\nJanuary 20: The Happy99 worm first appeared. It invisibly attaches itself to emails, displays fireworks to hide the changes being made, and wishes the user a happy New Year. It modifies system files related to Outlook Express and Internet Explorer (IE) on Windows 95 and Windows 98.\nMarch 26: The Melissa worm was released, targeting Microsoft Word and Outlook-based systems, and creating considerable network traffic.\nJune 6: The ExploreZip worm, which destroys Microsoft Office documents, was first detected.\nSeptember: the CTX virus is isolated\nDecember 30: The Kak worm is a JavaScript computer worm that spread itself by exploiting a bug in Outlook Express.\n\n== 2000s ==\n\n\n*** 2000 ***\nMay 5: The ILOVEYOU worm (also known as the Love Letter, VBS, or Love Bug worm), a computer worm written in VBScript and using social engineering techniques, infected millions of Windows computers worldwide within a few hours of its release.\nJune 28: The Pikachu virus is believed to be the first computer virus geared at children. It contains the character \"Pikachu\" from the Pok\u00e9mon series. The operating systems affected by this worm are Windows 95, Windows 98, and Windows ME.\n\n\n*** 2001 ***\nFebruary 11: The Anna Kournikova virus hits e-mail servers hard by sending e-mail to contacts in the Microsoft Outlook addressbook. Its creator, Jan de Wit, was sentenced to 150 hours of community service.\nMarch 13: Magistr, also called Disembowler, is discovered. It is a complex email worm for Windows systems with multiple payloads that trigger months apart from each other. It targets members of the Law profession by searching the files on a user's computer for various keywords relating to court proceedings, activating if such are found.\nMay 8: The Sadmind worm spreads by exploiting holes in both Sun Solaris and Microsoft IIS.\nJuly: The Sircam worm is released, spreading through Microsoft systems via e-mail and unprotected network shares.\nJuly 13: The Code Red worm attacking the Index Server ISAPI Extension in Microsoft Internet Information Services is released.\nAugust 4: A complete re-write of the Code Red worm, Code Red II begins aggressively spreading onto Microsoft systems, primarily in China.\nSeptember 18: The Nimda worm is discovered and spreads through a variety of means including vulnerabilities in Microsoft Windows and backdoors left by Code Red II and Sadmind worm.\nOctober 26: The Klez worm is first identified. It exploits a vulnerability in Microsoft Internet Explorer and Microsoft Outlook and Outlook Express.\n\n\n*** 2002 ***\nFebruary 11: The Simile virus is a metamorphic computer virus written in assembly.\nBeast is a Windows-based backdoor Trojan horse, more commonly known as a RAT (Remote Administration Tool). It is capable of infecting almost all versions of Windows. Written in Delphi and released first by its author Tataye in 2002, its most current version was released on October 3, 2004.\nMarch 7: Mylife is a computer worm that spread itself by sending malicious emails to all the contacts in Microsoft Outlook.\n\n\n*** 2003 ***\nJanuary 24: The SQL Slammer worm, aka Sapphire worm, Helkern and other names, attacks vulnerabilities in Microsoft SQL Server and MSDE becomes the fastest spreading worm of all time (measured by doubling time at the peak rate of growth), causing massive Internet access disruptions worldwide just fifteen minutes after infecting its first victim.\nApril 2: Graybird is a trojan horse also known as Backdoor.Graybird.\nJune 13: ProRat is a Turkish-made Microsoft Windows based backdoor trojan horse, more commonly known as a RAT (Remote Administration Tool).\nAugust 12: The Blaster worm, aka the Lovesan worm, rapidly spreads by exploiting a vulnerability in system services present on Windows computers.\nAugust 18: The Welchia (Nachi) worm is discovered. The worm tries to remove the Blaster worm and patch Windows.\nAugust 19: The Sobig worm (technically the Sobig.F worm) spreads rapidly through Microsoft systems via mail and network shares.\nSeptember 18: Swen is a computer worm written in C++.\nOctober 24: The Sober worm is first seen on Microsoft systems and maintains its presence until 2005 with many new variants. The simultaneous attacks on network weak points by the Blaster and Sobig worms cause massive damage.\nNovember 10: Agobot is a computer worm that can spread itself by exploiting vulnerabilities on Microsoft Windows. Some of the vulnerabilities are MS03-026 and MS05-039.\nNovember 20: Bolgimo is a computer worm that spread itself by exploiting a buffer overflow vulnerability at Microsoft Windows DCOM RPC Interface.\n\n\n*** 2004 ***\nJanuary 18: Bagle is a mass-mailing worm affecting all versions of Microsoft Windows. There were 2 variants of Bagle worm, Bagle.A and Bagle.B. Bagle.B was discovered on February 17, 2004.\nJanuary 26: The MyDoom worm emerges, and currently holds the record for the fastest-spreading mass mailer worm. The worm was most notable for performing a distributed denial-of-service (DDoS) attack on www.sco.com, which belonged to The SCO Group.\nFebruary 16: The Netsky worm is discovered. The worm spreads by email and by copying itself to folders on the local hard drive as well as on mapped network drives if available. Many variants of the Netsky worm appeared.\nMarch 19: The Witty worm is a record-breaking worm in many regards. It exploited holes in several Internet Security Systems (ISS) products. It was the fastest computer issue to be categorized as a worm, and it was the first internet worm to carry a destructive payload. It spread rapidly using a pre-populated list of ground-zero hosts.\nMay 1: The Sasser worm emerges by exploiting a vulnerability in the Microsoft Windows LSASS service and causes problems in networks, while removing MyDoom and Bagle variants, even interrupting business.\nJune 15: Caribe or Cabir is a computer worm that is designed to infect mobile phones that run Symbian OS. It is the first computer worm that can infect mobile phones. It spread itself through Bluetooth. More information can be found on F-Secure and Symantec.\nAugust 16: Nuclear RAT (short for Nuclear Remote Administration Tool) is a backdoor trojan that infects Windows NT family systems (Windows 2000, Windows XP, Windows 2003).\nAugust 20: Vundo, or the Vundo Trojan (also known as Virtumonde or Virtumondo and sometimes referred to as MS Juan) is a trojan known to cause popups and advertising for rogue antispyware programs, and sporadically other misbehavior including performance degradation and denial of service with some websites including Google and Facebook.\nOctober 12: Bifrost, also known as Bifrose, is a backdoor trojan which can infect Windows 95 through Vista. Bifrost uses the typical server, server builder, and client backdoor program configuration to allow a remote attack.\nDecember: Santy, the first known \"webworm\" is launched. It exploited a vulnerability in phpBB and used Google to find new targets. It infected around 40000 sites before Google filtered the search query used by the worm, preventing it from spreading.\n\n\n*** 2005 ***\nAugust 2005: Zotob is a computer worm which exploits security vulnerabilities in Microsoft operating systems like Windows 2000, including the MS05-039 plug-and-play vulnerability. This worm has been known to spread on Microsoft-ds or TCP port 445.\nOctober 2005: The copy protection rootkit deliberately and surreptitiously included on music CDs sold by Sony BMG is exposed.  The rootkit creates vulnerabilities on affected computers, making them susceptible to infection by worms and viruses.\nLate 2005: The Zlob Trojan, is a Trojan horse program that masquerades as a required video codec in the form of the Microsoft Windows ActiveX component. It was first detected in late 2005.\n\n\n*** 2006 ***\nJanuary 20: The Nyxem worm was discovered. It spread by mass-mailing. Its payload, which activates on the third of every month, starting on February 3, attempts to disable security-related and file-sharing software, and destroy files of certain types, such as Microsoft Office files.\nFebruary 16: Discovery of the first-ever malware for Mac OS X, a low-threat trojan-horse known as OSX/Leap-A or OSX/Oompa-A, is announced.\nLate March: Brontok variant N was found in late March. Brontok was a mass-email worm and the origin for the worm was from Indonesia.\nJune: Starbucks is a virus that infects StarOffice and OpenOffice.\nLate September: Stration or Warezov worm first discovered.\nDevelopment of Stuxnet is presumed to have been started between 2005 and 2006.\n\n\n*** 2007 ***\nJanuary 17: Storm Worm identified as a fast-spreading email spamming threat to Microsoft systems. It begins gathering infected computers into the Storm botnet. By around June 30, it had infected 1.7 million computers, and it had compromised between 1 and 10 million computers by September. Thought to have originated from Russia, it disguises itself as a news email containing a film about bogus news stories asking you to download the attachment which it claims is a film.\nJuly: Zeus is a trojan that targets Microsoft Windows to steal banking information by keystroke logging.\n\n\n*** 2008 ***\nFebruary 17: Mocmex is a trojan, which was found in a digital photo frame in February 2008. It was the first serious computer virus on a digital photo frame. The virus was traced back to a group in China.\nMarch 3: Torpig, also known as Sinowal and Mebroot, is a Trojan horse that affects Windows, turning off anti-virus applications. It allows others to access the computer, modifies data, steals confidential information (such as user passwords and other sensitive data) and installs more malware on the victim's computer.\nMay 6: Rustock.C, a hitherto-rumored spambot-type malware with advanced rootkit capabilities, was announced to have been detected on Microsoft systems and analyzed, having been in the wild and undetected since October 2007 at the very least.\nJuly 6: Bohmini.A is a configurable remote access tool or trojan that exploits security flaws in Adobe Flash 9.0.115 with Internet Explorer 7.0 and Firefox 2.0 under Windows XP SP2.\nJuly 31: The Koobface computer worm targets users of Facebook and Myspace. New variants constantly appear.\nNovember 21: Computer worm Conficker infects anywhere from 9 to 15 million Microsoft server systems running everything from Windows 2000 to the Windows 7 Beta. The French Navy, UK Ministry of Defence (including Royal Navy warships and submarines), Sheffield Hospital network, German Bundeswehr and Norwegian Police were all affected. Microsoft sets a bounty of US$250,000 for information leading to the capture of the worm's author(s). Five main variants of the Conficker worm are known and have been dubbed Conficker A, B, C, D and E. They were discovered 21 November 2008, 29 December 2008, 20 February 2009, 4 March 2009 and 7 April 2009, respectively. On December 16, 2008, Microsoft releases KB958644 patching the server service vulnerability responsible for the spread of Conficker.\n\n\n*** 2009 ***\nJuly 4: The July 2009 cyber attacks occur and the emergence of the W32.Dozer attack the United States and South Korea.\nJuly 15: Symantec discovered Daprosy Worm, a trojan worm is intended to steal online-game passwords in internet cafes. It could intercept all keystrokes and send them to its author, making it potentially a very dangerous worm to infect B2B (business-to-business) systems.\nAugust 24: Source code for MegaPanzer is released by its author under GPLv3. and appears to have been apparently detected in the wild.\nNovember 27: The virus Kenzero is a virus that spreads online from peer-to-peer networks (P2P) taking browsing history.\n\n== 2010s ==\n\n\n*** 2010 ***\nJanuary: The Waledac botnet sent spam emails. In February 2010, an international group of security researchers and Microsoft took Waledac down.\nJanuary: The Psyb0t worm is discovered.  It is thought to be unique in that it can infect routers and high-speed modems.\nFebruary 18: Microsoft announced that a BSoD problem on some Windows machines which was triggered by a batch of Patch Tuesday updates was caused by the Alureon Trojan.\nJune 17: Stuxnet, a Windows Trojan, was detected. It is the first worm to attack SCADA systems. There are suggestions that it was designed to target Iranian nuclear facilities. It uses a valid certificate from Realtek.\nSeptember 9: The virus, called \"here you have\" or \"VBMania\", is a simple Trojan horse that arrives in the inbox with the odd-but-suggestive subject line \"here you have\". The body reads \"This is The Document I told you about, you can find it Here\" or \"This is The Free Download Sex Movies, you can find it Here\".\n\n\n*** 2011 ***\nSpyEye and Zeus merged code is seen. New variants attack mobile phone banking information.\nAnti-Spyware 2011, a Trojan horse that attacks Windows 9x, 2000, XP, Vista, and Windows 7, posing as an anti-spyware program. It disables security-related processes of anti-virus programs, while also blocking access to the Internet, which prevents updates.\nSummer 2011: The Morto worm attempts to propagate itself to additional computers via the Microsoft Windows Remote Desktop Protocol (RDP). Morto spreads by forcing infected systems to scan for Windows servers allowing RDP login. Once Morto finds an RDP-accessible system, it attempts to log into a domain or local system account named 'Administrator' using several common passwords.  A detailed overview of how the worm works \u2013 along with the password dictionary Morto uses \u2013 was done by Imperva.\nJuly 13: the ZeroAccess rootkit (also known as Sirefef or max++) was discovered.\nSeptember 1: Duqu is a worm thought to be related to the Stuxnet worm. The Laboratory of Cryptography and System Security (CrySyS Lab) of the Budapest University of Technology and Economics in Hungary discovered the threat, analysed the malware, and wrote a 60-page report naming the threat Duqu. Duqu gets its name from the prefix \"~DQ\" it gives to the names of files it creates.\n\n\n*** 2012 ***\nMay: Flame \u2013 also known as Flamer, sKyWIper, and Skywiper \u2013  a modular computer malware that attacks computers running Microsoft Windows. Used for targeted cyber espionage in Middle Eastern countries. Its discovery was announced on 28 May 2012 by MAHER Center of Iranian National Computer Emergency Response Team (CERT), Kaspersky Lab and CrySyS Lab of the Budapest University of Technology and Economics. CrySyS stated in their report that \"sKyWIper is certainly the most sophisticated malware we encountered during our practice; arguably, it is the most complex malware ever found\".\nAugust 16: Shamoon is a computer virus designed to target computers running Microsoft Windows in the energy sector. Symantec, Kaspersky Lab, and Seculert announced its discovery on August 16, 2012.\nSeptember 20: NGRBot is a worm that uses the IRC network for file transfer, sending and receiving commands between zombie network machines and the attacker's IRC server, and monitoring and controlling network connectivity and intercept. It employs a user-mode rootkit technique to hide and steal its victim's information. This family of bot is also designed to infect HTML pages with inline frames (iframes), causing redirections, blocking victims from getting updates from security/antimalware products, and killing those services. The bot is designed to connect via a predefined IRC channel and communicate with a remote botnet.\n\n\n*** 2013 ***\nSeptember: The CryptoLocker Trojan horse is discovered. CryptoLocker encrypts the files on a user's hard drive, then prompts them to pay a ransom to the developer to receive the decryption key. In the following months, several copycat ransomware Trojans were also discovered.\nDecember: The Gameover ZeuS Trojan is discovered. This type of virus steals one's login details on popular Web sites that involve monetary transactions. It works by detecting a login page, then proceeds to inject malicious code into the page, keystroke logging the computer user's details.\nDecember: Linux.Darlloz targets the Internet of things and infects routers, security cameras, set-top boxes by exploiting a PHP vulnerability.\n\n\n*** 2014 ***\nNovember: The Regin Trojan horse is discovered. Regin is a dropper, primarily spread via spoofed Web pages. Once installed, it quietly downloads additional malware, making it difficult for signature-based anti-virus programs to detect. It is believed to have been created by the United States and United Kingdom as a tool for espionage and mass surveillance.\n\n\n*** 2015 ***\nThe BASHLITE malware is leaked leading to a massive spike in DDoS attacks.\nLinux.Wifatch is revealed to the general public. It is found to attempt to secure devices from other more malicious malware.\n\n\n*** 2016 ***\nJanuary: A trojan named \"MEMZ\" is created. The creator, Leurak, explained that the trojan was intended merely as a joke. The trojan alerts the user to the fact that it is a trojan and warns them that if they proceed, the computer may no longer be usable. It contains complex payloads that corrupt the system, displaying artifacts on the screen as it runs. Once run, the application cannot be closed without causing further damage to the computer, which will stop functioning properly regardless. When the computer is restarted, in place of the bootsplash is a message that reads \"Your computer has been trashed by the MEMZ Trojan. Now enjoy the Nyan cat\u2026\", which follows with an animation of the Nyan Cat.\nFebruary: Ransomware Locky with its over 60 derivatives spread throughout Europe and infected several million computers. At the height of the spread over five thousand computers per hour were infected in Germany alone. Although ransomware was not a new thing at the time, insufficient cyber security as well as a lack of standards in IT was responsible for the high number of infections. Unfortunately, even up to date antivirus and internet security software was unable to protect systems from early versions of Locky.\nFebruary: Tiny Banker Trojan (Tinba) makes headlines. Since its discovery, it has been found to have infected more than two dozen major banking institutions in the United States, including TD Bank, Chase, HSBC, Wells Fargo, PNC and Bank of America. Tiny Banker Trojan uses HTTP injection to force the user's computer to believe that it is on the bank's website. This spoof page will look and function just as the real one. The user then enters their information to log on, at which point Tinba can launch the bank webpage's \"incorrect login information\" return, and redirect the user to the real website. This is to trick the user into thinking they had entered the wrong information and proceed as normal, although now Tinba has captured the credentials and sent them to its host.\nAugust: Journalists and researchers report the discovery of spyware, called Pegasus, developed and distributed by a private company which can and has been used to infect iOS and Android smartphones often \u2013 based on 0-day exploits \u2013 without the need for any user-interaction or significant clues to the user and then be used to exfiltrate data, track user locations, capture film through its camera, and activate the microphone at any time. The investigation suggests it was used on many targets worldwide and revealed its use for e.g. governments' espionage on journalists, opposition politicians, activists, business people and others.\nSeptember: Mirai creates headlines by launching some of the most powerful and disruptive DDoS attacks seen to date by infecting the Internet of Things. Mirai ends up being used in the DDoS attack on 20 September 2016 on the Krebs on Security site which reached 620 Gbit/s. Ars Technica also reported a 1 Tbit/s attack on French web host OVH. On 21 October 2016 multiple major DDoS attacks in DNS services of DNS service provider Dyn occurred using Mirai malware installed on a large number of IoT devices, resulting in the inaccessibility of several high-profile websites such as GitHub, Twitter, Reddit, Netflix, Airbnb and many others. The attribution of the attack to the Mirai botnet was originally reported by BackConnect Inc., a security firm.\n\n\n*** 2017 ***\nMay: The WannaCry ransomware attack spreads globally. Exploits revealed in the NSA hacking toolkit leak of late 2016 were used to enable the propagation of the malware. Shortly after the news of the infections broke online, a UK cybersecurity researcher in collaboration with others found and activated a \"kill switch\" hidden within the ransomware, effectively halting the initial wave of its global propagation. The next day, researchers announced that they had found new variants of the malware without the kill switch.\nJune: The Petya (malware) attack spreads globally affecting Windows systems. Researchers at Symantec reveal that this ransomware uses the EternalBlue exploit, similar to the one used in the WannaCry ransomware attack.\nSeptember: The Xafecopy Trojan attacks 47 countries, affecting only Android operating systems. Kaspersky Lab identified it as a malware from the Ubsod family, stealing money through click based WAP billing systems.\nSeptember: A new variety of Remote Access Trojan (RAT), Kedi RAT, is distributed in a Spear Phishing Campaign. The attack targeted Citrix users. The Trojan was able to evade usual system scanners. Kedi Trojan had all the characteristics of a common Remote Access Trojan and it could communicate to its Command and Control center via Gmail using common HTML, HTTP protocols.\n\n\n*** 2018 ***\nFebruary: Thanatos, a ransomware, becomes the first ransomware program to accept ransom payment in Bitcoin Cash.\n\n\n*** 2019 ***\nNovember: Titanium is an advanced backdoor malware, developed by the PLATINUM APT.\nAnswer this question: What was the first virus to spread online from peer-to-peer networks (P2P) taking browsing history and when was it discovered?",
    "context": "",
    "output": "The virus Kenzero spread online from peer-to-peer networks (P2P) taking browsing history and it was discovered in November 2009.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What was the first virus to spread online from peer-to-peer networks (P2P) taking browsing history and when was it discovered?",
      "answer": "The virus Kenzero spread online from peer-to-peer networks (P2P) taking browsing history and it was discovered in November 2009.",
      "context": "Timeline of computer viruses and worms\n\n==Introduction==\nThis timeline of computer viruses and worms presents a chronological timeline of noteworthy computer viruses, computer worms, Trojan horses, similar malware, related research and events.\n\n\n\n== 1960s ==\nJohn von Neumann's article on the \"Theory of self-reproducing automata\" is published in 1966. The article is based on lectures given by von Neumann at the University of Illinois about the \"Theory and Organization of Complicated Automata\" in 1949.\n\n== 1970s ==\n\n\n*** 1970 ***\nThe first story written about a computer virus is The Scarred Man by Gregory Benford.\n\n\n*** 1971 ***\nThe Creeper system, an experimental self-replicating program, is written by Bob Thomas at BBN Technologies to test John von Neumann's theory. Creeper infected DEC PDP-10 computers running the TENEX operating system. Creeper gained access via the ARPANET and copied itself to the remote system where the message \"I'm the creeper, catch me if you can!\" was displayed. The Reaper program was later created to delete Creeper.\nAt the University of Illinois at Urbana-Champaign, a graduate student named Alan Davis (working for Prof. Donald Gillies) created a process on a PDP-11 that (a) checked to see if an identical copy of itself was currently running as an active process, and if not, created a copy of itself and started it running; (b) checked to see if any disk space (which all users shared) was available, and if so, created a file the size of that space; and (c) looped back to step (a). As a result, the process stole all available disk space. When users tried to save files, the operating system advised them that the disk was full and that they needed to delete some existing files. Of course, if they did delete a file, this process would immediately snatch up the available space. When users called in a system administrator (A. Ian Stocks) to fix the problem, he examined the active processes, discovered the offending process, and deleted it. Of course, before he left the room, the still existing process would create another copy of itself, and the problem wouldn't go away. The only way to make the computer work again was to reboot.\n\n\n*** 1972 ***\nThe science fiction novel, When HARLIE Was One, by David Gerrold, contains one of the first fictional representations of a computer virus, as well as one of the first uses of the word \"virus\" to denote a program that infects a computer.\n\n\n*** 1973 ***\nIn fiction, the 1973 Michael Crichton movie Westworld made an early mention of the concept of a computer virus, being a central plot theme that causes androids to run amok. Alan Oppenheimer's character summarizes the problem by stating that \"...there's a clear pattern here which suggests an analogy to an infectious disease process, spreading from one...area to the next.\"  To which the replies are stated: \"Perhaps there are superficial similarities to disease\" and, \"I must confess I find it difficult to believe in a disease of machinery.\" (Crichton's earlier work, the 1969 novel The Andromeda Strain and 1971 film were about an extraterrestrial biological virus-like disease that threatened the human race.)\n\n\n*** 1974 ***\nThe Rabbit (or Wabbit) virus, more a fork bomb than a virus, is written. The Rabbit virus makes multiple copies of itself on a single computer (and was named \"Rabbit\" for the speed at which it did so) until it clogs the system, reducing system performance, before finally reaching a threshold and crashing the computer.\n\n\n*** 1975 ***\nApril: ANIMAL is written by John Walker for the UNIVAC 1108. ANIMAL asked several questions of the user in an attempt to guess the type of animal the user was thinking of, while the related program PERVADE would create a copy of itself and ANIMAL in every directory to which the current user had access. It spread across the multi-user UNIVACs when users with overlapping permissions discovered the game, and to other computers when tapes were shared. The program was carefully written to avoid damaging existing file or directory structures, and to avoid copying itself if permissions did not exist or if harm would result. Its spread was halted by an OS upgrade that changed the format of the file status tables PERVADE used. Though non-malicious, \"Pervading Animal\" represents the first Trojan \"in the wild\".\nThe novel The Shockwave Rider by John Brunner is published, coining the word \"worm\" to describe a program that propagates itself through a computer network.\n\n\n*** 1977 ***\n\"The Adolescence of P-1\" novel, describes a worm program which propagates through modem-based networks, eventually developing its own strategy-developing AI, which deals with cross-hardware and cross-os issues, eventually infecting hardware manufactures and defense organizations.\n\n== 1980s ==\n\n\n*** 1982 ***\nA program called Elk Cloner, written for Apple II systems, was created by high school student Richard Skrenta, originally as a prank. The Apple II was particularly vulnerable due to the storage of its operating system on a floppy disk. Elk Cloner's design combined with public ignorance about what malware was and how to protect against it led to Elk Cloner being responsible for the first large-scale computer virus outbreak in history.\n\n\n*** 1983 ***\nNovember: The term \"virus\" is re-coined by Frederick B. Cohen in describing self-replicating computer programs. In 1984 Cohen uses the phrase \"computer virus\" (suggested by his teacher Leonard Adleman) to describe the operation of such programs in terms of \"infection\". He defines a \"virus\" as \"a program that can 'infect' other programs by modifying them to include a possibly evolved copy of itself.\" Cohen demonstrates a virus-like program on a VAX11/750 system at Lehigh University. The program could install itself in, or infect, other system objects.\n\n\n*** 1984 ***\nAugust: Ken Thompson publishes his seminal paper, Reflections on Trusting Trust, in which he describes how he modified a C compiler so that when used to compile a specific version of the Unix operating system, it inserts a backdoor into the login command, and when used to compile a new copy of itself, it inserts the backdoor insertion code, even if neither the backdoor nor the backdoor insertion code is present in the source code of this new copy.\n\n\n*** 1986 ***\nJanuary: The Brain boot sector virus is released. Brain is considered the first IBM PC compatible virus, and the program responsible for the first IBM PC compatible virus epidemic. The virus is also known as Lahore, Pakistani, Pakistani Brain, and Pakistani flu as it was created in Lahore, Pakistan by 19-year-old Pakistani programmer, Basit Farooq Alvi, and his brother, Amjad Farooq Alvi.\nDecember: Ralf Burger presented the Virdem model of programs at a meeting of the underground Chaos Computer Club in Germany. The Virdem model represented the first programs that could replicate themselves via addition of their code to executable DOS files in COM format.\n\n\n*** 1987 ***\nAppearance of the Vienna virus, which was subsequently neutralized \u2013 the first time this had happened on the IBM platform.\nAppearance of Lehigh virus (discovered at its namesake university), boot sector viruses such as Yale from the US, Stoned from New Zealand, Ping Pong from Italy, and appearance of the first self-encrypting file virus, Cascade. Lehigh was stopped on campus before it spread to the \"wild\" (to computers beyond the university), and as a result, has never been found elsewhere. A subsequent infection of Cascade in the offices of IBM Belgium led to IBM responding with its own antivirus product development. Prior to this, antivirus solutions developed at IBM were intended for staff use only.\nOctober: The Jerusalem virus, part of the (at that time unknown) Suriv family, is detected in the city of Jerusalem. The virus destroys all executable files on infected machines upon every occurrence of Friday the 13th (except Friday 13 November 1987 making its first trigger date May 13, 1988). Jerusalem caused a worldwide epidemic in 1988.\nNovember: The SCA virus, a boot sector virus for Amiga computers, appears.  It immediately creates a pandemic virus-writer storm. A short time later, SCA releases another, considerably more destructive virus, the Byte Bandit.\nDecember: Christmas Tree EXEC was the first widely disruptive replicating network program, which paralyzed several international computer networks in December 1987. It was written in Rexx on the VM/CMS operating system and originated in what was then West Germany. It re-emerged in 1990.\n\n\n*** 1988 ***\nMarch 1: The Ping-Pong virus (also called Boot, Bouncing Ball, Bouncing Dot, Italian, Italian-A or VeraCruz), an MS-DOS boot sector virus, is discovered at the University of Turin in Italy.\nJune: The CyberAIDS and Festering Hate Apple ProDOS viruses spreads from underground pirate BBS systems and starts infecting mainstream networks. Festering Hate was the last iteration of the CyberAIDS series extending back to 1985 and 1986. Unlike the few Apple viruses that had come before which were essentially annoying, but did no damage, the Festering Hate series of viruses was extremely destructive, spreading to all system files it could find on the host computer (hard drive, floppy, and system memory) and then destroying everything when it could no longer find any uninfected files.\nNovember 2: The Morris worm, created by Robert Tappan Morris, infects DEC VAX and Sun machines running BSD UNIX that are connected to the Internet, and becomes the first worm to spread extensively \"in the wild\", and one of the first well-known programs exploiting buffer overrun vulnerabilities.\nDecember: The Father Christmas worm attacks DEC VAX machines running VMS that are connected to the DECnet Internet (an international scientific research network using DECnet protocols), affecting NASA and other research centers. Its purpose was to deliver a Christmas greeting to all affected users.\n\n\n*** 1989 ***\nOctober: Ghostball, the first multipartite virus, is discovered by Fri\u00f0rik Sk\u00falason. It infects both executable .COM files and boot sectors on MS-DOS systems.\nDecember: Several thousand floppy disks containing the AIDS Trojan, the first known ransomware, are mailed to subscribers of PC Business World magazine and a WHO AIDS conference mailing list. This DOS Trojan lies dormant for 90 boot cycles, then encrypts all filenames on the system, displaying a notice asking for $189 to be sent to a post office box in Panama in order to receive a decryption program.\n\n== 1990s ==\n\n\n*** 1990 ***\nMark Washburn, working on an analysis of the Vienna and Cascade viruses with Ralf Burger, develops the first family of polymorphic viruses, the Chameleon family. Chameleon series debuted with the release of 1260.\nJune: The Form computer virus is isolated in Switzerland. It would remain in the wild for almost 20 years and reappear afterward; during the 1990s it tended to be the most common virus in the wild with 20 to more than 50 percent of reported infections.\n\n\n*** 1992 ***\nMarch: The Michelangelo virus was expected to create a digital apocalypse on March 6, with millions of computers having their information wiped, according to mass media hysteria surrounding the virus. Later assessments of the damage showed the aftermath to be minimal. John McAfee had been quoted by the media as saying that five million computers would be affected. He later said that pressed by the interviewer to come up with a number, he had estimated a range from five thousand to five million, but the media naturally went with just the higher number.\n\n\n*** 1993 ***\n\"Leandro\" or \"Leandro & Kelly\" and \"Freddy Krueger\" spread quickly due to popularity of BBS and shareware distribution.\n\n\n*** 1994 ***\nApril: OneHalf is a DOS-based polymorphic computer virus.\nSeptember: ReBoot first airs, containing another memorable fictional, sentient computer virus, Megabyte.\n\n\n*** 1995 ***\nThe first Macro virus, called \"Concept\", is created. It attacked Microsoft Word documents.\n\n\n*** 1996 ***\n\"Ply\" \u2013 DOS 16-bit based complicated polymorphic virus appeared with a built-in permutation engine.\nBoza, the first virus designed specifically for Windows 95 files arrives.\nLaroux, the first Excel macro virus appears.\nStaog, the first Linux virus attacks Linux machines\n\n\n*** 1998 ***\nJune 2: The first version of the CIH virus appears. It is the first known virus able to erase flash ROM BIOS content.\n\n\n*** 1999 ***\nJanuary 20: The Happy99 worm first appeared. It invisibly attaches itself to emails, displays fireworks to hide the changes being made, and wishes the user a happy New Year. It modifies system files related to Outlook Express and Internet Explorer (IE) on Windows 95 and Windows 98.\nMarch 26: The Melissa worm was released, targeting Microsoft Word and Outlook-based systems, and creating considerable network traffic.\nJune 6: The ExploreZip worm, which destroys Microsoft Office documents, was first detected.\nSeptember: the CTX virus is isolated\nDecember 30: The Kak worm is a JavaScript computer worm that spread itself by exploiting a bug in Outlook Express.\n\n== 2000s ==\n\n\n*** 2000 ***\nMay 5: The ILOVEYOU worm (also known as the Love Letter, VBS, or Love Bug worm), a computer worm written in VBScript and using social engineering techniques, infected millions of Windows computers worldwide within a few hours of its release.\nJune 28: The Pikachu virus is believed to be the first computer virus geared at children. It contains the character \"Pikachu\" from the Pok\u00e9mon series. The operating systems affected by this worm are Windows 95, Windows 98, and Windows ME.\n\n\n*** 2001 ***\nFebruary 11: The Anna Kournikova virus hits e-mail servers hard by sending e-mail to contacts in the Microsoft Outlook addressbook. Its creator, Jan de Wit, was sentenced to 150 hours of community service.\nMarch 13: Magistr, also called Disembowler, is discovered. It is a complex email worm for Windows systems with multiple payloads that trigger months apart from each other. It targets members of the Law profession by searching the files on a user's computer for various keywords relating to court proceedings, activating if such are found.\nMay 8: The Sadmind worm spreads by exploiting holes in both Sun Solaris and Microsoft IIS.\nJuly: The Sircam worm is released, spreading through Microsoft systems via e-mail and unprotected network shares.\nJuly 13: The Code Red worm attacking the Index Server ISAPI Extension in Microsoft Internet Information Services is released.\nAugust 4: A complete re-write of the Code Red worm, Code Red II begins aggressively spreading onto Microsoft systems, primarily in China.\nSeptember 18: The Nimda worm is discovered and spreads through a variety of means including vulnerabilities in Microsoft Windows and backdoors left by Code Red II and Sadmind worm.\nOctober 26: The Klez worm is first identified. It exploits a vulnerability in Microsoft Internet Explorer and Microsoft Outlook and Outlook Express.\n\n\n*** 2002 ***\nFebruary 11: The Simile virus is a metamorphic computer virus written in assembly.\nBeast is a Windows-based backdoor Trojan horse, more commonly known as a RAT (Remote Administration Tool). It is capable of infecting almost all versions of Windows. Written in Delphi and released first by its author Tataye in 2002, its most current version was released on October 3, 2004.\nMarch 7: Mylife is a computer worm that spread itself by sending malicious emails to all the contacts in Microsoft Outlook.\n\n\n*** 2003 ***\nJanuary 24: The SQL Slammer worm, aka Sapphire worm, Helkern and other names, attacks vulnerabilities in Microsoft SQL Server and MSDE becomes the fastest spreading worm of all time (measured by doubling time at the peak rate of growth), causing massive Internet access disruptions worldwide just fifteen minutes after infecting its first victim.\nApril 2: Graybird is a trojan horse also known as Backdoor.Graybird.\nJune 13: ProRat is a Turkish-made Microsoft Windows based backdoor trojan horse, more commonly known as a RAT (Remote Administration Tool).\nAugust 12: The Blaster worm, aka the Lovesan worm, rapidly spreads by exploiting a vulnerability in system services present on Windows computers.\nAugust 18: The Welchia (Nachi) worm is discovered. The worm tries to remove the Blaster worm and patch Windows.\nAugust 19: The Sobig worm (technically the Sobig.F worm) spreads rapidly through Microsoft systems via mail and network shares.\nSeptember 18: Swen is a computer worm written in C++.\nOctober 24: The Sober worm is first seen on Microsoft systems and maintains its presence until 2005 with many new variants. The simultaneous attacks on network weak points by the Blaster and Sobig worms cause massive damage.\nNovember 10: Agobot is a computer worm that can spread itself by exploiting vulnerabilities on Microsoft Windows. Some of the vulnerabilities are MS03-026 and MS05-039.\nNovember 20: Bolgimo is a computer worm that spread itself by exploiting a buffer overflow vulnerability at Microsoft Windows DCOM RPC Interface.\n\n\n*** 2004 ***\nJanuary 18: Bagle is a mass-mailing worm affecting all versions of Microsoft Windows. There were 2 variants of Bagle worm, Bagle.A and Bagle.B. Bagle.B was discovered on February 17, 2004.\nJanuary 26: The MyDoom worm emerges, and currently holds the record for the fastest-spreading mass mailer worm. The worm was most notable for performing a distributed denial-of-service (DDoS) attack on www.sco.com, which belonged to The SCO Group.\nFebruary 16: The Netsky worm is discovered. The worm spreads by email and by copying itself to folders on the local hard drive as well as on mapped network drives if available. Many variants of the Netsky worm appeared.\nMarch 19: The Witty worm is a record-breaking worm in many regards. It exploited holes in several Internet Security Systems (ISS) products. It was the fastest computer issue to be categorized as a worm, and it was the first internet worm to carry a destructive payload. It spread rapidly using a pre-populated list of ground-zero hosts.\nMay 1: The Sasser worm emerges by exploiting a vulnerability in the Microsoft Windows LSASS service and causes problems in networks, while removing MyDoom and Bagle variants, even interrupting business.\nJune 15: Caribe or Cabir is a computer worm that is designed to infect mobile phones that run Symbian OS. It is the first computer worm that can infect mobile phones. It spread itself through Bluetooth. More information can be found on F-Secure and Symantec.\nAugust 16: Nuclear RAT (short for Nuclear Remote Administration Tool) is a backdoor trojan that infects Windows NT family systems (Windows 2000, Windows XP, Windows 2003).\nAugust 20: Vundo, or the Vundo Trojan (also known as Virtumonde or Virtumondo and sometimes referred to as MS Juan) is a trojan known to cause popups and advertising for rogue antispyware programs, and sporadically other misbehavior including performance degradation and denial of service with some websites including Google and Facebook.\nOctober 12: Bifrost, also known as Bifrose, is a backdoor trojan which can infect Windows 95 through Vista. Bifrost uses the typical server, server builder, and client backdoor program configuration to allow a remote attack.\nDecember: Santy, the first known \"webworm\" is launched. It exploited a vulnerability in phpBB and used Google to find new targets. It infected around 40000 sites before Google filtered the search query used by the worm, preventing it from spreading.\n\n\n*** 2005 ***\nAugust 2005: Zotob is a computer worm which exploits security vulnerabilities in Microsoft operating systems like Windows 2000, including the MS05-039 plug-and-play vulnerability. This worm has been known to spread on Microsoft-ds or TCP port 445.\nOctober 2005: The copy protection rootkit deliberately and surreptitiously included on music CDs sold by Sony BMG is exposed.  The rootkit creates vulnerabilities on affected computers, making them susceptible to infection by worms and viruses.\nLate 2005: The Zlob Trojan, is a Trojan horse program that masquerades as a required video codec in the form of the Microsoft Windows ActiveX component. It was first detected in late 2005.\n\n\n*** 2006 ***\nJanuary 20: The Nyxem worm was discovered. It spread by mass-mailing. Its payload, which activates on the third of every month, starting on February 3, attempts to disable security-related and file-sharing software, and destroy files of certain types, such as Microsoft Office files.\nFebruary 16: Discovery of the first-ever malware for Mac OS X, a low-threat trojan-horse known as OSX/Leap-A or OSX/Oompa-A, is announced.\nLate March: Brontok variant N was found in late March. Brontok was a mass-email worm and the origin for the worm was from Indonesia.\nJune: Starbucks is a virus that infects StarOffice and OpenOffice.\nLate September: Stration or Warezov worm first discovered.\nDevelopment of Stuxnet is presumed to have been started between 2005 and 2006.\n\n\n*** 2007 ***\nJanuary 17: Storm Worm identified as a fast-spreading email spamming threat to Microsoft systems. It begins gathering infected computers into the Storm botnet. By around June 30, it had infected 1.7 million computers, and it had compromised between 1 and 10 million computers by September. Thought to have originated from Russia, it disguises itself as a news email containing a film about bogus news stories asking you to download the attachment which it claims is a film.\nJuly: Zeus is a trojan that targets Microsoft Windows to steal banking information by keystroke logging.\n\n\n*** 2008 ***\nFebruary 17: Mocmex is a trojan, which was found in a digital photo frame in February 2008. It was the first serious computer virus on a digital photo frame. The virus was traced back to a group in China.\nMarch 3: Torpig, also known as Sinowal and Mebroot, is a Trojan horse that affects Windows, turning off anti-virus applications. It allows others to access the computer, modifies data, steals confidential information (such as user passwords and other sensitive data) and installs more malware on the victim's computer.\nMay 6: Rustock.C, a hitherto-rumored spambot-type malware with advanced rootkit capabilities, was announced to have been detected on Microsoft systems and analyzed, having been in the wild and undetected since October 2007 at the very least.\nJuly 6: Bohmini.A is a configurable remote access tool or trojan that exploits security flaws in Adobe Flash 9.0.115 with Internet Explorer 7.0 and Firefox 2.0 under Windows XP SP2.\nJuly 31: The Koobface computer worm targets users of Facebook and Myspace. New variants constantly appear.\nNovember 21: Computer worm Conficker infects anywhere from 9 to 15 million Microsoft server systems running everything from Windows 2000 to the Windows 7 Beta. The French Navy, UK Ministry of Defence (including Royal Navy warships and submarines), Sheffield Hospital network, German Bundeswehr and Norwegian Police were all affected. Microsoft sets a bounty of US$250,000 for information leading to the capture of the worm's author(s). Five main variants of the Conficker worm are known and have been dubbed Conficker A, B, C, D and E. They were discovered 21 November 2008, 29 December 2008, 20 February 2009, 4 March 2009 and 7 April 2009, respectively. On December 16, 2008, Microsoft releases KB958644 patching the server service vulnerability responsible for the spread of Conficker.\n\n\n*** 2009 ***\nJuly 4: The July 2009 cyber attacks occur and the emergence of the W32.Dozer attack the United States and South Korea.\nJuly 15: Symantec discovered Daprosy Worm, a trojan worm is intended to steal online-game passwords in internet cafes. It could intercept all keystrokes and send them to its author, making it potentially a very dangerous worm to infect B2B (business-to-business) systems.\nAugust 24: Source code for MegaPanzer is released by its author under GPLv3. and appears to have been apparently detected in the wild.\nNovember 27: The virus Kenzero is a virus that spreads online from peer-to-peer networks (P2P) taking browsing history.\n\n== 2010s ==\n\n\n*** 2010 ***\nJanuary: The Waledac botnet sent spam emails. In February 2010, an international group of security researchers and Microsoft took Waledac down.\nJanuary: The Psyb0t worm is discovered.  It is thought to be unique in that it can infect routers and high-speed modems.\nFebruary 18: Microsoft announced that a BSoD problem on some Windows machines which was triggered by a batch of Patch Tuesday updates was caused by the Alureon Trojan.\nJune 17: Stuxnet, a Windows Trojan, was detected. It is the first worm to attack SCADA systems. There are suggestions that it was designed to target Iranian nuclear facilities. It uses a valid certificate from Realtek.\nSeptember 9: The virus, called \"here you have\" or \"VBMania\", is a simple Trojan horse that arrives in the inbox with the odd-but-suggestive subject line \"here you have\". The body reads \"This is The Document I told you about, you can find it Here\" or \"This is The Free Download Sex Movies, you can find it Here\".\n\n\n*** 2011 ***\nSpyEye and Zeus merged code is seen. New variants attack mobile phone banking information.\nAnti-Spyware 2011, a Trojan horse that attacks Windows 9x, 2000, XP, Vista, and Windows 7, posing as an anti-spyware program. It disables security-related processes of anti-virus programs, while also blocking access to the Internet, which prevents updates.\nSummer 2011: The Morto worm attempts to propagate itself to additional computers via the Microsoft Windows Remote Desktop Protocol (RDP). Morto spreads by forcing infected systems to scan for Windows servers allowing RDP login. Once Morto finds an RDP-accessible system, it attempts to log into a domain or local system account named 'Administrator' using several common passwords.  A detailed overview of how the worm works \u2013 along with the password dictionary Morto uses \u2013 was done by Imperva.\nJuly 13: the ZeroAccess rootkit (also known as Sirefef or max++) was discovered.\nSeptember 1: Duqu is a worm thought to be related to the Stuxnet worm. The Laboratory of Cryptography and System Security (CrySyS Lab) of the Budapest University of Technology and Economics in Hungary discovered the threat, analysed the malware, and wrote a 60-page report naming the threat Duqu. Duqu gets its name from the prefix \"~DQ\" it gives to the names of files it creates.\n\n\n*** 2012 ***\nMay: Flame \u2013 also known as Flamer, sKyWIper, and Skywiper \u2013  a modular computer malware that attacks computers running Microsoft Windows. Used for targeted cyber espionage in Middle Eastern countries. Its discovery was announced on 28 May 2012 by MAHER Center of Iranian National Computer Emergency Response Team (CERT), Kaspersky Lab and CrySyS Lab of the Budapest University of Technology and Economics. CrySyS stated in their report that \"sKyWIper is certainly the most sophisticated malware we encountered during our practice; arguably, it is the most complex malware ever found\".\nAugust 16: Shamoon is a computer virus designed to target computers running Microsoft Windows in the energy sector. Symantec, Kaspersky Lab, and Seculert announced its discovery on August 16, 2012.\nSeptember 20: NGRBot is a worm that uses the IRC network for file transfer, sending and receiving commands between zombie network machines and the attacker's IRC server, and monitoring and controlling network connectivity and intercept. It employs a user-mode rootkit technique to hide and steal its victim's information. This family of bot is also designed to infect HTML pages with inline frames (iframes), causing redirections, blocking victims from getting updates from security/antimalware products, and killing those services. The bot is designed to connect via a predefined IRC channel and communicate with a remote botnet.\n\n\n*** 2013 ***\nSeptember: The CryptoLocker Trojan horse is discovered. CryptoLocker encrypts the files on a user's hard drive, then prompts them to pay a ransom to the developer to receive the decryption key. In the following months, several copycat ransomware Trojans were also discovered.\nDecember: The Gameover ZeuS Trojan is discovered. This type of virus steals one's login details on popular Web sites that involve monetary transactions. It works by detecting a login page, then proceeds to inject malicious code into the page, keystroke logging the computer user's details.\nDecember: Linux.Darlloz targets the Internet of things and infects routers, security cameras, set-top boxes by exploiting a PHP vulnerability.\n\n\n*** 2014 ***\nNovember: The Regin Trojan horse is discovered. Regin is a dropper, primarily spread via spoofed Web pages. Once installed, it quietly downloads additional malware, making it difficult for signature-based anti-virus programs to detect. It is believed to have been created by the United States and United Kingdom as a tool for espionage and mass surveillance.\n\n\n*** 2015 ***\nThe BASHLITE malware is leaked leading to a massive spike in DDoS attacks.\nLinux.Wifatch is revealed to the general public. It is found to attempt to secure devices from other more malicious malware.\n\n\n*** 2016 ***\nJanuary: A trojan named \"MEMZ\" is created. The creator, Leurak, explained that the trojan was intended merely as a joke. The trojan alerts the user to the fact that it is a trojan and warns them that if they proceed, the computer may no longer be usable. It contains complex payloads that corrupt the system, displaying artifacts on the screen as it runs. Once run, the application cannot be closed without causing further damage to the computer, which will stop functioning properly regardless. When the computer is restarted, in place of the bootsplash is a message that reads \"Your computer has been trashed by the MEMZ Trojan. Now enjoy the Nyan cat\u2026\", which follows with an animation of the Nyan Cat.\nFebruary: Ransomware Locky with its over 60 derivatives spread throughout Europe and infected several million computers. At the height of the spread over five thousand computers per hour were infected in Germany alone. Although ransomware was not a new thing at the time, insufficient cyber security as well as a lack of standards in IT was responsible for the high number of infections. Unfortunately, even up to date antivirus and internet security software was unable to protect systems from early versions of Locky.\nFebruary: Tiny Banker Trojan (Tinba) makes headlines. Since its discovery, it has been found to have infected more than two dozen major banking institutions in the United States, including TD Bank, Chase, HSBC, Wells Fargo, PNC and Bank of America. Tiny Banker Trojan uses HTTP injection to force the user's computer to believe that it is on the bank's website. This spoof page will look and function just as the real one. The user then enters their information to log on, at which point Tinba can launch the bank webpage's \"incorrect login information\" return, and redirect the user to the real website. This is to trick the user into thinking they had entered the wrong information and proceed as normal, although now Tinba has captured the credentials and sent them to its host.\nAugust: Journalists and researchers report the discovery of spyware, called Pegasus, developed and distributed by a private company which can and has been used to infect iOS and Android smartphones often \u2013 based on 0-day exploits \u2013 without the need for any user-interaction or significant clues to the user and then be used to exfiltrate data, track user locations, capture film through its camera, and activate the microphone at any time. The investigation suggests it was used on many targets worldwide and revealed its use for e.g. governments' espionage on journalists, opposition politicians, activists, business people and others.\nSeptember: Mirai creates headlines by launching some of the most powerful and disruptive DDoS attacks seen to date by infecting the Internet of Things. Mirai ends up being used in the DDoS attack on 20 September 2016 on the Krebs on Security site which reached 620 Gbit/s. Ars Technica also reported a 1 Tbit/s attack on French web host OVH. On 21 October 2016 multiple major DDoS attacks in DNS services of DNS service provider Dyn occurred using Mirai malware installed on a large number of IoT devices, resulting in the inaccessibility of several high-profile websites such as GitHub, Twitter, Reddit, Netflix, Airbnb and many others. The attribution of the attack to the Mirai botnet was originally reported by BackConnect Inc., a security firm.\n\n\n*** 2017 ***\nMay: The WannaCry ransomware attack spreads globally. Exploits revealed in the NSA hacking toolkit leak of late 2016 were used to enable the propagation of the malware. Shortly after the news of the infections broke online, a UK cybersecurity researcher in collaboration with others found and activated a \"kill switch\" hidden within the ransomware, effectively halting the initial wave of its global propagation. The next day, researchers announced that they had found new variants of the malware without the kill switch.\nJune: The Petya (malware) attack spreads globally affecting Windows systems. Researchers at Symantec reveal that this ransomware uses the EternalBlue exploit, similar to the one used in the WannaCry ransomware attack.\nSeptember: The Xafecopy Trojan attacks 47 countries, affecting only Android operating systems. Kaspersky Lab identified it as a malware from the Ubsod family, stealing money through click based WAP billing systems.\nSeptember: A new variety of Remote Access Trojan (RAT), Kedi RAT, is distributed in a Spear Phishing Campaign. The attack targeted Citrix users. The Trojan was able to evade usual system scanners. Kedi Trojan had all the characteristics of a common Remote Access Trojan and it could communicate to its Command and Control center via Gmail using common HTML, HTTP protocols.\n\n\n*** 2018 ***\nFebruary: Thanatos, a ransomware, becomes the first ransomware program to accept ransom payment in Bitcoin Cash.\n\n\n*** 2019 ***\nNovember: Titanium is an advanced backdoor malware, developed by the PLATINUM APT."
    }
  },
  {
    "instruction": "context: Stuxnet infects project files belonging to Siemens' WinCC/PCS 7 SCADA control software by subverting the Step-7 software application that is used to reprogram these devices and intercepting communications between the WinCC software running under Windows and the target Siemens PLC devices.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does Stuxnet infect project files belonging to Siemens' WinCC/PCS 7 SCADA control software?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Stuxnet infect project files belonging to Siemens' WinCC/PCS 7 SCADA control software?",
      "answer": "Stuxnet infects project files belonging to Siemens' WinCC/PCS 7 SCADA control software by subverting the Step-7 software application that is used to reprogram these devices and intercepting communications between the WinCC software running under Windows and the target Siemens PLC devices."
    }
  },
  {
    "instruction": "Proxy server\n\n==Introduction==\nIn computer networking, a proxy server is a server application that acts as an intermediary between a client requesting a resource and the server providing that resource.Instead of connecting directly to a server that can fulfill a request for a resource, such as a file or web page, the client directs the request to the proxy server, which evaluates the request and performs the required network transactions. This serves as a method to simplify or control the complexity of the request, or provide additional benefits such as load balancing, privacy, or security. Proxies were devised to add structure and encapsulation to distributed systems. A proxy server thus functions on behalf of the client when requesting service, potentially masking the true origin of the request to the resource server.\n\n\n\n== Types ==\nA proxy server may reside on the user's local computer, or at any point between the user's computer and destination servers on the Internet. A proxy server that passes unmodified requests and responses is usually called a gateway or sometimes a tunneling proxy. A forward proxy is an Internet-facing proxy used to retrieve data from a wide range of sources (in most cases anywhere on the Internet). A reverse proxy is usually an internal-facing proxy used as a front-end to control and protect access to a server on a private network. A reverse proxy commonly also performs tasks such as load-balancing, authentication, decryption and caching.\n\n\n*** Open proxies ***\n\nAn open proxy is a forwarding proxy server that is accessible by any Internet user. In 2008, network security expert Gordon Lyon estimated that \"hundreds of thousands\" of open proxies are operated on the Internet.\nAnonymous proxy \u2013 This server reveals its identity as a proxy server but does not disclose the originating IP address of the client. Although this type of server can be discovered easily, it can be beneficial for some users as it hides the originating IP address.\nTransparent proxy \u2013 This server not only identifies itself as a proxy server but with the support of HTTP header fields such as X-Forwarded-For, the originating IP address can be retrieved as well. The main benefit of using this type of server is its ability to cache a website for faster retrieval.\n\n\n*** Reverse proxies ***\n\nA reverse proxy (or surrogate) is a proxy server that appears to clients to be an ordinary server. Reverse proxies forward requests to one or more ordinary servers that handle the request. The response from the proxy server is returned as if it came directly from the original server, leaving the client with no knowledge of the original server. Reverse proxies are installed in the neighborhood of one or more web servers. All traffic coming from the Internet and with a destination of one of the neighborhood's web servers goes through the proxy server. The use of reverse originates in its counterpart forward proxy since the reverse proxy sits closer to the web server and serves only a restricted set of websites. There are several reasons for installing reverse proxy servers:\n\nEncryption/SSL acceleration: when secure websites are created, the Secure Sockets Layer (SSL) encryption is often not done by the web server itself, but by a reverse proxy that is equipped with SSL acceleration hardware. Furthermore, a host can provide a single \"SSL proxy\" to provide SSL encryption for an arbitrary number of hosts, removing the need for a separate SSL server certificate for each host, with the downside that all hosts behind the SSL proxy have to share a common DNS name or IP address for SSL connections. This problem can partly be overcome by using the SubjectAltName feature of X.509 certificates or the SNI extension of TLS.\nLoad balancing: the reverse proxy can distribute the load to several web servers, each web server serving its own application area. In such a case, the reverse proxy may need to rewrite the URLs in each web page (translation from externally known URLs to the internal locations).\nServe/cache static content: A reverse proxy can offload the web servers by caching static content like pictures and other static graphical content.\nCompression: the proxy server can optimize and compress the content to speed up the load time.\nSpoon feeding: reduces resource usage caused by slow clients on the web servers by caching the content the web server sent and slowly \"spoon feeding\" it to the client. This especially benefits dynamically generated pages.\nSecurity: the proxy server is an additional layer of defense and can protect against some OS and web-server-specific attacks. However, it does not provide any protection from attacks against the web application or service itself, which is generally considered the larger threat.\nExtranet publishing: a reverse proxy server facing the Internet can be used to communicate to a firewall server internal to an organization, providing extranet access to some functions while keeping the servers behind the firewalls. If used in this way, security measures should be considered to protect the rest of your infrastructure in case this server is compromised, as its web application is exposed to attack from the Internet.\n\n== Uses ==\n\n\n*** Monitoring and filtering ***\n\n\n**** Content-control software ****\n\nA content-filtering web proxy server provides administrative control over the content that may be relayed in one or both directions through the proxy. It is commonly used in both commercial and non-commercial organizations (especially schools) to ensure that Internet usage conforms to acceptable use policy.\nContent filtering proxy servers will often support user authentication to control web access. It also usually produces logs, either to give detailed information about the URLs accessed by specific users or to monitor bandwidth usage statistics. It may also communicate to daemon-based and/or ICAP-based antivirus software to provide security against viruses and other malware by scanning incoming content in real-time before it enters the network.\nMany workplaces, schools, and colleges restrict web sites and online services that are accessible and available in their buildings. Governments also censor undesirable content. This is done either with a specialized proxy, called a content filter (both commercial and free products are available), or by using a cache-extension protocol such as ICAP, that allows plug-in extensions to an open caching architecture.\nWebsites commonly used by students to circumvent filters and access blocked content often include a proxy, from which the user can then access the websites that the filter is trying to block.\nRequests may be filtered by several methods, such as a URL or DNS blacklists, URL regex filtering, MIME filtering, or content keyword filtering. Blacklists are often provided and maintained by web-filtering companies, often grouped into categories (pornography, gambling, shopping, social networks, etc..).\nAssuming the requested URL is acceptable, the content is then fetched by the proxy. At this point, a dynamic filter may be applied on the return path. For example, JPEG files could be blocked based on fleshtone matches, or language filters could dynamically detect unwanted language. If the content is rejected then an HTTP fetch error may be returned to the requester.\nMost web filtering companies use an internet-wide crawling robot that assesses the likelihood that content is a certain type. The resultant database is then corrected by manual labor based on complaints or known flaws in the content-matching algorithms.\nSome proxies scan outbound content, e.g., for data loss prevention; or scan content for malicious software.\n\n\n**** Filtering of encrypted data ****\nWeb filtering proxies are not able to peer inside secure sockets HTTP transactions, assuming the chain-of-trust of SSL/TLS (Transport Layer Security) has not been tampered with. The SSL/TLS chain-of-trust relies on trusted root certificate authorities.\nIn a workplace setting where the client is managed by the organization, devices may be configured to trust a root certificate whose private key is known to the proxy. In such situations, proxy analysis of the contents of an SSL/TLS transaction becomes possible. The proxy is effectively operating a man-in-the-middle attack, allowed by the client's trust of a root certificate the proxy owns.\n\n\n**** Bypassing filters and censorship ****\nIf the destination server filters content based on the origin of the request, the use of a proxy can circumvent this filter. For example, a server using IP-based geolocation to restrict its service to a certain country can be accessed using a proxy located in that country to access the service.:\u200a3\u200aWeb proxies are the most common means of bypassing government censorship, although no more than 3% of Internet users use any circumvention tools.:\u200a7\u200aSome proxy service providers allow businesses access to their proxy network for rerouting traffic for business intelligence purposes.In some cases, users can circumvent proxies which filter using blacklists using services designed to proxy information from a non-blacklisted location.\n\n\n**** Logging and eavesdropping ****\nProxies can be installed in order to eavesdrop upon the data-flow between client machines and the web. All content sent or accessed \u2013 including passwords submitted and cookies used \u2013 can be captured and analyzed by the proxy operator. For this reason, passwords to online services (such as webmail and banking) should always be exchanged over a cryptographically secured connection, such as SSL.\nBy chaining the proxies which do not reveal data about the original requester, it is possible to obfuscate activities from the eyes of the user's destination. However, more traces will be left on the intermediate hops, which could be used or offered up to trace the user's activities. If the policies and administrators of these other proxies are unknown, the user may fall victim to a false sense of security just because those details are out of sight and mind.\nIn what is more of an inconvenience than a risk, proxy users may find themselves being blocked from certain Web sites, as numerous forums and Web sites block IP addresses from proxies known to have spammed or trolled the site. Proxy bouncing can be used to maintain privacy.\n\n\n*** Improving performance ***\nA caching proxy server accelerates service requests by retrieving the content saved from a previous request made by the same client or even other clients. Caching proxies keep local copies of frequently requested resources, allowing large organizations to significantly reduce their upstream bandwidth usage and costs, while significantly increasing performance. Most ISPs and large businesses have a caching proxy. Caching proxies were the first kind of proxy server. Web proxies are commonly used to cache web pages from a web server. Poorly implemented caching proxies can cause problems, such as an inability to use user authentication.A proxy that is designed to mitigate specific link related issues or degradation is a Performance Enhancing Proxy (PEPs). These are typically used to improve TCP performance in the presence of high round-trip times or high packet loss (such as wireless or mobile phone networks); or highly asymmetric links featuring very different upload and download rates. PEPs can make more efficient use of the network, for example, by merging TCP ACKs (acknowledgements) or compressing data sent at the application layer.\n\n\n*** Translation ***\nA translation proxy is a proxy server that is used to localize a website experience for different markets. Traffic from the global audience is routed through the translation proxy to the source website. As visitors browse the proxied site, requests go back to the source site where pages are rendered. The original language content in the response is replaced by the translated content as it passes back through the proxy. The translations used in a translation proxy can be either machine translation, human translation, or a combination of machine and human translation. Different translation proxy implementations have different capabilities. Some allow further customization of the source site for the local audiences such as excluding the source content or substituting the source content with the original local content.\n\n\n*** Accessing services anonymously ***\n\nAn anonymous proxy server (sometimes called a web proxy) generally attempts to anonymize web surfing.  Anonymizers may be differentiated into several varieties. The destination server (the server that ultimately satisfies the web request) receives requests from the anonymizing proxy server and thus does not receive information about the end user's address. The requests are not anonymous to the anonymizing proxy server, however, and so a degree of trust is present between the proxy server and the user. Many proxy servers are funded through a continued advertising link to the user.\nAccess control: Some proxy servers implement a logon requirement. In large organizations, authorized users must log on to gain access to the web. The organization can thereby track usage to individuals. Some anonymizing proxy servers may forward data packets with header lines such as HTTP_VIA, HTTP_X_FORWARDED_FOR, or HTTP_FORWARDED, which may reveal the IP address of the client. Other anonymizing proxy servers, known as elite or high-anonymity proxies, make it appear that the proxy server is the client. A website could still suspect a proxy is being used if the client sends packets that include a cookie from a previous visit that did not use the high-anonymity proxy server. Clearing cookies, and possibly the cache, would solve this problem.\n\n\n**** QA geotargeted advertising ****\nAdvertisers use proxy servers for validating, checking and quality assurance of geotargeted ads. A geotargeting ad server checks the request source IP address and uses a geo-IP database to determine the geographic source of requests. Using a proxy server that is physically located inside a specific country or a city gives advertisers the ability to test geotargeted ads.\n\n\n*** Security ***\nA proxy can keep the internal network structure of a company secret by using network address translation, which can help the security of the internal network. This makes requests from machines and users on the local network anonymous. Proxies can also be combined with firewalls.\nAn incorrectly configured proxy can provide access to a network otherwise isolated from the Internet.\n\n\n**** Cross-domain resources ****\nProxies allow web sites to make web requests to externally hosted resources (e.g. images, music files, etc.) when cross-domain restrictions prohibit the web site from linking directly to the outside domains. Proxies also allow the browser to make web requests to externally hosted content on behalf of a website when cross-domain restrictions (in place to protect websites from the likes of data theft) prohibit the browser from directly accessing the outside domains.\n\n\n*** Malicious usages ***\n\n\n**** Secondary market brokers ****\nSecondary market brokers use web proxy servers to circumvent restrictions on online purchase of limited products such as limited sneakers or tickets.\n\n== Implementations of proxies ==\n\n\n*** Web proxy servers ***\nWeb proxies forward HTTP requests. The request from the client is the same as a regular HTTP request except the full URL is passed, instead of just the path.\n\nThis request is sent to the proxy server, the proxy makes the request specified and returns the response.\n\nSome web proxies allow the HTTP CONNECT method to set up forwarding of arbitrary data through the connection; a common policy is to only forward port 443 to allow HTTPS traffic.\nExamples of web proxy servers include Apache (with mod_proxy or Traffic Server), HAProxy, IIS configured as proxy (e.g., with Application Request Routing), Nginx, Privoxy, Squid, Varnish (reverse proxy only), WinGate, Ziproxy, Tinyproxy, RabbIT and Polipo.\nFor clients, the problem of complex or multiple proxy-servers is solved by a client-server Proxy auto-config protocol (PAC file).\n\n\n*** SOCKS proxy ***\nSOCKS also forwards arbitrary data after a connection phase, and is similar to HTTP CONNECT in web proxies.\n\n\n*** Transparent proxy ***\nAlso known as an intercepting proxy, inline proxy, or forced proxy, a transparent proxy intercepts normal application layer communication without requiring any special client configuration. Clients need not be aware of the existence of the proxy. A transparent proxy is normally located between the client and the Internet, with the proxy performing some of the functions of a gateway or router.RFC 2616 (Hypertext Transfer Protocol\u2014HTTP/1.1) offers standard definitions:\n\"A 'transparent proxy' is a proxy that does not modify the request or response beyond what is required for proxy authentication and identification\". \"A 'non-transparent proxy' is a proxy that modifies the request or response in order to provide some added service to the user agent, such as group annotation services, media type transformation, protocol reduction, or anonymity filtering\".\nTCP Intercept is a traffic filtering security feature that protects TCP servers from TCP SYN flood attacks, which are a type of denial-of-service attack. TCP Intercept is available for IP traffic only.\nIn 2009 a security flaw in the way that transparent proxies operate was published by Robert Auger, and the Computer Emergency Response Team issued an advisory listing dozens of affected transparent and intercepting proxy servers.\n\n\n**** Purpose ****\nIntercepting proxies are commonly used in businesses to enforce acceptable use policy, and to ease administrative overheads since no client browser configuration is required. This second reason however is mitigated by features such as Active Directory group policy, or DHCP and automatic proxy detection.\nIntercepting proxies are also commonly used by ISPs in some countries to save upstream bandwidth and improve customer response times by caching. This is more common in countries where bandwidth is more limited (e.g. island nations) or must be paid for.\n\n\n**** Issues ****\nThe diversion/interception of a TCP connection creates several issues. First, the original destination IP and port must somehow be communicated to the proxy. This is not always possible (e.g., where the gateway and proxy reside on different hosts). There is a class of cross-site attacks that depend on certain behavior of intercepting proxies that do not check or have access to information about the original (intercepted) destination. This problem may be resolved by using an integrated packet-level and application level appliance or software which is then able to communicate this information between the packet handler and the proxy.\nIntercepting also creates problems for HTTP authentication, especially connection-oriented authentication such as NTLM, as the client browser believes it is talking to a server rather than a proxy. This can cause problems where an intercepting proxy requires authentication, then the user connects to a site that also requires authentication.\nFinally, intercepting connections can cause problems for HTTP caches, as some requests and responses become uncacheable by a shared cache.\n\n\n**** Implementation methods ****\nIn integrated firewall/proxy servers where the router/firewall is on the same host as the proxy, communicating original destination information can be done by any method, for example Microsoft TMG or WinGate.\nInterception can also be performed using Cisco's WCCP (Web Cache Control Protocol). This proprietary protocol resides on the router and is configured from the cache, allowing the cache to determine what ports and traffic is sent to it via transparent redirection from the router. This redirection can occur in one of two ways: GRE tunneling (OSI Layer 3) or MAC rewrites (OSI Layer 2).\nOnce traffic reaches the proxy machine itself interception is commonly performed with NAT (Network Address Translation). Such setups are invisible to the client browser, but leave the proxy visible to the web server and other devices on the internet side of the proxy. Recent Linux and some BSD releases provide TPROXY (transparent proxy) which performs IP-level (OSI Layer 3) transparent interception and spoofing of outbound traffic, hiding the proxy IP address from other network devices.\n\n\n**** Detection ****\nSeveral methods may be used to detect the presence of an intercepting proxy server:\n\nBy comparing the client's external IP address to the address seen by an external web server, or sometimes by examining the HTTP headers received by a server. A number of sites have been created to address this issue, by reporting the user's IP address as seen by the site back to the user on a web page. Google also returns the IP address as seen by the page if the user searches for \"IP\".\nBy comparing the result of online IP checkers when accessed using HTTPS vs HTTP, as most intercepting proxies do not intercept SSL. If there is suspicion of SSL being intercepted, one can examine the certificate associated with any secure web site, the root certificate should indicate whether it was issued for the purpose of intercepting.\nBy comparing the sequence of network hops reported by a tool such as traceroute for a proxied protocol such as HTTP (port 80) with that for a non-proxied protocol such as SMTP (port 25).\nBy attempting to make a connection to an IP address at which there is known to be no server. The proxy will accept the connection and then attempt to proxy it on. When the proxy finds no server to accept the connection it may return an error message or simply close the connection to the client. This difference in behavior is simple to detect. For example, most web browsers will generate a browser created error page in the case where they cannot connect to an HTTP server but will return a different error in the case where the connection is accepted and then closed.\nBy serving the end-user specially programmed Adobe Flash SWF applications or Sun Java applets that send HTTP calls back to their server.\n\n\n*** CGI proxy ***\nA CGI web proxy accepts target URLs using a Web form in the user's browser window, processes the request, and returns the results to the user's browser. Consequently, it can be used on a device or network that does not allow \"true\" proxy settings to be changed. The first recorded CGI proxy, named \"rover\" at the time but renamed in 1998 to \"CGIProxy\", was developed by American computer scientist James Marshall in early 1996 for an article in \"Unix Review\" by Rich Morin.The majority of CGI proxies are powered by one of CGIProxy (written in the Perl language), Glype (written in the PHP language), or PHProxy (written in the PHP language). As of April 2016, CGIProxy has received about 2 million downloads, Glype has received almost a million downloads, whilst PHProxy still receives hundreds of downloads per week. Despite waning in popularity due to VPNs and other privacy methods, as of September 2021 there are still a few hundred CGI proxies online.Some CGI proxies were set up for purposes such as making websites more accessible to disabled people, but have since been shut down due to excessive traffic, usually caused by a third party advertising the service as a means to bypass local filtering. Since many of these users don't care about the collateral damage they are causing, it became necessary for organizations to hide their proxies, disclosing the URLs only to those who take the trouble to contact the organization and demonstrate a genuine need.\n\n\n*** Suffix proxy ***\nA suffix proxy allows a user to access web content by appending the name of the proxy server to the URL of the requested content (e.g. \"en.wikipedia.org.SuffixProxy.com\"). Suffix proxy servers are easier to use than regular proxy servers but they do not offer high levels of anonymity and their primary use is for bypassing web filters. However, this is rarely used due to more advanced web filters.\n\n\n*** Tor onion proxy software ***\n\nTor is a system intended to provide online anonymity. Tor client software routes Internet traffic through a worldwide volunteer network of servers for concealing a user's computer location or usage from someone conducting network surveillance or traffic analysis. Using Tor makes tracing Internet activity more difficult, and is intended to protect users' personal freedom and their online privacy.\n\"Onion routing\" refers to the layered nature of the encryption service: The original data are encrypted and re-encrypted multiple times, then sent through successive Tor relays, each one of which decrypts a \"layer\" of encryption before passing the data on to the next relay and ultimately the destination. This reduces the possibility of the original data being unscrambled or understood in transit.\n\n\n*** I2P anonymous proxy ***\nThe I2P anonymous network ('I2P') is a proxy network aiming at online anonymity. It implements garlic routing, which is an enhancement of Tor's onion routing. I2P is fully distributed and works by encrypting all communications in various layers and relaying them through a network of routers run by volunteers in various locations. By keeping the source of the information hidden, I2P offers censorship resistance. The goals of I2P are to protect users' personal freedom, privacy, and ability to conduct confidential business.\nEach user of I2P runs an I2P router on their computer (node). The I2P router takes care of finding other peers and building anonymizing tunnels through them. I2P provides proxies for all protocols (HTTP, IRC, SOCKS, ...).\n\n\n*** Comparison to network address translators ***\nThe proxy concept refers to a layer 7 application in the OSI reference model. Network address translation (NAT) is similar to a proxy but operates in layer 3.\nIn the client configuration of layer-3 NAT, configuring the gateway is sufficient. However, for the client configuration of a layer 7 proxy, the destination of the packets that the client generates must always be the proxy server (layer 7), then the proxy server reads each packet and finds out the true destination.\nBecause NAT operates at layer-3, it is less resource-intensive than the layer-7 proxy, but also less flexible. As we compare these two technologies, we might encounter a terminology known as 'transparent firewall'. Transparent firewall means that the proxy uses the layer-7 proxy advantages without the knowledge of the client. The client presumes that the gateway is a NAT in layer 3, and it does not have any idea about the inside of the packet, but through this method, the layer-3 packets are sent to the layer-7 proxy for investigation.\n\n\n*** DNS proxy ***\nA DNS proxy server takes DNS queries from a (usually local) network and forwards them to an Internet Domain Name Server. It may also cache DNS records.\n\n\n*** Proxifiers ***\nSome client programs \"SOCKS-ify\" requests, which allows adaptation of any networked software to connect to external networks via certain types of proxy servers (mostly SOCKS).\n\n\n*** Residential proxy ***\nA residential proxy is an intermediary that uses a real IP address provided by an Internet Service Provider (ISP) with physical devices such as mobiles and computers of end-users. Instead of connecting directly to a server, residential proxy users connect to the target through residential IP addresses. The target then identifies them as organic internet users. It does not let any tracking tool identify the reallocation of the user. Any residential proxy can send any number of concurrent requests and IP addresses are directly related to a specific region. Unlike regular residential proxies, which hide user's real IP address behind another IP address, rotating residential proxies, also known as backconnect proxies, conceal user's real IP address behind a pool of proxies. These proxies switch between themselves with every session or at regular intervals.\nRead the text above and answer this question: How can cross-domain resources be accessed using a proxy server and what are some benefits of this approach?",
    "context": "",
    "output": "Cross-domain resources can be accessed using a proxy server by making web requests to externally hosted resources when cross-domain restrictions prohibit the web site from linking directly to the outside domains. This allows web sites to make web requests to externally hosted resources without violating cross-domain restrictions and potentially exposing sensitive information.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can cross-domain resources be accessed using a proxy server and what are some benefits of this approach?",
      "answer": "Cross-domain resources can be accessed using a proxy server by making web requests to externally hosted resources when cross-domain restrictions prohibit the web site from linking directly to the outside domains. This allows web sites to make web requests to externally hosted resources without violating cross-domain restrictions and potentially exposing sensitive information.",
      "context": "Proxy server\n\n==Introduction==\nIn computer networking, a proxy server is a server application that acts as an intermediary between a client requesting a resource and the server providing that resource.Instead of connecting directly to a server that can fulfill a request for a resource, such as a file or web page, the client directs the request to the proxy server, which evaluates the request and performs the required network transactions. This serves as a method to simplify or control the complexity of the request, or provide additional benefits such as load balancing, privacy, or security. Proxies were devised to add structure and encapsulation to distributed systems. A proxy server thus functions on behalf of the client when requesting service, potentially masking the true origin of the request to the resource server.\n\n\n\n== Types ==\nA proxy server may reside on the user's local computer, or at any point between the user's computer and destination servers on the Internet. A proxy server that passes unmodified requests and responses is usually called a gateway or sometimes a tunneling proxy. A forward proxy is an Internet-facing proxy used to retrieve data from a wide range of sources (in most cases anywhere on the Internet). A reverse proxy is usually an internal-facing proxy used as a front-end to control and protect access to a server on a private network. A reverse proxy commonly also performs tasks such as load-balancing, authentication, decryption and caching.\n\n\n*** Open proxies ***\n\nAn open proxy is a forwarding proxy server that is accessible by any Internet user. In 2008, network security expert Gordon Lyon estimated that \"hundreds of thousands\" of open proxies are operated on the Internet.\nAnonymous proxy \u2013 This server reveals its identity as a proxy server but does not disclose the originating IP address of the client. Although this type of server can be discovered easily, it can be beneficial for some users as it hides the originating IP address.\nTransparent proxy \u2013 This server not only identifies itself as a proxy server but with the support of HTTP header fields such as X-Forwarded-For, the originating IP address can be retrieved as well. The main benefit of using this type of server is its ability to cache a website for faster retrieval.\n\n\n*** Reverse proxies ***\n\nA reverse proxy (or surrogate) is a proxy server that appears to clients to be an ordinary server. Reverse proxies forward requests to one or more ordinary servers that handle the request. The response from the proxy server is returned as if it came directly from the original server, leaving the client with no knowledge of the original server. Reverse proxies are installed in the neighborhood of one or more web servers. All traffic coming from the Internet and with a destination of one of the neighborhood's web servers goes through the proxy server. The use of reverse originates in its counterpart forward proxy since the reverse proxy sits closer to the web server and serves only a restricted set of websites. There are several reasons for installing reverse proxy servers:\n\nEncryption/SSL acceleration: when secure websites are created, the Secure Sockets Layer (SSL) encryption is often not done by the web server itself, but by a reverse proxy that is equipped with SSL acceleration hardware. Furthermore, a host can provide a single \"SSL proxy\" to provide SSL encryption for an arbitrary number of hosts, removing the need for a separate SSL server certificate for each host, with the downside that all hosts behind the SSL proxy have to share a common DNS name or IP address for SSL connections. This problem can partly be overcome by using the SubjectAltName feature of X.509 certificates or the SNI extension of TLS.\nLoad balancing: the reverse proxy can distribute the load to several web servers, each web server serving its own application area. In such a case, the reverse proxy may need to rewrite the URLs in each web page (translation from externally known URLs to the internal locations).\nServe/cache static content: A reverse proxy can offload the web servers by caching static content like pictures and other static graphical content.\nCompression: the proxy server can optimize and compress the content to speed up the load time.\nSpoon feeding: reduces resource usage caused by slow clients on the web servers by caching the content the web server sent and slowly \"spoon feeding\" it to the client. This especially benefits dynamically generated pages.\nSecurity: the proxy server is an additional layer of defense and can protect against some OS and web-server-specific attacks. However, it does not provide any protection from attacks against the web application or service itself, which is generally considered the larger threat.\nExtranet publishing: a reverse proxy server facing the Internet can be used to communicate to a firewall server internal to an organization, providing extranet access to some functions while keeping the servers behind the firewalls. If used in this way, security measures should be considered to protect the rest of your infrastructure in case this server is compromised, as its web application is exposed to attack from the Internet.\n\n== Uses ==\n\n\n*** Monitoring and filtering ***\n\n\n**** Content-control software ****\n\nA content-filtering web proxy server provides administrative control over the content that may be relayed in one or both directions through the proxy. It is commonly used in both commercial and non-commercial organizations (especially schools) to ensure that Internet usage conforms to acceptable use policy.\nContent filtering proxy servers will often support user authentication to control web access. It also usually produces logs, either to give detailed information about the URLs accessed by specific users or to monitor bandwidth usage statistics. It may also communicate to daemon-based and/or ICAP-based antivirus software to provide security against viruses and other malware by scanning incoming content in real-time before it enters the network.\nMany workplaces, schools, and colleges restrict web sites and online services that are accessible and available in their buildings. Governments also censor undesirable content. This is done either with a specialized proxy, called a content filter (both commercial and free products are available), or by using a cache-extension protocol such as ICAP, that allows plug-in extensions to an open caching architecture.\nWebsites commonly used by students to circumvent filters and access blocked content often include a proxy, from which the user can then access the websites that the filter is trying to block.\nRequests may be filtered by several methods, such as a URL or DNS blacklists, URL regex filtering, MIME filtering, or content keyword filtering. Blacklists are often provided and maintained by web-filtering companies, often grouped into categories (pornography, gambling, shopping, social networks, etc..).\nAssuming the requested URL is acceptable, the content is then fetched by the proxy. At this point, a dynamic filter may be applied on the return path. For example, JPEG files could be blocked based on fleshtone matches, or language filters could dynamically detect unwanted language. If the content is rejected then an HTTP fetch error may be returned to the requester.\nMost web filtering companies use an internet-wide crawling robot that assesses the likelihood that content is a certain type. The resultant database is then corrected by manual labor based on complaints or known flaws in the content-matching algorithms.\nSome proxies scan outbound content, e.g., for data loss prevention; or scan content for malicious software.\n\n\n**** Filtering of encrypted data ****\nWeb filtering proxies are not able to peer inside secure sockets HTTP transactions, assuming the chain-of-trust of SSL/TLS (Transport Layer Security) has not been tampered with. The SSL/TLS chain-of-trust relies on trusted root certificate authorities.\nIn a workplace setting where the client is managed by the organization, devices may be configured to trust a root certificate whose private key is known to the proxy. In such situations, proxy analysis of the contents of an SSL/TLS transaction becomes possible. The proxy is effectively operating a man-in-the-middle attack, allowed by the client's trust of a root certificate the proxy owns.\n\n\n**** Bypassing filters and censorship ****\nIf the destination server filters content based on the origin of the request, the use of a proxy can circumvent this filter. For example, a server using IP-based geolocation to restrict its service to a certain country can be accessed using a proxy located in that country to access the service.:\u200a3\u200aWeb proxies are the most common means of bypassing government censorship, although no more than 3% of Internet users use any circumvention tools.:\u200a7\u200aSome proxy service providers allow businesses access to their proxy network for rerouting traffic for business intelligence purposes.In some cases, users can circumvent proxies which filter using blacklists using services designed to proxy information from a non-blacklisted location.\n\n\n**** Logging and eavesdropping ****\nProxies can be installed in order to eavesdrop upon the data-flow between client machines and the web. All content sent or accessed \u2013 including passwords submitted and cookies used \u2013 can be captured and analyzed by the proxy operator. For this reason, passwords to online services (such as webmail and banking) should always be exchanged over a cryptographically secured connection, such as SSL.\nBy chaining the proxies which do not reveal data about the original requester, it is possible to obfuscate activities from the eyes of the user's destination. However, more traces will be left on the intermediate hops, which could be used or offered up to trace the user's activities. If the policies and administrators of these other proxies are unknown, the user may fall victim to a false sense of security just because those details are out of sight and mind.\nIn what is more of an inconvenience than a risk, proxy users may find themselves being blocked from certain Web sites, as numerous forums and Web sites block IP addresses from proxies known to have spammed or trolled the site. Proxy bouncing can be used to maintain privacy.\n\n\n*** Improving performance ***\nA caching proxy server accelerates service requests by retrieving the content saved from a previous request made by the same client or even other clients. Caching proxies keep local copies of frequently requested resources, allowing large organizations to significantly reduce their upstream bandwidth usage and costs, while significantly increasing performance. Most ISPs and large businesses have a caching proxy. Caching proxies were the first kind of proxy server. Web proxies are commonly used to cache web pages from a web server. Poorly implemented caching proxies can cause problems, such as an inability to use user authentication.A proxy that is designed to mitigate specific link related issues or degradation is a Performance Enhancing Proxy (PEPs). These are typically used to improve TCP performance in the presence of high round-trip times or high packet loss (such as wireless or mobile phone networks); or highly asymmetric links featuring very different upload and download rates. PEPs can make more efficient use of the network, for example, by merging TCP ACKs (acknowledgements) or compressing data sent at the application layer.\n\n\n*** Translation ***\nA translation proxy is a proxy server that is used to localize a website experience for different markets. Traffic from the global audience is routed through the translation proxy to the source website. As visitors browse the proxied site, requests go back to the source site where pages are rendered. The original language content in the response is replaced by the translated content as it passes back through the proxy. The translations used in a translation proxy can be either machine translation, human translation, or a combination of machine and human translation. Different translation proxy implementations have different capabilities. Some allow further customization of the source site for the local audiences such as excluding the source content or substituting the source content with the original local content.\n\n\n*** Accessing services anonymously ***\n\nAn anonymous proxy server (sometimes called a web proxy) generally attempts to anonymize web surfing.  Anonymizers may be differentiated into several varieties. The destination server (the server that ultimately satisfies the web request) receives requests from the anonymizing proxy server and thus does not receive information about the end user's address. The requests are not anonymous to the anonymizing proxy server, however, and so a degree of trust is present between the proxy server and the user. Many proxy servers are funded through a continued advertising link to the user.\nAccess control: Some proxy servers implement a logon requirement. In large organizations, authorized users must log on to gain access to the web. The organization can thereby track usage to individuals. Some anonymizing proxy servers may forward data packets with header lines such as HTTP_VIA, HTTP_X_FORWARDED_FOR, or HTTP_FORWARDED, which may reveal the IP address of the client. Other anonymizing proxy servers, known as elite or high-anonymity proxies, make it appear that the proxy server is the client. A website could still suspect a proxy is being used if the client sends packets that include a cookie from a previous visit that did not use the high-anonymity proxy server. Clearing cookies, and possibly the cache, would solve this problem.\n\n\n**** QA geotargeted advertising ****\nAdvertisers use proxy servers for validating, checking and quality assurance of geotargeted ads. A geotargeting ad server checks the request source IP address and uses a geo-IP database to determine the geographic source of requests. Using a proxy server that is physically located inside a specific country or a city gives advertisers the ability to test geotargeted ads.\n\n\n*** Security ***\nA proxy can keep the internal network structure of a company secret by using network address translation, which can help the security of the internal network. This makes requests from machines and users on the local network anonymous. Proxies can also be combined with firewalls.\nAn incorrectly configured proxy can provide access to a network otherwise isolated from the Internet.\n\n\n**** Cross-domain resources ****\nProxies allow web sites to make web requests to externally hosted resources (e.g. images, music files, etc.) when cross-domain restrictions prohibit the web site from linking directly to the outside domains. Proxies also allow the browser to make web requests to externally hosted content on behalf of a website when cross-domain restrictions (in place to protect websites from the likes of data theft) prohibit the browser from directly accessing the outside domains.\n\n\n*** Malicious usages ***\n\n\n**** Secondary market brokers ****\nSecondary market brokers use web proxy servers to circumvent restrictions on online purchase of limited products such as limited sneakers or tickets.\n\n== Implementations of proxies ==\n\n\n*** Web proxy servers ***\nWeb proxies forward HTTP requests. The request from the client is the same as a regular HTTP request except the full URL is passed, instead of just the path.\n\nThis request is sent to the proxy server, the proxy makes the request specified and returns the response.\n\nSome web proxies allow the HTTP CONNECT method to set up forwarding of arbitrary data through the connection; a common policy is to only forward port 443 to allow HTTPS traffic.\nExamples of web proxy servers include Apache (with mod_proxy or Traffic Server), HAProxy, IIS configured as proxy (e.g., with Application Request Routing), Nginx, Privoxy, Squid, Varnish (reverse proxy only), WinGate, Ziproxy, Tinyproxy, RabbIT and Polipo.\nFor clients, the problem of complex or multiple proxy-servers is solved by a client-server Proxy auto-config protocol (PAC file).\n\n\n*** SOCKS proxy ***\nSOCKS also forwards arbitrary data after a connection phase, and is similar to HTTP CONNECT in web proxies.\n\n\n*** Transparent proxy ***\nAlso known as an intercepting proxy, inline proxy, or forced proxy, a transparent proxy intercepts normal application layer communication without requiring any special client configuration. Clients need not be aware of the existence of the proxy. A transparent proxy is normally located between the client and the Internet, with the proxy performing some of the functions of a gateway or router.RFC 2616 (Hypertext Transfer Protocol\u2014HTTP/1.1) offers standard definitions:\n\"A 'transparent proxy' is a proxy that does not modify the request or response beyond what is required for proxy authentication and identification\". \"A 'non-transparent proxy' is a proxy that modifies the request or response in order to provide some added service to the user agent, such as group annotation services, media type transformation, protocol reduction, or anonymity filtering\".\nTCP Intercept is a traffic filtering security feature that protects TCP servers from TCP SYN flood attacks, which are a type of denial-of-service attack. TCP Intercept is available for IP traffic only.\nIn 2009 a security flaw in the way that transparent proxies operate was published by Robert Auger, and the Computer Emergency Response Team issued an advisory listing dozens of affected transparent and intercepting proxy servers.\n\n\n**** Purpose ****\nIntercepting proxies are commonly used in businesses to enforce acceptable use policy, and to ease administrative overheads since no client browser configuration is required. This second reason however is mitigated by features such as Active Directory group policy, or DHCP and automatic proxy detection.\nIntercepting proxies are also commonly used by ISPs in some countries to save upstream bandwidth and improve customer response times by caching. This is more common in countries where bandwidth is more limited (e.g. island nations) or must be paid for.\n\n\n**** Issues ****\nThe diversion/interception of a TCP connection creates several issues. First, the original destination IP and port must somehow be communicated to the proxy. This is not always possible (e.g., where the gateway and proxy reside on different hosts). There is a class of cross-site attacks that depend on certain behavior of intercepting proxies that do not check or have access to information about the original (intercepted) destination. This problem may be resolved by using an integrated packet-level and application level appliance or software which is then able to communicate this information between the packet handler and the proxy.\nIntercepting also creates problems for HTTP authentication, especially connection-oriented authentication such as NTLM, as the client browser believes it is talking to a server rather than a proxy. This can cause problems where an intercepting proxy requires authentication, then the user connects to a site that also requires authentication.\nFinally, intercepting connections can cause problems for HTTP caches, as some requests and responses become uncacheable by a shared cache.\n\n\n**** Implementation methods ****\nIn integrated firewall/proxy servers where the router/firewall is on the same host as the proxy, communicating original destination information can be done by any method, for example Microsoft TMG or WinGate.\nInterception can also be performed using Cisco's WCCP (Web Cache Control Protocol). This proprietary protocol resides on the router and is configured from the cache, allowing the cache to determine what ports and traffic is sent to it via transparent redirection from the router. This redirection can occur in one of two ways: GRE tunneling (OSI Layer 3) or MAC rewrites (OSI Layer 2).\nOnce traffic reaches the proxy machine itself interception is commonly performed with NAT (Network Address Translation). Such setups are invisible to the client browser, but leave the proxy visible to the web server and other devices on the internet side of the proxy. Recent Linux and some BSD releases provide TPROXY (transparent proxy) which performs IP-level (OSI Layer 3) transparent interception and spoofing of outbound traffic, hiding the proxy IP address from other network devices.\n\n\n**** Detection ****\nSeveral methods may be used to detect the presence of an intercepting proxy server:\n\nBy comparing the client's external IP address to the address seen by an external web server, or sometimes by examining the HTTP headers received by a server. A number of sites have been created to address this issue, by reporting the user's IP address as seen by the site back to the user on a web page. Google also returns the IP address as seen by the page if the user searches for \"IP\".\nBy comparing the result of online IP checkers when accessed using HTTPS vs HTTP, as most intercepting proxies do not intercept SSL. If there is suspicion of SSL being intercepted, one can examine the certificate associated with any secure web site, the root certificate should indicate whether it was issued for the purpose of intercepting.\nBy comparing the sequence of network hops reported by a tool such as traceroute for a proxied protocol such as HTTP (port 80) with that for a non-proxied protocol such as SMTP (port 25).\nBy attempting to make a connection to an IP address at which there is known to be no server. The proxy will accept the connection and then attempt to proxy it on. When the proxy finds no server to accept the connection it may return an error message or simply close the connection to the client. This difference in behavior is simple to detect. For example, most web browsers will generate a browser created error page in the case where they cannot connect to an HTTP server but will return a different error in the case where the connection is accepted and then closed.\nBy serving the end-user specially programmed Adobe Flash SWF applications or Sun Java applets that send HTTP calls back to their server.\n\n\n*** CGI proxy ***\nA CGI web proxy accepts target URLs using a Web form in the user's browser window, processes the request, and returns the results to the user's browser. Consequently, it can be used on a device or network that does not allow \"true\" proxy settings to be changed. The first recorded CGI proxy, named \"rover\" at the time but renamed in 1998 to \"CGIProxy\", was developed by American computer scientist James Marshall in early 1996 for an article in \"Unix Review\" by Rich Morin.The majority of CGI proxies are powered by one of CGIProxy (written in the Perl language), Glype (written in the PHP language), or PHProxy (written in the PHP language). As of April 2016, CGIProxy has received about 2 million downloads, Glype has received almost a million downloads, whilst PHProxy still receives hundreds of downloads per week. Despite waning in popularity due to VPNs and other privacy methods, as of September 2021 there are still a few hundred CGI proxies online.Some CGI proxies were set up for purposes such as making websites more accessible to disabled people, but have since been shut down due to excessive traffic, usually caused by a third party advertising the service as a means to bypass local filtering. Since many of these users don't care about the collateral damage they are causing, it became necessary for organizations to hide their proxies, disclosing the URLs only to those who take the trouble to contact the organization and demonstrate a genuine need.\n\n\n*** Suffix proxy ***\nA suffix proxy allows a user to access web content by appending the name of the proxy server to the URL of the requested content (e.g. \"en.wikipedia.org.SuffixProxy.com\"). Suffix proxy servers are easier to use than regular proxy servers but they do not offer high levels of anonymity and their primary use is for bypassing web filters. However, this is rarely used due to more advanced web filters.\n\n\n*** Tor onion proxy software ***\n\nTor is a system intended to provide online anonymity. Tor client software routes Internet traffic through a worldwide volunteer network of servers for concealing a user's computer location or usage from someone conducting network surveillance or traffic analysis. Using Tor makes tracing Internet activity more difficult, and is intended to protect users' personal freedom and their online privacy.\n\"Onion routing\" refers to the layered nature of the encryption service: The original data are encrypted and re-encrypted multiple times, then sent through successive Tor relays, each one of which decrypts a \"layer\" of encryption before passing the data on to the next relay and ultimately the destination. This reduces the possibility of the original data being unscrambled or understood in transit.\n\n\n*** I2P anonymous proxy ***\nThe I2P anonymous network ('I2P') is a proxy network aiming at online anonymity. It implements garlic routing, which is an enhancement of Tor's onion routing. I2P is fully distributed and works by encrypting all communications in various layers and relaying them through a network of routers run by volunteers in various locations. By keeping the source of the information hidden, I2P offers censorship resistance. The goals of I2P are to protect users' personal freedom, privacy, and ability to conduct confidential business.\nEach user of I2P runs an I2P router on their computer (node). The I2P router takes care of finding other peers and building anonymizing tunnels through them. I2P provides proxies for all protocols (HTTP, IRC, SOCKS, ...).\n\n\n*** Comparison to network address translators ***\nThe proxy concept refers to a layer 7 application in the OSI reference model. Network address translation (NAT) is similar to a proxy but operates in layer 3.\nIn the client configuration of layer-3 NAT, configuring the gateway is sufficient. However, for the client configuration of a layer 7 proxy, the destination of the packets that the client generates must always be the proxy server (layer 7), then the proxy server reads each packet and finds out the true destination.\nBecause NAT operates at layer-3, it is less resource-intensive than the layer-7 proxy, but also less flexible. As we compare these two technologies, we might encounter a terminology known as 'transparent firewall'. Transparent firewall means that the proxy uses the layer-7 proxy advantages without the knowledge of the client. The client presumes that the gateway is a NAT in layer 3, and it does not have any idea about the inside of the packet, but through this method, the layer-3 packets are sent to the layer-7 proxy for investigation.\n\n\n*** DNS proxy ***\nA DNS proxy server takes DNS queries from a (usually local) network and forwards them to an Internet Domain Name Server. It may also cache DNS records.\n\n\n*** Proxifiers ***\nSome client programs \"SOCKS-ify\" requests, which allows adaptation of any networked software to connect to external networks via certain types of proxy servers (mostly SOCKS).\n\n\n*** Residential proxy ***\nA residential proxy is an intermediary that uses a real IP address provided by an Internet Service Provider (ISP) with physical devices such as mobiles and computers of end-users. Instead of connecting directly to a server, residential proxy users connect to the target through residential IP addresses. The target then identifies them as organic internet users. It does not let any tracking tool identify the reallocation of the user. Any residential proxy can send any number of concurrent requests and IP addresses are directly related to a specific region. Unlike regular residential proxies, which hide user's real IP address behind another IP address, rotating residential proxies, also known as backconnect proxies, conceal user's real IP address behind a pool of proxies. These proxies switch between themselves with every session or at regular intervals."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the history of BackTrack Linux and how was it developed?",
    "context": "",
    "output": "BackTrack Linux was an open source GNU General Public License Linux distribution developed by programmers from around the world with assistance, coordination, and funding from Offensive Security. It was originally developed under the names Whoppix, IWHAX, and Auditor, and was designed to delete any trace of its usage. It was widely known and used by security experts.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the history of BackTrack Linux and how was it developed?",
      "answer": "BackTrack Linux was an open source GNU General Public License Linux distribution developed by programmers from around the world with assistance, coordination, and funding from Offensive Security. It was originally developed under the names Whoppix, IWHAX, and Auditor, and was designed to delete any trace of its usage. It was widely known and used by security experts."
    }
  },
  {
    "instruction": "context: Monitor mode can be used for geographical packet analysis, observing widespread traffic, acquiring knowledge of Wi-Fi technology, auditing unsecure channels (such as those protected with WEP), and helping design Wi-Fi networks by discovering the number of Wi-Fi devices currently being used on a given area and channel to reduce interference with other Wi-Fi devices.\n\nAsk a question about this context.",
    "context": "",
    "output": "What are some common uses for Monitor mode?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some common uses for Monitor mode?",
      "answer": "Monitor mode can be used for geographical packet analysis, observing widespread traffic, acquiring knowledge of Wi-Fi technology, auditing unsecure channels (such as those protected with WEP), and helping design Wi-Fi networks by discovering the number of Wi-Fi devices currently being used on a given area and channel to reduce interference with other Wi-Fi devices."
    }
  },
  {
    "instruction": "Answer based on context:\n\nCopy attack\n\n==Introduction==\nThe copy attack is an attack on certain digital watermarking systems proposed by M. Kutter, S. Voloshynovskiy, and A. Herrige in a paper presented in January, 2000 at the Photonics West SPIE convention.In some scenarios, a digital watermark is added to a piece of media such as an image, film, or audio clip, to prove its authenticity.  If a piece of media were presented and found to lack a watermark, it would be considered suspect.  Alternatively, a security system could be devised which would limit a user's ability to manipulate any piece of media which contained a watermark.  For instance, a DVD burner may prohibit making copies of a film which contained a watermark.\nThe copy attack attempts to thwart the effectiveness of such systems by estimating the watermark given in an originally watermarked piece of media, and then adding that watermark to an un-watermarked piece.  In the first scenario listed above, this would allow an attacker to have an inauthentic image be declared authentic, since it contains a watermark.  In the second scenario, an attacker could flood the market with content which ordinarily would allow a user to manipulate it as he saw fit, but due to the presence of the watermark, limitations would be imposed.  In this way, schemes which sought to limit use of watermarked media may prove to be too unpopular for wide distribution.\nIn a 2003 paper presented at the International Conference on Acoustics, Speech, and Signal Processing, John Barr, Brett Bradley, and Brett T. Hannigan of Digimarc describe a way to tie the content of the digital watermark to the underlying image, so that if the watermark were placed into a different image, the watermark detection system would not authenticate it.\n\n\n\n\n\nHow does the solution presented by John Barr, Brett Bradley, and Brett T. Hannigan at the International Conference on Acoustics, Speech, and Signal Processing address the copy attack issue?",
    "context": "",
    "output": "John Barr, Brett Bradley, and Brett T. Hannigan presented a solution that ties the content of a digital watermark to the underlying image, making it impossible for the watermark to be authenticated if it is placed into a different image. This approach enhances security against copy attacks by ensuring watermarks cannot be reused in unauthorized media, thus preventing the bypassing of authentication or content limitations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the solution presented by John Barr, Brett Bradley, and Brett T. Hannigan at the International Conference on Acoustics, Speech, and Signal Processing address the copy attack issue?",
      "answer": "John Barr, Brett Bradley, and Brett T. Hannigan presented a solution that ties the content of a digital watermark to the underlying image, making it impossible for the watermark to be authenticated if it is placed into a different image. This approach enhances security against copy attacks by ensuring watermarks cannot be reused in unauthorized media, thus preventing the bypassing of authentication or content limitations.",
      "context": "Copy attack\n\n==Introduction==\nThe copy attack is an attack on certain digital watermarking systems proposed by M. Kutter, S. Voloshynovskiy, and A. Herrige in a paper presented in January, 2000 at the Photonics West SPIE convention.In some scenarios, a digital watermark is added to a piece of media such as an image, film, or audio clip, to prove its authenticity.  If a piece of media were presented and found to lack a watermark, it would be considered suspect.  Alternatively, a security system could be devised which would limit a user's ability to manipulate any piece of media which contained a watermark.  For instance, a DVD burner may prohibit making copies of a film which contained a watermark.\nThe copy attack attempts to thwart the effectiveness of such systems by estimating the watermark given in an originally watermarked piece of media, and then adding that watermark to an un-watermarked piece.  In the first scenario listed above, this would allow an attacker to have an inauthentic image be declared authentic, since it contains a watermark.  In the second scenario, an attacker could flood the market with content which ordinarily would allow a user to manipulate it as he saw fit, but due to the presence of the watermark, limitations would be imposed.  In this way, schemes which sought to limit use of watermarked media may prove to be too unpopular for wide distribution.\nIn a 2003 paper presented at the International Conference on Acoustics, Speech, and Signal Processing, John Barr, Brett Bradley, and Brett T. Hannigan of Digimarc describe a way to tie the content of the digital watermark to the underlying image, so that if the watermark were placed into a different image, the watermark detection system would not authenticate it.\n\n\n\n"
    }
  },
  {
    "instruction": "Write an answer to the following question: How can a security switch provide protection even if security has already been breached?",
    "context": "",
    "output": "A security switch provides protection even if security has already been breached since it does not have any access from other components and is not accessible by software, interrupting any unauthorized communication or data transfer.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a security switch provide protection even if security has already been breached?",
      "answer": "A security switch provides protection even if security has already been breached since it does not have any access from other components and is not accessible by software, interrupting any unauthorized communication or data transfer."
    }
  },
  {
    "instruction": "context: DEA in cryptography refers to a type of equation that deals with additions over two different groups, such as addition modulo 2^32 and addition over GF(2), where input and output differences are expressed as XORs.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the concept of differential equations of addition (DEA) in cryptography?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the concept of differential equations of addition (DEA) in cryptography?",
      "answer": "DEA in cryptography refers to a type of equation that deals with additions over two different groups, such as addition modulo 2^32 and addition over GF(2), where input and output differences are expressed as XORs."
    }
  },
  {
    "instruction": "Write an answer to the following question: How has the Spanish Supreme Court ruled on cybersquatting and how does it relate to the crime of misappropriation?",
    "context": "",
    "output": "The Spanish Supreme Court has ruled that cybersquatting relates to the crime of misappropriation, as seen in the case of Alpha Education for Comprehensive Health. However, the Supreme Court ultimately acquitted the four accused, understanding that the proven facts do not fit the crime of misappropriation.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How has the Spanish Supreme Court ruled on cybersquatting and how does it relate to the crime of misappropriation?",
      "answer": "The Spanish Supreme Court has ruled that cybersquatting relates to the crime of misappropriation, as seen in the case of Alpha Education for Comprehensive Health. However, the Supreme Court ultimately acquitted the four accused, understanding that the proven facts do not fit the crime of misappropriation."
    }
  },
  {
    "instruction": "context: The name of the system implemented by the UT Austin researchers for practical verifiable computing is Pepper.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the name of the system implemented by the UT Austin researchers for practical verifiable computing?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the name of the system implemented by the UT Austin researchers for practical verifiable computing?",
      "answer": "The name of the system implemented by the UT Austin researchers for practical verifiable computing is Pepper."
    }
  },
  {
    "instruction": "context: Aircrack-ptw is a utility for cracking WEP keys using the PTW attack method, which is based on a paper released on the RC4 cipher by Adi Shamir.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the function of Aircrack-ptw in the Aircrack-ng suite?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the function of Aircrack-ptw in the Aircrack-ng suite?",
      "answer": "Aircrack-ptw is a utility for cracking WEP keys using the PTW attack method, which is based on a paper released on the RC4 cipher by Adi Shamir."
    }
  },
  {
    "instruction": "Intrusion Detection Message Exchange Format\n\n==Introduction==\nUsed as part of computer security, IDMEF (Intrusion Detection Message Exchange Format) is a data format used to exchange information between software enabling intrusion detection, intrusion prevention, security information collection and management systems that may need to interact with them.\nIDMEF messages are designed to be processed automatically. The details of the format are described in the RFC 4765. This RFC presents an implementation of the XML data model and the associated DTD.\nThe requirements for this format are described in RFC 4766, and the recommended transport protocol (IDXP) is documented in RFC 4767\n\n== IDMEF ==\n\nThe purpose of IDMEF is to define data formats and exchange procedures for sharing information of interest to intrusion detection and response systems and to the management systems that may need to interact with them. It is used in computer security for incidents reporting and exchanging. It is intended for easy automatic processing.\nIDMEF is a well-structured object-oriented format, which consists of 33 classes containing 108 fields, including three mandatory:\n\nThe classification\nThe unique login\nThe date of creation of the alert.There are currently two types of IDMEF messages that can be created, Heartbeat or Alert\n\n== Heartbeat ==\nThe Heartbeats are sent by the analyzers to indicate their status. These messages are sent at regular intervals which period is defined in the Heartbeat Interval Field. If none of these messages are received for several periods of time, consider that this analyzer is not able to trigger alerts.\n\n== Alert ==\nAlerts are used to describe an attack that took place, the main areas that create the alert are:\n\nCreateTime: Date of creation of the alert\nDetectTime: alert detection time by the analyzer\nAnalyzerTime: The time the alert was sent by the analyzer\nSource: Details about the origin of the attack can be a service, a user, a process and / or a node\nTarget: Details on the target of the attack can be a service, a user, a process and / or a node and a file\nClassification: Name of the attack and references, as CVEs\nAssessment: Evaluation of the attack (severity, potential impact, etc.)\nAdditionalData: Additional information on the attackThere are three other alert types that inherit from this scheme:\n\nCorrelationAlert: Grouping of alerts related to one another\nToolAlert: alerts from the same Grouping tool\nOverflowAlert: Alert resulting from attack so-called buffer overflow\n\n== Example ==\nIDMEF report of ping of death attack can look as follows:\n\n== Tools implementing the IDMEF protocol ==\nPrelude (Intrusion Detection System)\nNIDS Snort\nNIDS Suricata Archived 2018-01-31 at the Wayback Machine ([1])\nHIDS Ossec ([2])\nHIDS Samhain ([3])\nSagan\nBarnyard 2\nOrchids\nLibPrelude : Part of the Prelude OSS Project, libprelude permits to communicate between agents using the IDMEF format. Libprelude is coded in C but multiple bindings are available (Python, Lua, Perl, etc.). It can be used in any open-source IDS tools.\nLibIDMEF : LibIDMEF is an implementation of the IETF (Internet Engineering Task Force), IDWG ( Intrusion Detection Exchange Format Charter Working Group), draft standard IDMEF protocol.\nIDMEF Framework Dotnet : Dotnet library to create IDMEF objects and export them in XML.\nDILCA \u2013 Distributed IDMEF Logical Correlation Architecture : DILCA is a distributed logical correlation and reaction architecture featuring collection and correlation of IDMEF formatted log events (Intrusion Detection Message Exchange Format \u2013 RFC 4765) through a multi-step signature based system.\nXML::IDMEF \u2013 A Perl module for building/parsing IDMEF messages : IDMEF.pm is an interface for simply creating and parsing IDMEF messages. IDMEF is an XML based protocol designed mainly for representing Intrusion Detection (IDS) alert messages.\nOther module for creating/parsing IDMEF messages\nSnort IDMEF Plugin : Snort IDMEF is an IDMEF XML plugin for Snort to output alert events in the form of IDMEF messages. The plugin is compatible with Snort 2.x\nA Broccoli server to send IDMEF alerts via Prelude\nConverter for the IDMEF format\nIDMEF Parser\nAn IDMEF alerting library for distributed IDPS\n\n== Competing frameworks ==\nMany telecommunications network elements produce security alarms that address intrusion detection in conformance with international standards. These security alarms are inserted into the normal alarm stream, where they can be seen and acted upon immediately by personnel in a network operations center.\n\nWhat is the purpose of the classification field in an IDMEF Alert message?",
    "context": "",
    "output": "A: The classification field in an IDMEF Alert message contains the name of the attack and any relevant references, such as CVEs.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the classification field in an IDMEF Alert message?",
      "answer": "The classification field in an IDMEF Alert message contains the name of the attack and any relevant references, such as CVEs.",
      "context": "Intrusion Detection Message Exchange Format\n\n==Introduction==\nUsed as part of computer security, IDMEF (Intrusion Detection Message Exchange Format) is a data format used to exchange information between software enabling intrusion detection, intrusion prevention, security information collection and management systems that may need to interact with them.\nIDMEF messages are designed to be processed automatically. The details of the format are described in the RFC 4765. This RFC presents an implementation of the XML data model and the associated DTD.\nThe requirements for this format are described in RFC 4766, and the recommended transport protocol (IDXP) is documented in RFC 4767\n\n== IDMEF ==\n\nThe purpose of IDMEF is to define data formats and exchange procedures for sharing information of interest to intrusion detection and response systems and to the management systems that may need to interact with them. It is used in computer security for incidents reporting and exchanging. It is intended for easy automatic processing.\nIDMEF is a well-structured object-oriented format, which consists of 33 classes containing 108 fields, including three mandatory:\n\nThe classification\nThe unique login\nThe date of creation of the alert.There are currently two types of IDMEF messages that can be created, Heartbeat or Alert\n\n== Heartbeat ==\nThe Heartbeats are sent by the analyzers to indicate their status. These messages are sent at regular intervals which period is defined in the Heartbeat Interval Field. If none of these messages are received for several periods of time, consider that this analyzer is not able to trigger alerts.\n\n== Alert ==\nAlerts are used to describe an attack that took place, the main areas that create the alert are:\n\nCreateTime: Date of creation of the alert\nDetectTime: alert detection time by the analyzer\nAnalyzerTime: The time the alert was sent by the analyzer\nSource: Details about the origin of the attack can be a service, a user, a process and / or a node\nTarget: Details on the target of the attack can be a service, a user, a process and / or a node and a file\nClassification: Name of the attack and references, as CVEs\nAssessment: Evaluation of the attack (severity, potential impact, etc.)\nAdditionalData: Additional information on the attackThere are three other alert types that inherit from this scheme:\n\nCorrelationAlert: Grouping of alerts related to one another\nToolAlert: alerts from the same Grouping tool\nOverflowAlert: Alert resulting from attack so-called buffer overflow\n\n== Example ==\nIDMEF report of ping of death attack can look as follows:\n\n== Tools implementing the IDMEF protocol ==\nPrelude (Intrusion Detection System)\nNIDS Snort\nNIDS Suricata Archived 2018-01-31 at the Wayback Machine ([1])\nHIDS Ossec ([2])\nHIDS Samhain ([3])\nSagan\nBarnyard 2\nOrchids\nLibPrelude : Part of the Prelude OSS Project, libprelude permits to communicate between agents using the IDMEF format. Libprelude is coded in C but multiple bindings are available (Python, Lua, Perl, etc.). It can be used in any open-source IDS tools.\nLibIDMEF : LibIDMEF is an implementation of the IETF (Internet Engineering Task Force), IDWG ( Intrusion Detection Exchange Format Charter Working Group), draft standard IDMEF protocol.\nIDMEF Framework Dotnet : Dotnet library to create IDMEF objects and export them in XML.\nDILCA \u2013 Distributed IDMEF Logical Correlation Architecture : DILCA is a distributed logical correlation and reaction architecture featuring collection and correlation of IDMEF formatted log events (Intrusion Detection Message Exchange Format \u2013 RFC 4765) through a multi-step signature based system.\nXML::IDMEF \u2013 A Perl module for building/parsing IDMEF messages : IDMEF.pm is an interface for simply creating and parsing IDMEF messages. IDMEF is an XML based protocol designed mainly for representing Intrusion Detection (IDS) alert messages.\nOther module for creating/parsing IDMEF messages\nSnort IDMEF Plugin : Snort IDMEF is an IDMEF XML plugin for Snort to output alert events in the form of IDMEF messages. The plugin is compatible with Snort 2.x\nA Broccoli server to send IDMEF alerts via Prelude\nConverter for the IDMEF format\nIDMEF Parser\nAn IDMEF alerting library for distributed IDPS\n\n== Competing frameworks ==\nMany telecommunications network elements produce security alarms that address intrusion detection in conformance with international standards. These security alarms are inserted into the normal alarm stream, where they can be seen and acted upon immediately by personnel in a network operations center."
    }
  },
  {
    "instruction": "context: The recent, stable release of ACARM-ng provides the following trigger implementations: informing administrator about suspicious events (file, gg, jabber, mail) and providing means of automatic reaction (extapp, python, snort sam).\n\nAsk a question about this context.",
    "context": "",
    "output": "What are the different implementations of trigger provided by ACARM-ng?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the different implementations of trigger provided by ACARM-ng?",
      "answer": "The recent, stable release of ACARM-ng provides the following trigger implementations: informing administrator about suspicious events (file, gg, jabber, mail) and providing means of automatic reaction (extapp, python, snort sam)."
    }
  },
  {
    "instruction": "Quantum computing\n\n==Introduction==\nA quantum computer is a computer that exploits quantum mechanical phenomena.\nAt small scales, physical matter exhibits properties of both particles and waves, and quantum computing leverages this behavior using specialized hardware.\nClassical physics cannot explain the operation of these quantum devices, and a scalable quantum computer could perform some calculations exponentially faster than any modern \"classical\" computer.\nIn particular, a large-scale quantum computer could break widely used encryption schemes and aid physicists in performing physical simulations; however, the current state of the art is largely experimental and impractical.\nThe basic unit of information in quantum computing is the qubit, similar to the bit in traditional digital electronics. Unlike a classical bit, a qubit can exist in a superposition of its two \"basis\" states, which loosely means that it is in both states simultaneously. When measuring a qubit, the result is a probabilistic output of a classical bit. If a quantum computer manipulates the qubit in a particular way, wave interference effects can amplify the desired measurement results. The design of quantum algorithms involves creating procedures that allow a quantum computer to perform calculations efficiently and quickly.\nPhysically engineering high-quality qubits has proven challenging.\nIf a physical qubit is not sufficiently isolated from its environment, it suffers from quantum decoherence, introducing noise into calculations.\nNational governments have invested heavily in experimental research that aims to develop scalable qubits with longer coherence times and lower error rates.\nTwo of the most promising technologies are superconductors (which isolate an electrical current by eliminating electrical resistance) and ion traps (which confine a single atomic particle using electromagnetic fields).\nAny computational problem that can be solved by a classical computer can also be solved by a quantum computer. Conversely, any problem that can be solved by a quantum computer can also be solved by a classical computer, at least in principle given enough time. In other words, quantum computers obey the Church\u2013Turing thesis. This means that while quantum computers provide no additional advantages over classical computers in terms of computability, quantum algorithms for certain problems have significantly lower time complexities than corresponding known classical algorithms. Notably, quantum computers are believed to be able to solve many problems quickly that no classical computer could solve in any feasible amount of time\u2014a feat known as \"quantum supremacy.\" The study of the computational complexity of problems with respect to quantum computers is known as quantum complexity theory.\n\n== Quantum information processing ==\n\nComputer engineers typically describe a modern computer's operation in terms of classical electrodynamics.\nWithin these \"classical\" computers, some components (such as semiconductors and random number generators) may rely on quantum behavior, but these components are not isolated from their environment, so any quantum information quickly decoheres.\nWhile programmers may depend on probability theory when designing a randomized algorithm, quantum mechanical notions like superposition and interference are largely irrelevant for program analysis.\nQuantum programs, in contrast, rely on precise control of coherent quantum systems. Physicists describe these systems mathematically using linear algebra. Complex numbers model probability amplitudes, vectors model quantum states, and matrices model the operations that can be performed on these states. Programming a quantum computer is then a matter of composing operations in such a way that the resulting program computes a useful result in theory and is implementable in practice.\nThe prevailing model of quantum computation describes the computation in terms of a network of quantum logic gates. This model is a complex linear-algebraic generalization of boolean circuits.\n\n\n*** Quantum information ***\nThe qubit serves as the basic unit of quantum information.\nIt represents a two-state system, just like a classical bit, except that it can exist in a superposition of its two states.\nIn one sense, a superposition is like a probability distribution over the two values.\nHowever, a quantum computation can be influenced by both values at once, inexplicable by either state individually.\nIn this sense, a \"superposed\" qubit stores both values simultaneously.\nA two-dimensional vector mathematically represents a qubit state. Physicists typically use Dirac notation for quantum mechanical linear algebra, writing |\u03c8\u27e9 'ket psi' for a vector labeled \u03c8. Because a qubit is a two-state system, any qubit state takes the form \u03b1|0\u27e9 + \u03b2|1\u27e9, where |0\u27e9 and |1\u27e9 are the standard basis states, and \u03b1 and \u03b2 are the probability amplitudes. If either \u03b1 or \u03b2 is zero, the qubit is effectively a classical bit; when both are nonzero, the qubit is in superposition. Such a quantum state vector acts similarly to a (classical) probability vector, with one key difference: unlike probabilities, probability amplitudes are not necessarily positive numbers. Negative amplitudes allow for destructive wave interference.When a qubit is measured in the standard basis, the result is a classical bit.\nThe Born rule describes the norm-squared correspondence between amplitudes and probabilities\u2014when measuring a qubit \u03b1|0\u27e9 + \u03b2|1\u27e9, the state collapses to |0\u27e9 with probability |\u03b1|2, or to |1\u27e9 with probability |\u03b2|2.\nAny valid qubit state has coefficients \u03b1 and \u03b2 such that |\u03b1|2 + |\u03b2|2\n\n== Communication ==\n\nQuantum cryptography could potentially fulfill some of the functions of public key cryptography. Quantum-based cryptographic systems could, therefore, be more secure than traditional systems against quantum hacking.\n\n== Algorithms ==\nProgress in finding quantum algorithms typically focuses on this quantum circuit model, though exceptions like the quantum adiabatic algorithm exist. Quantum algorithms can be roughly categorized by the type of speedup achieved over corresponding classical algorithms.Quantum algorithms that offer more than a polynomial speedup over the best-known classical algorithm include Shor's algorithm for factoring and the related quantum algorithms for computing discrete logarithms, solving Pell's equation, and more generally solving the hidden subgroup problem for abelian finite groups. These algorithms depend on the primitive of the quantum Fourier transform. No mathematical proof has been found that shows that an equally fast classical algorithm cannot be discovered, but evidence suggests that this is unlikely. Certain oracle problems like Simon's problem and the Bernstein\u2013Vazirani problem do give provable speedups, though this is in the quantum query model, which is a restricted model where lower bounds are much easier to prove and doesn't necessarily translate to speedups for practical problems.\nOther problems, including the simulation of quantum physical processes from chemistry and solid-state physics, the approximation of certain Jones polynomials, and the quantum algorithm for linear systems of equations have quantum algorithms appearing to give super-polynomial speedups and are BQP-complete. Because these problems are BQP-complete, an equally fast classical algorithm for them would imply that no quantum algorithm gives a super-polynomial speedup, which is believed to be unlikely.Some quantum algorithms, like Grover's algorithm and amplitude amplification, give polynomial speedups over corresponding classical algorithms. Though these algorithms give comparably modest quadratic speedup, they are widely applicable and thus give speedups for a wide range of problems. Many examples of provable quantum speedups for query problems are related to Grover's algorithm, including Brassard, H\u00f8yer, and Tapp's algorithm for finding collisions in two-to-one functions, which uses Grover's algorithm, and Farhi, Goldstone, and Gutmann's algorithm for evaluating NAND trees, which is a variant of the search problem.\n\n\n*** Post-quantum cryptography ***\n\nA notable application of quantum computation is for attacks on cryptographic systems that are currently in use. Integer factorization, which underpins the security of public key cryptographic systems, is believed to be computationally infeasible with an ordinary computer for large integers if they are the product of few prime numbers (e.g., products of two 300-digit primes). By comparison, a quantum computer could solve this problem exponentially faster using Shor's algorithm to find its factors. This ability would allow a quantum computer to break many of the cryptographic systems in use today, in the sense that there would be a polynomial time (in the number of digits of the integer) algorithm for solving the problem. In particular, most of the popular public key ciphers are based on the difficulty of factoring integers or the discrete logarithm problem, both of which can be solved by Shor's algorithm. In particular, the RSA, Diffie\u2013Hellman, and elliptic curve Diffie\u2013Hellman algorithms could be broken. These are used to protect secure Web pages, encrypted email, and many other types of data. Breaking these would have significant ramifications for electronic privacy and security.\nIdentifying cryptographic systems that may be secure against quantum algorithms is an actively researched topic under the field of post-quantum cryptography. Some public-key algorithms are based on problems other than the integer factorization and discrete logarithm problems to which Shor's algorithm applies, like the McEliece cryptosystem based on a problem in coding theory. Lattice-based cryptosystems are also not known to be broken by quantum computers, and finding a polynomial time algorithm for solving the dihedral hidden subgroup problem, which would break many lattice based cryptosystems, is a well-studied open problem. It has been proven that applying Grover's algorithm to break a symmetric (secret key) algorithm by brute force requires time equal to roughly 2n/2 invocations of the underlying cryptographic algorithm, compared with roughly 2n in the classical case, meaning that symmetric key lengths are effectively halved: AES-256 would have the same security against an attack using Grover's algorithm that AES-128 has against classical brute-force search (see Key size).\n\n\n*** Search problems ***\n\nThe most well-known example of a problem that allows for a polynomial quantum speedup is unstructured search, which involves finding a marked item out of a list of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   items in a database. This can be solved by Grover's algorithm using \n  \n    \n      \n        O\n        (\n        \n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle O({\\sqrt {n}})}\n   queries to the database, quadratically fewer than the \n  \n    \n      \n        \u03a9\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\Omega (n)}\n   queries required for classical algorithms. In this case, the advantage is not only provable but also optimal: it has been shown that Grover's algorithm gives the maximal possible probability of finding the desired element for any number of oracle lookups.\nProblems that can be efficiently addressed with Grover's algorithm have the following properties:\nThere is no searchable structure in the collection of possible answers,\nThe number of possible answers to check is the same as the number of inputs to the algorithm, and\nThere exists a boolean function that evaluates each input and determines whether it is the correct answerFor problems with all these properties, the running time of Grover's algorithm on a quantum computer scales as the square root of the number of inputs (or elements in the database), as opposed to the linear scaling of classical algorithms. A general class of problems to which Grover's algorithm can be applied is Boolean satisfiability problem, where the database through which the algorithm iterates is that of all possible answers. An example and possible application of this is a password cracker that attempts to guess a password. Breaking symmetric ciphers with this algorithm is of interest to government agencies.\n\n\n*** Simulation of quantum systems ***\n\nSince chemistry and nanotechnology rely on understanding quantum systems, and such systems are impossible to simulate in an efficient manner classically, quantum simulation may be an important application of quantum computing. Quantum simulation could also be used to simulate the behavior of atoms and particles at unusual conditions such as the reactions inside a collider.About 2% of the annual global energy output is used for nitrogen fixation to produce ammonia for the Haber process in the agricultural fertilizer industry (even though naturally occurring organisms also produce ammonia). Quantum simulations might be used to understand this process and increase the energy efficiency of production.\n\n\n*** Quantum annealing ***\nQuantum annealing relies on the adiabatic theorem to undertake calculations. A system is placed in the ground state for a simple Hamiltonian, which slowly evolves to a more complicated Hamiltonian whose ground state represents the solution to the problem in question. The adiabatic theorem states that if the evolution is slow enough the system will stay in its ground state at all times through the process. Adiabatic optimization may be helpful for solving computational biology problems.\n\n\n*** Machine learning ***\n\nSince quantum computers can produce outputs that classical computers cannot produce efficiently, and since quantum computation is fundamentally linear algebraic, some express hope in developing quantum algorithms that can speed up machine learning tasks.For example, the quantum algorithm for linear systems of equations, or \"HHL Algorithm\", named after its discoverers Harrow, Hassidim, and Lloyd, is believed to provide speedup over classical counterparts. Some research groups have recently explored the use of quantum annealing hardware for training Boltzmann machines and deep neural networks. \nDeep generative chemistry models emerge as powerful tools to expedite drug discovery. However, the immense size and complexity of the structural space of all possible drug-like molecules pose significant obstacles, which could be overcome in the future by quantum computers. Quantum computers are naturally good for solving complex quantum many-body problems and thus may be instrumental in applications involving quantum chemistry. Therefore, one can expect that quantum-enhanced generative models including quantum GANs may eventually be developed into ultimate generative chemistry algorithms.\n\n== Engineering ==\n\n\n*** Challenges ***\nThere are a number of technical challenges in building a large-scale quantum computer. Physicist David DiVincenzo has listed these requirements for a practical quantum computer:\nPhysically scalable to increase the number of qubits\nQubits that can be initialized to arbitrary values\nQuantum gates that are faster than decoherence time\nUniversal gate set\nQubits that can be read easily.Sourcing parts for quantum computers is also very difficult. Superconducting quantum computers, like those constructed by Google and IBM, need helium-3, a nuclear research byproduct, and special superconducting cables made only by the Japanese company Coax Co.The control of multi-qubit systems requires the generation and coordination of a large number of electrical signals with tight and deterministic timing resolution. This has led to the development of quantum controllers that enable interfacing with the qubits. Scaling these systems to support a growing number of qubits is an additional challenge.\n\n\n**** Decoherence ****\nOne of the greatest challenges involved with constructing quantum computers is controlling or removing quantum decoherence. This usually means isolating the system from its environment as interactions with the external world cause the system to decohere. However, other sources of decoherence also exist. Examples include the quantum gates, and the lattice vibrations and background thermonuclear spin of the physical system used to implement the qubits. Decoherence is irreversible, as it is effectively non-unitary, and is usually something that should be highly controlled, if not avoided. Decoherence times for candidate systems in particular, the transverse relaxation time T2 (for NMR and MRI technology, also called the dephasing time), typically range between nanoseconds and seconds at low temperature. Currently, some quantum computers require their qubits to be cooled to 20 millikelvin (usually using a dilution refrigerator) in order to prevent significant decoherence. A 2020 study argues that ionizing radiation such as cosmic rays can nevertheless cause certain systems to decohere within milliseconds.As a result, time-consuming tasks may render some quantum algorithms inoperable, as attempting to maintain the state of qubits for a long enough duration will eventually corrupt the superpositions.These issues are more difficult for optical approaches as the timescales are orders of magnitude shorter and an often-cited approach to overcoming them is optical pulse shaping. Error rates are typically proportional to the ratio of operating time to decoherence time, hence any operation must be completed much more quickly than the decoherence time.\nAs described in the threshold theorem, if the error rate is small enough, it is thought to be possible to use quantum error correction to suppress errors and decoherence. This allows the total calculation time to be longer than the decoherence time if the error correction scheme can correct errors faster than decoherence introduces them. An often-cited figure for the required error rate in each gate for fault-tolerant computation is 10\u22123, assuming the noise is depolarizing.\nMeeting this scalability condition is possible for a wide range of systems. However, the use of error correction brings with it the cost of a greatly increased number of required qubits. The number required to factor integers using Shor's algorithm is still polynomial, and thought to be between L and L2, where L is the number of digits in the number to be factored; error correction algorithms would inflate this figure by an additional factor of L. For a 1000-bit number, this implies a need for about 104 bits without error correction. With error correction, the figure would rise to about 107 bits. Computation time is about L2 or about 107 steps and at 1 MHz, about 10 seconds. However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.  Careful estimates show that at least 3 million physical qubits would factor 2,048-bit integer in 5 months on a fully error-corrected trapped-ion quantum computer. In terms of the number of physical qubits, to date, this remains the lowest estimate for practically useful integer factorization problem sizing 1,024-bit or larger. \nAnother approach to the stability-decoherence problem is to create a topological quantum computer with anyons, quasi-particles used as threads, and relying on braid theory to form stable logic gates.\n\n\n*** Quantum supremacy ***\nQuantum supremacy is a term coined by John Preskill referring to the engineering feat of demonstrating that a programmable quantum device can solve a problem beyond the capabilities of state-of-the-art classical computers. The problem need not be useful, so some view the quantum supremacy test only as a potential future benchmark.In October 2019, Google AI Quantum, with the help of NASA, became the first to claim to have achieved quantum supremacy by performing calculations on the Sycamore quantum computer more than 3,000,000 times faster than they could be done on Summit, generally considered the world's fastest computer. This claim has been subsequently challenged: IBM has stated that Summit can perform samples much faster than claimed, and researchers have since developed better algorithms for the sampling problem used to claim quantum supremacy, giving substantial reductions to the gap between Sycamore and classical supercomputers and even beating it.In December 2020, a group at USTC implemented a type of Boson sampling on 76 photons with a photonic quantum computer, Jiuzhang, to demonstrate quantum supremacy. The authors claim that a classical contemporary supercomputer would require a computational time of 600 million years to generate the number of samples their quantum processor can generate in 20 seconds.On November 16, 2021, at the quantum computing summit, IBM presented a 127-qubit microprocessor named IBM Eagle.\n\n\n*** Skepticism ***\nSome researchers have expressed skepticism that scalable quantum computers could ever be built, typically because of the issue of maintaining coherence at large scales, but also for other reasons.\nBill Unruh doubted the practicality of quantum computers in a paper published in 1994. Paul Davies argued that a 400-qubit computer would even come into conflict with the cosmological information bound implied by the holographic principle. Skeptics like Gil Kalai doubt that quantum supremacy will ever be achieved. Physicist Mikhail Dyakonov has expressed skepticism of quantum computing as follows:\n\n\"So the number of continuous parameters describing the state of such a useful quantum computer at any given moment must be... about 10300... Could we ever learn to control the more than 10300 continuously variable parameters defining the quantum state of such a system? My answer is simple. No, never.\"\n\n\n*** Candidates for physical realizations ***\nFor physically implementing a quantum computer, many different candidates are being pursued, among them (distinguished by the physical system used to realize the qubits):\n\nSuperconducting quantum computing (qubit implemented by the state of nonlinear resonant superconducting circuits containing Josephson junctions)\nTrapped ion quantum computer (qubit implemented by the internal state of trapped ions)\nNeutral atoms in optical lattices (qubit implemented by internal states of neutral atoms trapped in an optical lattice)\nQuantum dot computer, spin-based (e.g. the Loss-DiVincenzo quantum computer) (qubit given by the spin states of trapped electrons)\nQuantum dot computer, spatial-based (qubit given by electron position in double quantum dot)\nQuantum computing using engineered quantum wells, which could in principle enable the construction of a quantum computer that operates at room temperature\nCoupled quantum wire (qubit implemented by a pair of quantum wires coupled by a quantum point contact)\nNuclear magnetic resonance quantum computer (NMRQC) implemented with the nuclear magnetic resonance of molecules in solution, where qubits are provided by nuclear spins within the dissolved molecule and probed with radio waves\nSolid-state NMR Kane quantum computer (qubit realized by the nuclear spin state of phosphorus donors in silicon)\nVibrational quantum computer (qubits realized by vibrational superpositions in cold molecules)\nElectrons-on-helium quantum computer (qubit is the electron spin)\nCavity quantum electrodynamics (CQED) (qubit provided by the internal state of trapped atoms coupled to high-finesse cavities)\nMolecular magnet (qubit given by spin states)\nFullerene-based ESR quantum computer (qubit based on the electronic spin of atoms or molecules encased in fullerenes)\nNonlinear optical quantum computer (qubits realized by processing states of different modes of light through both linear and nonlinear elements)\nLinear optical quantum computer (LOQC) (qubits realized by processing states of different modes of light through linear elements e.g. mirrors, beam splitters and phase shifters). Quantum microprocessor based on laser photonics at room temperature made possible.\nDiamond-based quantum computer (qubit realized by the electronic or nuclear spin of nitrogen-vacancy centers in diamond)\nBose-Einstein condensate-based quantum computer\nTransistor-based quantum computer (string quantum computers with entrainment of positive holes using an electrostatic trap)\nRare-earth-metal-ion-doped inorganic crystal based quantum computer (qubit realized by the internal electronic state of dopants in optical fibers)\nMetallic-like carbon nanospheres-based quantum computerThe large number of candidates demonstrates that quantum computing, despite rapid progress, is still in its infancy.\n\n== Theory ==\n\n\n*** Computability ***\n\nAny computational problem solvable by a classical computer is also solvable by a quantum computer. Intuitively, this is because it is believed that all physical phenomena, including the operation of classical computers, can be described using quantum mechanics, which underlies the operation of quantum computers.\nConversely, any problem solvable by a quantum computer is also solvable by a classical computer. It is possible to simulate both quantum and classical computers manually with just some paper and a pen, if given enough time. More formally, any quantum computer can be simulated by a Turing machine. In other words, quantum computers provide no additional power over classical computers in terms of computability. This means that quantum computers cannot solve undecidable problems like the halting problem, and the existence of quantum computers does not disprove the Church\u2013Turing thesis.\n\n\n*** Complexity ***\n\nWhile quantum computers cannot solve any problems that classical computers cannot already solve, it is suspected that they can solve certain problems faster than classical computers. For instance, it is known that quantum computers can efficiently factor integers, while this is not believed to be the case for classical computers.\nThe class of problems that can be efficiently solved by a quantum computer with bounded error is called BQP, for \"bounded error, quantum, polynomial time\". More formally, BQP is the class of problems that can be solved by a polynomial-time quantum Turing machine with an error probability of at most 1/3. As a class of probabilistic problems, BQP is the quantum counterpart to BPP (\"bounded error, probabilistic, polynomial time\"), the class of problems that can be solved by polynomial-time probabilistic Turing machines with bounded error. It is known that \n  \n    \n      \n        \n          \n            B\n            P\n            P\n            \u2286\n            B\n            Q\n            P\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {BPP\\subseteq BQP}}}\n   and is widely suspected that \n  \n    \n      \n        \n          \n            B\n            Q\n            P\n            \u228a\n            B\n            P\n            P\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {BQP\\subsetneq BPP}}}\n  , which intuitively would mean that quantum computers are more powerful than classical computers in terms of time complexity.\n\nThe exact relationship of BQP to P, NP, and PSPACE is not known. However, it is known that \n  \n    \n      \n        \n          \n            P\n            \u2286\n            B\n            Q\n            P\n            \u2286\n            P\n            S\n            P\n            A\n            C\n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {P\\subseteq BQP\\subseteq PSPACE}}}\n  ; that is, all problems that can be efficiently solved by a deterministic classical computer can also be efficiently solved by a quantum computer, and all problems that can be efficiently solved by a quantum computer can also be solved by a deterministic classical computer with polynomial space resources. It is further suspected that BQP is a strict superset of P, meaning there are problems that are efficiently solvable by quantum computers that are not efficiently solvable by deterministic classical computers. For instance, integer factorization and the discrete logarithm problem are known to be in BQP and are suspected to be outside of P. On the relationship of BQP to NP, little is known beyond the fact that some NP problems that are believed not to be in P are also in BQP (integer factorization and the discrete logarithm problem are both in NP, for example). It is suspected that \n  \n    \n      \n        \n          \n            N\n            P\n            \u2288\n            B\n            Q\n            P\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {NP\\nsubseteq BQP}}}\n  ; that is, it is believed that there are efficiently checkable problems that are not efficiently solvable by a quantum computer. As a direct consequence of this belief, it is also suspected that BQP is disjoint from the class of NP-complete problems (if an NP-complete problem were in BQP, then it would follow from NP-hardness that all problems in NP are in BQP).The relationship of BQP to the basic classical complexity classes can be summarized as follows:\n\n  \n    \n      \n        \n          \n            P\n            \u2286\n            B\n            P\n            P\n            \u2286\n            B\n            Q\n            P\n            \u2286\n            P\n            P\n            \u2286\n            P\n            S\n            P\n            A\n            C\n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {P\\subseteq BPP\\subseteq BQP\\subseteq PP\\subseteq PSPACE}}}\n  It is also known that BQP is contained in the complexity class \n  \n    \n      \n        \n          \n            \n              #\n              P\n            \n          \n        \n      \n    \n    {\\displaystyle \\color {Blue}{\\mathsf {\\#P}}}\n   (or more precisely in the associated class of decision problems \n  \n    \n      \n        \n          \n            \n              P\n              \n                #\n                P\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {P^{\\#P}}}}\n  ), which is a subclass of PSPACE.\nIt has been speculated that further advances in physics could lead to even faster computers. For instance, it has been shown that a non-local hidden variable quantum computer based on Bohmian Mechanics could implement a search of an N-item database in at most \n  \n    \n      \n        O\n        (\n        \n          \n            N\n            \n              3\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle O({\\sqrt[{3}]{N}})}\n   steps, a slight speedup over Grover's algorithm, which runs in \n  \n    \n      \n        O\n        (\n        \n          \n            N\n          \n        \n        )\n      \n    \n    {\\displaystyle O({\\sqrt {N}})}\n   steps. Note, however, that neither search method would allow quantum computers to solve NP-complete problems in polynomial time. Theories of quantum gravity, such as M-theory and loop quantum gravity, may allow even faster computers to be built. However, defining computation in these theories is an open problem due to the problem of time; that is, within these physical theories there is currently no obvious way to describe what it means for an observer to submit input to a computer at one point in time and then receive output at a later point in time.\n\nQ: What is the basic unit of quantum information?",
    "context": "",
    "output": "A: The qubit is the basic unit of quantum information, similar to the bit in traditional digital electronics.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the basic unit of quantum information?",
      "answer": "The qubit is the basic unit of quantum information, similar to the bit in traditional digital electronics.",
      "context": "Quantum computing\n\n==Introduction==\nA quantum computer is a computer that exploits quantum mechanical phenomena.\nAt small scales, physical matter exhibits properties of both particles and waves, and quantum computing leverages this behavior using specialized hardware.\nClassical physics cannot explain the operation of these quantum devices, and a scalable quantum computer could perform some calculations exponentially faster than any modern \"classical\" computer.\nIn particular, a large-scale quantum computer could break widely used encryption schemes and aid physicists in performing physical simulations; however, the current state of the art is largely experimental and impractical.\nThe basic unit of information in quantum computing is the qubit, similar to the bit in traditional digital electronics. Unlike a classical bit, a qubit can exist in a superposition of its two \"basis\" states, which loosely means that it is in both states simultaneously. When measuring a qubit, the result is a probabilistic output of a classical bit. If a quantum computer manipulates the qubit in a particular way, wave interference effects can amplify the desired measurement results. The design of quantum algorithms involves creating procedures that allow a quantum computer to perform calculations efficiently and quickly.\nPhysically engineering high-quality qubits has proven challenging.\nIf a physical qubit is not sufficiently isolated from its environment, it suffers from quantum decoherence, introducing noise into calculations.\nNational governments have invested heavily in experimental research that aims to develop scalable qubits with longer coherence times and lower error rates.\nTwo of the most promising technologies are superconductors (which isolate an electrical current by eliminating electrical resistance) and ion traps (which confine a single atomic particle using electromagnetic fields).\nAny computational problem that can be solved by a classical computer can also be solved by a quantum computer. Conversely, any problem that can be solved by a quantum computer can also be solved by a classical computer, at least in principle given enough time. In other words, quantum computers obey the Church\u2013Turing thesis. This means that while quantum computers provide no additional advantages over classical computers in terms of computability, quantum algorithms for certain problems have significantly lower time complexities than corresponding known classical algorithms. Notably, quantum computers are believed to be able to solve many problems quickly that no classical computer could solve in any feasible amount of time\u2014a feat known as \"quantum supremacy.\" The study of the computational complexity of problems with respect to quantum computers is known as quantum complexity theory.\n\n== Quantum information processing ==\n\nComputer engineers typically describe a modern computer's operation in terms of classical electrodynamics.\nWithin these \"classical\" computers, some components (such as semiconductors and random number generators) may rely on quantum behavior, but these components are not isolated from their environment, so any quantum information quickly decoheres.\nWhile programmers may depend on probability theory when designing a randomized algorithm, quantum mechanical notions like superposition and interference are largely irrelevant for program analysis.\nQuantum programs, in contrast, rely on precise control of coherent quantum systems. Physicists describe these systems mathematically using linear algebra. Complex numbers model probability amplitudes, vectors model quantum states, and matrices model the operations that can be performed on these states. Programming a quantum computer is then a matter of composing operations in such a way that the resulting program computes a useful result in theory and is implementable in practice.\nThe prevailing model of quantum computation describes the computation in terms of a network of quantum logic gates. This model is a complex linear-algebraic generalization of boolean circuits.\n\n\n*** Quantum information ***\nThe qubit serves as the basic unit of quantum information.\nIt represents a two-state system, just like a classical bit, except that it can exist in a superposition of its two states.\nIn one sense, a superposition is like a probability distribution over the two values.\nHowever, a quantum computation can be influenced by both values at once, inexplicable by either state individually.\nIn this sense, a \"superposed\" qubit stores both values simultaneously.\nA two-dimensional vector mathematically represents a qubit state. Physicists typically use Dirac notation for quantum mechanical linear algebra, writing |\u03c8\u27e9 'ket psi' for a vector labeled \u03c8. Because a qubit is a two-state system, any qubit state takes the form \u03b1|0\u27e9 + \u03b2|1\u27e9, where |0\u27e9 and |1\u27e9 are the standard basis states, and \u03b1 and \u03b2 are the probability amplitudes. If either \u03b1 or \u03b2 is zero, the qubit is effectively a classical bit; when both are nonzero, the qubit is in superposition. Such a quantum state vector acts similarly to a (classical) probability vector, with one key difference: unlike probabilities, probability amplitudes are not necessarily positive numbers. Negative amplitudes allow for destructive wave interference.When a qubit is measured in the standard basis, the result is a classical bit.\nThe Born rule describes the norm-squared correspondence between amplitudes and probabilities\u2014when measuring a qubit \u03b1|0\u27e9 + \u03b2|1\u27e9, the state collapses to |0\u27e9 with probability |\u03b1|2, or to |1\u27e9 with probability |\u03b2|2.\nAny valid qubit state has coefficients \u03b1 and \u03b2 such that |\u03b1|2 + |\u03b2|2\n\n== Communication ==\n\nQuantum cryptography could potentially fulfill some of the functions of public key cryptography. Quantum-based cryptographic systems could, therefore, be more secure than traditional systems against quantum hacking.\n\n== Algorithms ==\nProgress in finding quantum algorithms typically focuses on this quantum circuit model, though exceptions like the quantum adiabatic algorithm exist. Quantum algorithms can be roughly categorized by the type of speedup achieved over corresponding classical algorithms.Quantum algorithms that offer more than a polynomial speedup over the best-known classical algorithm include Shor's algorithm for factoring and the related quantum algorithms for computing discrete logarithms, solving Pell's equation, and more generally solving the hidden subgroup problem for abelian finite groups. These algorithms depend on the primitive of the quantum Fourier transform. No mathematical proof has been found that shows that an equally fast classical algorithm cannot be discovered, but evidence suggests that this is unlikely. Certain oracle problems like Simon's problem and the Bernstein\u2013Vazirani problem do give provable speedups, though this is in the quantum query model, which is a restricted model where lower bounds are much easier to prove and doesn't necessarily translate to speedups for practical problems.\nOther problems, including the simulation of quantum physical processes from chemistry and solid-state physics, the approximation of certain Jones polynomials, and the quantum algorithm for linear systems of equations have quantum algorithms appearing to give super-polynomial speedups and are BQP-complete. Because these problems are BQP-complete, an equally fast classical algorithm for them would imply that no quantum algorithm gives a super-polynomial speedup, which is believed to be unlikely.Some quantum algorithms, like Grover's algorithm and amplitude amplification, give polynomial speedups over corresponding classical algorithms. Though these algorithms give comparably modest quadratic speedup, they are widely applicable and thus give speedups for a wide range of problems. Many examples of provable quantum speedups for query problems are related to Grover's algorithm, including Brassard, H\u00f8yer, and Tapp's algorithm for finding collisions in two-to-one functions, which uses Grover's algorithm, and Farhi, Goldstone, and Gutmann's algorithm for evaluating NAND trees, which is a variant of the search problem.\n\n\n*** Post-quantum cryptography ***\n\nA notable application of quantum computation is for attacks on cryptographic systems that are currently in use. Integer factorization, which underpins the security of public key cryptographic systems, is believed to be computationally infeasible with an ordinary computer for large integers if they are the product of few prime numbers (e.g., products of two 300-digit primes). By comparison, a quantum computer could solve this problem exponentially faster using Shor's algorithm to find its factors. This ability would allow a quantum computer to break many of the cryptographic systems in use today, in the sense that there would be a polynomial time (in the number of digits of the integer) algorithm for solving the problem. In particular, most of the popular public key ciphers are based on the difficulty of factoring integers or the discrete logarithm problem, both of which can be solved by Shor's algorithm. In particular, the RSA, Diffie\u2013Hellman, and elliptic curve Diffie\u2013Hellman algorithms could be broken. These are used to protect secure Web pages, encrypted email, and many other types of data. Breaking these would have significant ramifications for electronic privacy and security.\nIdentifying cryptographic systems that may be secure against quantum algorithms is an actively researched topic under the field of post-quantum cryptography. Some public-key algorithms are based on problems other than the integer factorization and discrete logarithm problems to which Shor's algorithm applies, like the McEliece cryptosystem based on a problem in coding theory. Lattice-based cryptosystems are also not known to be broken by quantum computers, and finding a polynomial time algorithm for solving the dihedral hidden subgroup problem, which would break many lattice based cryptosystems, is a well-studied open problem. It has been proven that applying Grover's algorithm to break a symmetric (secret key) algorithm by brute force requires time equal to roughly 2n/2 invocations of the underlying cryptographic algorithm, compared with roughly 2n in the classical case, meaning that symmetric key lengths are effectively halved: AES-256 would have the same security against an attack using Grover's algorithm that AES-128 has against classical brute-force search (see Key size).\n\n\n*** Search problems ***\n\nThe most well-known example of a problem that allows for a polynomial quantum speedup is unstructured search, which involves finding a marked item out of a list of \n  \n    \n      \n        n\n      \n    \n    {\\displaystyle n}\n   items in a database. This can be solved by Grover's algorithm using \n  \n    \n      \n        O\n        (\n        \n          \n            n\n          \n        \n        )\n      \n    \n    {\\displaystyle O({\\sqrt {n}})}\n   queries to the database, quadratically fewer than the \n  \n    \n      \n        \u03a9\n        (\n        n\n        )\n      \n    \n    {\\displaystyle \\Omega (n)}\n   queries required for classical algorithms. In this case, the advantage is not only provable but also optimal: it has been shown that Grover's algorithm gives the maximal possible probability of finding the desired element for any number of oracle lookups.\nProblems that can be efficiently addressed with Grover's algorithm have the following properties:\nThere is no searchable structure in the collection of possible answers,\nThe number of possible answers to check is the same as the number of inputs to the algorithm, and\nThere exists a boolean function that evaluates each input and determines whether it is the correct answerFor problems with all these properties, the running time of Grover's algorithm on a quantum computer scales as the square root of the number of inputs (or elements in the database), as opposed to the linear scaling of classical algorithms. A general class of problems to which Grover's algorithm can be applied is Boolean satisfiability problem, where the database through which the algorithm iterates is that of all possible answers. An example and possible application of this is a password cracker that attempts to guess a password. Breaking symmetric ciphers with this algorithm is of interest to government agencies.\n\n\n*** Simulation of quantum systems ***\n\nSince chemistry and nanotechnology rely on understanding quantum systems, and such systems are impossible to simulate in an efficient manner classically, quantum simulation may be an important application of quantum computing. Quantum simulation could also be used to simulate the behavior of atoms and particles at unusual conditions such as the reactions inside a collider.About 2% of the annual global energy output is used for nitrogen fixation to produce ammonia for the Haber process in the agricultural fertilizer industry (even though naturally occurring organisms also produce ammonia). Quantum simulations might be used to understand this process and increase the energy efficiency of production.\n\n\n*** Quantum annealing ***\nQuantum annealing relies on the adiabatic theorem to undertake calculations. A system is placed in the ground state for a simple Hamiltonian, which slowly evolves to a more complicated Hamiltonian whose ground state represents the solution to the problem in question. The adiabatic theorem states that if the evolution is slow enough the system will stay in its ground state at all times through the process. Adiabatic optimization may be helpful for solving computational biology problems.\n\n\n*** Machine learning ***\n\nSince quantum computers can produce outputs that classical computers cannot produce efficiently, and since quantum computation is fundamentally linear algebraic, some express hope in developing quantum algorithms that can speed up machine learning tasks.For example, the quantum algorithm for linear systems of equations, or \"HHL Algorithm\", named after its discoverers Harrow, Hassidim, and Lloyd, is believed to provide speedup over classical counterparts. Some research groups have recently explored the use of quantum annealing hardware for training Boltzmann machines and deep neural networks. \nDeep generative chemistry models emerge as powerful tools to expedite drug discovery. However, the immense size and complexity of the structural space of all possible drug-like molecules pose significant obstacles, which could be overcome in the future by quantum computers. Quantum computers are naturally good for solving complex quantum many-body problems and thus may be instrumental in applications involving quantum chemistry. Therefore, one can expect that quantum-enhanced generative models including quantum GANs may eventually be developed into ultimate generative chemistry algorithms.\n\n== Engineering ==\n\n\n*** Challenges ***\nThere are a number of technical challenges in building a large-scale quantum computer. Physicist David DiVincenzo has listed these requirements for a practical quantum computer:\nPhysically scalable to increase the number of qubits\nQubits that can be initialized to arbitrary values\nQuantum gates that are faster than decoherence time\nUniversal gate set\nQubits that can be read easily.Sourcing parts for quantum computers is also very difficult. Superconducting quantum computers, like those constructed by Google and IBM, need helium-3, a nuclear research byproduct, and special superconducting cables made only by the Japanese company Coax Co.The control of multi-qubit systems requires the generation and coordination of a large number of electrical signals with tight and deterministic timing resolution. This has led to the development of quantum controllers that enable interfacing with the qubits. Scaling these systems to support a growing number of qubits is an additional challenge.\n\n\n**** Decoherence ****\nOne of the greatest challenges involved with constructing quantum computers is controlling or removing quantum decoherence. This usually means isolating the system from its environment as interactions with the external world cause the system to decohere. However, other sources of decoherence also exist. Examples include the quantum gates, and the lattice vibrations and background thermonuclear spin of the physical system used to implement the qubits. Decoherence is irreversible, as it is effectively non-unitary, and is usually something that should be highly controlled, if not avoided. Decoherence times for candidate systems in particular, the transverse relaxation time T2 (for NMR and MRI technology, also called the dephasing time), typically range between nanoseconds and seconds at low temperature. Currently, some quantum computers require their qubits to be cooled to 20 millikelvin (usually using a dilution refrigerator) in order to prevent significant decoherence. A 2020 study argues that ionizing radiation such as cosmic rays can nevertheless cause certain systems to decohere within milliseconds.As a result, time-consuming tasks may render some quantum algorithms inoperable, as attempting to maintain the state of qubits for a long enough duration will eventually corrupt the superpositions.These issues are more difficult for optical approaches as the timescales are orders of magnitude shorter and an often-cited approach to overcoming them is optical pulse shaping. Error rates are typically proportional to the ratio of operating time to decoherence time, hence any operation must be completed much more quickly than the decoherence time.\nAs described in the threshold theorem, if the error rate is small enough, it is thought to be possible to use quantum error correction to suppress errors and decoherence. This allows the total calculation time to be longer than the decoherence time if the error correction scheme can correct errors faster than decoherence introduces them. An often-cited figure for the required error rate in each gate for fault-tolerant computation is 10\u22123, assuming the noise is depolarizing.\nMeeting this scalability condition is possible for a wide range of systems. However, the use of error correction brings with it the cost of a greatly increased number of required qubits. The number required to factor integers using Shor's algorithm is still polynomial, and thought to be between L and L2, where L is the number of digits in the number to be factored; error correction algorithms would inflate this figure by an additional factor of L. For a 1000-bit number, this implies a need for about 104 bits without error correction. With error correction, the figure would rise to about 107 bits. Computation time is about L2 or about 107 steps and at 1 MHz, about 10 seconds. However, the encoding and error-correction overheads increase the size of a real fault-tolerant quantum computer by several orders of magnitude.  Careful estimates show that at least 3 million physical qubits would factor 2,048-bit integer in 5 months on a fully error-corrected trapped-ion quantum computer. In terms of the number of physical qubits, to date, this remains the lowest estimate for practically useful integer factorization problem sizing 1,024-bit or larger. \nAnother approach to the stability-decoherence problem is to create a topological quantum computer with anyons, quasi-particles used as threads, and relying on braid theory to form stable logic gates.\n\n\n*** Quantum supremacy ***\nQuantum supremacy is a term coined by John Preskill referring to the engineering feat of demonstrating that a programmable quantum device can solve a problem beyond the capabilities of state-of-the-art classical computers. The problem need not be useful, so some view the quantum supremacy test only as a potential future benchmark.In October 2019, Google AI Quantum, with the help of NASA, became the first to claim to have achieved quantum supremacy by performing calculations on the Sycamore quantum computer more than 3,000,000 times faster than they could be done on Summit, generally considered the world's fastest computer. This claim has been subsequently challenged: IBM has stated that Summit can perform samples much faster than claimed, and researchers have since developed better algorithms for the sampling problem used to claim quantum supremacy, giving substantial reductions to the gap between Sycamore and classical supercomputers and even beating it.In December 2020, a group at USTC implemented a type of Boson sampling on 76 photons with a photonic quantum computer, Jiuzhang, to demonstrate quantum supremacy. The authors claim that a classical contemporary supercomputer would require a computational time of 600 million years to generate the number of samples their quantum processor can generate in 20 seconds.On November 16, 2021, at the quantum computing summit, IBM presented a 127-qubit microprocessor named IBM Eagle.\n\n\n*** Skepticism ***\nSome researchers have expressed skepticism that scalable quantum computers could ever be built, typically because of the issue of maintaining coherence at large scales, but also for other reasons.\nBill Unruh doubted the practicality of quantum computers in a paper published in 1994. Paul Davies argued that a 400-qubit computer would even come into conflict with the cosmological information bound implied by the holographic principle. Skeptics like Gil Kalai doubt that quantum supremacy will ever be achieved. Physicist Mikhail Dyakonov has expressed skepticism of quantum computing as follows:\n\n\"So the number of continuous parameters describing the state of such a useful quantum computer at any given moment must be... about 10300... Could we ever learn to control the more than 10300 continuously variable parameters defining the quantum state of such a system? My answer is simple. No, never.\"\n\n\n*** Candidates for physical realizations ***\nFor physically implementing a quantum computer, many different candidates are being pursued, among them (distinguished by the physical system used to realize the qubits):\n\nSuperconducting quantum computing (qubit implemented by the state of nonlinear resonant superconducting circuits containing Josephson junctions)\nTrapped ion quantum computer (qubit implemented by the internal state of trapped ions)\nNeutral atoms in optical lattices (qubit implemented by internal states of neutral atoms trapped in an optical lattice)\nQuantum dot computer, spin-based (e.g. the Loss-DiVincenzo quantum computer) (qubit given by the spin states of trapped electrons)\nQuantum dot computer, spatial-based (qubit given by electron position in double quantum dot)\nQuantum computing using engineered quantum wells, which could in principle enable the construction of a quantum computer that operates at room temperature\nCoupled quantum wire (qubit implemented by a pair of quantum wires coupled by a quantum point contact)\nNuclear magnetic resonance quantum computer (NMRQC) implemented with the nuclear magnetic resonance of molecules in solution, where qubits are provided by nuclear spins within the dissolved molecule and probed with radio waves\nSolid-state NMR Kane quantum computer (qubit realized by the nuclear spin state of phosphorus donors in silicon)\nVibrational quantum computer (qubits realized by vibrational superpositions in cold molecules)\nElectrons-on-helium quantum computer (qubit is the electron spin)\nCavity quantum electrodynamics (CQED) (qubit provided by the internal state of trapped atoms coupled to high-finesse cavities)\nMolecular magnet (qubit given by spin states)\nFullerene-based ESR quantum computer (qubit based on the electronic spin of atoms or molecules encased in fullerenes)\nNonlinear optical quantum computer (qubits realized by processing states of different modes of light through both linear and nonlinear elements)\nLinear optical quantum computer (LOQC) (qubits realized by processing states of different modes of light through linear elements e.g. mirrors, beam splitters and phase shifters). Quantum microprocessor based on laser photonics at room temperature made possible.\nDiamond-based quantum computer (qubit realized by the electronic or nuclear spin of nitrogen-vacancy centers in diamond)\nBose-Einstein condensate-based quantum computer\nTransistor-based quantum computer (string quantum computers with entrainment of positive holes using an electrostatic trap)\nRare-earth-metal-ion-doped inorganic crystal based quantum computer (qubit realized by the internal electronic state of dopants in optical fibers)\nMetallic-like carbon nanospheres-based quantum computerThe large number of candidates demonstrates that quantum computing, despite rapid progress, is still in its infancy.\n\n== Theory ==\n\n\n*** Computability ***\n\nAny computational problem solvable by a classical computer is also solvable by a quantum computer. Intuitively, this is because it is believed that all physical phenomena, including the operation of classical computers, can be described using quantum mechanics, which underlies the operation of quantum computers.\nConversely, any problem solvable by a quantum computer is also solvable by a classical computer. It is possible to simulate both quantum and classical computers manually with just some paper and a pen, if given enough time. More formally, any quantum computer can be simulated by a Turing machine. In other words, quantum computers provide no additional power over classical computers in terms of computability. This means that quantum computers cannot solve undecidable problems like the halting problem, and the existence of quantum computers does not disprove the Church\u2013Turing thesis.\n\n\n*** Complexity ***\n\nWhile quantum computers cannot solve any problems that classical computers cannot already solve, it is suspected that they can solve certain problems faster than classical computers. For instance, it is known that quantum computers can efficiently factor integers, while this is not believed to be the case for classical computers.\nThe class of problems that can be efficiently solved by a quantum computer with bounded error is called BQP, for \"bounded error, quantum, polynomial time\". More formally, BQP is the class of problems that can be solved by a polynomial-time quantum Turing machine with an error probability of at most 1/3. As a class of probabilistic problems, BQP is the quantum counterpart to BPP (\"bounded error, probabilistic, polynomial time\"), the class of problems that can be solved by polynomial-time probabilistic Turing machines with bounded error. It is known that \n  \n    \n      \n        \n          \n            B\n            P\n            P\n            \u2286\n            B\n            Q\n            P\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {BPP\\subseteq BQP}}}\n   and is widely suspected that \n  \n    \n      \n        \n          \n            B\n            Q\n            P\n            \u228a\n            B\n            P\n            P\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {BQP\\subsetneq BPP}}}\n  , which intuitively would mean that quantum computers are more powerful than classical computers in terms of time complexity.\n\nThe exact relationship of BQP to P, NP, and PSPACE is not known. However, it is known that \n  \n    \n      \n        \n          \n            P\n            \u2286\n            B\n            Q\n            P\n            \u2286\n            P\n            S\n            P\n            A\n            C\n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {P\\subseteq BQP\\subseteq PSPACE}}}\n  ; that is, all problems that can be efficiently solved by a deterministic classical computer can also be efficiently solved by a quantum computer, and all problems that can be efficiently solved by a quantum computer can also be solved by a deterministic classical computer with polynomial space resources. It is further suspected that BQP is a strict superset of P, meaning there are problems that are efficiently solvable by quantum computers that are not efficiently solvable by deterministic classical computers. For instance, integer factorization and the discrete logarithm problem are known to be in BQP and are suspected to be outside of P. On the relationship of BQP to NP, little is known beyond the fact that some NP problems that are believed not to be in P are also in BQP (integer factorization and the discrete logarithm problem are both in NP, for example). It is suspected that \n  \n    \n      \n        \n          \n            N\n            P\n            \u2288\n            B\n            Q\n            P\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {NP\\nsubseteq BQP}}}\n  ; that is, it is believed that there are efficiently checkable problems that are not efficiently solvable by a quantum computer. As a direct consequence of this belief, it is also suspected that BQP is disjoint from the class of NP-complete problems (if an NP-complete problem were in BQP, then it would follow from NP-hardness that all problems in NP are in BQP).The relationship of BQP to the basic classical complexity classes can be summarized as follows:\n\n  \n    \n      \n        \n          \n            P\n            \u2286\n            B\n            P\n            P\n            \u2286\n            B\n            Q\n            P\n            \u2286\n            P\n            P\n            \u2286\n            P\n            S\n            P\n            A\n            C\n            E\n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {P\\subseteq BPP\\subseteq BQP\\subseteq PP\\subseteq PSPACE}}}\n  It is also known that BQP is contained in the complexity class \n  \n    \n      \n        \n          \n            \n              #\n              P\n            \n          \n        \n      \n    \n    {\\displaystyle \\color {Blue}{\\mathsf {\\#P}}}\n   (or more precisely in the associated class of decision problems \n  \n    \n      \n        \n          \n            \n              P\n              \n                #\n                P\n              \n            \n          \n        \n      \n    \n    {\\displaystyle {\\mathsf {P^{\\#P}}}}\n  ), which is a subclass of PSPACE.\nIt has been speculated that further advances in physics could lead to even faster computers. For instance, it has been shown that a non-local hidden variable quantum computer based on Bohmian Mechanics could implement a search of an N-item database in at most \n  \n    \n      \n        O\n        (\n        \n          \n            N\n            \n              3\n            \n          \n        \n        )\n      \n    \n    {\\displaystyle O({\\sqrt[{3}]{N}})}\n   steps, a slight speedup over Grover's algorithm, which runs in \n  \n    \n      \n        O\n        (\n        \n          \n            N\n          \n        \n        )\n      \n    \n    {\\displaystyle O({\\sqrt {N}})}\n   steps. Note, however, that neither search method would allow quantum computers to solve NP-complete problems in polynomial time. Theories of quantum gravity, such as M-theory and loop quantum gravity, may allow even faster computers to be built. However, defining computation in these theories is an open problem due to the problem of time; that is, within these physical theories there is currently no obvious way to describe what it means for an observer to submit input to a computer at one point in time and then receive output at a later point in time."
    }
  },
  {
    "instruction": "Gamaredon\n\n==Introduction==\nGamaredon, also known as Primitive Bear and Actinium (by Microsoft) is a Russian advanced persistent threat that has been active since at least 2013.\n\n== Motivation ==\nCyber espionage appears to be the main goal of the group,; unlike most APTs, Gamaredon broadly targets all users all over the globe (in addition to also focusing on certain victims, especially Ukrainian organizations) and appears to provide services for other APTs. For example, the InvisiMole threat group has attacked select systems that Gamaredon had earlier compromised and fingerprinted.\n\n== Tactics ==\nThe group frequently uses spear phishing techniques with malicious code attachments that download remote templates containing malware.Malware used by the group includes Pterodo, PowerPunch, ObfuMerry, ObfuBerry, DilongTrash, DinoTrain, and DesertDown.\n\n== Ukraine ==\n\nOn 19 January 2022, they attempted to compromise a Western government entity in Ukraine.\n\nQ: Who are the typical targets of Gamaredon?",
    "context": "",
    "output": "A: Unlike most APTs, Gamaredon broadly targets all users all over the globe, with a specific focus on Ukrainian organizations.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who are the typical targets of Gamaredon?",
      "answer": "Unlike most APTs, Gamaredon broadly targets all users all over the globe, with a specific focus on Ukrainian organizations.",
      "context": "Gamaredon\n\n==Introduction==\nGamaredon, also known as Primitive Bear and Actinium (by Microsoft) is a Russian advanced persistent threat that has been active since at least 2013.\n\n== Motivation ==\nCyber espionage appears to be the main goal of the group,; unlike most APTs, Gamaredon broadly targets all users all over the globe (in addition to also focusing on certain victims, especially Ukrainian organizations) and appears to provide services for other APTs. For example, the InvisiMole threat group has attacked select systems that Gamaredon had earlier compromised and fingerprinted.\n\n== Tactics ==\nThe group frequently uses spear phishing techniques with malicious code attachments that download remote templates containing malware.Malware used by the group includes Pterodo, PowerPunch, ObfuMerry, ObfuBerry, DilongTrash, DinoTrain, and DesertDown.\n\n== Ukraine ==\n\nOn 19 January 2022, they attempted to compromise a Western government entity in Ukraine."
    }
  },
  {
    "instruction": "CESG Listed Adviser Scheme\n\n==Introduction==\nThe CESG Listed Adviser Scheme was a programme run by CESG, to provide a pool of information assurance consultants to government departments and other public-sector bodies in the UK.CLAS consultants advised on systems that handle protectively marked information, up to and including SECRET; for instance, they may have advised on GSI accreditation. CLAS consultants held a security clearance, at least SC.CLAS consultants developed risk assessments in line with IS1, and risk management and accreditation document sets (RMADS) in line with IS2.In 2011, entry to CLAS was closed while a replacement system was being designed.\nBy 2013 'new' CLAS was implemented and open for membership. 'New' CLAS required that members were CESG Certified Professionals.\nCLAS was closed in January 2016.\n\n== CESG Certified Professionals (CCP) ==\nThe CESG Certified Professional (CCP) scheme recognises the expertise of those working in the information assurance and cyber security arenas in both government and industry. It sets the standard for IA professionals working in this sector and provides a rigorous and independent assessment of the competence of IA professionals. CCP status is an endorsement of IA expertise and confirms that information risk in support of your business is managed in a balanced and pragmatic way.\nNow that CLAS has closed, CCP is the only CESG-approved credential that applies to individual professionals rather than companies.\nQuestion: What level of security clearance did CLAS consultants hold?",
    "context": "",
    "output": "Answer: CLAS consultants held a security clearance of at least SC, ensuring they could work on sensitive government projects.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What level of security clearance did CLAS consultants hold?",
      "answer": "CLAS consultants held a security clearance of at least SC, ensuring they could work on sensitive government projects.",
      "context": "CESG Listed Adviser Scheme\n\n==Introduction==\nThe CESG Listed Adviser Scheme was a programme run by CESG, to provide a pool of information assurance consultants to government departments and other public-sector bodies in the UK.CLAS consultants advised on systems that handle protectively marked information, up to and including SECRET; for instance, they may have advised on GSI accreditation. CLAS consultants held a security clearance, at least SC.CLAS consultants developed risk assessments in line with IS1, and risk management and accreditation document sets (RMADS) in line with IS2.In 2011, entry to CLAS was closed while a replacement system was being designed.\nBy 2013 'new' CLAS was implemented and open for membership. 'New' CLAS required that members were CESG Certified Professionals.\nCLAS was closed in January 2016.\n\n== CESG Certified Professionals (CCP) ==\nThe CESG Certified Professional (CCP) scheme recognises the expertise of those working in the information assurance and cyber security arenas in both government and industry. It sets the standard for IA professionals working in this sector and provides a rigorous and independent assessment of the competence of IA professionals. CCP status is an endorsement of IA expertise and confirms that information risk in support of your business is managed in a balanced and pragmatic way.\nNow that CLAS has closed, CCP is the only CESG-approved credential that applies to individual professionals rather than companies."
    }
  },
  {
    "instruction": "Write an answer to the following question: What kind of data did Tiversa's EagleVision X1 software look for on the deep web?",
    "context": "",
    "output": "EagleVision X1 looked for sensitive data on the deep web, which could include personal information, financial data, and other confidential information that could pose a security risk to businesses.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What kind of data did Tiversa's EagleVision X1 software look for on the deep web?",
      "answer": "EagleVision X1 looked for sensitive data on the deep web, which could include personal information, financial data, and other confidential information that could pose a security risk to businesses."
    }
  },
  {
    "instruction": "Common Criteria\n\n==Introduction==\nThe Common Criteria for Information Technology Security Evaluation (referred to as Common Criteria or CC) is an international standard (ISO/IEC 15408) for computer security certification. It is currently in version 3.1 revision 5.Common Criteria is a framework in which computer system users can specify their security functional and assurance requirements (SFRs and SARs respectively) in a Security Target (ST), and may be taken from Protection Profiles (PPs). Vendors can then implement  or make claims about the security attributes of their products, and testing laboratories can evaluate the products to determine if they actually meet the claims. In other words, Common Criteria provides assurance that the process of specification, implementation and evaluation of a computer security product has been conducted in a rigorous and standard and repeatable manner at a level that is commensurate with the target environment for use. Common Criteria maintains a list of certified products, including operating systems, access control systems, databases, and key management systems.\n\n\n\n== Key concepts ==\nCommon Criteria evaluations are performed on computer security products and systems.\n\nTarget of Evaluation (TOE) \u2013 the product or system that is the subject of the evaluation. The evaluation serves to validate claims made about the target. To be of practical use, the evaluation must verify the target's security features. This is done through the following:\nProtection Profile (PP) \u2013 a document, typically created by a user or user community, which identifies security requirements for a class of security devices (for example, smart cards used to provide digital signatures, or network firewalls) relevant to that user for a particular purpose. Product vendors can choose to implement products that comply with one or more PPs, and have their products evaluated against those PPs. In such a case, a PP may serve as a template for the product's ST (Security Target, as defined below), or the authors of the ST will at least ensure that all requirements in relevant PPs also appear in the target's ST document. Customers looking for particular types of products can focus on those certified against the PP that meets their requirements.\nSecurity Target (ST) \u2013 the document that identifies the security properties of the target of evaluation. The ST may claim conformance with one or more PPs. The TOE is evaluated against the SFRs (Security Functional Requirements. Again, see below) established in its ST, no more and no less. This allows vendors to tailor the evaluation to accurately match the intended capabilities of their product. This means that a network firewall does not have to meet the same functional requirements as a database management system, and that different firewalls may in fact be evaluated against completely different lists of requirements. The ST is usually published so that potential customers may determine the specific security features that have been certified by the evaluation.\nSecurity Functional Requirements (SFRs) \u2013 specify individual security functions which may be provided by a product. The Common Criteria presents a standard catalogue of such functions. For example, a SFR may state how a user acting a particular role might be authenticated. The list of SFRs can vary from one evaluation to the next, even if two targets are the same type of product.  Although Common Criteria does not prescribe any SFRs to be included in an ST, it identifies dependencies where the correct operation of one function (such as the ability to limit access according to roles) is dependent on another (such as the ability to identify individual roles).The evaluation process also tries to establish the level of confidence that may be placed in the product's security features through quality assurance processes:\n\nSecurity Assurance Requirements (SARs) \u2013 descriptions of the measures taken during development and evaluation of the product to assure compliance with the claimed security functionality. For example, an evaluation may require that all source code is kept in a change management system, or that full functional testing is performed. The Common Criteria provides a catalogue of these, and the requirements may vary from one evaluation to the next. The requirements for particular targets or types of products are documented in the ST and PP, respectively.\nEvaluation Assurance Level (EAL) \u2013 the numerical rating describing the depth and rigor of an evaluation. Each EAL corresponds to a package of security assurance requirements (SARs, see above) which covers the complete development of a product, with a given level of strictness. Common Criteria lists seven levels, with EAL 1 being the most basic (and therefore cheapest to implement and evaluate) and EAL 7 being the most stringent (and most expensive). Normally, an ST or PP author will not select assurance requirements individually but choose one of these packages, possibly 'augmenting' requirements in a few areas with requirements from a higher level. Higher EALs do not necessarily imply \"better security\", they only mean that the claimed security assurance of the TOE has been more extensively verified.So far, most PPs and most evaluated STs/certified products have been for IT components (e.g., firewalls, operating systems, smart cards).\nCommon Criteria certification is sometimes specified for IT procurement. Other standards containing, e.g., interoperation, system management, user training, supplement CC and other product standards. Examples include the ISO/IEC 27002 and the German IT baseline protection.\nDetails of cryptographic implementation within the TOE are outside the scope of the CC. Instead, national standards, like FIPS 140-2, give the specifications for cryptographic modules, and various standards specify the cryptographic algorithms in use.\nMore recently, PP authors are including cryptographic requirements for CC evaluations that would typically be covered by FIPS 140-2 evaluations, broadening the bounds of the CC through scheme-specific interpretations.\nSome national evaluation schemes are phasing out EAL-based evaluations and only accept products for evaluation that claim strict conformance with an approved PP. The United States currently only allows PP-based evaluations. Canada is in the process of phasing out EAL-based evaluations.\n\n== Testing organizations ==\nAll testing laboratories must comply with ISO/IEC 17025, and certification bodies will normally be approved against ISO/IEC 17065.\nThe compliance with ISO/IEC 17025 is typically demonstrated to a National approval authority:\n\nIn Canada, the Standards Council of Canada (SCC) under Program for the Accreditation of Laboratories (PALCAN) accredits Common Criteria Evaluation Facilities (CCEF)\nIn France, the Comit\u00e9 fran\u00e7ais d'accr\u00e9ditation (COFRAC) accredits Common Criteria evaluation facilities, commonly called Centre d'\u00e9valuation de la s\u00e9curit\u00e9 des technologies de l'information (CESTI). Evaluations are done according to norms and standards specified by the Agence nationale de la s\u00e9curit\u00e9 des syst\u00e8mes d'information (ANSSI).\nIn Italy, the OCSI (Organismo di Certificazione della Sicurezza Informatica accredits Common Criteria evaluation laboratories\nIn India, the STQC Directorate of the Ministry of Electronics and Information Technology evaluates and certifies IT products at assurance levels EAL 1 through EAL4.\nIn the UK the United Kingdom Accreditation Service (UKAS) used to accredit Commercial Evaluation Facilities (CLEF); the UK is since 2019 only a consumer in the CC ecosystem\nIn the US, the National Institute of Standards and Technology (NIST) National Voluntary Laboratory Accreditation Program (NVLAP) accredits Common Criteria Testing Laboratories (CCTL)\nIn Germany, the Bundesamt f\u00fcr Sicherheit in der Informationstechnik (BSI)\nIn Spain, the National Cryptologic Center (CCN) accredits Common Criteria Testing Laboratories operating in the Spanish Scheme.\nIn The Netherlands, the Netherlands scheme for Certification in the Area of IT Security (NSCIB) accredits IT Security Evaluation Facilities (ITSEF).\nIn Sweden, the Swedish Certification Body for IT Security (CSEC) licenses IT Security Evaluation Facilities (ITSEF).Characteristics of these organizations were examined and presented at ICCC 10.\n\n== Mutual recognition arrangement ==\nAs well as the Common Criteria standard, there is also a sub-treaty level Common Criteria MRA (Mutual Recognition Arrangement), whereby each party thereto recognizes evaluations against the Common Criteria standard done by other parties. Originally signed in 1998 by Canada, France, Germany, the United Kingdom and the United States, Australia and New Zealand joined 1999, followed by Finland, Greece, Israel, Italy, the Netherlands, Norway and Spain in 2000. The Arrangement has since been renamed Common Criteria Recognition Arrangement (CCRA) and membership continues to expand.  Within the CCRA only evaluations up to EAL 2 are mutually recognized (Including augmentation with flaw remediation).  The European countries within the SOGIS-MRA typically recognize higher EALs as well. Evaluations at EAL5 and above tend to involve the security requirements of the host nation's government.\nIn September 2012, a majority of members of the CCRA produced a vision statement whereby mutual recognition of CC evaluated products will be lowered to EAL 2 (Including augmentation with flaw remediation). Further, this vision indicates a move away from assurance levels altogether and evaluations will be confined to conformance with Protection Profiles that have no stated assurance level.  This will be achieved through technical working groups developing worldwide PPs, and as yet a transition period has not been fully determined.\nOn July 2, 2014, a new CCRA was ratified per the goals outlined within the 2012 vision statement. Major changes to the Arrangement include:\n\nRecognition of evaluations against only a collaborative Protection Profile (cPP) or Evaluation Assurance Levels 1 through 2 and ALC_FLR.\nThe emergence of international Technical Communities (iTC), groups of technical experts charged with the creation of cPPs.\nA transition plan from the previous CCRA, including recognition of certificates issued under the previous version of the Arrangement.\n\n== Issues ==\n\n\n*** Requirements ***\nCommon Criteria is very generic; it does not directly provide a list of product security requirements or features for specific (classes of) products: this follows the approach taken by ITSEC, but has been a source of debate to those used to the more prescriptive approach of other earlier standards such as TCSEC and FIPS 140-2.\n\n\n*** Value of certification ***\nCommon Criteria certification cannot guarantee security, but it can ensure that claims about the security attributes of the evaluated product were independently verified. In other words, products evaluated against a Common Criteria standard exhibit a clear chain of evidence that the process of specification, implementation, and evaluation has been conducted in a rigorous and standard manner.\nVarious Microsoft Windows versions, including Windows Server 2003 and Windows XP, have been certified, but security patches to address security vulnerabilities are still getting published by Microsoft for these Windows systems. This is possible because the process of obtaining a Common Criteria certification allows a vendor to restrict the analysis to certain security features and to make certain assumptions about the operating environment and the strength of threats faced by the product in that environment. Additionally, the CC recognizes a need to limit the scope of evaluation in order to provide cost-effective and useful security certifications, such that evaluated products are examined to a level of detail specified by the assurance level or PP.  Evaluations activities are therefore only performed to a certain depth, use of time, and resources and offer reasonable assurance for the intended environment.\nIn the Microsoft case, the assumptions include A.PEER: \n\n\"Any other systems with which the TOE communicates are assumed to be under the same management control and operate under the same security policy constraints. The TOE is applicable to networked or distributed environments only if the entire network operates under the same constraints and resides within a single management domain. There are no security requirements that address the need to trust external systems or the communications links to such systems.\"\n\nThis assumption is contained in the Controlled Access Protection Profile (CAPP) to which their products adhere. Based on this and other assumptions, which may not be realistic for the common use of general-purpose operating systems, the claimed security functions of the Windows products are evaluated. Thus they should only be considered secure in the assumed, specified circumstances, also known as the evaluated configuration.\nWhether you run Microsoft Windows in the precise evaluated configuration or not, you should apply Microsoft's security patches for the vulnerabilities in Windows as they continue to appear. If any of these security vulnerabilities are exploitable in the product's evaluated configuration, the product's Common Criteria certification should be voluntarily withdrawn by the vendor. Alternatively, the vendor should re-evaluate the product to include the application of patches to fix the security vulnerabilities within the evaluated configuration. Failure by the vendor to take either of these steps would result in involuntary withdrawal of the product's certification by the certification body of the country in which the product was evaluated.\nThe certified Microsoft Windows versions remain at EAL4+ without including the application of any Microsoft security vulnerability patches in their evaluated configuration. This shows both the limitation and strength of an evaluated configuration.\n\n\n*** Criticisms ***\nIn August 2007, Government Computing News (GCN) columnist William Jackson critically examined Common Criteria methodology and its US implementation by the Common Criteria Evaluation and Validation Scheme (CCEVS). In the column executives from the security industry, researchers, and representatives from the National Information Assurance Partnership (NIAP) were interviewed. Objections outlined in the article include:\n\nEvaluation is a costly process (often measured in hundreds of thousands of US dollars) \u2013 and the vendor's return on that investment is not necessarily a more secure product.\nEvaluation focuses primarily on assessing the evaluation documentation, not on the actual security, technical correctness or merits of the product itself. For U.S. evaluations, only at EAL5 and higher do experts from the National Security Agency participate in the analysis; and only at EAL7 is full source code analysis required.\nThe effort and time necessary to prepare evaluation evidence and other evaluation-related documentation is so cumbersome that by the time the work is completed, the product in evaluation is generally obsolete.\nIndustry input, including that from organizations such as the Common Criteria Vendor's Forum, generally has little impact on the process as a whole.In a 2006 research paper, computer specialist David A. Wheeler suggested that the Common Criteria process discriminates against free and open-source software (FOSS)-centric organizations and development models. Common Criteria assurance requirements tend to be inspired by the traditional waterfall software development methodology. In contrast, much FOSS software is produced using modern agile paradigms. Although some have argued that both paradigms do not align well, others have attempted to reconcile both paradigms. Political scientist Jan Kallberg raised concerns over the lack of control over the actual production of the products once they are certified, the absence of a permanently staffed organizational body that monitors compliance, and the idea that the trust in the Common Criteria IT-security certifications will be maintained across geopolitical boundaries.In 2017, the ROCA vulnerability was found in a list of Common Criteria certified smart card products. The vulnerability highlighted several shortcomings of Common Criteria certification scheme:\nThe vulnerability resided in a homegrown RSA key generation algorithm that has not been published and analyzed by the cryptanalysis community. However, the testing laboratory T\u00dcV Informationstechnik GmbH (T\u00dcViT) in Germany approved its use and the certification body BSI in Germany issued Common Criteria certificates for the vulnerable products. The Security Target of the evaluated product claimed that RSA keys are generated according to the standard algorithm. In response to this vulnerability, BSI now plans to improve transparency by requiring that the certification report at least specifies if the implemented proprietary cryptography is not exactly conformant to a recommended standard. BSI does not plan on requiring the proprietary algorithm to be published in any way.\nEven though the certification bodies are now aware that the security claims specified in the Common Criteria certificates do not hold anymore, neither ANSSI nor BSI have revoked the corresponding certificates. According to BSI, a certificate can only be withdrawn when it was issued under misconception, e.g., when it turns out that wrong evidence was submitted. After a certificate is issued, it must be presumed that the validity of the certificate decreases over time by improved and new attacks being discovered. Certification bodies can issue maintenance reports and even perform a re-certification of the product. These activities, however, have to be initiated and sponsored by the vendor.\nWhile several Common Criteria certified products have been affected by the ROCA flaw, vendors' responses in the context of certification have been different. For some products a maintenance report was issued, which states that only RSA keys with a length of 3072 and 3584 bits have a security level of at least 100 bits, while for some products the maintenance report does not mention that the change to the TOE affects certified cryptographic security functionality, but concludes that the change is at the level of guidance documentation and has no effect on assurance.\nAccording BSI, the users of the certified end products should have been informed of the ROCA vulnerability by the vendors. This information, however, did not reach in a timely manner the Estonian authorities who had deployed the vulnerable product on more than 750,000 Estonian identity cards.\n\n== Alternative approaches ==\nThroughout the lifetime of CC, it has not been universally adopted even by the creator nations, with, in particular, cryptographic approvals being handled separately, such as by the Canadian / US implementation of FIPS-140, and the CESG Assisted Products Scheme (CAPS) in the UK.\nThe UK has also produced a number of alternative schemes when the timescales, costs and overheads of mutual recognition have been found to be impeding the operation of the market:\n\nThe CESG System Evaluation (SYSn) and Fast Track Approach (FTA) schemes for assurance of government systems rather than generic products and services, which have now been merged into the CESG Tailored Assurance Service (CTAS) \nThe CESG Claims Tested Mark (CCT Mark), which is aimed at handling less exhaustive assurance requirements for products and services in a cost and time efficient manner.In early 2011, NSA/CSS published a paper by Chris Salter, which proposed a Protection Profile oriented approach towards evaluation. In this approach, communities of interest form around technology types which in turn develop protection profiles that define the evaluation methodology for the technology type. The objective is a more robust evaluation. There is some concern that this may have a negative impact on mutual recognition.In Sept of 2012, the Common Criteria published a Vision Statement implementing to a large extent Chris Salter's thoughts from the previous year.  Key elements of the Vision included:\n\nTechnical Communities will be focused on authoring Protection Profiles (PP) that support their goal of reasonable, comparable, reproducible and cost-effective evaluation results\nEvaluations should be done against these PP's if possible; if not mutual recognition of Security Target evaluations would be limited to EAL2.\n\nQ: How does Common Criteria standard facilitate mutual recognition of Common Criteria evaluated products?",
    "context": "",
    "output": "A: The Common Criteria standard, along with the Common Criteria MRA (Mutual Recognition Arrangement), enables mutual recognition of Common Criteria evaluated products by each party thereto, whereby they recognize evaluations against the Common Criteria standard done by other parties.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Common Criteria standard facilitate mutual recognition of Common Criteria evaluated products?",
      "answer": "The Common Criteria standard, along with the Common Criteria MRA (Mutual Recognition Arrangement), enables mutual recognition of Common Criteria evaluated products by each party thereto, whereby they recognize evaluations against the Common Criteria standard done by other parties.",
      "context": "Common Criteria\n\n==Introduction==\nThe Common Criteria for Information Technology Security Evaluation (referred to as Common Criteria or CC) is an international standard (ISO/IEC 15408) for computer security certification. It is currently in version 3.1 revision 5.Common Criteria is a framework in which computer system users can specify their security functional and assurance requirements (SFRs and SARs respectively) in a Security Target (ST), and may be taken from Protection Profiles (PPs). Vendors can then implement  or make claims about the security attributes of their products, and testing laboratories can evaluate the products to determine if they actually meet the claims. In other words, Common Criteria provides assurance that the process of specification, implementation and evaluation of a computer security product has been conducted in a rigorous and standard and repeatable manner at a level that is commensurate with the target environment for use. Common Criteria maintains a list of certified products, including operating systems, access control systems, databases, and key management systems.\n\n\n\n== Key concepts ==\nCommon Criteria evaluations are performed on computer security products and systems.\n\nTarget of Evaluation (TOE) \u2013 the product or system that is the subject of the evaluation. The evaluation serves to validate claims made about the target. To be of practical use, the evaluation must verify the target's security features. This is done through the following:\nProtection Profile (PP) \u2013 a document, typically created by a user or user community, which identifies security requirements for a class of security devices (for example, smart cards used to provide digital signatures, or network firewalls) relevant to that user for a particular purpose. Product vendors can choose to implement products that comply with one or more PPs, and have their products evaluated against those PPs. In such a case, a PP may serve as a template for the product's ST (Security Target, as defined below), or the authors of the ST will at least ensure that all requirements in relevant PPs also appear in the target's ST document. Customers looking for particular types of products can focus on those certified against the PP that meets their requirements.\nSecurity Target (ST) \u2013 the document that identifies the security properties of the target of evaluation. The ST may claim conformance with one or more PPs. The TOE is evaluated against the SFRs (Security Functional Requirements. Again, see below) established in its ST, no more and no less. This allows vendors to tailor the evaluation to accurately match the intended capabilities of their product. This means that a network firewall does not have to meet the same functional requirements as a database management system, and that different firewalls may in fact be evaluated against completely different lists of requirements. The ST is usually published so that potential customers may determine the specific security features that have been certified by the evaluation.\nSecurity Functional Requirements (SFRs) \u2013 specify individual security functions which may be provided by a product. The Common Criteria presents a standard catalogue of such functions. For example, a SFR may state how a user acting a particular role might be authenticated. The list of SFRs can vary from one evaluation to the next, even if two targets are the same type of product.  Although Common Criteria does not prescribe any SFRs to be included in an ST, it identifies dependencies where the correct operation of one function (such as the ability to limit access according to roles) is dependent on another (such as the ability to identify individual roles).The evaluation process also tries to establish the level of confidence that may be placed in the product's security features through quality assurance processes:\n\nSecurity Assurance Requirements (SARs) \u2013 descriptions of the measures taken during development and evaluation of the product to assure compliance with the claimed security functionality. For example, an evaluation may require that all source code is kept in a change management system, or that full functional testing is performed. The Common Criteria provides a catalogue of these, and the requirements may vary from one evaluation to the next. The requirements for particular targets or types of products are documented in the ST and PP, respectively.\nEvaluation Assurance Level (EAL) \u2013 the numerical rating describing the depth and rigor of an evaluation. Each EAL corresponds to a package of security assurance requirements (SARs, see above) which covers the complete development of a product, with a given level of strictness. Common Criteria lists seven levels, with EAL 1 being the most basic (and therefore cheapest to implement and evaluate) and EAL 7 being the most stringent (and most expensive). Normally, an ST or PP author will not select assurance requirements individually but choose one of these packages, possibly 'augmenting' requirements in a few areas with requirements from a higher level. Higher EALs do not necessarily imply \"better security\", they only mean that the claimed security assurance of the TOE has been more extensively verified.So far, most PPs and most evaluated STs/certified products have been for IT components (e.g., firewalls, operating systems, smart cards).\nCommon Criteria certification is sometimes specified for IT procurement. Other standards containing, e.g., interoperation, system management, user training, supplement CC and other product standards. Examples include the ISO/IEC 27002 and the German IT baseline protection.\nDetails of cryptographic implementation within the TOE are outside the scope of the CC. Instead, national standards, like FIPS 140-2, give the specifications for cryptographic modules, and various standards specify the cryptographic algorithms in use.\nMore recently, PP authors are including cryptographic requirements for CC evaluations that would typically be covered by FIPS 140-2 evaluations, broadening the bounds of the CC through scheme-specific interpretations.\nSome national evaluation schemes are phasing out EAL-based evaluations and only accept products for evaluation that claim strict conformance with an approved PP. The United States currently only allows PP-based evaluations. Canada is in the process of phasing out EAL-based evaluations.\n\n== Testing organizations ==\nAll testing laboratories must comply with ISO/IEC 17025, and certification bodies will normally be approved against ISO/IEC 17065.\nThe compliance with ISO/IEC 17025 is typically demonstrated to a National approval authority:\n\nIn Canada, the Standards Council of Canada (SCC) under Program for the Accreditation of Laboratories (PALCAN) accredits Common Criteria Evaluation Facilities (CCEF)\nIn France, the Comit\u00e9 fran\u00e7ais d'accr\u00e9ditation (COFRAC) accredits Common Criteria evaluation facilities, commonly called Centre d'\u00e9valuation de la s\u00e9curit\u00e9 des technologies de l'information (CESTI). Evaluations are done according to norms and standards specified by the Agence nationale de la s\u00e9curit\u00e9 des syst\u00e8mes d'information (ANSSI).\nIn Italy, the OCSI (Organismo di Certificazione della Sicurezza Informatica accredits Common Criteria evaluation laboratories\nIn India, the STQC Directorate of the Ministry of Electronics and Information Technology evaluates and certifies IT products at assurance levels EAL 1 through EAL4.\nIn the UK the United Kingdom Accreditation Service (UKAS) used to accredit Commercial Evaluation Facilities (CLEF); the UK is since 2019 only a consumer in the CC ecosystem\nIn the US, the National Institute of Standards and Technology (NIST) National Voluntary Laboratory Accreditation Program (NVLAP) accredits Common Criteria Testing Laboratories (CCTL)\nIn Germany, the Bundesamt f\u00fcr Sicherheit in der Informationstechnik (BSI)\nIn Spain, the National Cryptologic Center (CCN) accredits Common Criteria Testing Laboratories operating in the Spanish Scheme.\nIn The Netherlands, the Netherlands scheme for Certification in the Area of IT Security (NSCIB) accredits IT Security Evaluation Facilities (ITSEF).\nIn Sweden, the Swedish Certification Body for IT Security (CSEC) licenses IT Security Evaluation Facilities (ITSEF).Characteristics of these organizations were examined and presented at ICCC 10.\n\n== Mutual recognition arrangement ==\nAs well as the Common Criteria standard, there is also a sub-treaty level Common Criteria MRA (Mutual Recognition Arrangement), whereby each party thereto recognizes evaluations against the Common Criteria standard done by other parties. Originally signed in 1998 by Canada, France, Germany, the United Kingdom and the United States, Australia and New Zealand joined 1999, followed by Finland, Greece, Israel, Italy, the Netherlands, Norway and Spain in 2000. The Arrangement has since been renamed Common Criteria Recognition Arrangement (CCRA) and membership continues to expand.  Within the CCRA only evaluations up to EAL 2 are mutually recognized (Including augmentation with flaw remediation).  The European countries within the SOGIS-MRA typically recognize higher EALs as well. Evaluations at EAL5 and above tend to involve the security requirements of the host nation's government.\nIn September 2012, a majority of members of the CCRA produced a vision statement whereby mutual recognition of CC evaluated products will be lowered to EAL 2 (Including augmentation with flaw remediation). Further, this vision indicates a move away from assurance levels altogether and evaluations will be confined to conformance with Protection Profiles that have no stated assurance level.  This will be achieved through technical working groups developing worldwide PPs, and as yet a transition period has not been fully determined.\nOn July 2, 2014, a new CCRA was ratified per the goals outlined within the 2012 vision statement. Major changes to the Arrangement include:\n\nRecognition of evaluations against only a collaborative Protection Profile (cPP) or Evaluation Assurance Levels 1 through 2 and ALC_FLR.\nThe emergence of international Technical Communities (iTC), groups of technical experts charged with the creation of cPPs.\nA transition plan from the previous CCRA, including recognition of certificates issued under the previous version of the Arrangement.\n\n== Issues ==\n\n\n*** Requirements ***\nCommon Criteria is very generic; it does not directly provide a list of product security requirements or features for specific (classes of) products: this follows the approach taken by ITSEC, but has been a source of debate to those used to the more prescriptive approach of other earlier standards such as TCSEC and FIPS 140-2.\n\n\n*** Value of certification ***\nCommon Criteria certification cannot guarantee security, but it can ensure that claims about the security attributes of the evaluated product were independently verified. In other words, products evaluated against a Common Criteria standard exhibit a clear chain of evidence that the process of specification, implementation, and evaluation has been conducted in a rigorous and standard manner.\nVarious Microsoft Windows versions, including Windows Server 2003 and Windows XP, have been certified, but security patches to address security vulnerabilities are still getting published by Microsoft for these Windows systems. This is possible because the process of obtaining a Common Criteria certification allows a vendor to restrict the analysis to certain security features and to make certain assumptions about the operating environment and the strength of threats faced by the product in that environment. Additionally, the CC recognizes a need to limit the scope of evaluation in order to provide cost-effective and useful security certifications, such that evaluated products are examined to a level of detail specified by the assurance level or PP.  Evaluations activities are therefore only performed to a certain depth, use of time, and resources and offer reasonable assurance for the intended environment.\nIn the Microsoft case, the assumptions include A.PEER: \n\n\"Any other systems with which the TOE communicates are assumed to be under the same management control and operate under the same security policy constraints. The TOE is applicable to networked or distributed environments only if the entire network operates under the same constraints and resides within a single management domain. There are no security requirements that address the need to trust external systems or the communications links to such systems.\"\n\nThis assumption is contained in the Controlled Access Protection Profile (CAPP) to which their products adhere. Based on this and other assumptions, which may not be realistic for the common use of general-purpose operating systems, the claimed security functions of the Windows products are evaluated. Thus they should only be considered secure in the assumed, specified circumstances, also known as the evaluated configuration.\nWhether you run Microsoft Windows in the precise evaluated configuration or not, you should apply Microsoft's security patches for the vulnerabilities in Windows as they continue to appear. If any of these security vulnerabilities are exploitable in the product's evaluated configuration, the product's Common Criteria certification should be voluntarily withdrawn by the vendor. Alternatively, the vendor should re-evaluate the product to include the application of patches to fix the security vulnerabilities within the evaluated configuration. Failure by the vendor to take either of these steps would result in involuntary withdrawal of the product's certification by the certification body of the country in which the product was evaluated.\nThe certified Microsoft Windows versions remain at EAL4+ without including the application of any Microsoft security vulnerability patches in their evaluated configuration. This shows both the limitation and strength of an evaluated configuration.\n\n\n*** Criticisms ***\nIn August 2007, Government Computing News (GCN) columnist William Jackson critically examined Common Criteria methodology and its US implementation by the Common Criteria Evaluation and Validation Scheme (CCEVS). In the column executives from the security industry, researchers, and representatives from the National Information Assurance Partnership (NIAP) were interviewed. Objections outlined in the article include:\n\nEvaluation is a costly process (often measured in hundreds of thousands of US dollars) \u2013 and the vendor's return on that investment is not necessarily a more secure product.\nEvaluation focuses primarily on assessing the evaluation documentation, not on the actual security, technical correctness or merits of the product itself. For U.S. evaluations, only at EAL5 and higher do experts from the National Security Agency participate in the analysis; and only at EAL7 is full source code analysis required.\nThe effort and time necessary to prepare evaluation evidence and other evaluation-related documentation is so cumbersome that by the time the work is completed, the product in evaluation is generally obsolete.\nIndustry input, including that from organizations such as the Common Criteria Vendor's Forum, generally has little impact on the process as a whole.In a 2006 research paper, computer specialist David A. Wheeler suggested that the Common Criteria process discriminates against free and open-source software (FOSS)-centric organizations and development models. Common Criteria assurance requirements tend to be inspired by the traditional waterfall software development methodology. In contrast, much FOSS software is produced using modern agile paradigms. Although some have argued that both paradigms do not align well, others have attempted to reconcile both paradigms. Political scientist Jan Kallberg raised concerns over the lack of control over the actual production of the products once they are certified, the absence of a permanently staffed organizational body that monitors compliance, and the idea that the trust in the Common Criteria IT-security certifications will be maintained across geopolitical boundaries.In 2017, the ROCA vulnerability was found in a list of Common Criteria certified smart card products. The vulnerability highlighted several shortcomings of Common Criteria certification scheme:\nThe vulnerability resided in a homegrown RSA key generation algorithm that has not been published and analyzed by the cryptanalysis community. However, the testing laboratory T\u00dcV Informationstechnik GmbH (T\u00dcViT) in Germany approved its use and the certification body BSI in Germany issued Common Criteria certificates for the vulnerable products. The Security Target of the evaluated product claimed that RSA keys are generated according to the standard algorithm. In response to this vulnerability, BSI now plans to improve transparency by requiring that the certification report at least specifies if the implemented proprietary cryptography is not exactly conformant to a recommended standard. BSI does not plan on requiring the proprietary algorithm to be published in any way.\nEven though the certification bodies are now aware that the security claims specified in the Common Criteria certificates do not hold anymore, neither ANSSI nor BSI have revoked the corresponding certificates. According to BSI, a certificate can only be withdrawn when it was issued under misconception, e.g., when it turns out that wrong evidence was submitted. After a certificate is issued, it must be presumed that the validity of the certificate decreases over time by improved and new attacks being discovered. Certification bodies can issue maintenance reports and even perform a re-certification of the product. These activities, however, have to be initiated and sponsored by the vendor.\nWhile several Common Criteria certified products have been affected by the ROCA flaw, vendors' responses in the context of certification have been different. For some products a maintenance report was issued, which states that only RSA keys with a length of 3072 and 3584 bits have a security level of at least 100 bits, while for some products the maintenance report does not mention that the change to the TOE affects certified cryptographic security functionality, but concludes that the change is at the level of guidance documentation and has no effect on assurance.\nAccording BSI, the users of the certified end products should have been informed of the ROCA vulnerability by the vendors. This information, however, did not reach in a timely manner the Estonian authorities who had deployed the vulnerable product on more than 750,000 Estonian identity cards.\n\n== Alternative approaches ==\nThroughout the lifetime of CC, it has not been universally adopted even by the creator nations, with, in particular, cryptographic approvals being handled separately, such as by the Canadian / US implementation of FIPS-140, and the CESG Assisted Products Scheme (CAPS) in the UK.\nThe UK has also produced a number of alternative schemes when the timescales, costs and overheads of mutual recognition have been found to be impeding the operation of the market:\n\nThe CESG System Evaluation (SYSn) and Fast Track Approach (FTA) schemes for assurance of government systems rather than generic products and services, which have now been merged into the CESG Tailored Assurance Service (CTAS) \nThe CESG Claims Tested Mark (CCT Mark), which is aimed at handling less exhaustive assurance requirements for products and services in a cost and time efficient manner.In early 2011, NSA/CSS published a paper by Chris Salter, which proposed a Protection Profile oriented approach towards evaluation. In this approach, communities of interest form around technology types which in turn develop protection profiles that define the evaluation methodology for the technology type. The objective is a more robust evaluation. There is some concern that this may have a negative impact on mutual recognition.In Sept of 2012, the Common Criteria published a Vision Statement implementing to a large extent Chris Salter's thoughts from the previous year.  Key elements of the Vision included:\n\nTechnical Communities will be focused on authoring Protection Profiles (PP) that support their goal of reasonable, comparable, reproducible and cost-effective evaluation results\nEvaluations should be done against these PP's if possible; if not mutual recognition of Security Target evaluations would be limited to EAL2."
    }
  },
  {
    "instruction": "context: A MAC flooding attack forces legitimate MAC table contents out of the switch, causing a unicast flooding behavior that can potentially send sensitive information to portions of the network where it is not normally intended to go.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does a MAC flooding attack compromise the security of a network switch?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does a MAC flooding attack compromise the security of a network switch?",
      "answer": "A MAC flooding attack forces legitimate MAC table contents out of the switch, causing a unicast flooding behavior that can potentially send sensitive information to portions of the network where it is not normally intended to go."
    }
  },
  {
    "instruction": "context: A previously created saved packet file can be used with tcpdump by specifying the file as the input to the program, instead of capturing packets from a network interface card.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can a previously created saved packet file be used with tcpdump?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a previously created saved packet file be used with tcpdump?",
      "answer": "A previously created saved packet file can be used with tcpdump by specifying the file as the input to the program, instead of capturing packets from a network interface card."
    }
  },
  {
    "instruction": "context: The encrypting circuit in an encrypting PIN pad apparatus can be embedded in the housing by attaching it directly to the housing or by encapsulating it in a protective material (such as epoxy) and attaching it to the housing. This helps to prevent physical access to the encrypting circuit and provides additional tamper resistance.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can the encrypting circuit in an encrypting PIN pad apparatus be embedded in the housing?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can the encrypting circuit in an encrypting PIN pad apparatus be embedded in the housing?",
      "answer": "The encrypting circuit in an encrypting PIN pad apparatus can be embedded in the housing by attaching it directly to the housing or by encapsulating it in a protective material (such as epoxy) and attaching it to the housing. This helps to prevent physical access to the encrypting circuit and provides additional tamper resistance."
    }
  },
  {
    "instruction": "context: The clustering technology in GoAnywhere MFT enables enterprises to process high volumes of file transfers by load balancing processes across multiple systems. It also provides active-active automatic failover for disaster recovery, ensuring business continuity.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the clustering technology in GoAnywhere MFT benefit enterprises?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the clustering technology in GoAnywhere MFT benefit enterprises?",
      "answer": "The clustering technology in GoAnywhere MFT enables enterprises to process high volumes of file transfers by load balancing processes across multiple systems. It also provides active-active automatic failover for disaster recovery, ensuring business continuity."
    }
  },
  {
    "instruction": "context: History-of-Presence Based Access Control (HPBAC) is an access control paradigm that defines access control to resources in terms of presence policies that need to be satisfied by presence records stored by the requestor.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is History-of-Presence Based Access Control (HPBAC) in computer security?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is History-of-Presence Based Access Control (HPBAC) in computer security?",
      "answer": "History-of-Presence Based Access Control (HPBAC) is an access control paradigm that defines access control to resources in terms of presence policies that need to be satisfied by presence records stored by the requestor."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the resistance of blinding functions to side-channel attacks affect the overall security of the encryption scheme?",
    "context": "",
    "output": "The resistance of blinding functions to side-channel attacks is crucial for the overall security of the encryption scheme, as it directly impacts the ability to prevent leakage of sensitive information during the computation process.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the resistance of blinding functions to side-channel attacks affect the overall security of the encryption scheme?",
      "answer": "The resistance of blinding functions to side-channel attacks is crucial for the overall security of the encryption scheme, as it directly impacts the ability to prevent leakage of sensitive information during the computation process."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did piggybacking come to the public's attention in 1999?",
    "context": "",
    "output": "Piggybacking came to the public's attention in 1999 when a series of weaknesses were exposed in airport security. A study showed that many undercover agents were successful in passing through checkpoints, bringing banned items on planes, or boarding planes without tickets, using piggybacking as one of the methods to enter off-limits areas.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did piggybacking come to the public's attention in 1999?",
      "answer": "Piggybacking came to the public's attention in 1999 when a series of weaknesses were exposed in airport security. A study showed that many undercover agents were successful in passing through checkpoints, bringing banned items on planes, or boarding planes without tickets, using piggybacking as one of the methods to enter off-limits areas."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does FinalCode's CryptoEase technology ensure persistent file protection?",
    "context": "",
    "output": "FinalCode's CryptoEase technology ensures persistent file protection by adding a layer of encryption that remains active whether the file is circulated internally or externally within an organization. This technology enables organizations and file owners to maintain comprehensive file control and auditing capabilities, including setting recipients' usage permissions or deleting files remotely.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does FinalCode's CryptoEase technology ensure persistent file protection?",
      "answer": "FinalCode's CryptoEase technology ensures persistent file protection by adding a layer of encryption that remains active whether the file is circulated internally or externally within an organization. This technology enables organizations and file owners to maintain comprehensive file control and auditing capabilities, including setting recipients' usage permissions or deleting files remotely."
    }
  },
  {
    "instruction": "context: eIDAS addresses the need for non-repudiation of electronic signatures by defining the standards for qualified digital certificates and other specific services provided by qualified trust service providers. This helps to ensure the authenticity and data integrity of electronic signatures and their accompanying messages and/or attached data.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does eIDAS address the need for non-repudiation of electronic signatures?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does eIDAS address the need for non-repudiation of electronic signatures?",
      "answer": "eIDAS addresses the need for non-repudiation of electronic signatures by defining the standards for qualified digital certificates and other specific services provided by qualified trust service providers. This helps to ensure the authenticity and data integrity of electronic signatures and their accompanying messages and/or attached data."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the advantages of offloading cryptographic encryption keys from the protected client and supplying key material externally within the user authentication process?",
    "context": "",
    "output": "Offloading cryptographic encryption keys from the protected client and supplying key material externally within the user authentication process eliminates attacks on any built-in authentication method that are weaker than a brute-force attack to the symmetric AES keys used for full disk encryption. This method offers the best security for pre-boot authentication.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the advantages of offloading cryptographic encryption keys from the protected client and supplying key material externally within the user authentication process?",
      "answer": "Offloading cryptographic encryption keys from the protected client and supplying key material externally within the user authentication process eliminates attacks on any built-in authentication method that are weaker than a brute-force attack to the symmetric AES keys used for full disk encryption. This method offers the best security for pre-boot authentication."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the function of a reverse proxy server?",
    "context": "",
    "output": "A reverse proxy server is an intermediary that provides indirect access for an external network to internal resources. It is used to provide an extra layer of security, particularly when internal resources need to be accessed from the outside.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the function of a reverse proxy server?",
      "answer": "A reverse proxy server is an intermediary that provides indirect access for an external network to internal resources. It is used to provide an extra layer of security, particularly when internal resources need to be accessed from the outside."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does onion routing ensure the anonymity of the sender and the message?",
    "context": "",
    "output": "Onion routing ensures the anonymity of the sender and the message by encapsulating the data in layers of encryption, similar to the layers of an onion. The encrypted data is transmitted through a series of network nodes called onion routers, with each node peeling away a single layer of encryption to reveal the next destination. The sender remains anonymous as each intermediary node only knows the location of the immediately preceding and following nodes, without knowing the origin or final destination of the data.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does onion routing ensure the anonymity of the sender and the message?",
      "answer": "Onion routing ensures the anonymity of the sender and the message by encapsulating the data in layers of encryption, similar to the layers of an onion. The encrypted data is transmitted through a series of network nodes called onion routers, with each node peeling away a single layer of encryption to reveal the next destination. The sender remains anonymous as each intermediary node only knows the location of the immediately preceding and following nodes, without knowing the origin or final destination of the data."
    }
  },
  {
    "instruction": "context: SCIP addresses the problems with earlier NSA encryption systems for voice, such as STU-III and Secure Terminal Equipment (STE), by not making assumptions about the underlying communication systems, which allows for interoperability with more modern wireless systems.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does SCIP address the problems with earlier NSA encryption systems for voice, such as STU-III and Secure Terminal Equipment (STE)?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does SCIP address the problems with earlier NSA encryption systems for voice, such as STU-III and Secure Terminal Equipment (STE)?",
      "answer": "SCIP addresses the problems with earlier NSA encryption systems for voice, such as STU-III and Secure Terminal Equipment (STE), by not making assumptions about the underlying communication systems, which allows for interoperability with more modern wireless systems."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Bureau 121's alleged involvement in the 2014 Sony Pictures hack compare to other operations?",
    "context": "",
    "output": "The 2014 Sony Pictures hack is notable for its scale and public visibility, but it is just one example of Bureau 121's capabilities. The agency has also been linked to other high-profile cyber offensives, such as the Bangladesh Bank robbery and the WannaCry ransomware attack.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Bureau 121's alleged involvement in the 2014 Sony Pictures hack compare to other operations?",
      "answer": "The 2014 Sony Pictures hack is notable for its scale and public visibility, but it is just one example of Bureau 121's capabilities. The agency has also been linked to other high-profile cyber offensives, such as the Bangladesh Bank robbery and the WannaCry ransomware attack."
    }
  },
  {
    "instruction": "context: The Evil Twin attack is an example of snarfing because it involves impersonating a legitimate access point and capturing users' credentials through a captive portal. This is done using a simple shell script and software like AirSnarf to create a wireless hotspot that appears legitimate to users.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the Evil Twin attack use the concept of snarfing?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the Evil Twin attack use the concept of snarfing?",
      "answer": "The Evil Twin attack is an example of snarfing because it involves impersonating a legitimate access point and capturing users' credentials through a captive portal. This is done using a simple shell script and software like AirSnarf to create a wireless hotspot that appears legitimate to users."
    }
  },
  {
    "instruction": "context: Psychological coercion can be as effective as physical torture in rubber-hose cryptanalysis because the goal is to extract cryptographic secrets from a person through intimidation and fear. This can include threats of harsh legal penalties, plea bargains, or even threats to harm close relatives. The person being questioned may feel pressured to cooperate, even if no physical violence is used.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can psychological coercion be as effective as physical torture in rubber-hose cryptanalysis?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can psychological coercion be as effective as physical torture in rubber-hose cryptanalysis?",
      "answer": "Psychological coercion can be as effective as physical torture in rubber-hose cryptanalysis because the goal is to extract cryptographic secrets from a person through intimidation and fear. This can include threats of harsh legal penalties, plea bargains, or even threats to harm close relatives. The person being questioned may feel pressured to cooperate, even if no physical violence is used."
    }
  },
  {
    "instruction": "Write an answer to the following question: Which organization continued the Jericho Forum's work on Identity after its closure?",
    "context": "",
    "output": "The Global Identity Foundation continued the Jericho Forum's work on Identity after its closure.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Which organization continued the Jericho Forum's work on Identity after its closure?",
      "answer": "The Global Identity Foundation continued the Jericho Forum's work on Identity after its closure."
    }
  },
  {
    "instruction": "Answer based on context:\n\nRed Cross data breach\n\n==Introduction==\nOn 20 January 2022 the International Committee of the Red Cross made an appeal to hackers who had stolen private data, saying they would speak \"directly and confidentially\" to those responsible for the attack. The hackers had stolen private data on more than 515,000 vulnerable people from at least 60 Red Cross and Red Crescent societies. So far there is no proof that the data has been leaked, but the ICRC said that their gravest concern was the risk posed by exposing the data.The attack was aimed at a Swiss contractor that stores the data.The perpetrators have not been identified.\n\n\n\n== Impact ==\nThe ICRC has suspended access to compromised computer systems which are part of the Restoring Family Links programme, which was targeted in the attack. A spokesman said \"We will do our utmost to ensure some business continuity and a resumption of services as soon as possible\".\n\nWhat is the Restoring Family Links programme, and what systems were compromised in the attack?",
    "context": "",
    "output": "The Restoring Family Links programme is a service provided by the Red Cross and Red Crescent societies, and the compromised systems are computer systems that are part of this programme.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Restoring Family Links programme, and what systems were compromised in the attack?",
      "answer": "The Restoring Family Links programme is a service provided by the Red Cross and Red Crescent societies, and the compromised systems are computer systems that are part of this programme.",
      "context": "Red Cross data breach\n\n==Introduction==\nOn 20 January 2022 the International Committee of the Red Cross made an appeal to hackers who had stolen private data, saying they would speak \"directly and confidentially\" to those responsible for the attack. The hackers had stolen private data on more than 515,000 vulnerable people from at least 60 Red Cross and Red Crescent societies. So far there is no proof that the data has been leaked, but the ICRC said that their gravest concern was the risk posed by exposing the data.The attack was aimed at a Swiss contractor that stores the data.The perpetrators have not been identified.\n\n\n\n== Impact ==\nThe ICRC has suspended access to compromised computer systems which are part of the Restoring Family Links programme, which was targeted in the attack. A spokesman said \"We will do our utmost to ensure some business continuity and a resumption of services as soon as possible\"."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does entanglement purification work in a quantum network?",
    "context": "",
    "output": "Entanglement purification allows for the creation of nearly maximally entangled qubits from a large number of arbitrary weakly entangled qubits, providing additional protection against errors in a quantum network.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does entanglement purification work in a quantum network?",
      "answer": "Entanglement purification allows for the creation of nearly maximally entangled qubits from a large number of arbitrary weakly entangled qubits, providing additional protection against errors in a quantum network."
    }
  },
  {
    "instruction": "context: AppLocker is a feature of recent versions of Microsoft Windows that allows administrators to control which executable files are allowed or denied to execute. AppLocker rules can be based on file names, publishers, or file locations, and can apply to individual users or groups. Policies can also be used to group users into different enforcement levels.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is AppLocker and how does it work on Microsoft Windows?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is AppLocker and how does it work on Microsoft Windows?",
      "answer": "AppLocker is a feature of recent versions of Microsoft Windows that allows administrators to control which executable files are allowed or denied to execute. AppLocker rules can be based on file names, publishers, or file locations, and can apply to individual users or groups. Policies can also be used to group users into different enforcement levels."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does the application of artificial neural networks in cryptanalysis work?",
    "context": "",
    "output": "The application of artificial neural networks in cryptanalysis is based on their ability to selectively explore the solution space of a given problem and their proven capability to reproduce any function, including the inverse-function of cryptographic algorithms.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the application of artificial neural networks in cryptanalysis work?",
      "answer": "The application of artificial neural networks in cryptanalysis is based on their ability to selectively explore the solution space of a given problem and their proven capability to reproduce any function, including the inverse-function of cryptographic algorithms."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is secrecy capacity and how is it used in physical layer encryption?",
    "context": "",
    "output": "Secrecy capacity is a measure of the rate at which Alice can transmit secret information to Bob in the Alice-Bob-Eve problem.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is secrecy capacity and how is it used in physical layer encryption?",
      "answer": "Secrecy capacity is a measure of the rate at which Alice can transmit secret information to Bob in the Alice-Bob-Eve problem."
    }
  },
  {
    "instruction": "context: A hierarchy of multiple certificate authorities can help maintain security and functionality by distributing workload and reducing the potential impact of electronic attacks, such as denial-of-service attacks. Additionally, in the event of a certificate authority failure, other authorities in the hierarchy can continue to issue and manage certificates, ensuring the system remains operational.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can a hierarchy of multiple certificate authorities help maintain the security and functionality of a certificate-based encryption system?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a hierarchy of multiple certificate authorities help maintain the security and functionality of a certificate-based encryption system?",
      "answer": "A hierarchy of multiple certificate authorities can help maintain security and functionality by distributing workload and reducing the potential impact of electronic attacks, such as denial-of-service attacks. Additionally, in the event of a certificate authority failure, other authorities in the hierarchy can continue to issue and manage certificates, ensuring the system remains operational."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the significance of the Cisco Network Admission Control product being marked End of Life?",
    "context": "",
    "output": "The Cisco Network Admission Control product being marked End of Life means that it is no longer developed or supported by Cisco.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the Cisco Network Admission Control product being marked End of Life?",
      "answer": "The Cisco Network Admission Control product being marked End of Life means that it is no longer developed or supported by Cisco."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does Zwangi redirect URLs typed into the browser's address bar, and what else does it do without permission?",
    "context": "",
    "output": "Zwangi redirects URLs typed into the browser's address bar to a search page at www.zwangi.com, and it may also take screenshots without permission.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Zwangi redirect URLs typed into the browser's address bar, and what else does it do without permission?",
      "answer": "Zwangi redirects URLs typed into the browser's address bar to a search page at www.zwangi.com, and it may also take screenshots without permission."
    }
  },
  {
    "instruction": "Context: Piggybacking (security)\n\n==Introduction==\nIn security, piggybacking, similar to tailgating, refers to when a person tags along with another person who is authorized to gain entry into a restricted area, or pass a certain checkpoint. It can be either electronic or physical. The act may be legal or illegal, authorized or unauthorized, depending on the circumstances. However, the term more often has the connotation of being an illegal or unauthorized act.To describe the act of an unauthorized person who follows someone to a restricted area without the consent of the authorized person, the term tailgating is also used. \"Tailgating\" implies no consent (similar to a car tailgating another vehicle on a road), while \"piggybacking\" usually implies consent of the authorized person.Piggybacking came to the public's attention particularly in 1999, when a series of weaknesses were exposed in airport security. A study showed that the majority of undercover agents attempting to pass through checkpoints, bring banned items on planes, or board planes without tickets,  were successful. Piggybacking was revealed as one of the methods that was used in order to enter off-limits areas.\n\n== Methods ==\n\n\n*** Electronic ***\nA user fails to properly log off their computer, allowing an unauthorized user to \"piggyback\" on the authorized user's session.\n\n\n*** Physical ***\nPiggybackers have various methods of breaching security. These may include:\n\nSurreptitiously following an individual authorized to enter a location, giving the appearance of being legitimately escorted\nJoining a large crowd authorized to enter, and pretending to be a member of the crowd that is largely unchecked\nFinding an authorized person who either disregards the law or the rules of the facility, or is tricked into believing the piggybacker is authorized, and agreeably allows the piggybacker to tag alongPiggybacking can be regarded as one of the simpler forms of social engineering.\nAnswer this question: How can piggybackers trick an authorized person into allowing them to enter a restricted area?",
    "context": "",
    "output": "Piggybackers can trick an authorized person into allowing them to enter a restricted area by finding an authorized person who is tricked into believing the piggybacker is authorized and agreeably allows the piggybacker to tag along.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can piggybackers trick an authorized person into allowing them to enter a restricted area?",
      "answer": "Piggybackers can trick an authorized person into allowing them to enter a restricted area by finding an authorized person who is tricked into believing the piggybacker is authorized and agreeably allows the piggybacker to tag along.",
      "context": "Piggybacking (security)\n\n==Introduction==\nIn security, piggybacking, similar to tailgating, refers to when a person tags along with another person who is authorized to gain entry into a restricted area, or pass a certain checkpoint. It can be either electronic or physical. The act may be legal or illegal, authorized or unauthorized, depending on the circumstances. However, the term more often has the connotation of being an illegal or unauthorized act.To describe the act of an unauthorized person who follows someone to a restricted area without the consent of the authorized person, the term tailgating is also used. \"Tailgating\" implies no consent (similar to a car tailgating another vehicle on a road), while \"piggybacking\" usually implies consent of the authorized person.Piggybacking came to the public's attention particularly in 1999, when a series of weaknesses were exposed in airport security. A study showed that the majority of undercover agents attempting to pass through checkpoints, bring banned items on planes, or board planes without tickets,  were successful. Piggybacking was revealed as one of the methods that was used in order to enter off-limits areas.\n\n== Methods ==\n\n\n*** Electronic ***\nA user fails to properly log off their computer, allowing an unauthorized user to \"piggyback\" on the authorized user's session.\n\n\n*** Physical ***\nPiggybackers have various methods of breaching security. These may include:\n\nSurreptitiously following an individual authorized to enter a location, giving the appearance of being legitimately escorted\nJoining a large crowd authorized to enter, and pretending to be a member of the crowd that is largely unchecked\nFinding an authorized person who either disregards the law or the rules of the facility, or is tricked into believing the piggybacker is authorized, and agreeably allows the piggybacker to tag alongPiggybacking can be regarded as one of the simpler forms of social engineering."
    }
  },
  {
    "instruction": "Write an answer to the following question: Why does the number of coincidences go up sharply when the bottom message is shifted by a multiple of the key length in the generalized method of attacks on polyalphabetic ciphers?",
    "context": "",
    "output": "The number of coincidences goes up sharply when the bottom message is shifted by a multiple of the key length because then the adjacent letters are in the same language using the same alphabet.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why does the number of coincidences go up sharply when the bottom message is shifted by a multiple of the key length in the generalized method of attacks on polyalphabetic ciphers?",
      "answer": "The number of coincidences goes up sharply when the bottom message is shifted by a multiple of the key length because then the adjacent letters are in the same language using the same alphabet."
    }
  },
  {
    "instruction": "context: The GSSAPI standardizes only authentication, rather than authorization, because authentication is the process of verifying the identity of a user, process, or device, while authorization is the process of giving permission to perform certain actions. Authentication is a prerequisite for authorization.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the purpose of the GSSAPI standardizing only authentication, rather than authorization?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the GSSAPI standardizing only authentication, rather than authorization?",
      "answer": "The GSSAPI standardizes only authentication, rather than authorization, because authentication is the process of verifying the identity of a user, process, or device, while authorization is the process of giving permission to perform certain actions. Authentication is a prerequisite for authorization."
    }
  },
  {
    "instruction": "context: While stalkerware can be used for parental monitoring, it is crucial to ensure that all parties involved are aware of and consent to the monitoring.\n\nAsk a question about this context.",
    "context": "",
    "output": "Is it legal for parents to use stalkerware for monitoring their children's activities?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Is it legal for parents to use stalkerware for monitoring their children's activities?",
      "answer": "While stalkerware can be used for parental monitoring, it is crucial to ensure that all parties involved are aware of and consent to the monitoring."
    }
  },
  {
    "instruction": "Universal 2nd Factor\n\n==Introduction==\nUniversal 2nd Factor (U2F) is an open standard that strengthens and simplifies two-factor authentication (2FA) using specialized Universal Serial Bus (USB) or near-field communication (NFC) devices based on similar security technology found in smart cards. It is succeeded by the FIDO2 Project, which includes the W3C Web Authentication (WebAuthn) standard and the FIDO Alliance's Client to Authenticator Protocol 2 (CTAP2).While initially developed by Google and Yubico, with contribution from NXP Semiconductors, the standard is now hosted by the FIDO Alliance.\n\n\n\n== Advantages (and disadvantages) ==\nWhile Time-based one-time passwords (e.g. 6-digit codes generated on Google Authenticator) were a significant improvement over SMS-based security codes, a number of security vulnerabilities were still possible to exploit, which U2F sought to improve.   Specifically: \n\nIn terms of disadvantages, one significant difference and potential drawback to be considered regarding hardware-based U2F solutions is that unlike with TOTP shared secret methods, there is no possibility of \"backing up\" recovery codes or shared secrets.  If a hardware duplicate or alternate hardware key is not kept and the original U2F hardware key is lost, no recovery of the key is possible (because the private key exists only in hardware).  Therefore, for services that do not provide any alternate account recovery method, the use of U2F should be carefully considered.\n\n== Design ==\nThe USB devices communicate with the host computer using the human interface device (HID) protocol, essentially mimicking a keyboard. This avoids the need for the user to install special hardware driver software in the host computer, and permits application software (such as a browser) to directly access the security features of the device without user effort other than possessing and inserting the device. Once communication is established, the application exercises a challenge\u2013response authentication with the device using public-key cryptography methods and a secret unique device key manufactured into the device.\n\n== Vulnerabilities ==\nThe device key is vulnerable to  malicious manufacturer duplication.In 2020, independent security researchers found a method to extract private keys from Google Titan Key, a popular U2F hardware security token. The method required physical access to the key for several hours, several thousand euros-worth of equipment, and was destructive to the plastic case of the key. The attackers concluded that the difficulty of the attack meant that people were still safer to use the keys than not. The attack was possible due to a vulnerability in the A700X microchip made by NXP Semiconductors, which is also used in security tokens made by Feitian and Yubico, meaning that those tokens are also vulnerable. The vulnerability was responsibly disclosed to the affected manufacturers so that it might be fixed in future products.\n\n== Support and use ==\nU2F security keys are supported by Google Chrome since version 38, Firefox since version 57 and Opera since version 40. U2F security keys can be used as an additional method of two-step verification on online services that support the U2F protocol, including Google, Azure, Dropbox, GitHub, GitLab, Bitbucket, Nextcloud, Facebook, and others.Chrome, Firefox, and Opera were, as of 2015, the only browsers supporting U2F natively. Microsoft has enabled FIDO 2.0 support for Windows 10's Windows Hello login platform. Microsoft Edge browser gained support for U2F in the October 2018 Windows Update. Microsoft accounts, including Office 365, OneDrive, and other Microsoft services, do not yet have U2F support. Mozilla has integrated it into Firefox 57, and enabled it by default in Firefox 60 and Thunderbird 60. Microsoft Edge starting from build 17723 support FIDO2. As of iOS and iPadOS 13.3 Apple now supports U2F in the Safari browser on those platforms.\n\n== Specifications ==\n\nThe U2F standard has undergone two major revisions:\n\nU2F 1.0 Proposed Standard (October 9, 2014)\nU2F 1.2 Proposed Standard (April 11, 2017)Additional specification documents may be obtained from the FIDO web site.The U2F 1.0 Proposed Standard (October 9, 2014) was the starting point for a short-lived specification known as the FIDO 2.0 Proposed Standard (September 4, 2015). The latter was formally submitted to the World Wide Web Consortium (W3C) on November 12, 2015. Subsequently, the first Working Draft of the W3C Web Authentication (WebAuthn) standard was published on May 31, 2016. The WebAuthn standard has been revised numerous times since then, becoming a W3C Recommendation on March 4, 2019.\nMeanwhile the U2F 1.2 Proposed Standard (April 11, 2017) became the starting point for the Client to Authenticator Protocol (CTAP) Proposed Standard, which was published on September 27, 2017. FIDO CTAP complements W3C WebAuthn, both of which are in scope for the FIDO2 Project.\nWebAuthn and CTAP provide a complete replacement for U2F, which has been renamed \"CTAP1\" in the latest version of the FIDO2 standard. The WebAuthn protocol is backward-compatible (via the AppID extension) with U2F-only security keys but the U2F protocol is not compatible with a WebAuthn-only authenticator. Some authenticators support both U2F and WebAuthn while some WebAuthn clients support keys created via the legacy U2F API.\n\nQ: What are the advantages of U2F over Time-based one-time passwords (TOTP)?",
    "context": "",
    "output": "A: U2F aims to improve upon TOTP by addressing several security vulnerabilities. The specific advantages are not mentioned in the text, but U2F is said to strengthen and simplify two-factor authentication using specialized USB or NFC devices.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the advantages of U2F over Time-based one-time passwords (TOTP)?",
      "answer": "U2F aims to improve upon TOTP by addressing several security vulnerabilities. The specific advantages are not mentioned in the text, but U2F is said to strengthen and simplify two-factor authentication using specialized USB or NFC devices.",
      "context": "Universal 2nd Factor\n\n==Introduction==\nUniversal 2nd Factor (U2F) is an open standard that strengthens and simplifies two-factor authentication (2FA) using specialized Universal Serial Bus (USB) or near-field communication (NFC) devices based on similar security technology found in smart cards. It is succeeded by the FIDO2 Project, which includes the W3C Web Authentication (WebAuthn) standard and the FIDO Alliance's Client to Authenticator Protocol 2 (CTAP2).While initially developed by Google and Yubico, with contribution from NXP Semiconductors, the standard is now hosted by the FIDO Alliance.\n\n\n\n== Advantages (and disadvantages) ==\nWhile Time-based one-time passwords (e.g. 6-digit codes generated on Google Authenticator) were a significant improvement over SMS-based security codes, a number of security vulnerabilities were still possible to exploit, which U2F sought to improve.   Specifically: \n\nIn terms of disadvantages, one significant difference and potential drawback to be considered regarding hardware-based U2F solutions is that unlike with TOTP shared secret methods, there is no possibility of \"backing up\" recovery codes or shared secrets.  If a hardware duplicate or alternate hardware key is not kept and the original U2F hardware key is lost, no recovery of the key is possible (because the private key exists only in hardware).  Therefore, for services that do not provide any alternate account recovery method, the use of U2F should be carefully considered.\n\n== Design ==\nThe USB devices communicate with the host computer using the human interface device (HID) protocol, essentially mimicking a keyboard. This avoids the need for the user to install special hardware driver software in the host computer, and permits application software (such as a browser) to directly access the security features of the device without user effort other than possessing and inserting the device. Once communication is established, the application exercises a challenge\u2013response authentication with the device using public-key cryptography methods and a secret unique device key manufactured into the device.\n\n== Vulnerabilities ==\nThe device key is vulnerable to  malicious manufacturer duplication.In 2020, independent security researchers found a method to extract private keys from Google Titan Key, a popular U2F hardware security token. The method required physical access to the key for several hours, several thousand euros-worth of equipment, and was destructive to the plastic case of the key. The attackers concluded that the difficulty of the attack meant that people were still safer to use the keys than not. The attack was possible due to a vulnerability in the A700X microchip made by NXP Semiconductors, which is also used in security tokens made by Feitian and Yubico, meaning that those tokens are also vulnerable. The vulnerability was responsibly disclosed to the affected manufacturers so that it might be fixed in future products.\n\n== Support and use ==\nU2F security keys are supported by Google Chrome since version 38, Firefox since version 57 and Opera since version 40. U2F security keys can be used as an additional method of two-step verification on online services that support the U2F protocol, including Google, Azure, Dropbox, GitHub, GitLab, Bitbucket, Nextcloud, Facebook, and others.Chrome, Firefox, and Opera were, as of 2015, the only browsers supporting U2F natively. Microsoft has enabled FIDO 2.0 support for Windows 10's Windows Hello login platform. Microsoft Edge browser gained support for U2F in the October 2018 Windows Update. Microsoft accounts, including Office 365, OneDrive, and other Microsoft services, do not yet have U2F support. Mozilla has integrated it into Firefox 57, and enabled it by default in Firefox 60 and Thunderbird 60. Microsoft Edge starting from build 17723 support FIDO2. As of iOS and iPadOS 13.3 Apple now supports U2F in the Safari browser on those platforms.\n\n== Specifications ==\n\nThe U2F standard has undergone two major revisions:\n\nU2F 1.0 Proposed Standard (October 9, 2014)\nU2F 1.2 Proposed Standard (April 11, 2017)Additional specification documents may be obtained from the FIDO web site.The U2F 1.0 Proposed Standard (October 9, 2014) was the starting point for a short-lived specification known as the FIDO 2.0 Proposed Standard (September 4, 2015). The latter was formally submitted to the World Wide Web Consortium (W3C) on November 12, 2015. Subsequently, the first Working Draft of the W3C Web Authentication (WebAuthn) standard was published on May 31, 2016. The WebAuthn standard has been revised numerous times since then, becoming a W3C Recommendation on March 4, 2019.\nMeanwhile the U2F 1.2 Proposed Standard (April 11, 2017) became the starting point for the Client to Authenticator Protocol (CTAP) Proposed Standard, which was published on September 27, 2017. FIDO CTAP complements W3C WebAuthn, both of which are in scope for the FIDO2 Project.\nWebAuthn and CTAP provide a complete replacement for U2F, which has been renamed \"CTAP1\" in the latest version of the FIDO2 standard. The WebAuthn protocol is backward-compatible (via the AppID extension) with U2F-only security keys but the U2F protocol is not compatible with a WebAuthn-only authenticator. Some authenticators support both U2F and WebAuthn while some WebAuthn clients support keys created via the legacy U2F API."
    }
  },
  {
    "instruction": "context: The purpose of the Turing Test approaches in challenge-response systems is to provide challenges that can be fulfilled easily for legitimate senders and non-easily for spammers. These challenges can include converting a date string into its corresponding timestamp, answering a simple question about the text or the recipient, or solving a simple problem.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the purpose of the Turing Test approaches in challenge-response systems?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the Turing Test approaches in challenge-response systems?",
      "answer": "The purpose of the Turing Test approaches in challenge-response systems is to provide challenges that can be fulfilled easily for legitimate senders and non-easily for spammers. These challenges can include converting a date string into its corresponding timestamp, answering a simple question about the text or the recipient, or solving a simple problem."
    }
  },
  {
    "instruction": "Sony Pictures hack\n\n==Introduction==\nOn November 24, 2014, a hacker group identifying itself as \"Guardians of Peace\" leaked a release of confidential data from the film studio Sony Pictures entertainment (SPE). The data included personal information about Sony Pictures employees and their families, emails between employees, information about executive salaries at the company, copies of then-unreleased Sony films, plans for future Sony films, scripts for certain films, and other information. The perpetrators then employed a variant of the Shamoon wiper malware to erase Sony's computer infrastructure.During the hack, the group demanded that Sony withdraw its then-upcoming film The Interview, starring James Franco as a reporter and Seth Rogen (who also wrote, produced, and directed the film alongside his creative partner Evan Goldberg) as his producer who are hired by the United States and South Korean governments to set up an interview with North Korean leader Kim Jong-un as part of a plot to assassinate him, and threatened terrorist attacks at cinemas screening the film. After many major U.S. theater chains opted not to screen The Interview in response to these threats, Sony chose to cancel the film's formal premiere and mainstream release, opting to skip directly to a downloadable digital release followed by a limited theatrical release the next day.United States intelligence officials, after evaluating the software, techniques, and network sources used in the hack, concluded that the attack was sponsored by the government of North Korea, which has since denied all responsibility.\n\n\n\n== Hack and perpetrators ==\nThe exact duration of the hack is yet unknown. U.S. investigators say the culprits spent at least two months copying critical files. A purported member of the Guardians of Peace (GOP) who has claimed to have performed the hack stated that they had access for at least a year prior to its discovery in November 2014, according to Wired. The hackers involved claim to have taken more than 100 terabytes of data from Sony, but that claim has never been confirmed. The attack was conducted using malware. Although Sony was not specifically mentioned in its advisory, US-CERT said that attackers used a Server Message Block (SMB) Worm Tool to conduct attacks against a major entertainment company. Components of the attack included a listening implant, backdoor, proxy tool, destructive hard drive tool, and destructive target cleaning tool. The components clearly suggest an intent to gain repeated entry, extract information, and be destructive, as well as remove evidence of the attack.Sony was made aware of the hack on Monday, November 24, 2014, as the malware previously installed rendered many Sony employees' computers inoperable by the software, with the warning by a group calling themselves the Guardians of Peace, along with a portion of the confidential data taken during the hack. Several Sony-related Twitter accounts were also taken over. This followed a message that several Sony Pictures executives had received via email on the previous Friday, November 21; the message, coming from a group called \"God'sApstls\"  [sic], demanded \"monetary compensation\" or otherwise, \"Sony Pictures will be bombarded as a whole\". This email message had been mostly ignored by executives, lost in the volume they had received or treated as spam email. In addition to the activation of the malware on November 24, the message included a warning for Sony to decide on their course of action by 11:00 p.m. that evening, although no apparent threat was made when that deadline passed. In the days following this hack, the Guardians of Peace began leaking yet-unreleased films and started to release portions of the confidential data to attract the attention of social media sites, although they did not specify what they wanted in return. Sony quickly organized internal teams to try to manage the loss of data to the Internet, and contacted the FBI and the private security firm FireEye to help protect Sony employees whose personal data was exposed by the hack, repair the damaged computer infrastructure and trace the source of the leak. The first public report concerning a North Korean link to the attack was published by Re/code on November 28 and later confirmed by NBC News.\n\nOn December 8, 2014, alongside the eighth large data dump of confidential information, the Guardians of Peace threatened Sony with language relating to the September 11 attacks that drew the attention of U.S. security agencies. North Korean state-sponsored hackers are suspected by the United States of being involved in part due to specific threats made toward Sony and movie theaters showing The Interview, a comedy film about an assassination attempt against Kim Jong-un. North Korean officials had previously expressed concerns about the film to the United Nations, stating that \"to allow the production and distribution of such a film on the assassination of an incumbent head of a sovereign state should be regarded as the most undisguised sponsoring of terrorism as well as an act of war.\"In its first quarter financials for 2015, Sony Pictures set aside $15 million to deal with ongoing damages from the hack. Sony has bolstered its cyber-security infrastructure as a result, using solutions to prevent similar hacks or data loss in the future. Sony co-chairperson Amy Pascal announced in the wake of the hack that she would step down as of May 2015, and instead will become more involved with film production under Sony.\n\n== Information obtained ==\nAccording to a notice letter dated December 8, 2014, from SPE to its employees, SPE learned on December 1, 2014, that personally identifiable information about employees and their dependents may have been obtained by unauthorized individuals as a result of a \"brazen cyber-attack\", including names, addresses, Social Security numbers and financial information. On December 7, 2014, C-SPAN reported that the hackers stole 47,000 unique Social Security numbers from the SPE computer network.Although personal data may have been stolen, early news reports focused mainly on celebrity gossip and embarrassing details about Hollywood and film industry business affairs gleaned by the media from electronic files, including private email messages. Among the information revealed in the emails was that Sony CEO Kazuo Hirai pressured Sony Pictures co-chairwoman Amy Pascal to \"soften\" the assassination scene in The Interview. Many details relating to the actions of the Sony Pictures executives, including Pascal and Michael Lynton, were also released, in a manner that appeared to be intended to spur distrust between these executives and other employees of Sony.Other emails released in the hack showed Pascal and Scott Rudin, a film and theatrical producer, discussing Angelina Jolie. In the emails, Rudin referred to Jolie as \"a minimally talented spoiled brat\" because Jolie wanted David Fincher to direct her film Cleopatra, which Rudin felt would interfere with Fincher directing a planned film about Steve Jobs. Pascal and Rudin were also noted to have had an email exchange about Pascal's upcoming encounter with Barack Obama that included characterizations described as racist, which led to Pascal's resignation from Sony. The two had suggested they should mention films about African-Americans upon meeting the president, such as Django Unchained, 12 Years a Slave and The Butler, all of which depict slavery in the United States or the pre-civil rights era. Pascal and Rudin later apologized. Details of lobbying efforts by politician Mike Moore on behalf of the Digital Citizens Alliance and FairSearch against Google were also revealed.The leak revealed multiple details of behind-the-scenes politics on Columbia Pictures' current Spider-Man film series, including emails between Pascal and others to various heads of Marvel Studios. Due to the outcry from fans, the Spider-Man license was eventually negotiated to be shared between both studios. In addition to the emails, a copy of the screenplay for the James Bond film Spectre, released in 2015, was obtained. Several future Sony Pictures films, including Annie, Mr. Turner, Still Alice and To Write Love on Her Arms, were also leaked. The hackers intended to release additional information on December 25, 2014, which coincided with the release date of The Interview in the United States.\nAccording to The Daily Dot, based on the email leaks, while he was at Sony, executive Charles Sipkins was responsible for following senior executives' orders to edit Wikipedia articles about them.In December 2014, former Sony Pictures Entertainment employees filed four lawsuits against the company for not protecting their data that was released in the hack, which included Social Security numbers and medical information. As part of the emails, it was revealed that Sony was in talks with Nintendo to make an animated film based on the Super Mario Bros. series (which came to fruition 4 years later, albeit under Universal and Illumination instead of Sony, released in April of 2023).In January 2015, details were revealed of the MPAA's lobbying of the United States International Trade Commission to mandate U.S. ISPs either at the internet transit level or consumer level internet service provider, to implement IP address blocking pirate websites as well as linking websites. WikiLeaks published over 30,000 documents that were obtained via the hack in April 2015, with founder Julian Assange stating that the document archive \"shows the inner workings of an influential multinational corporation\" that should be made public.In November 2015, after Charlie Sheen revealed he was HIV positive in a television interview to Matt Lauer, it was revealed that information about his diagnosis was leaked in an email between senior Sony bosses dated March 10, 2014. In December, Snap Inc., due to the hack, was revealed to have acquired Vergence Labs for $15 million in cash and stock, the developers of Epiphany Eyewear, and mobile app Scan for $150 million.\n\n== Threats surrounding The Interview ==\nOn December 16, for the first time since the hack, the \"Guardians of Peace\" mentioned the then-upcoming film The Interview by name, and threatened to take terrorist actions against the film's New York City premiere at Sunshine Cinema on December 18, as well as on its American wide release date, set for December 25. Sony pulled the theatrical release the following day.\n\nWe will clearly show it to you at the very time and places The Interview be shown, including the premiere, how bitter fate those who seek fun in terror should be doomed to. Soon all the world will see what an awful movie Sony Pictures Entertainment has made. The world will be full of fear. Remember the 11th of September 2001. We recommend you to keep yourself distant from the places at that time. (If your house is nearby, you'd better leave.)\nWhatever comes in the coming days is called by the greed of Sony Pictures Entertainment. All the world will denounce the SONY.\nSeth Rogen and James Franco, the stars of The Interview, responded by saying they did not know if it was definitely caused by the film, but later canceled all media appearances tied to the film outside of the planned New York City premiere on December 16, 2014. Following initial threats made towards theaters that would show The Interview, several theatrical chains, including Carmike Cinemas, Bow Tie Cinemas, Regal Entertainment Group, Showcase Cinemas, AMC Theatres, Cinemark Theatres, as well as several independent movie theater owners announced that they would not screen The Interview. The same day, Sony stated that they would allow theaters to opt out of showing The Interview, but later decided to fully pull the national December 25 release of the film, as well as announce that there were \"no further release plans\" to release the film on any platform, including home video, in the foreseeable future.On December 18, two messages (both allegedly from the Guardians of Peace) were released. One, sent in a private message to Sony executives, stated that they would not release any further information if Sony never releases the film and removed its presence from the internet. The other, posted to Pastebin, a web application used for text storage that the Guardians of Peace have used for previous messages, stated that the studio had \"suffered enough\" and could release The Interview, but only if Kim Jong-un's death scene was not \"too happy\". The post also stated that the company cannot \"test [them] again\", and that \"if [Sony Pictures] makes anything else, [they] will be here ready to fight\".President Barack Obama, in an end-of-year press speech on December 19, commented on the Sony hacking and stated that he felt Sony made a mistake in pulling the film, and that producers should \"not get into a pattern where you are intimidated by these acts\". He also said, \"We will respond proportionally and we will respond in a place and time and manner that we choose.\" In response to President Obama's statement, Sony Entertainment's CEO Michael Lynton said on the CNN program Anderson Cooper 360 that the public, the press and the President misunderstood the events. Lynton said the decision to cancel the wide release was in response to a majority of theaters pulling their showings and not to the hackers' threats. Lynton stated that they would seek other options to distribute the film in the future, and noted \"We have not given in. And we have not backed down. We have always had every desire to have the American public see this movie.\"On December 23, Sony opted to authorize approximately 300 mostly-independent theaters to show The Interview on Christmas Day, as the four major theater chains had yet to change their earlier decision not to show the film. The FBI worked with these theaters to detail the specifics of the prior threats and how to manage security for the showings, but noted that there was no actionable intelligence on the prior threats. Sony's Lynton stated on the announcement that \"we are proud to make it available to the public and to have stood up to those who attempted to suppress free speech\". The Interview was also released to Google Play, Xbox Video, and YouTube on December 24. No incidents predicated by the threats occurred with the release, and instead, the unorthodox release of the film led to it being considered a success due to increased interest in the film following the attention it had received.On December 27, the North Korean National Defence Commission released a statement accusing Obama of being \"the chief culprit who forced the Sony Pictures Entertainment to indiscriminately distribute the movie.\"\n\n== U.S. accusations and formal charges against North Korea ==\nU.S. government officials stated on December 17, 2014 their belief that the North Korean government was \"centrally involved\" in the hacking, although there was initially some debate within the White House whether or not to make this finding public. White House officials treated the situation as a \"serious national security matter\", and the Federal Bureau of Investigation (FBI) formally stated on December 19 that they connected the North Korean government to the cyber-attacks. Including undisclosed evidence, these claims were made based on the use of similar malicious hacking tools and techniques previously employed by North Korean hackers\u2014including North Korea's cyberwarfare agency Bureau 121 on South Korean targets. According to the FBI:\n\"[A] technical analysis of the data deletion malware used in this attack revealed links to other malware that the FBI knows North Korea previously developed. For example, there were similarities in specific lines of code, encryption algorithms, data deletion methods, and compromised networks.\n\"The FBI also observed significant overlap between the infrastructure used in this attack and other malicious cyber activity the U.S. government has previously linked directly to North Korea. For example, the FBI discovered that several Internet protocol (IP) addresses associated with known North Korean infrastructure communicated with IP addresses that were hardcoded into the data deletion malware used in this attack. The FBI later clarified that the source IP addresses were associated with a group of North Korean businesses located in Shenyang in northeastern China.\n\"Separately, the tools used in the SPE attack have similarities to a cyber-attack in March of last year against South Korean banks and media outlets, which was carried out by North Korea.\"The FBI later clarified more details of the attacks, attributing them to North Korea by noting that the hackers were \"sloppy\" with the use of proxy IP addresses that originated from within North Korea. At one point the hackers logged into the Guardians of Peace Facebook account and Sony's servers without effective concealment. FBI Director James Comey stated that Internet access is tightly controlled within North Korea, and as such, it was unlikely that a third party had hijacked these addresses without allowance from the North Korean government. The National Security Agency assisted the FBI in analyzing the attack, specifically in reviewing the malware and tracing its origins; NSA director Admiral Michael Rogers agreed with the FBI that the attack originated from North Korea. A disclosed NSA report published by Der Spiegel stated that the agency had become aware of the origins of the hack due to their own cyber-intrusion on North Korea's network that they had set up in 2010, following concerns of the technology maturation of the country.The North Korean news agency KCNA denied the \"wild rumours\" of North Korean involvement, but said that \"The hacking into the SONY Pictures might be a righteous deed of the supporters and sympathizers with the DPRK in response to its appeal.\" North Korea offered to be part of a joint probe with the United States to determine the hackers' identities, threatening consequences if the United States refused to collaborate and continued the allegation. The U.S. refused and asked China for investigative assistance instead. Some days after the FBI's announcement, North Korea temporarily suffered a nationwide Internet outage, which the country claimed to be the United States' response to the hacking attempts.On the day following the FBI's accusation of North Korea's involvement, the FBI received an email purportedly from the hacking group, linking to a YouTube video entitled \"you are an idiot!\", apparently mocking the organization.On December 19, 2014, U.S. Secretary of Homeland Security Jeh Johnson released a statement saying, \"The cyber attack against Sony Pictures Entertainment was not just an attack against a company and its employees. It was also an attack on our freedom of expression and way of life.\" He encouraged businesses and other organizations to use the Cybersecurity Framework developed by the National Institute of Standards and Technology (NIST) to assess and limit cyber risks and protect against cyber threats. On the same day, U.S. Secretary of State John Kerry published his remarks condemning North Korea for the cyber-attack and threats against movie theatres and moviegoers. \"This provocative and unprecedented attack and subsequent threats only strengthen our resolve to continue to work with partners around the world to strengthen cybersecurity, promote norms of acceptable state behavior, uphold freedom of expression, and ensure that the Internet remains open, interoperable, secure and reliable,\" he said.On January 2, 2015, the U.S., under an Executive Order issued by President Obama, installed additional economic sanctions on already-sanctioned North Korea for the hack, which North Korean officials called out as \"groundlessly stirring up bad blood towards\" the country.\n\n\n*** Doubts about accusations against North Korea ***\nCyber security expert Kurt Stammberger from cyber security firm Norse, DEFCON organizer and Cloudflare researcher Marc Rogers, Hector Monsegur and Kim Zetter, a security journalist at Wired magazine, have expressed doubt and tended to agree that North Korea might not be behind the attack.\nMichael Hiltzik, a journalist for the Los Angeles Times, said that all evidence against North Korea was \"circumstantial\" and that some cybersecurity experts were \"skeptical\" about attributing the attack to the North Koreans. Cybersecurity expert Lucas Zaichkowsky said, \"State-sponsored attackers don't create cool names for themselves like 'Guardians of Peace' and promote their activity to the public.\" Kim Zetter of Wired magazine called released evidence against the government \"flimsy\". Former hacker Hector Monsegur, who once hacked into Sony, explained to CBS News that exfiltrating one or one hundred terabytes of data \"without anyone noticing\" would have taken months or years, not weeks. Monsegur doubted the accusations due to North Korea's insufficient internet infrastructure to handle the transfer of that much data. He believed that it could have been either Chinese, Russian, or North Korean-sponsored hackers working outside of the country, but most likely to be the deed of a Sony employee.Stammberger provided to the FBI Norse's findings that suggest the hack was an inside job, stating, \"Sony was not just hacked; this is a company that was essentially nuked from the inside. We are very confident that this was not an attack master-minded by North Korea and that insiders were key to the implementation of one of the most devastating attacks in history.\" Stammberger believes that the security failure may have originated from six disgruntled former Sony employees, based on their past skill sets and discussions these people made in chat rooms. Norse employees identified these people from a list of workers that were eliminated from Sony during a restructuring in May 2014, and noted that some had made very public and angry responses to their firing, and would be in appropriate positions to identify the means to access secure parts of Sony's servers. After a private briefing lasting three hours, the FBI formally rejected Norse's alternative assessment.Seth Rogen also expressed doubts about the claims that North Korea was behind the hack. Based on the timeline of events and the amount of information hacked, he believes the hack may have been conducted by a Sony employee. \"I've also heard people say that they think someone was hired to do the hack as a way of getting Amy Pascal fired. I don't know if I subscribe to those theories, but I kind of don't think it was North Korea.\"\n\n\n*** Other investigations ***\nIn response to allegations that the intrusion was the result of an inside job, or something other than a state-sponsored cyber attack, computer forensic specialist Kevin Mandia, president of the security firm FireEye, commented that there was not a \"shred of evidence\" that an insider was responsible for the attack and that the evidence uncovered by his security firm supports the position of the United States government.In February 2016, analytics firm Novetta issued a joint investigative report into the attack. The report, published in collaboration with Kaspersky Lab, Symantec, AlienVault, Invincea, Trend Micro, Carbon Black, PunchCyber, RiskIQ, ThreatConnect and Volexity, concluded that a well-resourced organization had committed the intrusion, and that \"we strongly believe that the SPE attack was not the work of insiders or hacktivists\". The analysis said that the same group is engaged in military espionage campaigns.\nBecause of the depth and scope of malware tools, structure of the analyzed code bases, TTP overlap with similar attacks, and long trail of activities attributed to the Lazarus Group, Novetta does not believe that the SPE attack was carried out by insiders or hacktivists, but rather by a more structured, resourced, and motivated organization. ... Although our analysis cannot support direct attribution of a nation-state or other specific group due to the difficulty of proper attribution in the cyber realm, the FBI's official attribution claims could be supported by our findings.\n\n\n*** Formal charges ***\nThe U.S. Department of Justice issued formal charges related to the Sony hack on North Korean citizen Park Jin-hyok on September 6, 2018. The Department of Justice contends that Park was a North Korean hacker that worked for the country's Reconnaissance General Bureau, the equivalent of the Central Intelligence Agency. The Department of Justice also asserted that Park was partially responsible for arranging the WannaCry ransomware attack of 2017, having developed part of the ransomware software. The Department of Justice had previously identified Park and had been monitoring him for some time, but could not indict him immediately as much of the information around him was classified.  The Criminal Complaint was unsealed by the US Department of Justice via a press release in September 2018.\n\n== Legal responses ==\nObama also issued a legislative proposal to Congress to update current laws such as the Racketeer Influenced and Corrupt Organizations Act and introduce new ones to allow federal and national law enforcement officials to better respond to cybercrimes like the Sony hack, and to be able to prosecute such crimes compatibly to similar off-line crimes, while protecting the privacy of Americans.\n\n== Public discussion ==\n\n\n*** About reporting on the hack ***\nIn December 2014, Sony requested that the media stop covering the hack. Sony also threatened legal action if the media did not comply, but according to law professor Eugene Volokh, Sony's legal threats are \"unlikely to prevail\". Sony then threatened legal action against Twitter if it did not suspend accounts of people who posted the hacked material. American screenwriter Aaron Sorkin wrote an op-ed for The New York Times opining that the media was helping the hackers by publishing and reporting on the leaked information. On December 18, Reddit took the unusual step of banning the subreddit r/SonyGOP that was being used to distribute the hacked files.\n\n\n*** About pulling The Interview ***\nThe threats made directly at Sony over The Interview were seen by many as a threat to free speech. The decision to pull the film was criticized by several Hollywood filmmakers, actors, and television hosts, including Ben Stiller, Steve Carell, Rob Lowe, Jimmy Kimmel and Judd Apatow. Some commentators contrasted the situation to the non-controversial release of the 2004 Team America: World Police, a film that mocked the leadership of North Korea's prior leader, Kim Jong-il. The Alamo Drafthouse was poised to replace showings of The Interview with Team America until the film's distributor Paramount Pictures ordered the theaters to stop.In light of the threats made to Sony over The Interview, New Regency cancelled its March 2015 production plans for a film adaptation of the graphic novel Pyongyang: A Journey in North Korea, which was set to star Steve Carell. Hustler announced its intentions to make a pornographic parody film of The Interview. Hustler founder Larry Flynt said, \"If Kim Jong-un and his henchmen were upset before, wait till they see the movie we're going to make\".\n\n\n*** Outside the United States ***\nIn China, the media coverage of the hackings has been limited and outside sources have been censored. A search for \"North Korea hack\" on Baidu, China's leading search engine returned just one article, which named North Korea as \"one of several suspects.\" However, Google, which was and is inaccessible in China, returned more than 36 million results for the same query.\nHua Chunying, a spokeswoman of foreign affairs, \"shied away from directly addressing\" the Sony hacking situation.\nQuestion: What did the hackers threaten to do if Sony released The Interview?",
    "context": "",
    "output": "Answer: The hackers threatened to take terrorist actions against the film's New York City premiere and American wide release.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What did the hackers threaten to do if Sony released The Interview?",
      "answer": "The hackers threatened to take terrorist actions against the film's New York City premiere and American wide release.",
      "context": "Sony Pictures hack\n\n==Introduction==\nOn November 24, 2014, a hacker group identifying itself as \"Guardians of Peace\" leaked a release of confidential data from the film studio Sony Pictures entertainment (SPE). The data included personal information about Sony Pictures employees and their families, emails between employees, information about executive salaries at the company, copies of then-unreleased Sony films, plans for future Sony films, scripts for certain films, and other information. The perpetrators then employed a variant of the Shamoon wiper malware to erase Sony's computer infrastructure.During the hack, the group demanded that Sony withdraw its then-upcoming film The Interview, starring James Franco as a reporter and Seth Rogen (who also wrote, produced, and directed the film alongside his creative partner Evan Goldberg) as his producer who are hired by the United States and South Korean governments to set up an interview with North Korean leader Kim Jong-un as part of a plot to assassinate him, and threatened terrorist attacks at cinemas screening the film. After many major U.S. theater chains opted not to screen The Interview in response to these threats, Sony chose to cancel the film's formal premiere and mainstream release, opting to skip directly to a downloadable digital release followed by a limited theatrical release the next day.United States intelligence officials, after evaluating the software, techniques, and network sources used in the hack, concluded that the attack was sponsored by the government of North Korea, which has since denied all responsibility.\n\n\n\n== Hack and perpetrators ==\nThe exact duration of the hack is yet unknown. U.S. investigators say the culprits spent at least two months copying critical files. A purported member of the Guardians of Peace (GOP) who has claimed to have performed the hack stated that they had access for at least a year prior to its discovery in November 2014, according to Wired. The hackers involved claim to have taken more than 100 terabytes of data from Sony, but that claim has never been confirmed. The attack was conducted using malware. Although Sony was not specifically mentioned in its advisory, US-CERT said that attackers used a Server Message Block (SMB) Worm Tool to conduct attacks against a major entertainment company. Components of the attack included a listening implant, backdoor, proxy tool, destructive hard drive tool, and destructive target cleaning tool. The components clearly suggest an intent to gain repeated entry, extract information, and be destructive, as well as remove evidence of the attack.Sony was made aware of the hack on Monday, November 24, 2014, as the malware previously installed rendered many Sony employees' computers inoperable by the software, with the warning by a group calling themselves the Guardians of Peace, along with a portion of the confidential data taken during the hack. Several Sony-related Twitter accounts were also taken over. This followed a message that several Sony Pictures executives had received via email on the previous Friday, November 21; the message, coming from a group called \"God'sApstls\"  [sic], demanded \"monetary compensation\" or otherwise, \"Sony Pictures will be bombarded as a whole\". This email message had been mostly ignored by executives, lost in the volume they had received or treated as spam email. In addition to the activation of the malware on November 24, the message included a warning for Sony to decide on their course of action by 11:00 p.m. that evening, although no apparent threat was made when that deadline passed. In the days following this hack, the Guardians of Peace began leaking yet-unreleased films and started to release portions of the confidential data to attract the attention of social media sites, although they did not specify what they wanted in return. Sony quickly organized internal teams to try to manage the loss of data to the Internet, and contacted the FBI and the private security firm FireEye to help protect Sony employees whose personal data was exposed by the hack, repair the damaged computer infrastructure and trace the source of the leak. The first public report concerning a North Korean link to the attack was published by Re/code on November 28 and later confirmed by NBC News.\n\nOn December 8, 2014, alongside the eighth large data dump of confidential information, the Guardians of Peace threatened Sony with language relating to the September 11 attacks that drew the attention of U.S. security agencies. North Korean state-sponsored hackers are suspected by the United States of being involved in part due to specific threats made toward Sony and movie theaters showing The Interview, a comedy film about an assassination attempt against Kim Jong-un. North Korean officials had previously expressed concerns about the film to the United Nations, stating that \"to allow the production and distribution of such a film on the assassination of an incumbent head of a sovereign state should be regarded as the most undisguised sponsoring of terrorism as well as an act of war.\"In its first quarter financials for 2015, Sony Pictures set aside $15 million to deal with ongoing damages from the hack. Sony has bolstered its cyber-security infrastructure as a result, using solutions to prevent similar hacks or data loss in the future. Sony co-chairperson Amy Pascal announced in the wake of the hack that she would step down as of May 2015, and instead will become more involved with film production under Sony.\n\n== Information obtained ==\nAccording to a notice letter dated December 8, 2014, from SPE to its employees, SPE learned on December 1, 2014, that personally identifiable information about employees and their dependents may have been obtained by unauthorized individuals as a result of a \"brazen cyber-attack\", including names, addresses, Social Security numbers and financial information. On December 7, 2014, C-SPAN reported that the hackers stole 47,000 unique Social Security numbers from the SPE computer network.Although personal data may have been stolen, early news reports focused mainly on celebrity gossip and embarrassing details about Hollywood and film industry business affairs gleaned by the media from electronic files, including private email messages. Among the information revealed in the emails was that Sony CEO Kazuo Hirai pressured Sony Pictures co-chairwoman Amy Pascal to \"soften\" the assassination scene in The Interview. Many details relating to the actions of the Sony Pictures executives, including Pascal and Michael Lynton, were also released, in a manner that appeared to be intended to spur distrust between these executives and other employees of Sony.Other emails released in the hack showed Pascal and Scott Rudin, a film and theatrical producer, discussing Angelina Jolie. In the emails, Rudin referred to Jolie as \"a minimally talented spoiled brat\" because Jolie wanted David Fincher to direct her film Cleopatra, which Rudin felt would interfere with Fincher directing a planned film about Steve Jobs. Pascal and Rudin were also noted to have had an email exchange about Pascal's upcoming encounter with Barack Obama that included characterizations described as racist, which led to Pascal's resignation from Sony. The two had suggested they should mention films about African-Americans upon meeting the president, such as Django Unchained, 12 Years a Slave and The Butler, all of which depict slavery in the United States or the pre-civil rights era. Pascal and Rudin later apologized. Details of lobbying efforts by politician Mike Moore on behalf of the Digital Citizens Alliance and FairSearch against Google were also revealed.The leak revealed multiple details of behind-the-scenes politics on Columbia Pictures' current Spider-Man film series, including emails between Pascal and others to various heads of Marvel Studios. Due to the outcry from fans, the Spider-Man license was eventually negotiated to be shared between both studios. In addition to the emails, a copy of the screenplay for the James Bond film Spectre, released in 2015, was obtained. Several future Sony Pictures films, including Annie, Mr. Turner, Still Alice and To Write Love on Her Arms, were also leaked. The hackers intended to release additional information on December 25, 2014, which coincided with the release date of The Interview in the United States.\nAccording to The Daily Dot, based on the email leaks, while he was at Sony, executive Charles Sipkins was responsible for following senior executives' orders to edit Wikipedia articles about them.In December 2014, former Sony Pictures Entertainment employees filed four lawsuits against the company for not protecting their data that was released in the hack, which included Social Security numbers and medical information. As part of the emails, it was revealed that Sony was in talks with Nintendo to make an animated film based on the Super Mario Bros. series (which came to fruition 4 years later, albeit under Universal and Illumination instead of Sony, released in April of 2023).In January 2015, details were revealed of the MPAA's lobbying of the United States International Trade Commission to mandate U.S. ISPs either at the internet transit level or consumer level internet service provider, to implement IP address blocking pirate websites as well as linking websites. WikiLeaks published over 30,000 documents that were obtained via the hack in April 2015, with founder Julian Assange stating that the document archive \"shows the inner workings of an influential multinational corporation\" that should be made public.In November 2015, after Charlie Sheen revealed he was HIV positive in a television interview to Matt Lauer, it was revealed that information about his diagnosis was leaked in an email between senior Sony bosses dated March 10, 2014. In December, Snap Inc., due to the hack, was revealed to have acquired Vergence Labs for $15 million in cash and stock, the developers of Epiphany Eyewear, and mobile app Scan for $150 million.\n\n== Threats surrounding The Interview ==\nOn December 16, for the first time since the hack, the \"Guardians of Peace\" mentioned the then-upcoming film The Interview by name, and threatened to take terrorist actions against the film's New York City premiere at Sunshine Cinema on December 18, as well as on its American wide release date, set for December 25. Sony pulled the theatrical release the following day.\n\nWe will clearly show it to you at the very time and places The Interview be shown, including the premiere, how bitter fate those who seek fun in terror should be doomed to. Soon all the world will see what an awful movie Sony Pictures Entertainment has made. The world will be full of fear. Remember the 11th of September 2001. We recommend you to keep yourself distant from the places at that time. (If your house is nearby, you'd better leave.)\nWhatever comes in the coming days is called by the greed of Sony Pictures Entertainment. All the world will denounce the SONY.\nSeth Rogen and James Franco, the stars of The Interview, responded by saying they did not know if it was definitely caused by the film, but later canceled all media appearances tied to the film outside of the planned New York City premiere on December 16, 2014. Following initial threats made towards theaters that would show The Interview, several theatrical chains, including Carmike Cinemas, Bow Tie Cinemas, Regal Entertainment Group, Showcase Cinemas, AMC Theatres, Cinemark Theatres, as well as several independent movie theater owners announced that they would not screen The Interview. The same day, Sony stated that they would allow theaters to opt out of showing The Interview, but later decided to fully pull the national December 25 release of the film, as well as announce that there were \"no further release plans\" to release the film on any platform, including home video, in the foreseeable future.On December 18, two messages (both allegedly from the Guardians of Peace) were released. One, sent in a private message to Sony executives, stated that they would not release any further information if Sony never releases the film and removed its presence from the internet. The other, posted to Pastebin, a web application used for text storage that the Guardians of Peace have used for previous messages, stated that the studio had \"suffered enough\" and could release The Interview, but only if Kim Jong-un's death scene was not \"too happy\". The post also stated that the company cannot \"test [them] again\", and that \"if [Sony Pictures] makes anything else, [they] will be here ready to fight\".President Barack Obama, in an end-of-year press speech on December 19, commented on the Sony hacking and stated that he felt Sony made a mistake in pulling the film, and that producers should \"not get into a pattern where you are intimidated by these acts\". He also said, \"We will respond proportionally and we will respond in a place and time and manner that we choose.\" In response to President Obama's statement, Sony Entertainment's CEO Michael Lynton said on the CNN program Anderson Cooper 360 that the public, the press and the President misunderstood the events. Lynton said the decision to cancel the wide release was in response to a majority of theaters pulling their showings and not to the hackers' threats. Lynton stated that they would seek other options to distribute the film in the future, and noted \"We have not given in. And we have not backed down. We have always had every desire to have the American public see this movie.\"On December 23, Sony opted to authorize approximately 300 mostly-independent theaters to show The Interview on Christmas Day, as the four major theater chains had yet to change their earlier decision not to show the film. The FBI worked with these theaters to detail the specifics of the prior threats and how to manage security for the showings, but noted that there was no actionable intelligence on the prior threats. Sony's Lynton stated on the announcement that \"we are proud to make it available to the public and to have stood up to those who attempted to suppress free speech\". The Interview was also released to Google Play, Xbox Video, and YouTube on December 24. No incidents predicated by the threats occurred with the release, and instead, the unorthodox release of the film led to it being considered a success due to increased interest in the film following the attention it had received.On December 27, the North Korean National Defence Commission released a statement accusing Obama of being \"the chief culprit who forced the Sony Pictures Entertainment to indiscriminately distribute the movie.\"\n\n== U.S. accusations and formal charges against North Korea ==\nU.S. government officials stated on December 17, 2014 their belief that the North Korean government was \"centrally involved\" in the hacking, although there was initially some debate within the White House whether or not to make this finding public. White House officials treated the situation as a \"serious national security matter\", and the Federal Bureau of Investigation (FBI) formally stated on December 19 that they connected the North Korean government to the cyber-attacks. Including undisclosed evidence, these claims were made based on the use of similar malicious hacking tools and techniques previously employed by North Korean hackers\u2014including North Korea's cyberwarfare agency Bureau 121 on South Korean targets. According to the FBI:\n\"[A] technical analysis of the data deletion malware used in this attack revealed links to other malware that the FBI knows North Korea previously developed. For example, there were similarities in specific lines of code, encryption algorithms, data deletion methods, and compromised networks.\n\"The FBI also observed significant overlap between the infrastructure used in this attack and other malicious cyber activity the U.S. government has previously linked directly to North Korea. For example, the FBI discovered that several Internet protocol (IP) addresses associated with known North Korean infrastructure communicated with IP addresses that were hardcoded into the data deletion malware used in this attack. The FBI later clarified that the source IP addresses were associated with a group of North Korean businesses located in Shenyang in northeastern China.\n\"Separately, the tools used in the SPE attack have similarities to a cyber-attack in March of last year against South Korean banks and media outlets, which was carried out by North Korea.\"The FBI later clarified more details of the attacks, attributing them to North Korea by noting that the hackers were \"sloppy\" with the use of proxy IP addresses that originated from within North Korea. At one point the hackers logged into the Guardians of Peace Facebook account and Sony's servers without effective concealment. FBI Director James Comey stated that Internet access is tightly controlled within North Korea, and as such, it was unlikely that a third party had hijacked these addresses without allowance from the North Korean government. The National Security Agency assisted the FBI in analyzing the attack, specifically in reviewing the malware and tracing its origins; NSA director Admiral Michael Rogers agreed with the FBI that the attack originated from North Korea. A disclosed NSA report published by Der Spiegel stated that the agency had become aware of the origins of the hack due to their own cyber-intrusion on North Korea's network that they had set up in 2010, following concerns of the technology maturation of the country.The North Korean news agency KCNA denied the \"wild rumours\" of North Korean involvement, but said that \"The hacking into the SONY Pictures might be a righteous deed of the supporters and sympathizers with the DPRK in response to its appeal.\" North Korea offered to be part of a joint probe with the United States to determine the hackers' identities, threatening consequences if the United States refused to collaborate and continued the allegation. The U.S. refused and asked China for investigative assistance instead. Some days after the FBI's announcement, North Korea temporarily suffered a nationwide Internet outage, which the country claimed to be the United States' response to the hacking attempts.On the day following the FBI's accusation of North Korea's involvement, the FBI received an email purportedly from the hacking group, linking to a YouTube video entitled \"you are an idiot!\", apparently mocking the organization.On December 19, 2014, U.S. Secretary of Homeland Security Jeh Johnson released a statement saying, \"The cyber attack against Sony Pictures Entertainment was not just an attack against a company and its employees. It was also an attack on our freedom of expression and way of life.\" He encouraged businesses and other organizations to use the Cybersecurity Framework developed by the National Institute of Standards and Technology (NIST) to assess and limit cyber risks and protect against cyber threats. On the same day, U.S. Secretary of State John Kerry published his remarks condemning North Korea for the cyber-attack and threats against movie theatres and moviegoers. \"This provocative and unprecedented attack and subsequent threats only strengthen our resolve to continue to work with partners around the world to strengthen cybersecurity, promote norms of acceptable state behavior, uphold freedom of expression, and ensure that the Internet remains open, interoperable, secure and reliable,\" he said.On January 2, 2015, the U.S., under an Executive Order issued by President Obama, installed additional economic sanctions on already-sanctioned North Korea for the hack, which North Korean officials called out as \"groundlessly stirring up bad blood towards\" the country.\n\n\n*** Doubts about accusations against North Korea ***\nCyber security expert Kurt Stammberger from cyber security firm Norse, DEFCON organizer and Cloudflare researcher Marc Rogers, Hector Monsegur and Kim Zetter, a security journalist at Wired magazine, have expressed doubt and tended to agree that North Korea might not be behind the attack.\nMichael Hiltzik, a journalist for the Los Angeles Times, said that all evidence against North Korea was \"circumstantial\" and that some cybersecurity experts were \"skeptical\" about attributing the attack to the North Koreans. Cybersecurity expert Lucas Zaichkowsky said, \"State-sponsored attackers don't create cool names for themselves like 'Guardians of Peace' and promote their activity to the public.\" Kim Zetter of Wired magazine called released evidence against the government \"flimsy\". Former hacker Hector Monsegur, who once hacked into Sony, explained to CBS News that exfiltrating one or one hundred terabytes of data \"without anyone noticing\" would have taken months or years, not weeks. Monsegur doubted the accusations due to North Korea's insufficient internet infrastructure to handle the transfer of that much data. He believed that it could have been either Chinese, Russian, or North Korean-sponsored hackers working outside of the country, but most likely to be the deed of a Sony employee.Stammberger provided to the FBI Norse's findings that suggest the hack was an inside job, stating, \"Sony was not just hacked; this is a company that was essentially nuked from the inside. We are very confident that this was not an attack master-minded by North Korea and that insiders were key to the implementation of one of the most devastating attacks in history.\" Stammberger believes that the security failure may have originated from six disgruntled former Sony employees, based on their past skill sets and discussions these people made in chat rooms. Norse employees identified these people from a list of workers that were eliminated from Sony during a restructuring in May 2014, and noted that some had made very public and angry responses to their firing, and would be in appropriate positions to identify the means to access secure parts of Sony's servers. After a private briefing lasting three hours, the FBI formally rejected Norse's alternative assessment.Seth Rogen also expressed doubts about the claims that North Korea was behind the hack. Based on the timeline of events and the amount of information hacked, he believes the hack may have been conducted by a Sony employee. \"I've also heard people say that they think someone was hired to do the hack as a way of getting Amy Pascal fired. I don't know if I subscribe to those theories, but I kind of don't think it was North Korea.\"\n\n\n*** Other investigations ***\nIn response to allegations that the intrusion was the result of an inside job, or something other than a state-sponsored cyber attack, computer forensic specialist Kevin Mandia, president of the security firm FireEye, commented that there was not a \"shred of evidence\" that an insider was responsible for the attack and that the evidence uncovered by his security firm supports the position of the United States government.In February 2016, analytics firm Novetta issued a joint investigative report into the attack. The report, published in collaboration with Kaspersky Lab, Symantec, AlienVault, Invincea, Trend Micro, Carbon Black, PunchCyber, RiskIQ, ThreatConnect and Volexity, concluded that a well-resourced organization had committed the intrusion, and that \"we strongly believe that the SPE attack was not the work of insiders or hacktivists\". The analysis said that the same group is engaged in military espionage campaigns.\nBecause of the depth and scope of malware tools, structure of the analyzed code bases, TTP overlap with similar attacks, and long trail of activities attributed to the Lazarus Group, Novetta does not believe that the SPE attack was carried out by insiders or hacktivists, but rather by a more structured, resourced, and motivated organization. ... Although our analysis cannot support direct attribution of a nation-state or other specific group due to the difficulty of proper attribution in the cyber realm, the FBI's official attribution claims could be supported by our findings.\n\n\n*** Formal charges ***\nThe U.S. Department of Justice issued formal charges related to the Sony hack on North Korean citizen Park Jin-hyok on September 6, 2018. The Department of Justice contends that Park was a North Korean hacker that worked for the country's Reconnaissance General Bureau, the equivalent of the Central Intelligence Agency. The Department of Justice also asserted that Park was partially responsible for arranging the WannaCry ransomware attack of 2017, having developed part of the ransomware software. The Department of Justice had previously identified Park and had been monitoring him for some time, but could not indict him immediately as much of the information around him was classified.  The Criminal Complaint was unsealed by the US Department of Justice via a press release in September 2018.\n\n== Legal responses ==\nObama also issued a legislative proposal to Congress to update current laws such as the Racketeer Influenced and Corrupt Organizations Act and introduce new ones to allow federal and national law enforcement officials to better respond to cybercrimes like the Sony hack, and to be able to prosecute such crimes compatibly to similar off-line crimes, while protecting the privacy of Americans.\n\n== Public discussion ==\n\n\n*** About reporting on the hack ***\nIn December 2014, Sony requested that the media stop covering the hack. Sony also threatened legal action if the media did not comply, but according to law professor Eugene Volokh, Sony's legal threats are \"unlikely to prevail\". Sony then threatened legal action against Twitter if it did not suspend accounts of people who posted the hacked material. American screenwriter Aaron Sorkin wrote an op-ed for The New York Times opining that the media was helping the hackers by publishing and reporting on the leaked information. On December 18, Reddit took the unusual step of banning the subreddit r/SonyGOP that was being used to distribute the hacked files.\n\n\n*** About pulling The Interview ***\nThe threats made directly at Sony over The Interview were seen by many as a threat to free speech. The decision to pull the film was criticized by several Hollywood filmmakers, actors, and television hosts, including Ben Stiller, Steve Carell, Rob Lowe, Jimmy Kimmel and Judd Apatow. Some commentators contrasted the situation to the non-controversial release of the 2004 Team America: World Police, a film that mocked the leadership of North Korea's prior leader, Kim Jong-il. The Alamo Drafthouse was poised to replace showings of The Interview with Team America until the film's distributor Paramount Pictures ordered the theaters to stop.In light of the threats made to Sony over The Interview, New Regency cancelled its March 2015 production plans for a film adaptation of the graphic novel Pyongyang: A Journey in North Korea, which was set to star Steve Carell. Hustler announced its intentions to make a pornographic parody film of The Interview. Hustler founder Larry Flynt said, \"If Kim Jong-un and his henchmen were upset before, wait till they see the movie we're going to make\".\n\n\n*** Outside the United States ***\nIn China, the media coverage of the hackings has been limited and outside sources have been censored. A search for \"North Korea hack\" on Baidu, China's leading search engine returned just one article, which named North Korea as \"one of several suspects.\" However, Google, which was and is inaccessible in China, returned more than 36 million results for the same query.\nHua Chunying, a spokeswoman of foreign affairs, \"shied away from directly addressing\" the Sony hacking situation."
    }
  },
  {
    "instruction": "Context: Common Criteria Evaluation and Validation Scheme\n\n==Introduction==\nCommon Criteria Evaluation and Validation Scheme (CCEVS) is a United States Government program administered by the National Information Assurance Partnership (NIAP) to evaluate security functionality of an information technology with conformance to the Common Criteria international standard. The new standard uses Protection Profiles and the Common Criteria Standards to certify the product. This change happened in 2009. Their stated goal in making the change was to ensure achievable, repeatable and testable evaluations. \n\n\n\n== Objectives ==\nThe CCEVS program is a partnership between the U.S. Government and industry to assist themselves and the consumers:\n\nTo meet the needs of government and industry for cost-effective evaluation of IT products\nTo encourage the formation of commercial security testing laboratories and the development of a private sector security testing industry\nTo ensure that security evaluations of IT products are performed to consistent standards\nTo improve the availability of evaluated IT products.The scheme is intended to serve many communities of interest with very diverse roles and responsibilities. This community includes IT product developers, product vendors, value-added resellers, systems integrators, IT security researchers, acquisition/procurement authorities, consumers of IT products, auditors, and accreditors (individuals deciding the fitness for operation of those products within their respective organizations). Close cooperation between government and industry is paramount to the success of the scheme and the realization of its objectives.\n\n== Validation Body ==\nThe Validation Body has the ultimate responsibility for the operation of the CCEVS in accordance with NIAP policies and procedures. Where appropriate it will interpret and amend those policies and procedures. The NIST and NSA are responsible for providing sufficient resources to the NIAP so that the Validation Body may carry out its responsibilities. However as of 2009 the NIAP has reached out to other vendors, labs, academia and customers to help in the evaluation of products therefore diminishing the reliance on the NSA. \nThe Validation Body is led by a Director and Deputy Director selected by NIST and NSA management and other personnel include validators and technical experts in various technology areas.\nThe Validation Body ensures that appropriate mechanisms are in place to protect the interests of all parties within the CCEVS participating in the process of IT security evaluation.\nDisputes brought forth by any participating party, i.e. the sponsor of an evaluation, product or Protection Profile developer or CCTL concerning the operation of the CCEVS or any of its associated activities shall be referred to the Validation Body for resolution.\nOnce the product has been certified it is listed as PP Compliant in the NIAP Product Compliant List (PCL).\n\nQuestion: What happens to a product once it has been certified in the Common Criteria Evaluation and Validation Scheme?\n\nAnswer:",
    "context": "",
    "output": "Once a product has been certified in the Common Criteria Evaluation and Validation Scheme, it is listed as PP Compliant in the NIAP Product Compliant List (PCL).",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What happens to a product once it has been certified in the Common Criteria Evaluation and Validation Scheme?",
      "answer": "Once a product has been certified in the Common Criteria Evaluation and Validation Scheme, it is listed as PP Compliant in the NIAP Product Compliant List (PCL).",
      "context": "Common Criteria Evaluation and Validation Scheme\n\n==Introduction==\nCommon Criteria Evaluation and Validation Scheme (CCEVS) is a United States Government program administered by the National Information Assurance Partnership (NIAP) to evaluate security functionality of an information technology with conformance to the Common Criteria international standard. The new standard uses Protection Profiles and the Common Criteria Standards to certify the product. This change happened in 2009. Their stated goal in making the change was to ensure achievable, repeatable and testable evaluations. \n\n\n\n== Objectives ==\nThe CCEVS program is a partnership between the U.S. Government and industry to assist themselves and the consumers:\n\nTo meet the needs of government and industry for cost-effective evaluation of IT products\nTo encourage the formation of commercial security testing laboratories and the development of a private sector security testing industry\nTo ensure that security evaluations of IT products are performed to consistent standards\nTo improve the availability of evaluated IT products.The scheme is intended to serve many communities of interest with very diverse roles and responsibilities. This community includes IT product developers, product vendors, value-added resellers, systems integrators, IT security researchers, acquisition/procurement authorities, consumers of IT products, auditors, and accreditors (individuals deciding the fitness for operation of those products within their respective organizations). Close cooperation between government and industry is paramount to the success of the scheme and the realization of its objectives.\n\n== Validation Body ==\nThe Validation Body has the ultimate responsibility for the operation of the CCEVS in accordance with NIAP policies and procedures. Where appropriate it will interpret and amend those policies and procedures. The NIST and NSA are responsible for providing sufficient resources to the NIAP so that the Validation Body may carry out its responsibilities. However as of 2009 the NIAP has reached out to other vendors, labs, academia and customers to help in the evaluation of products therefore diminishing the reliance on the NSA. \nThe Validation Body is led by a Director and Deputy Director selected by NIST and NSA management and other personnel include validators and technical experts in various technology areas.\nThe Validation Body ensures that appropriate mechanisms are in place to protect the interests of all parties within the CCEVS participating in the process of IT security evaluation.\nDisputes brought forth by any participating party, i.e. the sponsor of an evaluation, product or Protection Profile developer or CCTL concerning the operation of the CCEVS or any of its associated activities shall be referred to the Validation Body for resolution.\nOnce the product has been certified it is listed as PP Compliant in the NIAP Product Compliant List (PCL)."
    }
  },
  {
    "instruction": "context: Manual recounts can still be conducted in Scantegrity as the underlying system produces both an electronic tally and a human-readable paper trail.\n\nAsk a question about this context.",
    "context": "",
    "output": "How are manual recounts conducted in Scantegrity?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How are manual recounts conducted in Scantegrity?",
      "answer": "Manual recounts can still be conducted in Scantegrity as the underlying system produces both an electronic tally and a human-readable paper trail."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is a brute force attack and how is its difficulty determined?",
    "context": "",
    "output": "A brute force attack is a method of cryptanalysis where every possible key is tried until the correct one is found. The difficulty of a brute force attack depends only on the key length and not on the cipher itself. If the key has N bits, there are 2^N possible keys to try, so a brute-force attack can recover the cipher in a worst-case time proportional to 2^N and an average time of 2^N-1.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is a brute force attack and how is its difficulty determined?",
      "answer": "A brute force attack is a method of cryptanalysis where every possible key is tried until the correct one is found. The difficulty of a brute force attack depends only on the key length and not on the cipher itself. If the key has N bits, there are 2^N possible keys to try, so a brute-force attack can recover the cipher in a worst-case time proportional to 2^N and an average time of 2^N-1."
    }
  },
  {
    "instruction": "Secure Real-time Transport Protocol\n\n==Introduction==\nThe Secure Real-time Transport Protocol (SRTP) is a profile for Real-time Transport Protocol (RTP) intended to provide encryption, message authentication and integrity, and replay attack protection to the RTP data in both unicast and multicast applications. It was developed by a small team of Internet Protocol and cryptographic experts from Cisco and Ericsson. It was first published by the IETF in March 2004 as RFC 3711.\nSince RTP is accompanied by the RTP Control Protocol (RTCP) which is used to control an RTP session, SRTP has a sister protocol, called Secure RTCP (SRTCP); it securely provides the same functions to SRTP as the ones provided by RTCP to RTP.\nUtilization of SRTP or SRTCP is optional in RTP or RTCP applications; but even if SRTP or SRTCP are used, all provided features (such as encryption and authentication) are optional and can be separately enabled or disabled. The only exception is the message authentication feature which is indispensable and required when using SRTCP.\n\n\n\n== Data flow encryption ==\nSRTP and SRTCP use Advanced Encryption Standard (AES) as the default cipher. There are two cipher modes defined which allow the AES block cipher to be used as a stream cipher:\n\nSegmented Integer Counter Mode\nA typical counter mode, which allows random access to any blocks, which is essential for RTP traffic running over unreliable network with possible loss of packets. In the general case, almost any function can be used in the role of counter, assuming that this function does not repeat for a large number of iterations.  But the standard for encryption of RTP data is just a usual integer incremental counter. AES running in this mode is the default encryption algorithm, with a default key size of 128 bits and a default session salt key length of 112 bits.\nf8-mode\nA variation of output feedback mode, enhanced to be seekable and with an altered initialization function. The default values of the encryption key and salt key are the same as for AES in counter mode. (AES running in this mode has been chosen to be used in 3G mobile networks.)Besides the AES cipher, SRTP allows the ability to disable encryption outright, using the so-called NULL cipher, which can be assumed as an alternate supported cipher. In fact, the NULL cipher does not perform any encryption; The encryption algorithm functions as the identity function, and copies the input stream to the output stream without any changes.  It is mandatory for this cipher mode to be implemented in any SRTP-compatible system.  As such, it can be used when the confidentiality guarantees ensured by SRTP are not required, while other SRTP features, such as authentication and message integrity, may be used.\nThrough SRTP can easily accommodate new encryption algorithms, the SRTP standard states that new encryption algorithms may only be introduced through publication of a new companion standard track RFC which must clearly define the new algorithm.\n\n== Authentication, integrity and replay protection ==\nThe above-listed encryption algorithms do not alone secure message integrity, an attacker will not be able to decrypt data but may be able to forge or replay previously transmitted data. Hence the SRTP standard also provides the means to secure the integrity of data and safety from replay.\nTo authenticate the message and protect its integrity, the HMAC-SHA1 algorithm is used. This produces a 160-bit result, which is then truncated to 80 or 32 bits to become the authentication tag appended to each packet.  The HMAC is calculated over the packet payload and material from the packet header, including the packet sequence number. To protect against replay attacks, the receiver maintains the sequence numbers of previously received messages, compares them with the sequence number in each new received message and admits the new message only if it has not been previously received.  This approach relies on the integrity protection to make it impossible to modify the sequence number without detection.\n\n== Key derivation ==\nA key derivation function is used to derive the different keys used in a crypto context (SRTP and SRTCP encryption keys and salts, SRTP and SRTCP authentication keys) from one single master key in a cryptographically secure way. Thus, the key management protocol needs to exchange only one master key, all the necessary session keys are generated by applying the key derivation function.\nPeriodic application of the key derivation function prevents an attacker from collecting large amounts of ciphertext encrypted with one single session key. This provides protection against certain attacks which are easier to carry out when a large amount of ciphertext is available. Furthermore, multiple applications of the key derivation function provides backwards and forward security in the sense that a compromised session key does not compromise other session keys derived from the same master key.  This means that even if an attacker managed to recover a session key, he is not able to decrypt messages secured with previous and later session keys derived from the same master key. (Note that, of course, a leaked master key reveals all the session keys derived from it.)\nSRTP relies on an external key management protocol to set up the initial master key. Two protocols specifically designed to be used with SRTP are ZRTP and MIKEY. There are also other methods to negotiate the SRTP keys. There are several vendors which offer products that use the SDES key exchange method.\n\n== Interoperability and applications ==\nSee Comparison of VoIP software \u00a7 Secure VoIP software for phones, servers and applications supporting SRTP.\n\n\n*** Telephony (VoIP) ***\nAsterisk (PBX)\n\n\n*** Web browser support ***\n\nKnown browsers with SRTP support of some kind\n\nBlink (browser engine) family\nChromium (web browser) supporting (but not universally) SRTP experimentally since 2016\nOpera (web browser)\nVivaldi (web browser)Web browser families with some level of SRTP in the mainline updating branches from the core rendering system\n\nGecko (software)\nMSHTML (superseded, but minimal support existed at time of expiration)\nWebKitSo far no known SRTP support exists for text based web browsers. Although SRTP could be used to operate in a VPN, in conjunction with web browsers, no VPN networks are known to be using it.\n\n== Standards documents ==\nRFC 3711, Proposed Standard, The Secure Real-time Transport Protocol (SRTP)\nRFC 4771, Proposed Standard, Integrity Transform Carrying Roll-Over Counter for the Secure Real-time Transport Protocol (SRTP)\nRFC 3551, Standard 65, RTP Profile for Audio and Video Conferences with Minimal Control\nRFC 3550, Standard 64, RTP: A Transport Protocol for Real-Time Applications\nRFC 2104, Informational, HMAC: Keyed-Hashing for Message Authentication\nRFC 7714, Proposed Standard, AES-GCM Authenticated Encryption in the Secure Real-time Transport Protocol (SRTP)\n\nWhat is the role of SRTCP in the context of SRTP?",
    "context": "",
    "output": "A: SRTCP provides the same functions to SRTP as RTCP provides to RTP, securely.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of SRTCP in the context of SRTP?",
      "answer": "SRTCP provides the same functions to SRTP as RTCP provides to RTP, securely.",
      "context": "Secure Real-time Transport Protocol\n\n==Introduction==\nThe Secure Real-time Transport Protocol (SRTP) is a profile for Real-time Transport Protocol (RTP) intended to provide encryption, message authentication and integrity, and replay attack protection to the RTP data in both unicast and multicast applications. It was developed by a small team of Internet Protocol and cryptographic experts from Cisco and Ericsson. It was first published by the IETF in March 2004 as RFC 3711.\nSince RTP is accompanied by the RTP Control Protocol (RTCP) which is used to control an RTP session, SRTP has a sister protocol, called Secure RTCP (SRTCP); it securely provides the same functions to SRTP as the ones provided by RTCP to RTP.\nUtilization of SRTP or SRTCP is optional in RTP or RTCP applications; but even if SRTP or SRTCP are used, all provided features (such as encryption and authentication) are optional and can be separately enabled or disabled. The only exception is the message authentication feature which is indispensable and required when using SRTCP.\n\n\n\n== Data flow encryption ==\nSRTP and SRTCP use Advanced Encryption Standard (AES) as the default cipher. There are two cipher modes defined which allow the AES block cipher to be used as a stream cipher:\n\nSegmented Integer Counter Mode\nA typical counter mode, which allows random access to any blocks, which is essential for RTP traffic running over unreliable network with possible loss of packets. In the general case, almost any function can be used in the role of counter, assuming that this function does not repeat for a large number of iterations.  But the standard for encryption of RTP data is just a usual integer incremental counter. AES running in this mode is the default encryption algorithm, with a default key size of 128 bits and a default session salt key length of 112 bits.\nf8-mode\nA variation of output feedback mode, enhanced to be seekable and with an altered initialization function. The default values of the encryption key and salt key are the same as for AES in counter mode. (AES running in this mode has been chosen to be used in 3G mobile networks.)Besides the AES cipher, SRTP allows the ability to disable encryption outright, using the so-called NULL cipher, which can be assumed as an alternate supported cipher. In fact, the NULL cipher does not perform any encryption; The encryption algorithm functions as the identity function, and copies the input stream to the output stream without any changes.  It is mandatory for this cipher mode to be implemented in any SRTP-compatible system.  As such, it can be used when the confidentiality guarantees ensured by SRTP are not required, while other SRTP features, such as authentication and message integrity, may be used.\nThrough SRTP can easily accommodate new encryption algorithms, the SRTP standard states that new encryption algorithms may only be introduced through publication of a new companion standard track RFC which must clearly define the new algorithm.\n\n== Authentication, integrity and replay protection ==\nThe above-listed encryption algorithms do not alone secure message integrity, an attacker will not be able to decrypt data but may be able to forge or replay previously transmitted data. Hence the SRTP standard also provides the means to secure the integrity of data and safety from replay.\nTo authenticate the message and protect its integrity, the HMAC-SHA1 algorithm is used. This produces a 160-bit result, which is then truncated to 80 or 32 bits to become the authentication tag appended to each packet.  The HMAC is calculated over the packet payload and material from the packet header, including the packet sequence number. To protect against replay attacks, the receiver maintains the sequence numbers of previously received messages, compares them with the sequence number in each new received message and admits the new message only if it has not been previously received.  This approach relies on the integrity protection to make it impossible to modify the sequence number without detection.\n\n== Key derivation ==\nA key derivation function is used to derive the different keys used in a crypto context (SRTP and SRTCP encryption keys and salts, SRTP and SRTCP authentication keys) from one single master key in a cryptographically secure way. Thus, the key management protocol needs to exchange only one master key, all the necessary session keys are generated by applying the key derivation function.\nPeriodic application of the key derivation function prevents an attacker from collecting large amounts of ciphertext encrypted with one single session key. This provides protection against certain attacks which are easier to carry out when a large amount of ciphertext is available. Furthermore, multiple applications of the key derivation function provides backwards and forward security in the sense that a compromised session key does not compromise other session keys derived from the same master key.  This means that even if an attacker managed to recover a session key, he is not able to decrypt messages secured with previous and later session keys derived from the same master key. (Note that, of course, a leaked master key reveals all the session keys derived from it.)\nSRTP relies on an external key management protocol to set up the initial master key. Two protocols specifically designed to be used with SRTP are ZRTP and MIKEY. There are also other methods to negotiate the SRTP keys. There are several vendors which offer products that use the SDES key exchange method.\n\n== Interoperability and applications ==\nSee Comparison of VoIP software \u00a7 Secure VoIP software for phones, servers and applications supporting SRTP.\n\n\n*** Telephony (VoIP) ***\nAsterisk (PBX)\n\n\n*** Web browser support ***\n\nKnown browsers with SRTP support of some kind\n\nBlink (browser engine) family\nChromium (web browser) supporting (but not universally) SRTP experimentally since 2016\nOpera (web browser)\nVivaldi (web browser)Web browser families with some level of SRTP in the mainline updating branches from the core rendering system\n\nGecko (software)\nMSHTML (superseded, but minimal support existed at time of expiration)\nWebKitSo far no known SRTP support exists for text based web browsers. Although SRTP could be used to operate in a VPN, in conjunction with web browsers, no VPN networks are known to be using it.\n\n== Standards documents ==\nRFC 3711, Proposed Standard, The Secure Real-time Transport Protocol (SRTP)\nRFC 4771, Proposed Standard, Integrity Transform Carrying Roll-Over Counter for the Secure Real-time Transport Protocol (SRTP)\nRFC 3551, Standard 65, RTP Profile for Audio and Video Conferences with Minimal Control\nRFC 3550, Standard 64, RTP: A Transport Protocol for Real-Time Applications\nRFC 2104, Informational, HMAC: Keyed-Hashing for Message Authentication\nRFC 7714, Proposed Standard, AES-GCM Authenticated Encryption in the Secure Real-time Transport Protocol (SRTP)"
    }
  },
  {
    "instruction": "Write an answer to the following question: What international participants were involved in the first Cyber Storm exercise?",
    "context": "",
    "output": "Officials from the United Kingdom, Canada, Australia, and New Zealand participated in the first Cyber Storm exercise.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What international participants were involved in the first Cyber Storm exercise?",
      "answer": "Officials from the United Kingdom, Canada, Australia, and New Zealand participated in the first Cyber Storm exercise."
    }
  },
  {
    "instruction": "TCP Wrappers\n\n==Introduction==\nTCP Wrappers (also known as tcp_wrappers) is a host-based networking ACL system, used to filter network access to Internet Protocol servers on (Unix-like) operating systems such as Linux or BSD. It allows host or subnetwork IP addresses, names and/or ident query replies, to be used as tokens on which to filter for access control purposes.\nThe original code was written by Wietse Venema in 1990 to monitor a cracker's activities on the Unix workstations at the Department of Math and Computer Science at the Eindhoven University of Technology. He maintained it until 1995, and on June 1, 2001, released it under its own BSD-style license.\nThe tarball includes a library named libwrap that implements the actual functionality. Initially, only services that were spawned for each connection from a super-server (such as inetd) got wrapped, utilizing the tcpd program. However most common network service daemons today can be linked against libwrap directly.  This is used by daemons that operate without being spawned from a super-server, or when a single process handles multiple connections.  Otherwise, only the first connection attempt would get checked against its ACLs.\nWhen compared to host access control directives often found in daemons' configuration files, TCP Wrappers have the benefit of runtime ACL reconfiguration (i.e., services don't have to be reloaded or restarted) and a generic approach to network administration.\nThis makes it easy to use for anti-worm scripts, such as DenyHosts or Fail2ban, to add and expire client-blocking rules, when excessive connections and/or many failed login attempts are encountered.\nWhile originally written to protect TCP and UDP accepting services, examples of usage to filter on certain ICMP packets exist too, such as 'pingd' \u2013 the userspace ping request responder.\n\n\n\n== 1999 Trojan ==\nIn January 1999, the distribution package at Eindhoven University of Technology (the primary distribution site until that day) was replaced by a modified version. The replacement contained a trojaned version of the software that would allow the intruder access to any server that it was installed on. The author spotted this within hours, upon which he relocated the primary distribution to his personal site.\n\nBased on the above text, answer a question. What are some examples of usage for TCP Wrappers in filtering network services?",
    "context": "",
    "output": "TCP Wrappers can be used to filter various network services, including TCP and UDP accepting services, as well as certain ICMP packets such as 'pingd' - the userspace ping request responder.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are some examples of usage for TCP Wrappers in filtering network services?",
      "answer": "TCP Wrappers can be used to filter various network services, including TCP and UDP accepting services, as well as certain ICMP packets such as 'pingd' - the userspace ping request responder.",
      "context": "TCP Wrappers\n\n==Introduction==\nTCP Wrappers (also known as tcp_wrappers) is a host-based networking ACL system, used to filter network access to Internet Protocol servers on (Unix-like) operating systems such as Linux or BSD. It allows host or subnetwork IP addresses, names and/or ident query replies, to be used as tokens on which to filter for access control purposes.\nThe original code was written by Wietse Venema in 1990 to monitor a cracker's activities on the Unix workstations at the Department of Math and Computer Science at the Eindhoven University of Technology. He maintained it until 1995, and on June 1, 2001, released it under its own BSD-style license.\nThe tarball includes a library named libwrap that implements the actual functionality. Initially, only services that were spawned for each connection from a super-server (such as inetd) got wrapped, utilizing the tcpd program. However most common network service daemons today can be linked against libwrap directly.  This is used by daemons that operate without being spawned from a super-server, or when a single process handles multiple connections.  Otherwise, only the first connection attempt would get checked against its ACLs.\nWhen compared to host access control directives often found in daemons' configuration files, TCP Wrappers have the benefit of runtime ACL reconfiguration (i.e., services don't have to be reloaded or restarted) and a generic approach to network administration.\nThis makes it easy to use for anti-worm scripts, such as DenyHosts or Fail2ban, to add and expire client-blocking rules, when excessive connections and/or many failed login attempts are encountered.\nWhile originally written to protect TCP and UDP accepting services, examples of usage to filter on certain ICMP packets exist too, such as 'pingd' \u2013 the userspace ping request responder.\n\n\n\n== 1999 Trojan ==\nIn January 1999, the distribution package at Eindhoven University of Technology (the primary distribution site until that day) was replaced by a modified version. The replacement contained a trojaned version of the software that would allow the intruder access to any server that it was installed on. The author spotted this within hours, upon which he relocated the primary distribution to his personal site."
    }
  },
  {
    "instruction": "context: The stolen information from the magnetic strips on the cards gets stored in the POS terminal/device memory before being encrypted and forwarded to the cybercriminal's Control and Command Server (C&C).\n\nAsk a question about this context.",
    "context": "",
    "output": "Where is the stolen information from the magnetic strips on the cards stored before being forwarded to the cybercriminal's Control and Command Server (C&C)?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Where is the stolen information from the magnetic strips on the cards stored before being forwarded to the cybercriminal's Control and Command Server (C&C)?",
      "answer": "The stolen information from the magnetic strips on the cards gets stored in the POS terminal/device memory before being encrypted and forwarded to the cybercriminal's Control and Command Server (C&C)."
    }
  },
  {
    "instruction": "Write an answer to the following question: What is the Cyber Training Academy and what does it provide?",
    "context": "",
    "output": "The Cyber Training Academy is a component of the A3C's work that provides training in cyber security.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the Cyber Training Academy and what does it provide?",
      "answer": "The Cyber Training Academy is a component of the A3C's work that provides training in cyber security."
    }
  },
  {
    "instruction": "context: MAPS does not provide a formal definition for acknowledged ISPs and end-users of IP addresses, making it difficult to differentiate between the two. This issue is further complicated when mailbox providers are confused with end-users of different kinds. As a result, using the DUL to block mail may lead to an obscure policy with potential global reliability issues for email delivery.\n\nAsk a question about this context.",
    "context": "",
    "output": "Why does MAPS fail to disambiguate the concepts of acknowledged ISP and end-users of IP addresses?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Why does MAPS fail to disambiguate the concepts of acknowledged ISP and end-users of IP addresses?",
      "answer": "MAPS does not provide a formal definition for acknowledged ISPs and end-users of IP addresses, making it difficult to differentiate between the two. This issue is further complicated when mailbox providers are confused with end-users of different kinds. As a result, using the DUL to block mail may lead to an obscure policy with potential global reliability issues for email delivery."
    }
  },
  {
    "instruction": "Context: Wi-Fi Protected Access\n\n==Introduction==\nWi-Fi Protected Access (WPA), Wi-Fi Protected Access 2 (WPA2), and Wi-Fi Protected Access 3 (WPA3) are the three security certification programs developed after 2000 by the Wi-Fi Alliance to secure wireless computer networks. The Alliance defined these in response to serious weaknesses researchers had found in the previous system, Wired Equivalent Privacy (WEP).WPA (sometimes referred to as the TKIP standard) became available in 2003. The Wi-Fi Alliance intended it as an intermediate measure in anticipation of the availability of the more secure and complex WPA2, which became available in 2004 and is a common shorthand for the full IEEE 802.11i (or IEEE 802.11i-2004) standard.\nIn January 2018, the Wi-Fi Alliance announced the release of WPA3, which has several security improvements over WPA2.\n\n\n\n== Versions ==\n\n\n*** WPA ***\nThe Wi-Fi Alliance intended WPA as an intermediate measure to take the place of WEP pending the availability of the full IEEE 802.11i standard. WPA could be implemented through firmware upgrades on wireless network interface cards designed for WEP that began shipping as far back as 1999. However, since the changes required in the wireless access points (APs) were more extensive than those needed on the network cards, most pre-2003 APs could not be upgraded to support WPA.\nThe WPA protocol implements the Temporal Key Integrity Protocol (TKIP). WEP used a 64-bit or 128-bit encryption key that must be manually entered on wireless access points and devices and does not change. TKIP employs a per-packet key, meaning that it dynamically generates a new 128-bit key for each packet and thus prevents the types of attacks that compromised WEP.WPA also includes a Message Integrity Check, which is designed to prevent an attacker from altering and resending data packets. This replaces the cyclic redundancy check (CRC) that was used by the WEP standard. CRC's main flaw was that it did not provide a sufficiently strong data integrity guarantee for the packets it handled. Well-tested message authentication codes existed to solve these problems, but they required too much computation to be used on old network cards. WPA uses a message integrity check algorithm called TKIP to verify the integrity of the packets. TKIP is much stronger than a CRC, but not as strong as the algorithm used in WPA2. Researchers have since discovered a flaw in WPA that relied on older weaknesses in WEP and the limitations of the message integrity code hash function, named Michael, to retrieve the keystream from short packets to use for re-injection and spoofing.\n\n\n*** WPA2 ***\n\nRatified in 2004, WPA2 replaced WPA. WPA2, which requires testing and certification by the Wi-Fi Alliance, implements the mandatory elements of IEEE 802.11i. In particular, it includes mandatory support for CCMP, an AES-based encryption mode. Certification began in September, 2004. From March 13, 2006, to June 30, 2020, WPA2 certification was mandatory for all new devices to bear the Wi-Fi trademark. As of July 1, 2020, support for WPA3 is mandatory.\n\n\n*** WPA3 ***\nIn January 2018, the Wi-Fi Alliance announced WPA3 as a replacement to WPA2. Certification began in June 2018, and WPA3 support has been mandatory for devices which bear the \"Wi-Fi CERTIFIED\u2122\" logo since July 2020.The new standard uses an equivalent 192-bit cryptographic strength in WPA3-Enterprise mode (AES-256 in GCM mode with SHA-384 as HMAC), and still mandates the use of CCMP-128 (AES-128 in CCM mode) as the minimum encryption algorithm in WPA3-Personal mode.\nThe WPA3 standard also replaces the pre-shared key (PSK) exchange with Simultaneous Authentication of Equals (SAE) exchange, a method originally introduced with IEEE 802.11s, resulting in a more secure initial key exchange in personal mode and forward secrecy. The Wi-Fi Alliance also says that WPA3 will mitigate security issues posed by weak passwords and simplify the process of setting up devices with no display interface.Protection of management frames as specified in the IEEE 802.11w amendment is also enforced by the WPA3 specifications.\n\n== Hardware support ==\nWPA has been designed specifically to work with wireless hardware produced prior to the introduction of WPA protocol, which provides inadequate security through WEP. Some of these devices support WPA only after applying firmware upgrades, which are not available for some legacy devices.Wi-Fi devices certified since 2006 support both the WPA and WPA2 security protocols. WPA3 is required since July 1, 2020.\n\n== WPA terminology ==\nDifferent WPA versions and protection mechanisms can be distinguished based on the target end-user(such as wep, wpa, wpa2, wpa3) (according to the method of authentication key distribution), and the encryption protocol used.\n\n\n*** Target users (authentication key distribution) ***\nWPA-Personal\nAlso referred to as WPA-PSK (pre-shared key) mode, this is designed for home, small office and basic uses these networks and does not require an authentication server. Each wireless network device encrypts the network traffic by deriving its 128-bit encryption key from a 256-bit shared key. This key may be entered either as a string of 64 hexadecimal digits, or as a passphrase of 8 to 63 printable ASCII characters. This pass-phrase-to-PSK mapping is nevertheless not binding, as Annex J is informative in the latest 802.11 standard. If ASCII characters are used, the 256-bit key is calculated by applying the PBKDF2 key derivation function to the passphrase, using the SSID as the salt and 4096 iterations of HMAC-SHA1. WPA-Personal mode is available on all three WPA versions.\nWPA-Enterprise\nAlso referred to as WPA-802.1X mode, and sometimes just WPA (as opposed to WPA-PSK), this is designed for enterprise networks and requires a RADIUS authentication server. This requires a more complicated setup, but provides additional security (e.g. protection against dictionary attacks on short passwords). Various kinds of the Extensible Authentication Protocol (EAP) are used for authentication. WPA-Enterprise mode is available on all three WPA versions.\nWi-Fi Protected Setup (WPS)\nThis is an alternative authentication key distribution method intended to simplify and strengthen the process, but which, as widely implemented, creates a major security hole via WPS PIN recovery.\n\n\n*** Encryption protocol ***\nTKIP (Temporal Key Integrity Protocol)\nThe RC4 stream cipher is used with a 128-bit per-packet key, meaning that it dynamically generates a new key for each packet. This is used by WPA.\nCCMP (CTR mode with CBC-MAC Protocol)\nThe protocol used by WPA2, based on the Advanced Encryption Standard (AES) cipher along with strong message authenticity and integrity checking is significantly stronger in protection for both privacy and integrity than the RC4-based TKIP that is used by WPA. Among informal names are AES and AES-CCMP. According to the 802.11n specification, this encryption protocol must be used to achieve fast 802.11n high bitrate schemes, though not all implementations enforce this. Otherwise, the data rate will not exceed 54 Mbit/s.\n\n== EAP extensions under WPA and WPA2 Enterprise ==\nOriginally, only EAP-TLS (Extensible Authentication Protocol - Transport Layer Security) was certified by the Wi-Fi alliance. In April 2010, the Wi-Fi Alliance announced the inclusion of additional EAP types to its WPA- and WPA2-Enterprise certification programs. This was to ensure that WPA-Enterprise certified products can interoperate with one another.\nAs of 2010 the certification program includes the following EAP types:\n\nEAP-TLS (previously tested)\nEAP-TTLS/MSCHAPv2 (April 2005)\nPEAPv0/EAP-MSCHAPv2 (April 2005)\nPEAPv1/EAP-GTC (April 2005)\nPEAP-TLS\nEAP-SIM (April 2005)\nEAP-AKA (April 2009)\nEAP-FAST (April 2009)802.1X clients and servers developed by specific firms may support other EAP types. This certification is an attempt for popular EAP types to interoperate; their failure to do so as of 2013 is one of the major issues preventing rollout of 802.1X on heterogeneous networks.\nCommercial 802.1X servers include Microsoft Internet Authentication Service and Juniper Networks Steelbelted RADIUS as well as Aradial Radius server. FreeRADIUS is an open source 802.1X server.\n\n== Security issues ==\n\n\n*** Weak password ***\nPre-shared key WPA and WPA2 remain vulnerable to password cracking attacks if users rely on a weak password or passphrase. WPA passphrase hashes are seeded from the SSID name and its length; rainbow tables exist for the top 1,000 network SSIDs and a multitude of common passwords, requiring only a quick lookup to speed up cracking WPA-PSK.Brute forcing of simple passwords can be attempted using the Aircrack Suite starting from the four-way authentication handshake exchanged during association or periodic re-authentication.WPA3 replaces cryptographic protocols susceptible to off-line analysis with protocols that require interaction with the infrastructure for each guessed password, supposedly placing temporal limits on the number of guesses. However, design flaws in WPA3 enable attackers to plausibly launch brute-force attacks (see Dragonblood attack).\n\n\n*** Lack of forward secrecy ***\nWPA and WPA2 do not provide forward secrecy, meaning that once an adverse person discovers the pre-shared key, they can potentially decrypt all packets encrypted using that PSK transmitted in the future and even past, which could be passively and silently collected by the attacker. This also means an attacker can silently capture and decrypt others' packets if a WPA-protected access point is provided free of charge at a public place, because its password is usually shared to anyone in that place. In other words, WPA only protects from attackers who do not have access to the password. Because of that, it's safer to use Transport Layer Security (TLS) or similar on top of that for the transfer of any sensitive data. However starting from WPA3, this issue has been addressed.\n\n\n*** WPA packet spoofing and decryption ***\nIn 2013, Mathy Vanhoef and Frank Piessens significantly improved upon the WPA-TKIP attacks of Erik Tews and Martin Beck. They demonstrated how to inject an arbitrary number of packets, with each packet containing at most 112 bytes of payload. This was demonstrated by implementing a port scanner, which can be executed against any client using WPA-TKIP. Additionally, they showed how to decrypt arbitrary packets sent to a client. They mentioned this can be used to hijack a TCP connection, allowing an attacker to inject malicious JavaScript when the victim visits a website.\nIn contrast, the Beck-Tews attack could only decrypt short packets with mostly known content, such as ARP messages, and only allowed injection of 3 to 7 packets of at most 28 bytes. The Beck-Tews attack also requires quality of service (as defined in 802.11e) to be enabled, while the Vanhoef-Piessens attack does not. Neither attack leads to recovery of the shared session key between the client and Access Point. The authors say using a short rekeying interval can prevent some attacks but not all, and strongly recommend switching from TKIP to AES-based CCMP.\nHalvorsen and others show how to modify the Beck-Tews attack to allow injection of 3 to 7 packets having a size of at most 596 bytes. The downside is that their attack requires substantially more time to execute: approximately 18 minutes and 25 seconds. In other work Vanhoef and Piessens showed that, when WPA is used to encrypt broadcast packets, their original attack can also be executed. This is an important extension, as substantially more networks use WPA to protect broadcast packets, than to protect unicast packets. The execution time of this attack is on average around 7 minutes, compared to the 14 minutes of the original Vanhoef-Piessens and Beck-Tews attack.\nThe vulnerabilities of TKIP are significant because WPA-TKIP had been held before to be an extremely safe combination; indeed, WPA-TKIP is still a configuration option upon a wide variety of wireless routing devices provided by many hardware vendors. A survey in 2013 showed that 71% still allow usage of TKIP, and 19% exclusively support TKIP.\n\n\n*** WPS PIN recovery ***\nA more serious security flaw was revealed in December 2011 by Stefan Viehb\u00f6ck that affects wireless routers with the Wi-Fi Protected Setup (WPS) feature, regardless of which encryption method they use. Most recent models have this feature and enable it by default. Many consumer Wi-Fi device manufacturers had taken steps to eliminate the potential of weak passphrase choices by promoting alternative methods of automatically generating and distributing strong keys when users add a new wireless adapter or appliance to a network. These methods include pushing buttons on the devices or entering an 8-digit PIN.\nThe Wi-Fi Alliance standardized these methods as Wi-Fi Protected Setup; however, the PIN feature as widely implemented introduced a major new security flaw. The flaw allows a remote attacker to recover the WPS PIN and, with it, the router's WPA/WPA2 password in a few hours. Users have been urged to turn off the WPS feature, although this may not be possible on some router models. Also, the PIN is written on a label on most Wi-Fi routers with WPS, and cannot be changed if compromised.\nWPA3 introduces a new alternative for the configuration of devices that lack sufficient user interface capabilities by allowing nearby devices to serve as an adequate UI for network provisioning purposes, thus mitigating the need for WPS.\n\n\n*** MS-CHAPv2 and lack of AAA server CN validation ***\nSeveral weaknesses have been found in MS-CHAPv2, some of which severely reduce the complexity of brute-force attacks, making them feasible with modern hardware. In 2012 the complexity of breaking MS-CHAPv2 was reduced to that of breaking a single DES key (work by Moxie Marlinspike and Marsh Ray). Moxie advised: \"Enterprises who are depending on the mutual authentication properties of MS-CHAPv2 for connection to their WPA2 Radius servers should immediately start migrating to something else.\"Tunneled EAP methods using TTLS or PEAP which encrypt the MSCHAPv2 exchange are widely deployed to protect against exploitation of this vulnerability.  However, prevalent WPA2 client implementations during the early 2000s were prone to misconfiguration by end users, or in some cases (e.g. Android), lacked any user-accessible way to properly configure validation of AAA server certificate CNs.  This extended the relevance of the original weakness in MSCHAPv2 within MiTM attack scenarios.  Under stricter WPA2 compliance tests announced alongside WPA3, certified client software will be required to conform to certain behaviors surrounding AAA certificate validation.\n\n\n*** Hole196 ***\nHole196 is a vulnerability in the WPA2 protocol that abuses the shared Group Temporal Key (GTK). It can be used to conduct man-in-the-middle and denial-of-service attacks. However, it assumes that the attacker is already authenticated against Access Point and thus in possession of the GTK.\n\n\n*** Predictable Group Temporal Key (GTK) ***\nIn 2016 it was shown that the WPA and WPA2 standards contain an insecure expository random number generator (RNG). Researchers showed that, if vendors implement the proposed RNG, an attacker is able to predict the group key (GTK) that is supposed to be randomly generated by the access point (AP). Additionally, they showed that possession of the GTK enables the attacker to inject any traffic into the network, and allowed the attacker to decrypt unicast internet traffic transmitted over the wireless network. They demonstrated their attack against an Asus RT-AC51U router that uses the MediaTek out-of-tree drivers, which generate the GTK themselves, and showed the GTK can be recovered within two minutes or less. Similarly, they demonstrated the keys generated by Broadcom access daemons running on VxWorks 5 and later can be recovered in four minutes or less, which affects, for example, certain versions of Linksys WRT54G and certain Apple AirPort Extreme models. Vendors can defend against this attack by using a secure RNG. By doing so, Hostapd running on Linux kernels is not vulnerable against this attack and thus routers running typical OpenWrt or LEDE installations do not exhibit this issue.\n\n\n*** KRACK attack ***\n\nIn October 2017, details of the KRACK (Key Reinstallation Attack) attack on WPA2 were published. The KRACK attack is believed to affect all variants of WPA and WPA2; however, the security implications vary between implementations, depending upon how individual developers interpreted a poorly specified part of the standard. Software patches can resolve the vulnerability but are not available for all devices.\n\n\n*** Dragonblood attack ***\nIn April 2019, serious design flaws in WPA3 were found which allow attackers to perform downgrade attacks and side-channel attacks, enabling brute-forcing the passphrase, as well as launching denial-of-service attacks on Wi-Fi base stations.\nAnswer this question: What is the significance of the lack of forward secrecy in WPA and WPA2?",
    "context": "",
    "output": "The lack of forward secrecy in WPA and WPA2 means that once an attacker discovers the pre-shared key, they can potentially decrypt all packets encrypted using that PSK in the past and future, which could be passively and silently collected by the attacker.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the significance of the lack of forward secrecy in WPA and WPA2?",
      "answer": "The lack of forward secrecy in WPA and WPA2 means that once an attacker discovers the pre-shared key, they can potentially decrypt all packets encrypted using that PSK in the past and future, which could be passively and silently collected by the attacker.",
      "context": "Wi-Fi Protected Access\n\n==Introduction==\nWi-Fi Protected Access (WPA), Wi-Fi Protected Access 2 (WPA2), and Wi-Fi Protected Access 3 (WPA3) are the three security certification programs developed after 2000 by the Wi-Fi Alliance to secure wireless computer networks. The Alliance defined these in response to serious weaknesses researchers had found in the previous system, Wired Equivalent Privacy (WEP).WPA (sometimes referred to as the TKIP standard) became available in 2003. The Wi-Fi Alliance intended it as an intermediate measure in anticipation of the availability of the more secure and complex WPA2, which became available in 2004 and is a common shorthand for the full IEEE 802.11i (or IEEE 802.11i-2004) standard.\nIn January 2018, the Wi-Fi Alliance announced the release of WPA3, which has several security improvements over WPA2.\n\n\n\n== Versions ==\n\n\n*** WPA ***\nThe Wi-Fi Alliance intended WPA as an intermediate measure to take the place of WEP pending the availability of the full IEEE 802.11i standard. WPA could be implemented through firmware upgrades on wireless network interface cards designed for WEP that began shipping as far back as 1999. However, since the changes required in the wireless access points (APs) were more extensive than those needed on the network cards, most pre-2003 APs could not be upgraded to support WPA.\nThe WPA protocol implements the Temporal Key Integrity Protocol (TKIP). WEP used a 64-bit or 128-bit encryption key that must be manually entered on wireless access points and devices and does not change. TKIP employs a per-packet key, meaning that it dynamically generates a new 128-bit key for each packet and thus prevents the types of attacks that compromised WEP.WPA also includes a Message Integrity Check, which is designed to prevent an attacker from altering and resending data packets. This replaces the cyclic redundancy check (CRC) that was used by the WEP standard. CRC's main flaw was that it did not provide a sufficiently strong data integrity guarantee for the packets it handled. Well-tested message authentication codes existed to solve these problems, but they required too much computation to be used on old network cards. WPA uses a message integrity check algorithm called TKIP to verify the integrity of the packets. TKIP is much stronger than a CRC, but not as strong as the algorithm used in WPA2. Researchers have since discovered a flaw in WPA that relied on older weaknesses in WEP and the limitations of the message integrity code hash function, named Michael, to retrieve the keystream from short packets to use for re-injection and spoofing.\n\n\n*** WPA2 ***\n\nRatified in 2004, WPA2 replaced WPA. WPA2, which requires testing and certification by the Wi-Fi Alliance, implements the mandatory elements of IEEE 802.11i. In particular, it includes mandatory support for CCMP, an AES-based encryption mode. Certification began in September, 2004. From March 13, 2006, to June 30, 2020, WPA2 certification was mandatory for all new devices to bear the Wi-Fi trademark. As of July 1, 2020, support for WPA3 is mandatory.\n\n\n*** WPA3 ***\nIn January 2018, the Wi-Fi Alliance announced WPA3 as a replacement to WPA2. Certification began in June 2018, and WPA3 support has been mandatory for devices which bear the \"Wi-Fi CERTIFIED\u2122\" logo since July 2020.The new standard uses an equivalent 192-bit cryptographic strength in WPA3-Enterprise mode (AES-256 in GCM mode with SHA-384 as HMAC), and still mandates the use of CCMP-128 (AES-128 in CCM mode) as the minimum encryption algorithm in WPA3-Personal mode.\nThe WPA3 standard also replaces the pre-shared key (PSK) exchange with Simultaneous Authentication of Equals (SAE) exchange, a method originally introduced with IEEE 802.11s, resulting in a more secure initial key exchange in personal mode and forward secrecy. The Wi-Fi Alliance also says that WPA3 will mitigate security issues posed by weak passwords and simplify the process of setting up devices with no display interface.Protection of management frames as specified in the IEEE 802.11w amendment is also enforced by the WPA3 specifications.\n\n== Hardware support ==\nWPA has been designed specifically to work with wireless hardware produced prior to the introduction of WPA protocol, which provides inadequate security through WEP. Some of these devices support WPA only after applying firmware upgrades, which are not available for some legacy devices.Wi-Fi devices certified since 2006 support both the WPA and WPA2 security protocols. WPA3 is required since July 1, 2020.\n\n== WPA terminology ==\nDifferent WPA versions and protection mechanisms can be distinguished based on the target end-user(such as wep, wpa, wpa2, wpa3) (according to the method of authentication key distribution), and the encryption protocol used.\n\n\n*** Target users (authentication key distribution) ***\nWPA-Personal\nAlso referred to as WPA-PSK (pre-shared key) mode, this is designed for home, small office and basic uses these networks and does not require an authentication server. Each wireless network device encrypts the network traffic by deriving its 128-bit encryption key from a 256-bit shared key. This key may be entered either as a string of 64 hexadecimal digits, or as a passphrase of 8 to 63 printable ASCII characters. This pass-phrase-to-PSK mapping is nevertheless not binding, as Annex J is informative in the latest 802.11 standard. If ASCII characters are used, the 256-bit key is calculated by applying the PBKDF2 key derivation function to the passphrase, using the SSID as the salt and 4096 iterations of HMAC-SHA1. WPA-Personal mode is available on all three WPA versions.\nWPA-Enterprise\nAlso referred to as WPA-802.1X mode, and sometimes just WPA (as opposed to WPA-PSK), this is designed for enterprise networks and requires a RADIUS authentication server. This requires a more complicated setup, but provides additional security (e.g. protection against dictionary attacks on short passwords). Various kinds of the Extensible Authentication Protocol (EAP) are used for authentication. WPA-Enterprise mode is available on all three WPA versions.\nWi-Fi Protected Setup (WPS)\nThis is an alternative authentication key distribution method intended to simplify and strengthen the process, but which, as widely implemented, creates a major security hole via WPS PIN recovery.\n\n\n*** Encryption protocol ***\nTKIP (Temporal Key Integrity Protocol)\nThe RC4 stream cipher is used with a 128-bit per-packet key, meaning that it dynamically generates a new key for each packet. This is used by WPA.\nCCMP (CTR mode with CBC-MAC Protocol)\nThe protocol used by WPA2, based on the Advanced Encryption Standard (AES) cipher along with strong message authenticity and integrity checking is significantly stronger in protection for both privacy and integrity than the RC4-based TKIP that is used by WPA. Among informal names are AES and AES-CCMP. According to the 802.11n specification, this encryption protocol must be used to achieve fast 802.11n high bitrate schemes, though not all implementations enforce this. Otherwise, the data rate will not exceed 54 Mbit/s.\n\n== EAP extensions under WPA and WPA2 Enterprise ==\nOriginally, only EAP-TLS (Extensible Authentication Protocol - Transport Layer Security) was certified by the Wi-Fi alliance. In April 2010, the Wi-Fi Alliance announced the inclusion of additional EAP types to its WPA- and WPA2-Enterprise certification programs. This was to ensure that WPA-Enterprise certified products can interoperate with one another.\nAs of 2010 the certification program includes the following EAP types:\n\nEAP-TLS (previously tested)\nEAP-TTLS/MSCHAPv2 (April 2005)\nPEAPv0/EAP-MSCHAPv2 (April 2005)\nPEAPv1/EAP-GTC (April 2005)\nPEAP-TLS\nEAP-SIM (April 2005)\nEAP-AKA (April 2009)\nEAP-FAST (April 2009)802.1X clients and servers developed by specific firms may support other EAP types. This certification is an attempt for popular EAP types to interoperate; their failure to do so as of 2013 is one of the major issues preventing rollout of 802.1X on heterogeneous networks.\nCommercial 802.1X servers include Microsoft Internet Authentication Service and Juniper Networks Steelbelted RADIUS as well as Aradial Radius server. FreeRADIUS is an open source 802.1X server.\n\n== Security issues ==\n\n\n*** Weak password ***\nPre-shared key WPA and WPA2 remain vulnerable to password cracking attacks if users rely on a weak password or passphrase. WPA passphrase hashes are seeded from the SSID name and its length; rainbow tables exist for the top 1,000 network SSIDs and a multitude of common passwords, requiring only a quick lookup to speed up cracking WPA-PSK.Brute forcing of simple passwords can be attempted using the Aircrack Suite starting from the four-way authentication handshake exchanged during association or periodic re-authentication.WPA3 replaces cryptographic protocols susceptible to off-line analysis with protocols that require interaction with the infrastructure for each guessed password, supposedly placing temporal limits on the number of guesses. However, design flaws in WPA3 enable attackers to plausibly launch brute-force attacks (see Dragonblood attack).\n\n\n*** Lack of forward secrecy ***\nWPA and WPA2 do not provide forward secrecy, meaning that once an adverse person discovers the pre-shared key, they can potentially decrypt all packets encrypted using that PSK transmitted in the future and even past, which could be passively and silently collected by the attacker. This also means an attacker can silently capture and decrypt others' packets if a WPA-protected access point is provided free of charge at a public place, because its password is usually shared to anyone in that place. In other words, WPA only protects from attackers who do not have access to the password. Because of that, it's safer to use Transport Layer Security (TLS) or similar on top of that for the transfer of any sensitive data. However starting from WPA3, this issue has been addressed.\n\n\n*** WPA packet spoofing and decryption ***\nIn 2013, Mathy Vanhoef and Frank Piessens significantly improved upon the WPA-TKIP attacks of Erik Tews and Martin Beck. They demonstrated how to inject an arbitrary number of packets, with each packet containing at most 112 bytes of payload. This was demonstrated by implementing a port scanner, which can be executed against any client using WPA-TKIP. Additionally, they showed how to decrypt arbitrary packets sent to a client. They mentioned this can be used to hijack a TCP connection, allowing an attacker to inject malicious JavaScript when the victim visits a website.\nIn contrast, the Beck-Tews attack could only decrypt short packets with mostly known content, such as ARP messages, and only allowed injection of 3 to 7 packets of at most 28 bytes. The Beck-Tews attack also requires quality of service (as defined in 802.11e) to be enabled, while the Vanhoef-Piessens attack does not. Neither attack leads to recovery of the shared session key between the client and Access Point. The authors say using a short rekeying interval can prevent some attacks but not all, and strongly recommend switching from TKIP to AES-based CCMP.\nHalvorsen and others show how to modify the Beck-Tews attack to allow injection of 3 to 7 packets having a size of at most 596 bytes. The downside is that their attack requires substantially more time to execute: approximately 18 minutes and 25 seconds. In other work Vanhoef and Piessens showed that, when WPA is used to encrypt broadcast packets, their original attack can also be executed. This is an important extension, as substantially more networks use WPA to protect broadcast packets, than to protect unicast packets. The execution time of this attack is on average around 7 minutes, compared to the 14 minutes of the original Vanhoef-Piessens and Beck-Tews attack.\nThe vulnerabilities of TKIP are significant because WPA-TKIP had been held before to be an extremely safe combination; indeed, WPA-TKIP is still a configuration option upon a wide variety of wireless routing devices provided by many hardware vendors. A survey in 2013 showed that 71% still allow usage of TKIP, and 19% exclusively support TKIP.\n\n\n*** WPS PIN recovery ***\nA more serious security flaw was revealed in December 2011 by Stefan Viehb\u00f6ck that affects wireless routers with the Wi-Fi Protected Setup (WPS) feature, regardless of which encryption method they use. Most recent models have this feature and enable it by default. Many consumer Wi-Fi device manufacturers had taken steps to eliminate the potential of weak passphrase choices by promoting alternative methods of automatically generating and distributing strong keys when users add a new wireless adapter or appliance to a network. These methods include pushing buttons on the devices or entering an 8-digit PIN.\nThe Wi-Fi Alliance standardized these methods as Wi-Fi Protected Setup; however, the PIN feature as widely implemented introduced a major new security flaw. The flaw allows a remote attacker to recover the WPS PIN and, with it, the router's WPA/WPA2 password in a few hours. Users have been urged to turn off the WPS feature, although this may not be possible on some router models. Also, the PIN is written on a label on most Wi-Fi routers with WPS, and cannot be changed if compromised.\nWPA3 introduces a new alternative for the configuration of devices that lack sufficient user interface capabilities by allowing nearby devices to serve as an adequate UI for network provisioning purposes, thus mitigating the need for WPS.\n\n\n*** MS-CHAPv2 and lack of AAA server CN validation ***\nSeveral weaknesses have been found in MS-CHAPv2, some of which severely reduce the complexity of brute-force attacks, making them feasible with modern hardware. In 2012 the complexity of breaking MS-CHAPv2 was reduced to that of breaking a single DES key (work by Moxie Marlinspike and Marsh Ray). Moxie advised: \"Enterprises who are depending on the mutual authentication properties of MS-CHAPv2 for connection to their WPA2 Radius servers should immediately start migrating to something else.\"Tunneled EAP methods using TTLS or PEAP which encrypt the MSCHAPv2 exchange are widely deployed to protect against exploitation of this vulnerability.  However, prevalent WPA2 client implementations during the early 2000s were prone to misconfiguration by end users, or in some cases (e.g. Android), lacked any user-accessible way to properly configure validation of AAA server certificate CNs.  This extended the relevance of the original weakness in MSCHAPv2 within MiTM attack scenarios.  Under stricter WPA2 compliance tests announced alongside WPA3, certified client software will be required to conform to certain behaviors surrounding AAA certificate validation.\n\n\n*** Hole196 ***\nHole196 is a vulnerability in the WPA2 protocol that abuses the shared Group Temporal Key (GTK). It can be used to conduct man-in-the-middle and denial-of-service attacks. However, it assumes that the attacker is already authenticated against Access Point and thus in possession of the GTK.\n\n\n*** Predictable Group Temporal Key (GTK) ***\nIn 2016 it was shown that the WPA and WPA2 standards contain an insecure expository random number generator (RNG). Researchers showed that, if vendors implement the proposed RNG, an attacker is able to predict the group key (GTK) that is supposed to be randomly generated by the access point (AP). Additionally, they showed that possession of the GTK enables the attacker to inject any traffic into the network, and allowed the attacker to decrypt unicast internet traffic transmitted over the wireless network. They demonstrated their attack against an Asus RT-AC51U router that uses the MediaTek out-of-tree drivers, which generate the GTK themselves, and showed the GTK can be recovered within two minutes or less. Similarly, they demonstrated the keys generated by Broadcom access daemons running on VxWorks 5 and later can be recovered in four minutes or less, which affects, for example, certain versions of Linksys WRT54G and certain Apple AirPort Extreme models. Vendors can defend against this attack by using a secure RNG. By doing so, Hostapd running on Linux kernels is not vulnerable against this attack and thus routers running typical OpenWrt or LEDE installations do not exhibit this issue.\n\n\n*** KRACK attack ***\n\nIn October 2017, details of the KRACK (Key Reinstallation Attack) attack on WPA2 were published. The KRACK attack is believed to affect all variants of WPA and WPA2; however, the security implications vary between implementations, depending upon how individual developers interpreted a poorly specified part of the standard. Software patches can resolve the vulnerability but are not available for all devices.\n\n\n*** Dragonblood attack ***\nIn April 2019, serious design flaws in WPA3 were found which allow attackers to perform downgrade attacks and side-channel attacks, enabling brute-forcing the passphrase, as well as launching denial-of-service attacks on Wi-Fi base stations."
    }
  },
  {
    "instruction": "context: Slides and other materials from OSSEC Conferences are available online. Users can access the 2019 OSSEC Con resources on the official conference website.\n\nAsk a question about this context.",
    "context": "",
    "output": "Where can users find slides and materials from past OSSEC Conferences?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Where can users find slides and materials from past OSSEC Conferences?",
      "answer": "Slides and other materials from OSSEC Conferences are available online. Users can access the 2019 OSSEC Con resources on the official conference website."
    }
  },
  {
    "instruction": "context: In an X.509-based PKI, a root certificate is usually distributed through some mechanism other than a certificate, such as secure physical distribution. This is because the root certificate is the top-most certificate of the tree and is used to sign other certificates, so it needs to be established as trustworthy before it can be used to establish trust in other certificates.\n\nAsk a question about this context.",
    "context": "",
    "output": "How is a root certificate distributed in an X.509-based PKI?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is a root certificate distributed in an X.509-based PKI?",
      "answer": "In an X.509-based PKI, a root certificate is usually distributed through some mechanism other than a certificate, such as secure physical distribution. This is because the root certificate is the top-most certificate of the tree and is used to sign other certificates, so it needs to be established as trustworthy before it can be used to establish trust in other certificates."
    }
  },
  {
    "instruction": "context: The code for the CEH examination is 312\u201350.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the code for the CEH examination?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the code for the CEH examination?",
      "answer": "The code for the CEH examination is 312\u201350."
    }
  },
  {
    "instruction": "Monero\n\n==Introduction==\nMonero (; Abbreviation: XMR) is a cryptocurrency which uses a blockchain with privacy-enhancing technologies to obfuscate transactions to achieve anonymity and fungibility. Observers cannot decipher addresses trading Monero, transaction amounts, address balances, or transaction histories.\nThe protocol is open source and based on CryptoNote, a concept described in a 2013 white paper authored by Nicolas van Saberhagen. Developers used this concept to design Monero, and deployed its mainnet in 2014. The Monero protocol includes various methods to obfuscate transaction details, though users can optionally share view keys for third-party auditing. Transactions are validated through a miner network running RandomX, a proof-of-work algorithm. The algorithm issues new coins to miners, and was designed to be resistant to application-specific integrated circuit (ASIC) mining.\nMonero's privacy features have attracted cypherpunks and users desiring privacy measures not provided in other cryptocurrencies. It is used in illicit activities such as money laundering, darknet markets, ransomware, and cryptojacking. The United States Internal Revenue Service (IRS) has posted bounties for contractors that can develop Monero-tracing technologies.\n\n== Background ==\nMonero's roots can be traced back to CryptoNote, a cryptocurrency protocol first described in a white paper published by Nicolas van Saberhagen (presumed pseudonymous) in October 2013. The author described privacy and anonymity as \"the most important aspects of electronic cash\" and called bitcoin's traceability a \"critical flaw\". A Bitcointalk forum user \"thankful_for_today\" coded these ideas into a coin they dubbed BitMonero. Other forum users disagreed with thankful_for_today's direction for BitMonero, so forked it in 2014 to create Monero. Monero translates to coin in Esperanto, and the Esperanto moneroj is sometimes used for plural. Both van Saberhagen and thankful_for_today remain anonymous.Monero has the third-largest community of developers, behind bitcoin and Ethereum. The protocol's lead maintainer was previously South African developer Riccardo Spagni. Much of the core development team chooses to remain anonymous.Improvements to Monero's protocol and features are, in part, the task of the Monero Research Lab (MRL), some of whom are anonymous.\n\n== Privacy ==\n\nMonero's key features are those around privacy and anonymity. Even though it is a public and decentralized ledger, all transaction details are obfuscated. This contrasts to bitcoin, where all transaction details, user addresses, and wallet balances are public and transparent. These features have given Monero a loyal following among crypto anarchists, cypherpunks, and privacy advocates.The transaction outputs, or notes, of users sending Monero are obfuscated through ring signatures, which groups a sender's outputs with other decoy outputs. Encryption of transaction amounts began in 2017 with the implementation of ring confidential transactions (RingCTs). Developers also implemented a zero-knowledge proof method, \"Bulletproofs\", which guarantee a transaction occurred without revealing its value. Monero recipients are protected through \"stealth addresses\", addresses generated by users to receive funds, but untraceable to an owner by a network observer. These privacy features are enforced on the network by default, though users have the option to share a private view key to permit third party auditing of their wallet, or a transaction key to audit a transaction.Monero uses Dandelion++, a protocol which obscures the IP address of devices producing transactions. This is done through a method of transaction broadcast propagation; new transactions are initially passed to one node on Monero's peer-to-peer network, and a repeated probabilistic method is used to determine when the transaction should be sent to just one node or broadcast to many nodes in a process called flooding.\n\n\n*** Efforts to trace transactions ***\nIn April 2017, researchers highlighted three major threats to Monero users' privacy. The first relies on leveraging the ring signature size of zero, and ability to see the output amounts. The second, \"Leveraging Output Merging\", involves tracking transactions where two outputs belong to the same user, such as when they send funds to themselves (\"churning\"). Finally, \"Temporal Analysis\", shows that predicting the right output in a ring signature could potentially be easier than previously thought. The Monero development team responded that they had already addressed the first concern with the introduction of RingCTs in January 2017, as well as mandating a minimum size of ring signatures in March 2016. In 2018, researchers presented possible vulnerabilities in a paper titled \"An Empirical Analysis of Traceability in the Monero Blockchain\". The Monero team responded in March 2018.In September 2020, the United States Internal Revenue Service's criminal investigation division (IRS-CI), posted a $625,000 bounty for contractors who could develop tools to help trace Monero, other privacy-enhanced cryptocurrencies, the Bitcoin Lightning Network, or other \"layer 2\" protocols. The contract was awarded to blockchain analysis groups Chainalysis and Integra FEC.\n\n== Mining ==\n\nMonero uses a proof-of-work algorithm, RandomX, to validate transactions. The method was introduced in November 2019 to replace the former algorithm CryptoNightR. Both algorithms were designed to be resistant to ASIC mining, which is commonly used to mine other cryptocurrencies such as Bitcoin. Monero can be mined somewhat efficiently on consumer-grade hardware such as x86, x86-64, ARM and GPUs, a design decision which was based on Monero project's opposition to mining centralisation which ASIC mining creates, but has also resulted in Monero's popularity among malware-based non-consensual miners.\n\n== Illicit use ==\nMonero's privacy features have made it popular for illicit purposes.\n\n\n*** Darknet markets ***\nMonero is a common medium of exchange on darknet markets. In August 2016, dark market AlphaBay permitted its vendors to start accepting Monero as an alternative to bitcoin. The site was taken offline by law enforcement in 2017, but it was relaunched in 2021 with Monero as the sole permitted currency. Reuters reported in 2019 that three of the five largest darknet markets accepted Monero, though bitcoin was still the most widely used form of payment in those markets.\n\n\n*** Mining malware ***\nHackers have embedded malware into websites and applications that hijack victim CPUs to mine Monero (sometimes called cryptojacking). In late 2017, malware and antivirus service providers blocked Coinhive, a JavaScript implementation of a Monero miner that was embedded in websites and apps, in some cases by hackers. Coinhive generated the script as an alternative to advertisements; a website or app could embed it, and use website visitor's CPU to mine the cryptocurrency while the visitor is consuming the content of the webpage, with the site or app owner getting a percentage of the mined coins. Some websites and apps did this without informing visitors, or in some cases using all possible system resources. As a result, the script was blocked by companies offering ad blocking subscription lists, antivirus services, and antimalware services. Coinhive had been previously found hidden in Showtime-owned streaming platforms and Starbucks Wi-Fi hotspots in Argentina. Researchers in 2018 found similar malware that mined Monero and sent it to Kim Il-sung University in North Korea.\n\n\n*** Ransomware ***\n\nMonero is sometimes used by ransomware groups. According to CNBC, in the first half of 2018, Monero was used in 44% of cryptocurrency ransomware attacks.One group behind the 2017 WannaCry ransomware attack, the Shadow Brokers, attempted to exchange the ransom they collected in bitcoin to Monero. Ars Technica and Fast Company reported that the exchange was successful, but BBC News reported that the service the criminal attempted to use, ShapeShift, denied any such transfer. The Shadow Brokers began accepting Monero as payment later in 2017.In 2021, CNBC, the Financial Times, and Newsweek reported that demand for Monero was increasing following the recovery of a bitcoin ransom paid in the Colonial Pipeline cyber attack. The May 2021 hack forced the pipeline to pay a $4.4M ransom in bitcoin, though a large portion was recovered by the United States federal government the following month. The group behind the attack, DarkSide, normally requests payment in either bitcoin or Monero, but charge a 10\u201320% premium for payments made in bitcoin due to its increased traceability risk. Ransomware group REvil removed the option of paying ransom in bitcoin in 2021, demanding only Monero. Ransomware negotiators, groups that help victims pay ransoms, have contacted Monero developers to understand the technology. Despite this, CNBC reported that bitcoin was still the currency of choice demanded in most ransomware attacks, as insurers refuse to pay Monero ransom payments because of traceability concerns.\n\n\n*** Regulatory responses ***\nThe attribution of Monero to illicit markets has influenced some exchanges to forgo listing it. This has made it more difficult for users to exchange Monero for fiat currencies or other cryptocurrencies. Exchanges in South Korea and Australia have delisted Monero and other privacy coins due to regulatory pressure.In 2018, Europol and its director Rob Wainwright wrote that the year would see criminals shift from using bitcoin to using Monero, as well as Ethereum, Dash, and Zcash. Bloomberg and CNN reported that this demand for Monero was because authorities were becoming better at monitoring the Bitcoin blockchain.\n\n== Publicity ==\nAfter many online payment platforms shut down access for white nationalists following the Unite the Right rally in 2017, some of them, including Christopher Cantwell and Andrew Auernheimer (\"weev\"), started using and promoting Monero.\nIn December 2017, the Monero team announced a partnership with 45 musicians and several online stores for Monero to be used as a form of payment for their merchandise.\nIn November 2018, Bail Bloc released a mobile app that mines Monero to raise funds for low-income defendants who cannot otherwise cover their own bail.\nIn April 2020, the Monero Film Workgroup released Monero Means Money: Cryptocurrency 101, Live from Leipzig, a documentary feature film that was the second highest grossing film in the United States for the weekend of April 10, 2020 according to The Numbers (when theaters were shutdown due to the COVID-19 pandemic). Proceeds of the film went to independent theaters.\nQ: How is Monero used in mining malware and cryptojacking?",
    "context": "",
    "output": "Hackers have embedded malware into websites and applications that hijack victim CPUs to mine Monero (sometimes called cryptojacking). Malware such as Coinhive, a JavaScript implementation of a Monero miner, has been embedded in websites and apps, in some cases by hackers, to mine Monero using website visitor's CPU.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How is Monero used in mining malware and cryptojacking?",
      "answer": "Hackers have embedded malware into websites and applications that hijack victim CPUs to mine Monero (sometimes called cryptojacking). Malware such as Coinhive, a JavaScript implementation of a Monero miner, has been embedded in websites and apps, in some cases by hackers, to mine Monero using website visitor's CPU.",
      "context": "Monero\n\n==Introduction==\nMonero (; Abbreviation: XMR) is a cryptocurrency which uses a blockchain with privacy-enhancing technologies to obfuscate transactions to achieve anonymity and fungibility. Observers cannot decipher addresses trading Monero, transaction amounts, address balances, or transaction histories.\nThe protocol is open source and based on CryptoNote, a concept described in a 2013 white paper authored by Nicolas van Saberhagen. Developers used this concept to design Monero, and deployed its mainnet in 2014. The Monero protocol includes various methods to obfuscate transaction details, though users can optionally share view keys for third-party auditing. Transactions are validated through a miner network running RandomX, a proof-of-work algorithm. The algorithm issues new coins to miners, and was designed to be resistant to application-specific integrated circuit (ASIC) mining.\nMonero's privacy features have attracted cypherpunks and users desiring privacy measures not provided in other cryptocurrencies. It is used in illicit activities such as money laundering, darknet markets, ransomware, and cryptojacking. The United States Internal Revenue Service (IRS) has posted bounties for contractors that can develop Monero-tracing technologies.\n\n== Background ==\nMonero's roots can be traced back to CryptoNote, a cryptocurrency protocol first described in a white paper published by Nicolas van Saberhagen (presumed pseudonymous) in October 2013. The author described privacy and anonymity as \"the most important aspects of electronic cash\" and called bitcoin's traceability a \"critical flaw\". A Bitcointalk forum user \"thankful_for_today\" coded these ideas into a coin they dubbed BitMonero. Other forum users disagreed with thankful_for_today's direction for BitMonero, so forked it in 2014 to create Monero. Monero translates to coin in Esperanto, and the Esperanto moneroj is sometimes used for plural. Both van Saberhagen and thankful_for_today remain anonymous.Monero has the third-largest community of developers, behind bitcoin and Ethereum. The protocol's lead maintainer was previously South African developer Riccardo Spagni. Much of the core development team chooses to remain anonymous.Improvements to Monero's protocol and features are, in part, the task of the Monero Research Lab (MRL), some of whom are anonymous.\n\n== Privacy ==\n\nMonero's key features are those around privacy and anonymity. Even though it is a public and decentralized ledger, all transaction details are obfuscated. This contrasts to bitcoin, where all transaction details, user addresses, and wallet balances are public and transparent. These features have given Monero a loyal following among crypto anarchists, cypherpunks, and privacy advocates.The transaction outputs, or notes, of users sending Monero are obfuscated through ring signatures, which groups a sender's outputs with other decoy outputs. Encryption of transaction amounts began in 2017 with the implementation of ring confidential transactions (RingCTs). Developers also implemented a zero-knowledge proof method, \"Bulletproofs\", which guarantee a transaction occurred without revealing its value. Monero recipients are protected through \"stealth addresses\", addresses generated by users to receive funds, but untraceable to an owner by a network observer. These privacy features are enforced on the network by default, though users have the option to share a private view key to permit third party auditing of their wallet, or a transaction key to audit a transaction.Monero uses Dandelion++, a protocol which obscures the IP address of devices producing transactions. This is done through a method of transaction broadcast propagation; new transactions are initially passed to one node on Monero's peer-to-peer network, and a repeated probabilistic method is used to determine when the transaction should be sent to just one node or broadcast to many nodes in a process called flooding.\n\n\n*** Efforts to trace transactions ***\nIn April 2017, researchers highlighted three major threats to Monero users' privacy. The first relies on leveraging the ring signature size of zero, and ability to see the output amounts. The second, \"Leveraging Output Merging\", involves tracking transactions where two outputs belong to the same user, such as when they send funds to themselves (\"churning\"). Finally, \"Temporal Analysis\", shows that predicting the right output in a ring signature could potentially be easier than previously thought. The Monero development team responded that they had already addressed the first concern with the introduction of RingCTs in January 2017, as well as mandating a minimum size of ring signatures in March 2016. In 2018, researchers presented possible vulnerabilities in a paper titled \"An Empirical Analysis of Traceability in the Monero Blockchain\". The Monero team responded in March 2018.In September 2020, the United States Internal Revenue Service's criminal investigation division (IRS-CI), posted a $625,000 bounty for contractors who could develop tools to help trace Monero, other privacy-enhanced cryptocurrencies, the Bitcoin Lightning Network, or other \"layer 2\" protocols. The contract was awarded to blockchain analysis groups Chainalysis and Integra FEC.\n\n== Mining ==\n\nMonero uses a proof-of-work algorithm, RandomX, to validate transactions. The method was introduced in November 2019 to replace the former algorithm CryptoNightR. Both algorithms were designed to be resistant to ASIC mining, which is commonly used to mine other cryptocurrencies such as Bitcoin. Monero can be mined somewhat efficiently on consumer-grade hardware such as x86, x86-64, ARM and GPUs, a design decision which was based on Monero project's opposition to mining centralisation which ASIC mining creates, but has also resulted in Monero's popularity among malware-based non-consensual miners.\n\n== Illicit use ==\nMonero's privacy features have made it popular for illicit purposes.\n\n\n*** Darknet markets ***\nMonero is a common medium of exchange on darknet markets. In August 2016, dark market AlphaBay permitted its vendors to start accepting Monero as an alternative to bitcoin. The site was taken offline by law enforcement in 2017, but it was relaunched in 2021 with Monero as the sole permitted currency. Reuters reported in 2019 that three of the five largest darknet markets accepted Monero, though bitcoin was still the most widely used form of payment in those markets.\n\n\n*** Mining malware ***\nHackers have embedded malware into websites and applications that hijack victim CPUs to mine Monero (sometimes called cryptojacking). In late 2017, malware and antivirus service providers blocked Coinhive, a JavaScript implementation of a Monero miner that was embedded in websites and apps, in some cases by hackers. Coinhive generated the script as an alternative to advertisements; a website or app could embed it, and use website visitor's CPU to mine the cryptocurrency while the visitor is consuming the content of the webpage, with the site or app owner getting a percentage of the mined coins. Some websites and apps did this without informing visitors, or in some cases using all possible system resources. As a result, the script was blocked by companies offering ad blocking subscription lists, antivirus services, and antimalware services. Coinhive had been previously found hidden in Showtime-owned streaming platforms and Starbucks Wi-Fi hotspots in Argentina. Researchers in 2018 found similar malware that mined Monero and sent it to Kim Il-sung University in North Korea.\n\n\n*** Ransomware ***\n\nMonero is sometimes used by ransomware groups. According to CNBC, in the first half of 2018, Monero was used in 44% of cryptocurrency ransomware attacks.One group behind the 2017 WannaCry ransomware attack, the Shadow Brokers, attempted to exchange the ransom they collected in bitcoin to Monero. Ars Technica and Fast Company reported that the exchange was successful, but BBC News reported that the service the criminal attempted to use, ShapeShift, denied any such transfer. The Shadow Brokers began accepting Monero as payment later in 2017.In 2021, CNBC, the Financial Times, and Newsweek reported that demand for Monero was increasing following the recovery of a bitcoin ransom paid in the Colonial Pipeline cyber attack. The May 2021 hack forced the pipeline to pay a $4.4M ransom in bitcoin, though a large portion was recovered by the United States federal government the following month. The group behind the attack, DarkSide, normally requests payment in either bitcoin or Monero, but charge a 10\u201320% premium for payments made in bitcoin due to its increased traceability risk. Ransomware group REvil removed the option of paying ransom in bitcoin in 2021, demanding only Monero. Ransomware negotiators, groups that help victims pay ransoms, have contacted Monero developers to understand the technology. Despite this, CNBC reported that bitcoin was still the currency of choice demanded in most ransomware attacks, as insurers refuse to pay Monero ransom payments because of traceability concerns.\n\n\n*** Regulatory responses ***\nThe attribution of Monero to illicit markets has influenced some exchanges to forgo listing it. This has made it more difficult for users to exchange Monero for fiat currencies or other cryptocurrencies. Exchanges in South Korea and Australia have delisted Monero and other privacy coins due to regulatory pressure.In 2018, Europol and its director Rob Wainwright wrote that the year would see criminals shift from using bitcoin to using Monero, as well as Ethereum, Dash, and Zcash. Bloomberg and CNN reported that this demand for Monero was because authorities were becoming better at monitoring the Bitcoin blockchain.\n\n== Publicity ==\nAfter many online payment platforms shut down access for white nationalists following the Unite the Right rally in 2017, some of them, including Christopher Cantwell and Andrew Auernheimer (\"weev\"), started using and promoting Monero.\nIn December 2017, the Monero team announced a partnership with 45 musicians and several online stores for Monero to be used as a form of payment for their merchandise.\nIn November 2018, Bail Bloc released a mobile app that mines Monero to raise funds for low-income defendants who cannot otherwise cover their own bail.\nIn April 2020, the Monero Film Workgroup released Monero Means Money: Cryptocurrency 101, Live from Leipzig, a documentary feature film that was the second highest grossing film in the United States for the weekend of April 10, 2020 according to The Numbers (when theaters were shutdown due to the COVID-19 pandemic). Proceeds of the film went to independent theaters."
    }
  },
  {
    "instruction": "context: Cross-certification is the process of generating a certificate for the same subject and public key, but signed with different private keys from different CAs or different private keys from the same CA. This allows for the validation of user certificates across different PKIs or applications.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is cross-certification in the context of X.509 certificates?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is cross-certification in the context of X.509 certificates?",
      "answer": "Cross-certification is the process of generating a certificate for the same subject and public key, but signed with different private keys from different CAs or different private keys from the same CA. This allows for the validation of user certificates across different PKIs or applications."
    }
  },
  {
    "instruction": "context: LSH was measured on Intel Core i7-4770k @ 3.5 GHz quad core platform for the Haswell-based platform and Samsung Exynos 5250 ARM Cortex-A15 @ 1.7 GHz dual core platform for the ARM Cortex-A15-based platform.\n\nAsk a question about this context.",
    "context": "",
    "output": "On which platform was LSH measured for the speed performance tables?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "On which platform was LSH measured for the speed performance tables?",
      "answer": "LSH was measured on Intel Core i7-4770k @ 3.5 GHz quad core platform for the Haswell-based platform and Samsung Exynos 5250 ARM Cortex-A15 @ 1.7 GHz dual core platform for the ARM Cortex-A15-based platform."
    }
  },
  {
    "instruction": "context: Yes, 18 U.S.C. \u00a7 1030(a)(2) makes it a criminal offense to intentionally access a computer without authorization and obtain information from any department or agency of the United States or from any protected computer.\n\nAsk a question about this context.",
    "context": "",
    "output": "Can the CFAA be used to prosecute individuals who intentionally access a protected computer without authorization and obtain information?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Can the CFAA be used to prosecute individuals who intentionally access a protected computer without authorization and obtain information?",
      "answer": "Yes, 18 U.S.C. \u00a7 1030(a)(2) makes it a criminal offense to intentionally access a computer without authorization and obtain information from any department or agency of the United States or from any protected computer."
    }
  },
  {
    "instruction": "Write an answer to the following question: How does LXC differ from traditional virtualization methods?",
    "context": "",
    "output": "LXC provides operating system-level virtualization through a virtual environment that has its own process and network space, rather than creating a full-fledged virtual machine.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does LXC differ from traditional virtualization methods?",
      "answer": "LXC provides operating system-level virtualization through a virtual environment that has its own process and network space, rather than creating a full-fledged virtual machine."
    }
  },
  {
    "instruction": "Silver Sparrow (malware)\n\n==Introduction==\nThe Silver Sparrow computer virus is malware that runs on x86- and Apple M1-based Macintosh computers. Engineers at the cyber security firm Red Canary have detected two versions of the malware in January and February 2021.\n\n\n\n== Description ==\nTwo versions of the malware were reported. The first version (described as the \"non-M1\" version) is compiled for Intel x86-64. It was first detected in January 2021. The second version contains code that runs natively on Apple's proprietary M1 processor, and was probably released in December 2020 and discovered in February 2021. The virus connects to a server hosted on Amazon Web Services.  The software includes a self-destruct mechanism.As of 23 February 2021, information about how the malware is spread and what system may be compromised is sparse. It is uncertain whether Silver Sparrow is embedded inside malicious advertisements, pirated software, or bogus Adobe Flash Player updaters. Red Canary has theorized that systems could have been infected through malicious search engine results that might have directed them to download the code. The ultimate object of the malware's release is also still unknown.Silver Sparrow is the second malware virus observed to include M1-native code.\n\n== Impact ==\nAs of 23 February 2021, Internet security company Malwarebytes has discovered over 29,000 Macs worldwide running their anti-malware software to be infected with Silver Sparrow. Silver Sparrow infected Macs have been found in 153 countries as of February 17, with higher concentrations reported in the US, UK, Canada, France, and Germany, according to data from Malwarebytes. Over 39,000 Macs were affected in the beginning of March 2021.On 23 February 2021, a spokesperson of Apple Inc. stated that \"there is no evidence to suggest the malware they identified has delivered a malicious payload to infected users.\" Apple also revoked the certificates of the developer accounts used to sign the packages, thereby preventing any additional Macs from becoming infected.\n\nBased on the above text, answer a question. What is the function of the software included in Silver Sparrow?",
    "context": "",
    "output": "The software included in Silver Sparrow connects to a server hosted on Amazon Web Services and includes a self-destruct mechanism.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the function of the software included in Silver Sparrow?",
      "answer": "The software included in Silver Sparrow connects to a server hosted on Amazon Web Services and includes a self-destruct mechanism.",
      "context": "Silver Sparrow (malware)\n\n==Introduction==\nThe Silver Sparrow computer virus is malware that runs on x86- and Apple M1-based Macintosh computers. Engineers at the cyber security firm Red Canary have detected two versions of the malware in January and February 2021.\n\n\n\n== Description ==\nTwo versions of the malware were reported. The first version (described as the \"non-M1\" version) is compiled for Intel x86-64. It was first detected in January 2021. The second version contains code that runs natively on Apple's proprietary M1 processor, and was probably released in December 2020 and discovered in February 2021. The virus connects to a server hosted on Amazon Web Services.  The software includes a self-destruct mechanism.As of 23 February 2021, information about how the malware is spread and what system may be compromised is sparse. It is uncertain whether Silver Sparrow is embedded inside malicious advertisements, pirated software, or bogus Adobe Flash Player updaters. Red Canary has theorized that systems could have been infected through malicious search engine results that might have directed them to download the code. The ultimate object of the malware's release is also still unknown.Silver Sparrow is the second malware virus observed to include M1-native code.\n\n== Impact ==\nAs of 23 February 2021, Internet security company Malwarebytes has discovered over 29,000 Macs worldwide running their anti-malware software to be infected with Silver Sparrow. Silver Sparrow infected Macs have been found in 153 countries as of February 17, with higher concentrations reported in the US, UK, Canada, France, and Germany, according to data from Malwarebytes. Over 39,000 Macs were affected in the beginning of March 2021.On 23 February 2021, a spokesperson of Apple Inc. stated that \"there is no evidence to suggest the malware they identified has delivered a malicious payload to infected users.\" Apple also revoked the certificates of the developer accounts used to sign the packages, thereby preventing any additional Macs from becoming infected."
    }
  },
  {
    "instruction": "Write an answer to the following question: What are the terms used to define the maximum time constraints for how long an enterprise's key products or services can be unavailable or undeliverable?",
    "context": "",
    "output": "The terms used to define the maximum time constraints for how long an enterprise's key products or services can be unavailable or undeliverable include Maximum Tolerable Period of Disruption (MTPoD), Maximum Tolerable Downtime (MTD), Maximum Tolerable Outage (MTO), and Maximum Acceptable Outage (MAO).",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What are the terms used to define the maximum time constraints for how long an enterprise's key products or services can be unavailable or undeliverable?",
      "answer": "The terms used to define the maximum time constraints for how long an enterprise's key products or services can be unavailable or undeliverable include Maximum Tolerable Period of Disruption (MTPoD), Maximum Tolerable Downtime (MTD), Maximum Tolerable Outage (MTO), and Maximum Acceptable Outage (MAO)."
    }
  },
  {
    "instruction": "context: Paul Oldfield considered Happy99 to be the first virus to spread rapidly by email.\n\nAsk a question about this context.",
    "context": "",
    "output": "Who is considered the first virus to spread rapidly by email, according to Paul Oldfield?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "Who is considered the first virus to spread rapidly by email, according to Paul Oldfield?",
      "answer": "Paul Oldfield considered Happy99 to be the first virus to spread rapidly by email."
    }
  },
  {
    "instruction": "Write an answer to the following question: How did Amazon disable domain fronting from their content delivery services?",
    "context": "",
    "output": "Amazon implemented a set of changes that prohibited the obfuscation that allowed sites to masquerade as and use CloudFront domains of other websites as fronts, effectively disabling domain fronting from their content delivery services.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How did Amazon disable domain fronting from their content delivery services?",
      "answer": "Amazon implemented a set of changes that prohibited the obfuscation that allowed sites to masquerade as and use CloudFront domains of other websites as fronts, effectively disabling domain fronting from their content delivery services."
    }
  },
  {
    "instruction": "Context: Department of Defense Cyber Crime Center\n\n==Introduction==\nThe Department of Defense Cyber Crime Center (DC3) is designated as a Federal Cyber Center by National Security Presidential Directive 54/Homeland Security Presidential Directive 23, as a Department of Defense (DoD) Center Of Excellence for Digital and Multimedia (D/MM) forensics by DoD Directive 5505.13E, and serves as the operational focal point for the Defense Industrial Base (DIB) Cybersecurity program. DC3 operates as a Field Operating Agency (FOA) under the Inspector General of the Department of the Air Force.\n\n\n\n== Mission ==\nDeliver superior digital and multimedia forensic services, cyber technical training, vulnerability sharing, technical solutions development, and cyber analysis within the following DoD mission areas: cybersecurity and critical infrastructure protection, law enforcement and counterintelligence, document and media exploitation, and counterterrorism.\n\n== Cyber Forensics Laboratory ==\nThe Cyber Forensics Laboratory performs Digital and Multimedia (D/MM) forensic examinations, repairs damaged devices and extracts otherwise inaccessible data from them, and provides expert testimony in legal proceedings for DC3 customers. The lab's robust intrusion and malware analysis capability supports law enforcement, counterintelligence, and Defense Industrial Base activities and operations. The CFL also works with the Defense Cyber Operations Panel (which consists of Defense Criminal Investigative Organizations and Military Department Counterintelligence Organizations) to develop requirements and set standards for digital investigations as new technologies emerge and evolve. The CFL is an accredited lab under ISO 17025 by the ANSI National Accreditation Board, and its operations are subject to strict quality control and peer review. The CFL produces results which are valid and reliable, based on conditions and methods which are repeatable.\n\nDigital and Multimedia (D/MM) forensic examinations\nDevice Repair\nData Extraction\nExpert Testimony for DC3 Customers\n\n== Cyber Training Academy ==\nThe mission of the DoD Cyber Crime Center \u2013 Cyber Training Academy is to design, develop, and deliver the highest possible quality in cyber training to Department of Defense (DoD) personnel. In operation since 1998, the CTA has been instrumental in training Defense Criminal Investigative Organizations (DCIOs), Military Department Counterintelligence Organizations, Cyber Mission Forces (CMFs), Cyber Protection Teams (CPTs), Mission Defense Teams (MDTs), and many other entities across the greater DoD enterprise. \"The CTA offers more than 30 unique courses of classroom, online, and Instructor-Led Virtual (ILV) cyber training to both individuals and organizations within the DoD charged with protecting defense information systems from unauthorized use, criminal and fraudulent activities, and foreign intelligence/counterintelligence efforts.\" \u2014CTA\n\n== Technical Solutions Development ==\nTechnical Solutions Development (TSD) tailors innovative software and system solutions engineered to the specific requirements of digital forensic examiners and cyber intrusion analysts. TSD validates digital forensic tools from commercial off-the-shelf, government off-the-shelf, and open-source domains to ensure relevancy and reproducibility as to expected use. In coordination with its cooperative partners, TSD:\n\nLeads the way by proactively identifying, researching and evaluating relevant new technologies, techniques and tools\nActively participates in the development of industry standards, including Structured Threat Information eXpression (STIX) and Cyber-investigation Analysis Standard Expression (CASE)\nShares in-house-developed tools with federal, state, and local law enforcement partners\nMaintains the Counterintelligence Tool Repository (CITR), a warehouse of classified and unclassified tools that support digital forensics and counterintelligence needs.\n\n== DIB Cybersecurity ==\nDoD-Defense Industrial Base Collaborative Information Sharing Environment (DCISE)\u2014DCISE is the operational hub of the Defense Industrial Base (DIB) Cybersecurity Program of the Department of Defense, focused on protecting intellectual property and safeguarding DoD content residing on, or transiting through, contractor unclassified networks. The public-private cybersecurity partnership provides a collaborative environment for crowd-sourced threat sharing at both unclassified and classified levels. DCISE provides cyber resilience analyses for Cleared Defense Contractor (CDC) companies and offers unmatched Cybersecurity-as-a-Service capabilities. DCISE performs cyber threat analysis and diagnostics, offers mitigation and remediation strategies, provides best practices, and conducts analyst-to-analyst exchanges with DIB participants ranging in size from small to enterprise-sized companies.\n\n== Operations Enablement ==\nOperations Enablement Directorate (OED) The mission and principal focus of the OED is to amplify the effects of DoD-wide law enforcement and counterintelligence (LE/CI) investigations and operations, and by extension, the effects of the U.S. Intelligence Community at large. That charge encompasses:\n\nConducting expert technical and all-source analysis (resulting in more than 493 products released in FY21) focused on countering foreign intelligence threats to DoD and the U.S. government as a whole\nIntegrating disparate and emerging technologies to enhance collaboration, interoperability, and the collective capabilities of DoD and Federal LE/CI, cybersecurity, and acquisition communities\nProviding focused oversight and integration with the LE/CI and intelligence communities through liaison officers and embeds with:\nAir Force Life Cycle Management Center (AFLCMC)\nArmy Military Intelligence\nU.S. Cyber Command\nDefense Counterintelligence and Security Agency (DCSA)\nFBI\nNational Cyber Investigative Task Force (NCIJTF)\n\n== Vulnerability Disclosure ==\nThe mission of the DoD VDP is to function as the single focal point for receiving vulnerability reports and interacting with crowd-sourced cybersecurity researchers supporting the DoDIN.1 This improves network defenses and enhances mission assurance by embracing a previously overlooked, yet indispensable, resource: private-sector white hat researchers. In January 2021, the DoD VDP scope was officially expanded from public-facing websites to all publicly accessible information systems throughout the DoD. This broadens the protection for the DoD attack surface and offers a safe harbor for researchers while providing more asset and technology security. The success of the program relies solely on the expertise and support of the security researcher community, and the program's success contributes to the overall security of the DoD.\nAnswer this question: What is the role of the DoD-Defense Industrial Base Collaborative Information Sharing Environment (DCISE) in the DIB Cybersecurity program?",
    "context": "",
    "output": "DCISE is the operational hub of the DIB Cybersecurity Program of the Department of Defense, focused on protecting intellectual property and safeguarding DoD content residing on, or transiting through, contractor unclassified networks. DCISE provides a collaborative environment for crowd-sourced threat sharing at both unclassified and classified levels and offers Cybersecurity-as-a-Service capabilities.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the role of the DoD-Defense Industrial Base Collaborative Information Sharing Environment (DCISE) in the DIB Cybersecurity program?",
      "answer": "DCISE is the operational hub of the DIB Cybersecurity Program of the Department of Defense, focused on protecting intellectual property and safeguarding DoD content residing on, or transiting through, contractor unclassified networks. DCISE provides a collaborative environment for crowd-sourced threat sharing at both unclassified and classified levels and offers Cybersecurity-as-a-Service capabilities.",
      "context": "Department of Defense Cyber Crime Center\n\n==Introduction==\nThe Department of Defense Cyber Crime Center (DC3) is designated as a Federal Cyber Center by National Security Presidential Directive 54/Homeland Security Presidential Directive 23, as a Department of Defense (DoD) Center Of Excellence for Digital and Multimedia (D/MM) forensics by DoD Directive 5505.13E, and serves as the operational focal point for the Defense Industrial Base (DIB) Cybersecurity program. DC3 operates as a Field Operating Agency (FOA) under the Inspector General of the Department of the Air Force.\n\n\n\n== Mission ==\nDeliver superior digital and multimedia forensic services, cyber technical training, vulnerability sharing, technical solutions development, and cyber analysis within the following DoD mission areas: cybersecurity and critical infrastructure protection, law enforcement and counterintelligence, document and media exploitation, and counterterrorism.\n\n== Cyber Forensics Laboratory ==\nThe Cyber Forensics Laboratory performs Digital and Multimedia (D/MM) forensic examinations, repairs damaged devices and extracts otherwise inaccessible data from them, and provides expert testimony in legal proceedings for DC3 customers. The lab's robust intrusion and malware analysis capability supports law enforcement, counterintelligence, and Defense Industrial Base activities and operations. The CFL also works with the Defense Cyber Operations Panel (which consists of Defense Criminal Investigative Organizations and Military Department Counterintelligence Organizations) to develop requirements and set standards for digital investigations as new technologies emerge and evolve. The CFL is an accredited lab under ISO 17025 by the ANSI National Accreditation Board, and its operations are subject to strict quality control and peer review. The CFL produces results which are valid and reliable, based on conditions and methods which are repeatable.\n\nDigital and Multimedia (D/MM) forensic examinations\nDevice Repair\nData Extraction\nExpert Testimony for DC3 Customers\n\n== Cyber Training Academy ==\nThe mission of the DoD Cyber Crime Center \u2013 Cyber Training Academy is to design, develop, and deliver the highest possible quality in cyber training to Department of Defense (DoD) personnel. In operation since 1998, the CTA has been instrumental in training Defense Criminal Investigative Organizations (DCIOs), Military Department Counterintelligence Organizations, Cyber Mission Forces (CMFs), Cyber Protection Teams (CPTs), Mission Defense Teams (MDTs), and many other entities across the greater DoD enterprise. \"The CTA offers more than 30 unique courses of classroom, online, and Instructor-Led Virtual (ILV) cyber training to both individuals and organizations within the DoD charged with protecting defense information systems from unauthorized use, criminal and fraudulent activities, and foreign intelligence/counterintelligence efforts.\" \u2014CTA\n\n== Technical Solutions Development ==\nTechnical Solutions Development (TSD) tailors innovative software and system solutions engineered to the specific requirements of digital forensic examiners and cyber intrusion analysts. TSD validates digital forensic tools from commercial off-the-shelf, government off-the-shelf, and open-source domains to ensure relevancy and reproducibility as to expected use. In coordination with its cooperative partners, TSD:\n\nLeads the way by proactively identifying, researching and evaluating relevant new technologies, techniques and tools\nActively participates in the development of industry standards, including Structured Threat Information eXpression (STIX) and Cyber-investigation Analysis Standard Expression (CASE)\nShares in-house-developed tools with federal, state, and local law enforcement partners\nMaintains the Counterintelligence Tool Repository (CITR), a warehouse of classified and unclassified tools that support digital forensics and counterintelligence needs.\n\n== DIB Cybersecurity ==\nDoD-Defense Industrial Base Collaborative Information Sharing Environment (DCISE)\u2014DCISE is the operational hub of the Defense Industrial Base (DIB) Cybersecurity Program of the Department of Defense, focused on protecting intellectual property and safeguarding DoD content residing on, or transiting through, contractor unclassified networks. The public-private cybersecurity partnership provides a collaborative environment for crowd-sourced threat sharing at both unclassified and classified levels. DCISE provides cyber resilience analyses for Cleared Defense Contractor (CDC) companies and offers unmatched Cybersecurity-as-a-Service capabilities. DCISE performs cyber threat analysis and diagnostics, offers mitigation and remediation strategies, provides best practices, and conducts analyst-to-analyst exchanges with DIB participants ranging in size from small to enterprise-sized companies.\n\n== Operations Enablement ==\nOperations Enablement Directorate (OED) The mission and principal focus of the OED is to amplify the effects of DoD-wide law enforcement and counterintelligence (LE/CI) investigations and operations, and by extension, the effects of the U.S. Intelligence Community at large. That charge encompasses:\n\nConducting expert technical and all-source analysis (resulting in more than 493 products released in FY21) focused on countering foreign intelligence threats to DoD and the U.S. government as a whole\nIntegrating disparate and emerging technologies to enhance collaboration, interoperability, and the collective capabilities of DoD and Federal LE/CI, cybersecurity, and acquisition communities\nProviding focused oversight and integration with the LE/CI and intelligence communities through liaison officers and embeds with:\nAir Force Life Cycle Management Center (AFLCMC)\nArmy Military Intelligence\nU.S. Cyber Command\nDefense Counterintelligence and Security Agency (DCSA)\nFBI\nNational Cyber Investigative Task Force (NCIJTF)\n\n== Vulnerability Disclosure ==\nThe mission of the DoD VDP is to function as the single focal point for receiving vulnerability reports and interacting with crowd-sourced cybersecurity researchers supporting the DoDIN.1 This improves network defenses and enhances mission assurance by embracing a previously overlooked, yet indispensable, resource: private-sector white hat researchers. In January 2021, the DoD VDP scope was officially expanded from public-facing websites to all publicly accessible information systems throughout the DoD. This broadens the protection for the DoD attack surface and offers a safe harbor for researchers while providing more asset and technology security. The success of the program relies solely on the expertise and support of the security researcher community, and the program's success contributes to the overall security of the DoD."
    }
  },
  {
    "instruction": "Write an answer to the following question: What techniques did the ShadowCrew group use to steal credit and ATM card numbers?",
    "context": "",
    "output": "The ShadowCrew group used a variety of techniques to steal credit and ATM card numbers. These methods included SQL injection to deploy backdoors on corporate systems, packet sniffing (specifically, ARP Spoofing) attacks to steal computer data from internal corporate networks, and the use of cryptography in magnetic strips on credit cards, debit cards, and ATM cards.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What techniques did the ShadowCrew group use to steal credit and ATM card numbers?",
      "answer": "The ShadowCrew group used a variety of techniques to steal credit and ATM card numbers. These methods included SQL injection to deploy backdoors on corporate systems, packet sniffing (specifically, ARP Spoofing) attacks to steal computer data from internal corporate networks, and the use of cryptography in magnetic strips on credit cards, debit cards, and ATM cards."
    }
  },
  {
    "instruction": "context: By encrypting connections using a VPN, an attacker would need to perform a TCP reset attack on all encrypted connections. This would result in collateral damage, making it more difficult for the attacker to target specific connections.\n\nAsk a question about this context.",
    "context": "",
    "output": "How can a VPN help prevent TCP reset attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How can a VPN help prevent TCP reset attacks?",
      "answer": "By encrypting connections using a VPN, an attacker would need to perform a TCP reset attack on all encrypted connections. This would result in collateral damage, making it more difficult for the attacker to target specific connections."
    }
  },
  {
    "instruction": "context: AV-TEST's testing process can help prevent cyber attacks by evaluating the software's ability to detect and remove malware, which can help to prevent the spread of malware and protect users from cyber attacks.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does AV-TEST's testing process help to prevent cyber attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does AV-TEST's testing process help to prevent cyber attacks?",
      "answer": "AV-TEST's testing process can help prevent cyber attacks by evaluating the software's ability to detect and remove malware, which can help to prevent the spread of malware and protect users from cyber attacks."
    }
  },
  {
    "instruction": "Cthulhu (developer)\n\n==Introduction==\nThomas White aka  Cthulhu is a British former Tor hidden service developer and administrator.\nActivities involved being consulted on a number of Tor security matters such as dark web scams, law enforcement raids and darknet markets.He has hosted a number of data dumps including those associated with Hacking Team, Ashley Madison, and Patreon.In January 2016 he hosted a release of the files hacked from the Fraternal Order of Police.\n\n\n\n== Arrest & Silk Road 2.0 ==\nIn November 2014, White was arrested as the mastermind behind Silk Road 2. In April 2019, White pleaded guilty to charges including drug trafficking, money laundering, as well as making indecent images of children, and was sentenced to a total of 5 years and 4 months in prison.\n\n== Career (other activities) ==\nHe had claimed to have worked in a security vetted/cleared role at Enhanced Developed Vetting (eDV) level from August 2013 to December 2016 on his LinkedIn profile.\n\nQ: How does Cthulhu's criminal activity relate to the dark web's reputation?",
    "context": "",
    "output": "A: Cthulhu's criminal activities, including his involvement with Silk Road 2.0 and hosting of illegal data dumps, contribute to the dark web's negative reputation as a haven for illegal activities and criminal behavior.",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does Cthulhu's criminal activity relate to the dark web's reputation?",
      "answer": "Cthulhu's criminal activities, including his involvement with Silk Road 2.0 and hosting of illegal data dumps, contribute to the dark web's negative reputation as a haven for illegal activities and criminal behavior.",
      "context": "Cthulhu (developer)\n\n==Introduction==\nThomas White aka  Cthulhu is a British former Tor hidden service developer and administrator.\nActivities involved being consulted on a number of Tor security matters such as dark web scams, law enforcement raids and darknet markets.He has hosted a number of data dumps including those associated with Hacking Team, Ashley Madison, and Patreon.In January 2016 he hosted a release of the files hacked from the Fraternal Order of Police.\n\n\n\n== Arrest & Silk Road 2.0 ==\nIn November 2014, White was arrested as the mastermind behind Silk Road 2. In April 2019, White pleaded guilty to charges including drug trafficking, money laundering, as well as making indecent images of children, and was sentenced to a total of 5 years and 4 months in prison.\n\n== Career (other activities) ==\nHe had claimed to have worked in a security vetted/cleared role at Enhanced Developed Vetting (eDV) level from August 2013 to December 2016 on his LinkedIn profile."
    }
  },
  {
    "instruction": "context: A breach of availability refers to a delay in accessing information, while a breach of utility refers to the uselessness of information, even if it is available.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the difference between a breach of availability and a breach of utility?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the difference between a breach of availability and a breach of utility?",
      "answer": "A breach of availability refers to a delay in accessing information, while a breach of utility refers to the uselessness of information, even if it is available."
    }
  },
  {
    "instruction": "context: At least one computer security expert is in favor of passing a law requiring 100% of all ISPs to implement network ingress filtering as defined in IETF BCP 38.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the opinion of some computer security experts regarding network ingress filtering implementation by ISPs?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the opinion of some computer security experts regarding network ingress filtering implementation by ISPs?",
      "answer": "At least one computer security expert is in favor of passing a law requiring 100% of all ISPs to implement network ingress filtering as defined in IETF BCP 38."
    }
  },
  {
    "instruction": "context: HijackPro is a professional version of HijackThis with the built-in capabilities to kill processes. It was jointly developed by Glenn Bluff and Merijn Bellekom during 2002 and 2003.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is HijackPro and what is its relation to HijackThis?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is HijackPro and what is its relation to HijackThis?",
      "answer": "HijackPro is a professional version of HijackThis with the built-in capabilities to kill processes. It was jointly developed by Glenn Bluff and Merijn Bellekom during 2002 and 2003."
    }
  },
  {
    "instruction": "context: Mutual authentication prevents man-in-the-middle attacks because both the sender and recipient verify each other before sending them their message keys. If one of the parties is not verified to be who they claim they are, the session will end.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does mutual authentication prevent man-in-the-middle attacks?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does mutual authentication prevent man-in-the-middle attacks?",
      "answer": "Mutual authentication prevents man-in-the-middle attacks because both the sender and recipient verify each other before sending them their message keys. If one of the parties is not verified to be who they claim they are, the session will end."
    }
  },
  {
    "instruction": "context: The marriage agency scam involves the scammer pretending to be a translation agency or marriage agency and fabricating emails and creating fake profiles on dating sites. The scammer may use a variety of tactics to deceive the victim, such as using pictures of real people from other websites and impersonating the brides instead of providing a matchmaking service to them.\n\nAsk a question about this context.",
    "context": "",
    "output": "How does the marriage agency scam work, and what tactics does it use to deceive the victim?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "How does the marriage agency scam work, and what tactics does it use to deceive the victim?",
      "answer": "The marriage agency scam involves the scammer pretending to be a translation agency or marriage agency and fabricating emails and creating fake profiles on dating sites. The scammer may use a variety of tactics to deceive the victim, such as using pictures of real people from other websites and impersonating the brides instead of providing a matchmaking service to them."
    }
  },
  {
    "instruction": "context: The four-way handshake is designed to allow the access point (or authenticator) and wireless client (or supplicant) to independently prove to each other that they know the PSK/PMK, without ever disclosing the key. Instead, they encrypt messages to each other using the PMK, and if decryption of the messages is successful, this proves knowledge of the PMK.\n\nAsk a question about this context.",
    "context": "",
    "output": "What is the purpose of the four-way handshake in 802.11i?",
    "category": "WikiQAFlan",
    "instruction_type": "retrieval1",
    "parsed_raw_data": {
      "question": "What is the purpose of the four-way handshake in 802.11i?",
      "answer": "The four-way handshake is designed to allow the access point (or authenticator) and wireless client (or supplicant) to independently prove to each other that they know the PSK/PMK, without ever disclosing the key. Instead, they encrypt messages to each other using the PMK, and if decryption of the messages is successful, this proves knowledge of the PMK."
    }
  }
]